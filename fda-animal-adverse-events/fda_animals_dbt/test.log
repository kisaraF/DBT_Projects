diff --git a/dbt_dbx_guided/dbt_dbx/dbt_project.yml b/dbt_dbx_guided/dbt_dbx/dbt_project.yml
index ad03132..9c2b2b6 100644
--- a/dbt_dbx_guided/dbt_dbx/dbt_project.yml
+++ b/dbt_dbx_guided/dbt_dbx/dbt_project.yml
@@ -22,6 +22,9 @@ clean-targets:         # directories to be removed by `dbt clean`
   - "target"
   - "dbt_packages"
 
+# DBT Artficats package hook
+on-run-end:
+  - "{% if target.name == 'dev' %}{{ dbt_artifacts.upload_results(results) }}{% endif %}"
 
 # Configuring models
 # Full documentation: https://docs.getdbt.com/docs/configuring-models
diff --git a/dbt_dbx_guided/dbt_dbx/target/manifest.json b/dbt_dbx_guided/dbt_dbx/target/manifest.json
index fc7be7f..af556d6 100644
--- a/dbt_dbx_guided/dbt_dbx/target/manifest.json
+++ b/dbt_dbx_guided/dbt_dbx/target/manifest.json
@@ -1 +1 @@
-{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/manifest/v12.json", "dbt_version": "1.10.13", "generated_at": "2025-09-29T10:26:41.466628Z", "invocation_id": "9040d5b5-c9a4-4a73-81cc-771089bde328", "invocation_started_at": "2025-09-29T10:26:39.489941Z", "env": {}, "project_name": "dbt_dbx", "project_id": "0d3e7ae267c3d80e5b0e9b0a8e99ced4", "user_id": "3fa4e79b-5437-49c7-b9ce-cc65b236cf59", "send_anonymous_usage_stats": true, "adapter_type": "databricks", "quoting": {"database": true, "schema": true, "identifier": true, "column": null}}, "nodes": {"model.dbt_dbx.silver_orders": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_orders", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_orders.sql", "original_file_path": "models/silver/silver_orders.sql", "unique_id": "model.dbt_dbx.silver_orders", "fqn": ["dbt_dbx", "silver", "silver_orders"], "alias": "silver_orders", "checksum": {"name": "sha256", "checksum": "ac34d7aa6482f47d9b19f60f9f3536d8eeb7fafc697dd467a648facbd8183807"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_orders.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1759141602.6369267, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_orders`", "raw_code": "select\n    id,\n    date(created_at) as order_date,\n    user_id,\n    product_id\n    quantity,\n    unit_price,\n    quantity * unit_price as order_amount\nfrom {{ ref('bronze_orders') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_orders", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_orders"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_orders.sql", "compiled": true, "compiled_code": "select\n    id,\n    date(created_at) as order_date,\n    user_id,\n    product_id\n    quantity,\n    unit_price,\n    quantity * unit_price as order_amount\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_orders`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.silver_products": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_products", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_products.sql", "original_file_path": "models/silver/silver_products.sql", "unique_id": "model.dbt_dbx.silver_products", "fqn": ["dbt_dbx", "silver", "silver_products"], "alias": "silver_products", "checksum": {"name": "sha256", "checksum": "e67de830b944747fdbea721729d0cdaf232694cc89dbb08cc339b339d347b759"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_products.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1759141602.6640584, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_products`", "raw_code": "select\n    id,\n    created_at,\n    title as product_name,\n    category,\n    ean,\n    vendor,\n    price\nfrom {{ ref('bronze_products') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_products", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_products"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_products.sql", "compiled": true, "compiled_code": "select\n    id,\n    created_at,\n    title as product_name,\n    category,\n    ean,\n    vendor,\n    price\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_products`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.silver_users": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_users", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_users.sql", "original_file_path": "models/silver/silver_users.sql", "unique_id": "model.dbt_dbx.silver_users", "fqn": ["dbt_dbx", "silver", "silver_users"], "alias": "silver_users", "checksum": {"name": "sha256", "checksum": "34396beb97d2d52a1c634b1dd5ac954c2392a1f37ba48a596d5d6c9137dc59b7"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_users.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1759141602.6660342, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_users`", "raw_code": "select\n    id,\n    created_at,\n    city,\n    state,\n    year(birth_date) as birth_year,\n    source as sales_channel\nfrom {{ ref('bronze_users') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_users", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_users"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_users.sql", "compiled": true, "compiled_code": "select\n    id,\n    created_at,\n    city,\n    state,\n    year(birth_date) as birth_year,\n    source as sales_channel\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_users`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_reviews": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_reviews", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_reviews.sql", "original_file_path": "models/bronze/bronze_reviews.sql", "unique_id": "model.dbt_dbx.bronze_reviews", "fqn": ["dbt_dbx", "bronze", "bronze_reviews"], "alias": "bronze_reviews", "checksum": {"name": "sha256", "checksum": "684b27d5196aee450cec81eb584d9fefaff2a073342eff92131d84bc950ce086"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1759141602.667885, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_reviews`", "raw_code": "select *\nfrom {{ source('landing_s', 'reviews') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "reviews"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.reviews"]}, "compiled_path": null, "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_orders": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_orders", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_orders.sql", "original_file_path": "models/bronze/bronze_orders.sql", "unique_id": "model.dbt_dbx.bronze_orders", "fqn": ["dbt_dbx", "bronze", "bronze_orders"], "alias": "bronze_orders", "checksum": {"name": "sha256", "checksum": "7a5182df216c04629f2c75fc418f18bbf1b3eeecd28db5bd52e78ca364fe8491"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1759141602.6696403, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_orders`", "raw_code": "select *\nfrom {{ source('landing_s', 'orders') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "orders"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.orders"]}, "compiled_path": null, "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_users": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_users", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_users.sql", "original_file_path": "models/bronze/bronze_users.sql", "unique_id": "model.dbt_dbx.bronze_users", "fqn": ["dbt_dbx", "bronze", "bronze_users"], "alias": "bronze_users", "checksum": {"name": "sha256", "checksum": "f7b4283d3247d927f9f21a526e7bc79a3f414314e6562cf1dae7d5ba3aabc916"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1759141602.671366, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_users`", "raw_code": "select *\nfrom {{ source('landing_s', 'users') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "users"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.users"]}, "compiled_path": null, "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_products": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_products", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_products.sql", "original_file_path": "models/bronze/bronze_products.sql", "unique_id": "model.dbt_dbx.bronze_products", "fqn": ["dbt_dbx", "bronze", "bronze_products"], "alias": "bronze_products", "checksum": {"name": "sha256", "checksum": "8b27fb6c3fab7a376bc8595371164f69a2072cc9e29d119f67b4b6dc0345bb8a"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1759141602.6731813, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_products`", "raw_code": "select *\nfrom {{ source('landing_s', 'products') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "products"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.products"]}, "compiled_path": null, "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}}, "sources": {"source.dbt_dbx.landing_s.orders": {"database": "dbt_project_catalog", "schema": "landing", "name": "orders", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.orders", "fqn": ["dbt_dbx", "landing_s", "orders"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "orders", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`orders`", "created_at": 1759141602.7713132, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.users": {"database": "dbt_project_catalog", "schema": "landing", "name": "users", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.users", "fqn": ["dbt_dbx", "landing_s", "users"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "users", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`users`", "created_at": 1759141602.7727537, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.products": {"database": "dbt_project_catalog", "schema": "landing", "name": "products", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.products", "fqn": ["dbt_dbx", "landing_s", "products"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "products", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`products`", "created_at": 1759141602.773153, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.reviews": {"database": "dbt_project_catalog", "schema": "landing", "name": "reviews", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.reviews", "fqn": ["dbt_dbx", "landing_s", "reviews"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "reviews", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`reviews`", "created_at": 1759141602.7734904, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}}, "macros": {"macro.dbt_databricks.databricks__comment_clause": {"name": "databricks__comment_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/comment.sql", "original_file_path": "macros/relations/comment.sql", "unique_id": "macro.dbt_databricks.databricks__comment_clause", "macro_sql": "{% macro databricks__comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation and model.description -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {%- endif -%}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5416093, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_intermediate_sql": {"name": "databricks__get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_intermediate_sql", "macro_sql": "{%- macro databricks__get_create_intermediate_sql(relation, sql) -%}\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    -- drop any pre-existing intermediate\n    {{ drop_relation(intermediate_relation) }}\n\n    {{ return(get_create_sql(intermediate_relation, sql)) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.drop_relation", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5420985, "supported_languages": null}, "macro.dbt_databricks.location_clause": {"name": "location_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/location.sql", "original_file_path": "macros/relations/location.sql", "unique_id": "macro.dbt_databricks.location_clause", "macro_sql": "{% macro location_clause(relation) %}\n  {#--\n    Moving forward, `relation` should be a `CatalogRelation`, which is covered by the first condition.\n    However, there could be existing macros that are still passing in a `BaseRelation`, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  --#}\n  {%- if relation.catalog_type is not none -%}\n\n    {%- if relation.location is not none -%}\n    location '{{ relation.location }}{% if is_incremental() %}_tmp{% endif %}'\n    {%- endif -%}\n\n  {%- else -%}\n\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n  {%- set model_path = adapter.compute_external_path(config, model, is_incremental()) %}\n    location '{{ model_path }}'\n  {%- elif (not relation.is_hive_metastore()) and file_format != 'delta' -%}\n    {{ exceptions.raise_compiler_error(\n        'Incompatible configuration: `location_root` must be set when using a non-delta file format with Unity Catalog'\n    ) }}\n  {%- endif %}\n\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5435479, "supported_languages": null}, "macro.dbt_databricks.create_backup": {"name": "create_backup", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt_databricks.create_backup", "macro_sql": "{%- macro create_backup(relation) -%}\n  -- get the standard backup name\n  {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n  -- drop any pre-existing backup\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ adapter.rename_relation(relation, backup_relation) }}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5440538, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_sql": {"name": "databricks__get_create_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_sql", "macro_sql": "{%- macro databricks__get_create_sql(relation, sql) -%}\n    {%- if relation.is_view -%}\n        {{ get_create_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_create_table_as_sql(False, relation, sql) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_create_materialized_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_streaming_table -%}\n        {{ get_create_streaming_table_as_sql(relation, sql) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_create_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.get_create_view_as_sql", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt_databricks.get_create_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5448506, "supported_languages": null}, "macro.dbt_databricks.file_format_clause": {"name": "file_format_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/file_format.sql", "original_file_path": "macros/relations/file_format.sql", "unique_id": "macro.dbt_databricks.file_format_clause", "macro_sql": "{% macro file_format_clause(catalog_relation=none) %}\n  {#--\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  --#}\n  {% if catalog_relation is not none %}\n    {%- set file_format = catalog_relation.file_format -%}\n  {% else %}\n    {%- set file_format = config.get('file_format', default='delta') -%}\n  {% endif %}\n  using {{ file_format }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5454764, "supported_languages": null}, "macro.dbt_databricks.get_file_format": {"name": "get_file_format", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/file_format.sql", "original_file_path": "macros/relations/file_format.sql", "unique_id": "macro.dbt_databricks.get_file_format", "macro_sql": "{% macro get_file_format(catalog_relation=none) %}\n  {#-\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  -#}\n  {% if catalog_relation is not none %}\n    {%- set raw_file_format = catalog_relation.file_format -%}\n  {% else %}\n    {%- set raw_file_format = config.get('file_format', default='delta') -%}\n  {% endif %}\n  {% do return(dbt_databricks_validate_get_file_format(raw_file_format)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_validate_get_file_format"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5459454, "supported_languages": null}, "macro.dbt_databricks.optimize": {"name": "optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.optimize", "macro_sql": "{% macro optimize(relation) %}\n  {{ return(adapter.dispatch('optimize', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5466623, "supported_languages": null}, "macro.dbt_databricks.databricks__optimize": {"name": "databricks__optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.databricks__optimize", "macro_sql": "\n\n{%- macro databricks__optimize(relation) -%}\n  {%- if var('DATABRICKS_SKIP_OPTIMIZE', 'false')|lower != 'true' and\n        var('databricks_skip_optimize', 'false')|lower != 'true' and\n        config.get('file_format', 'delta') == 'delta' -%}\n    {%- if (config.get('zorder', False) or config.get('liquid_clustered_by', False)) or config.get('auto_liquid_cluster', False) -%}\n      {%- call statement('run_optimize_stmt') -%}\n        {{ get_optimize_sql(relation) }}\n      {%- endcall -%}\n    {%- endif -%}\n  {%- endif -%}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_optimize_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5475018, "supported_languages": null}, "macro.dbt_databricks.get_optimize_sql": {"name": "get_optimize_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.get_optimize_sql", "macro_sql": "{%- macro get_optimize_sql(relation) %}\n  optimize {{ relation.render() }}\n  {%- if config.get('zorder', False) and config.get('file_format', 'delta') == 'delta' %}\n    {%- if config.get('liquid_clustered_by', False) or config.get('auto_liquid_cluster', False) %}\n      {{ exceptions.warn(\"Both zorder and liquid_clustering are set but they are incompatible. zorder will be ignored.\") }}\n    {%- else %}\n      {%- set zorder = config.get('zorder', none) %}\n      {# TODO: predicates here? WHERE ...  #}\n      {%- if zorder is sequence and zorder is not string %}\n        zorder by (\n        {%- for col in zorder %}\n        {{ col }}{% if not loop.last %}, {% endif %}\n        {%- endfor %}\n        )\n      {%- else %}\n        zorder by ({{zorder}})\n      {%- endif %}\n    {%- endif %}\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5486286, "supported_languages": null}, "macro.dbt_databricks.execute_no_op": {"name": "execute_no_op", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/execute.sql", "original_file_path": "macros/relations/execute.sql", "unique_id": "macro.dbt_databricks.execute_no_op", "macro_sql": "{% macro execute_no_op(target_relation) %}\n    {% do store_raw_result(\n        name=\"main\",\n        message=\"skip \" ~ target_relation,\n        code=\"skip\",\n        rows_affected=\"-1\"\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5490117, "supported_languages": null}, "macro.dbt_databricks.get_replace_sql": {"name": "get_replace_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.get_replace_sql", "macro_sql": "{% macro get_replace_sql(existing_relation, target_relation, sql) %}\n  {{- log('Applying REPLACE to: ' ~ existing_relation) -}}\n  {% do return(adapter.dispatch('get_replace_sql', 'dbt')(existing_relation, target_relation, sql)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5498621, "supported_languages": null}, "macro.dbt_databricks.databricks__get_replace_sql": {"name": "databricks__get_replace_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.databricks__get_replace_sql", "macro_sql": "{% macro databricks__get_replace_sql(existing_relation, target_relation, sql) %}\n  {# /* if safe_relation_replace, prefer renaming */ #}\n  {% if target_relation.type == \"table\" %}\n    {{ exceptions.raise_not_implemented('get_replace_sql not implemented for target of table') }}\n  {% endif %}\n\n  {% set safe_replace = config.get('use_safer_relation_operations', False) | as_bool  %}\n  {% set file_format = config.get('file_format', default='delta') %}\n  {% set is_replaceable = existing_relation.type == target_relation.type and existing_relation.can_be_replaced and file_format == \"delta\" %}\n\n  {% if not safe_replace %}\n    {# Prioritize 'create or replace' for speed #}\n    {% if is_replaceable and existing_relation.is_view %}\n      {{ return(get_replace_view_sql(target_relation, sql)) }}\n    {% elif is_replaceable and existing_relation.is_table %}\n      {{ return(get_replace_table_sql(target_relation, sql)) }}\n    {% endif %}\n  {% endif %}\n\n  {# If safe_replace, then we know that anything that would have been caught above is instead caught here #}\n  {% if target_relation.can_be_renamed and existing_relation.can_be_renamed %}\n    {{ return(safely_replace(existing_relation, target_relation, sql)) }}\n  {% elif target_relation.can_be_renamed %}\n    {{ return(stage_then_replace(existing_relation, target_relation, sql)) }}\n  {% elif existing_relation.can_be_renamed %}\n    {{ return(backup_and_create_in_place(existing_relation, target_relation, sql)) }}\n  {% else %}\n    {{ return(drop_and_create(existing_relation, target_relation, sql)) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_replace_view_sql", "macro.dbt.get_replace_table_sql", "macro.dbt_databricks.safely_replace", "macro.dbt_databricks.stage_then_replace", "macro.dbt_databricks.backup_and_create_in_place", "macro.dbt_databricks.drop_and_create"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.551373, "supported_languages": null}, "macro.dbt_databricks.safely_replace": {"name": "safely_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.safely_replace", "macro_sql": "{% macro safely_replace(existing_relation, target_relation, sql) %}\n  {{ log('Using safely_replace') }}\n  {% set staging_relation = make_staging_relation(target_relation, type='view') %}\n  {{ drop_relation_if_exists(staging_relation) }}\n  {% call statement(name=\"main\") %}\n    {{ get_create_sql(staging_relation, sql) }}\n  {% endcall %}\n  {{ create_backup(existing_relation) }}\n  {{ return([\n    get_rename_sql(staging_relation, existing_relation.render()),\n    get_drop_backup_sql(existing_relation)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.make_staging_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt_databricks.create_backup", "macro.dbt.get_rename_sql", "macro.dbt.get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5522268, "supported_languages": null}, "macro.dbt_databricks.stage_then_replace": {"name": "stage_then_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.stage_then_replace", "macro_sql": "{% macro stage_then_replace(existing_relation, target_relation, sql) %}\n  {{ log('Using stage_then_replace') }}\n  {% set staging_relation = make_staging_relation(target_relation, type='view') %}\n  {{ drop_relation_if_exists(staging_relation) }}\n  {% call statement(name=\"main\") %}\n    {{ get_create_sql(staging_relation, sql) }}\n  {% endcall %}\n\n  {{ return([\n    get_drop_sql(existing_relation),\n    get_rename_sql(staging_relation, existing_relation.render()),\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.make_staging_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt.get_drop_sql", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5530045, "supported_languages": null}, "macro.dbt_databricks.backup_and_create_in_place": {"name": "backup_and_create_in_place", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.backup_and_create_in_place", "macro_sql": "{% macro backup_and_create_in_place(existing_relation, target_relation, sql) %}\n  {{ log('Using backup_and_create_in_place') }}\n  {{ create_backup(existing_relation) }}\n  {{ return([\n    get_create_sql(target_relation, sql),\n    get_drop_backup_sql(existing_relation)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_backup", "macro.dbt.get_create_sql", "macro.dbt.get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5533435, "supported_languages": null}, "macro.dbt_databricks.drop_and_create": {"name": "drop_and_create", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.drop_and_create", "macro_sql": "{% macro drop_and_create(existing_relation, target_relation, sql) %}\n  {{ log('Using drop_and_create') }}\n  {{ return([\n    get_drop_sql(existing_relation),\n    get_create_sql(target_relation, sql)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.553625, "supported_languages": null}, "macro.dbt_databricks.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5562108, "supported_languages": null}, "macro.dbt_databricks.databricks__persist_constraints": {"name": "databricks__persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__persist_constraints", "macro_sql": "{% macro databricks__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% set has_model_contract = contract_config and contract_config.enforced %}\n  {% set has_databricks_constraints = config.get('persist_constraints', False) %}\n\n  {% if (has_model_contract or has_databricks_constraints) %}\n    {% if config.get('file_format', 'delta') != 'delta' %}\n      {# Constraints are only supported for delta tables #}\n      {{ exceptions.warn(\"Constraints not supported for file format: \" ~ config.get('file_format')) }}\n    {% elif relation.is_view %}\n      {# Constraints are not supported for views. This point in the code should not have been reached. #}\n      {{ exceptions.raise_compiler_error(\"Constraints not supported for views.\") }}\n    {% elif is_incremental() %}\n      {# Constraints are not applied for incremental updates. This point in the code should not have been reached #}\n      {{ exceptions.raise_compiler_error(\"Constraints are not applied for incremental updates. Full refresh is required to update constraints.\") }}\n    {% else %}\n      {% do alter_column_set_constraints(relation, model) %}\n      {% do alter_table_add_constraints(relation, model) %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_databricks.alter_column_set_constraints", "macro.dbt_databricks.alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5572329, "supported_languages": null}, "macro.dbt_databricks.apply_alter_constraints": {"name": "apply_alter_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.apply_alter_constraints", "macro_sql": "{% macro apply_alter_constraints(relation) %}\n  {%- for constraint in relation.alter_constraints -%}\n    {% call statement('add constraint') %}\n      ALTER TABLE {{ relation.render() }} ADD {{ constraint.render() }}\n    {% endcall %}\n  {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5575662, "supported_languages": null}, "macro.dbt_databricks.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5578008, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_table_add_constraints": {"name": "databricks__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__alter_table_add_constraints", "macro_sql": "{% macro databricks__alter_table_add_constraints(relation, model) %}\n    {% set constraints = get_model_constraints(model) %}\n    {% set statements = get_constraints_sql(relation, constraints, model) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_model_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5582526, "supported_languages": null}, "macro.dbt_databricks.get_model_constraints": {"name": "get_model_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_model_constraints", "macro_sql": "{% macro get_model_constraints(model) %}\n  {% set constraints = model.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and model.get('meta', {}).get('constraints') is sequence %}\n    {# Databricks constraints implementation.  Constraints are in the meta property. #}\n    {% set db_constraints = model.get('meta', {}).get('constraints', []) %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5588844, "supported_languages": null}, "macro.dbt_databricks.get_column_constraints": {"name": "get_column_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_column_constraints", "macro_sql": "{% macro get_column_constraints(column) %}\n  {% set constraints = column.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and column.get('meta', {}).get('constraint') %}\n    {# Databricks constraints implementation.  Constraint is in the meta property. #}\n    {% set db_constraints = [column.get('meta', {}).get('constraint')] %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints, column) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5595043, "supported_languages": null}, "macro.dbt_databricks.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5597482, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_set_constraints": {"name": "databricks__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_set_constraints", "macro_sql": "{% macro databricks__alter_column_set_constraints(relation, model) %}\n  {% set column_dict = model.columns %}\n  {% for column_name in column_dict %}\n    {% set column = column_dict[column_name] %}\n    {% set constraints = get_column_constraints(column)  %}\n    {% set statements = get_constraints_sql(relation, constraints, model, column) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_column_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5604718, "supported_languages": null}, "macro.dbt_databricks.get_constraints_sql": {"name": "get_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_constraints_sql", "macro_sql": "{% macro get_constraints_sql(relation, constraints, model, column={}) %}\n  {% set statements = [] %}\n  -- Hack so that not null constraints will be applied before other constraints\n  {% for constraint in constraints|selectattr('type', 'eq', 'not_null') %}\n    {% if constraint %}\n      {% set constraint_statements = get_constraint_sql(relation, constraint, model, column) %}\n      {% for statement in constraint_statements %}\n        {% if statement %}\n          {% do statements.append(statement) %}\n        {% endif %}\n      {% endfor %}\n    {% endif %}\n  {% endfor %}\n  {% for constraint in constraints|rejectattr('type', 'eq', 'not_null') %}\n    {% if constraint %}\n      {% set constraint_statements = get_constraint_sql(relation, constraint, model, column) %}\n      {% for statement in constraint_statements %}\n        {% if statement %}\n          {% do statements.append(statement) %}\n        {% endif %}\n      {% endfor %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_constraint_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.561667, "supported_languages": null}, "macro.dbt_databricks.get_constraint_sql": {"name": "get_constraint_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_constraint_sql", "macro_sql": "{% macro get_constraint_sql(relation, constraint, model, column={}) %}\n  {% set statements = [] %}\n  {% set type = constraint.get('type', '') %}\n\n  {% if type == 'check' %}\n    {% set expression = constraint.get('expression', '') %}\n    {% if not expression %}\n      {{ exceptions.raise_compiler_error('Invalid check constraint expression') }}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5 (relation.identifier ~ \";\" ~ column.get('name', '') ~ \";\" ~ expression ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" check (\" ~ expression ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'not_null' %}\n    {% set column_names = constraint.get('columns', []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if column %}\n        {% set quoted_name = api.Column.get_name(column) %}\n        {% set stmt = \"alter table \" ~ relation.render() ~ \" change column \" ~ quoted_name ~ \" set not null \" ~ (constraint.expression or \"\") ~ \";\" %}\n        {% do statements.append(stmt) %}\n      {% else %}\n        {{ exceptions.warn('not_null constraint on invalid column: ' ~ column_name) }}\n      {% endif %}\n    {% endfor %}\n  {% elif type == 'primary_key' %}\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ type)}}\n    {% endif %}\n    {% set column_names = constraint.get('columns', []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% set quoted_names = [] %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if not column %}\n        {{ exceptions.warn('Invalid primary key column: ' ~ column_name) }}\n      {% else %}\n        {% set quoted_name = api.Column.get_name(column) %}\n        {% do quoted_names.append(quoted_name) %}\n      {% endif %}\n    {% endfor %}\n\n    {% set joined_names = quoted_names|join(\", \") %}\n\n    {% set name = constraint.get('name') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5(\"primary_key;\" ~ relation.identifier ~ \";\" ~ column_names ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" primary key(\" ~ joined_names ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'foreign_key' %}\n\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ constraint.type)}}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    \n    {% if constraint.get('expression') %}\n\n      {% if not name %}\n        {% if local_md5 %}\n          {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n          {%- set name = local_md5(\"foreign_key;\" ~ relation.identifier ~ \";\" ~ constraint.get('expression') ~ \";\") -%}\n        {% else %}\n          {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n        {% endif %}    \n      {% endif %}\n\n      {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" foreign key\" ~ constraint.get('expression') %}\n    {% else %}\n      {% set column_names = constraint.get('columns', []) %}\n      {% if column and not column_names %}\n        {% set column_names = [column['name']] %}\n      {% endif %}\n      {% set quoted_names = [] %}\n      {% for column_name in column_names %}\n        {% set column = model.get('columns', {}).get(column_name) %}\n        {% if not column %}\n          {{ exceptions.warn('Invalid foreign key column: ' ~ column_name) }}\n        {% else %}\n          {% set quoted_name = api.Column.get_name(column) %}\n          {% do quoted_names.append(quoted_name) %}\n        {% endif %}\n      {% endfor %}\n\n      {% set joined_names = quoted_names|join(\", \") %}\n\n      {% set parent = constraint.get('to') %}\n      {% if not parent %}\n        {{ exceptions.raise_compiler_error('No parent table defined for foreign key: ' ~ expression) }}\n      {% endif %}\n      {% if not \".\" in parent %}\n        {% set parent = relation.schema ~ \".\" ~ parent%}\n      {% endif %}\n\n      {% if not name %}\n        {% if local_md5 %}\n          {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n          {%- set name = local_md5(\"foreign_key;\" ~ relation.identifier ~ \";\" ~ column_names ~ \";\" ~ parent ~ \";\") -%}\n        {% else %}\n          {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n        {% endif %}    \n      {% endif %}\n\n      {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" foreign key(\" ~ joined_names ~ \") references \" ~ parent %}\n      {% set parent_columns = constraint.get('to_columns') %}\n      {% if parent_columns %}\n        {% set stmt = stmt ~ \"(\" ~ parent_columns|join(\", \") ~ \")\"%}\n      {% endif %}\n    {% endif %}\n    {% set stmt = stmt ~ \";\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'custom' %}\n    {% set expression = constraint.get('expression', '') %}\n    {% if not expression %}\n      {{ exceptions.raise_compiler_error('Missing custom constraint expression') }}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    {% set expression = constraint.get('expression') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5 (relation.identifier ~ \";\" ~ expression ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" \" ~ expression ~ \";\" %}\n    {% do statements.append(stmt) %}\n  {% elif constraint.get('warn_unsupported') %}\n    {{ exceptions.warn(\"unsupported constraint type: \" ~ constraint.type)}}\n  {% endif %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5702696, "supported_languages": null}, "macro.dbt_databricks.databricks_constraints_to_dbt": {"name": "databricks_constraints_to_dbt", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks_constraints_to_dbt", "macro_sql": "{% macro databricks_constraints_to_dbt(constraints, column) %}\n  {# convert constraints defined using the original databricks format #}\n  {% set dbt_constraints = [] %}\n  {% for constraint in constraints %}\n    {% if constraint.get and constraint.get('type') %}\n      {# already in model contract format #}\n      {% do dbt_constraints.append(constraint) %}\n    {% else %}\n      {% if column %}\n        {% if constraint == \"not_null\" %}\n          {% do dbt_constraints.append({\"type\": \"not_null\", \"columns\": [column.get('name')]}) %}\n        {% else %}\n          {{ exceptions.raise_compiler_error('Invalid constraint for column ' ~ column.get('name', \"\") ~ '. Only `not_null` is supported.') }}\n        {% endif %}\n      {% else %}\n        {% set name = constraint['name'] %}\n        {% if not name %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint name') }}\n        {% endif %}\n        {% set condition = constraint['condition'] %}\n        {% if not condition %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint condition') }}\n        {% endif %}\n        {% do dbt_constraints.append({\"name\": name, \"type\": \"check\", \"expression\": condition}) %}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(dbt_constraints) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.571887, "supported_languages": null}, "macro.dbt_databricks.databricks__get_drop_sql": {"name": "databricks__get_drop_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt_databricks.databricks__get_drop_sql", "macro_sql": "{% macro databricks__get_drop_sql(relation) -%}\n    {%- if relation.is_materialized_view -%}\n        {{ drop_materialized_view(relation) }}\n    {%- elif relation.is_streaming_table-%}\n        {{ drop_streaming_table(relation) }}\n    {%- elif relation.is_view -%}\n        {{ drop_view(relation) }}\n    {%- else -%}\n        {{ drop_table(relation) }}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.drop_materialized_view", "macro.dbt_databricks.drop_streaming_table", "macro.dbt.drop_view", "macro.dbt.drop_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5725024, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_relation": {"name": "databricks__drop_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_relation", "macro_sql": "{% macro databricks__drop_relation(relation) -%}\n    {% call statement('drop_relation', auto_begin=False) -%}\n        {{ get_drop_sql(relation) }}\n    {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.572741, "supported_languages": null}, "macro.dbt_databricks.tblproperties_clause": {"name": "tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.tblproperties_clause", "macro_sql": "{% macro tblproperties_clause() -%}\n  {{ return(adapter.dispatch('tblproperties_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5731294, "supported_languages": null}, "macro.dbt_databricks.databricks__tblproperties_clause": {"name": "databricks__tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.databricks__tblproperties_clause", "macro_sql": "{% macro databricks__tblproperties_clause(tblproperties=None) -%}\n  {%- set tblproperties = adapter.update_tblproperties_for_iceberg(config, tblproperties) -%}\n  {%- if tblproperties != {} %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5735912, "supported_languages": null}, "macro.dbt_databricks.apply_tblproperties": {"name": "apply_tblproperties", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.apply_tblproperties", "macro_sql": "{% macro apply_tblproperties(relation, tblproperties) -%}\n  {% set tblproperty_statment = databricks__tblproperties_clause(tblproperties) %}\n  {% if tblproperty_statment %}\n    {%- call statement('main') -%}\n      ALTER {{ relation.type }} {{ relation.render() }} SET {{ tblproperty_statment}}\n    {%- endcall -%}\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5739663, "supported_languages": null}, "macro.dbt_databricks.liquid_clustered_cols": {"name": "liquid_clustered_cols", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/liquid_clustering.sql", "original_file_path": "macros/relations/liquid_clustering.sql", "unique_id": "macro.dbt_databricks.liquid_clustered_cols", "macro_sql": "{% macro liquid_clustered_cols() -%}\n  {%- set cols = config.get('liquid_clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set auto_cluster = config.get('auto_liquid_cluster', validator=validation.any[boolean]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    CLUSTER BY ({{ cols | join(', ') }})\n    {%- elif auto_cluster -%}\n    CLUSTER BY AUTO\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.574843, "supported_languages": null}, "macro.dbt_databricks.apply_liquid_clustered_cols": {"name": "apply_liquid_clustered_cols", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/liquid_clustering.sql", "original_file_path": "macros/relations/liquid_clustering.sql", "unique_id": "macro.dbt_databricks.apply_liquid_clustered_cols", "macro_sql": "{% macro apply_liquid_clustered_cols(target_relation, liquid_clustering) -%}\n  {%- set cols = liquid_clustering.cluster_by -%}\n  {%- set auto_cluster = liquid_clustering.auto_cluster -%}\n  {%- if cols and cols != [] %}\n    {%- call statement('set_cluster_by_columns') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY ({{ cols | join(', ') }})\n    {%- endcall -%}\n  {%- elif auto_cluster -%}\n    {%- call statement('set_cluster_by_auto') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY AUTO\n    {%- endcall -%}\n  {% else %}\n    {%- call statement('unset_cluster_by') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY NONE\n    {%- endcall -%}\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5756736, "supported_languages": null}, "macro.dbt_databricks.fetch_tags": {"name": "fetch_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.fetch_tags", "macro_sql": "{% macro fetch_tags(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {% call statement('list_tags', fetch_result=True) -%}\n    {{ fetch_tags_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_tags').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_tags_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5764153, "supported_languages": null}, "macro.dbt_databricks.fetch_tags_sql": {"name": "fetch_tags_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.fetch_tags_sql", "macro_sql": "{% macro fetch_tags_sql(relation) -%}\n  SELECT tag_name, tag_value\n  FROM `system`.`information_schema`.`table_tags`\n  WHERE catalog_name = '{{ relation.database|lower }}' \n    AND schema_name = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5766451, "supported_languages": null}, "macro.dbt_databricks.apply_tags": {"name": "apply_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.apply_tags", "macro_sql": "{% macro apply_tags(relation, set_tags) -%}\n  {{ log(\"Applying tags to relation \" ~ set_tags) }}\n  {%- if set_tags and relation.is_hive_metastore() -%}\n    {{ exceptions.raise_compiler_error(\"Tags are only supported for Unity Catalog\") }}\n  {%- endif -%}\n  {%- if set_tags %}\n    {%- call statement('main') -%}\n       {{ alter_set_tags(relation, set_tags) }}\n    {%- endcall -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_set_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5770867, "supported_languages": null}, "macro.dbt_databricks.alter_set_tags": {"name": "alter_set_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.alter_set_tags", "macro_sql": "{% macro alter_set_tags(relation, tags) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} SET TAGS (\n    {% for tag in tags -%}\n      '{{ tag }}' = '{{ tags[tag] }}' {%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  )\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5774567, "supported_languages": null}, "macro.dbt_databricks.get_configuration_changes": {"name": "get_configuration_changes", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/config.sql", "original_file_path": "macros/relations/config.sql", "unique_id": "macro.dbt_databricks.get_configuration_changes", "macro_sql": "{%- macro get_configuration_changes(existing_relation) -%}\n    {%- set existing_config = adapter.get_relation_config(existing_relation) -%}\n    {%- set model_config = adapter.get_config_from_model(config.model) -%}\n    {%- set configuration_changes = model_config.get_changeset(existing_config) -%}\n    {% do return(configuration_changes) %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5778704, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_partition_by": {"name": "get_create_sql_partition_by", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/partitioning.sql", "original_file_path": "macros/relations/components/partitioning.sql", "unique_id": "macro.dbt_databricks.get_create_sql_partition_by", "macro_sql": "{% macro get_create_sql_partition_by(partition_by) -%}\n{%- if partition_by -%}\n  PARTITIONED BY ({%- for col in partition_by -%}{{ col }}{% if not loop.last %}, {% endif %}{%- endfor %})\n{%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5782514, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_comment": {"name": "get_create_sql_comment", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/comment.sql", "original_file_path": "macros/relations/components/comment.sql", "unique_id": "macro.dbt_databricks.get_create_sql_comment", "macro_sql": "{%- macro get_create_sql_comment(comment) -%}\n{% if comment is string -%}\n  COMMENT '{{ comment }}'\n{%- endif -%}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5784721, "supported_languages": null}, "macro.dbt_databricks.fetch_column_tags": {"name": "fetch_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.fetch_column_tags", "macro_sql": "{% macro fetch_column_tags(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {% call statement('list_column_tags', fetch_result=True) -%}\n    {{ fetch_column_tags_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_column_tags').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_column_tags_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5792763, "supported_languages": null}, "macro.dbt_databricks.fetch_column_tags_sql": {"name": "fetch_column_tags_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.fetch_column_tags_sql", "macro_sql": "{% macro fetch_column_tags_sql(relation) -%}\n  SELECT \n    column_name,\n    tag_name,\n    tag_value\n  FROM `system`.`information_schema`.`column_tags`\n  WHERE catalog_name = '{{ relation.database|lower }}'\n    AND schema_name = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5795124, "supported_languages": null}, "macro.dbt_databricks.apply_column_tags": {"name": "apply_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.apply_column_tags", "macro_sql": "{% macro apply_column_tags(relation, column_tags) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {{ log(\"Applying column tags to relation \" ~ relation) }}\n  {%- if column_tags.set_column_tags %}\n    {%- for column, tags in column_tags.set_column_tags.items() -%}\n      {%- call statement('main') -%}\n        {{ alter_set_column_tags(relation, column, tags) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_set_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5801146, "supported_languages": null}, "macro.dbt_databricks.alter_set_column_tags": {"name": "alter_set_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.alter_set_column_tags", "macro_sql": "{% macro alter_set_column_tags(relation, column, tags) -%}\n  {# ALTER VIEW does not support setting column tags, but ALTER TABLE works for views #}\n  {%- if relation.type == 'view' -%}\n    ALTER TABLE {{ relation.render() }}\n  {%- else -%}\n    ALTER {{ relation.type | replace('_', ' ') }} {{ relation.render() }}\n  {%- endif -%}\n  ALTER COLUMN `{{ column }}`\n  SET TAGS (\n    {%- for tag_name, tag_value in tags.items() -%}\n      '{{ tag_name }}' = '{{ tag_value }}'{%- if not loop.last %}, {% endif -%}\n    {%- endfor -%}\n  )\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.58081, "supported_languages": null}, "macro.dbt_databricks.column_tags_exist": {"name": "column_tags_exist", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.column_tags_exist", "macro_sql": "{% macro column_tags_exist() %}\n  {% for column_name, column in model.columns.items() %}\n    {% if column is mapping and column.get('databricks_tags') %}\n      {{ return(true) }}\n    {% endif %}\n  {% endfor %}\n  {{ return(false) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5812092, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_refresh_schedule": {"name": "get_create_sql_refresh_schedule", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/refresh_schedule.sql", "original_file_path": "macros/relations/components/refresh_schedule.sql", "unique_id": "macro.dbt_databricks.get_create_sql_refresh_schedule", "macro_sql": "{% macro get_create_sql_refresh_schedule(cron, time_zone_value) %}\n  {%- if cron -%}\n    SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5816243, "supported_languages": null}, "macro.dbt_databricks.get_alter_sql_refresh_schedule": {"name": "get_alter_sql_refresh_schedule", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/refresh_schedule.sql", "original_file_path": "macros/relations/components/refresh_schedule.sql", "unique_id": "macro.dbt_databricks.get_alter_sql_refresh_schedule", "macro_sql": "{% macro get_alter_sql_refresh_schedule(cron, time_zone_value, is_altered) %}\n  {%- if cron -%}\n    {%- if is_altered -%}\n      ALTER SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n    {%- else -%}\n      ADD SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n    {%- endif -%}\n  {%- else -%}\n    DROP SCHEDULE\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5820441, "supported_languages": null}, "macro.dbt_databricks.alter_query": {"name": "alter_query", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/query.sql", "original_file_path": "macros/relations/components/query.sql", "unique_id": "macro.dbt_databricks.alter_query", "macro_sql": "{% macro alter_query(target_relation, query) %}\n  {{ log(\"Altering query\") }}\n  {% if query %}\n    {% call statement('main') %}\n      {{- get_alter_query_sql(target_relation, query) }}\n    {% endcall %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_alter_query_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.582513, "supported_languages": null}, "macro.dbt_databricks.get_alter_query_sql": {"name": "get_alter_query_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/query.sql", "original_file_path": "macros/relations/components/query.sql", "unique_id": "macro.dbt_databricks.get_alter_query_sql", "macro_sql": "{% macro get_alter_query_sql(target_relation, query) -%}\n  ALTER {{ target_relation.type|upper }} {{ target_relation.render() }} AS (\n    {{ query }}\n  )\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5827265, "supported_languages": null}, "macro.dbt_databricks.fetch_column_masks": {"name": "fetch_column_masks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.fetch_column_masks", "macro_sql": "{% macro fetch_column_masks(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column masks are not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_column_masks', fetch_result=True) -%}\n    {{ fetch_column_masks_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_column_masks').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_column_masks_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5835443, "supported_languages": null}, "macro.dbt_databricks.fetch_column_masks_sql": {"name": "fetch_column_masks_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.fetch_column_masks_sql", "macro_sql": "{% macro fetch_column_masks_sql(relation) -%}\n  SELECT \n    column_name,\n    mask_name,\n    using_columns\n  FROM `system`.`information_schema`.`column_masks`\n  WHERE table_catalog = '{{ relation.database|lower }}'\n    AND table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5837836, "supported_languages": null}, "macro.dbt_databricks.apply_column_masks": {"name": "apply_column_masks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.apply_column_masks", "macro_sql": "{% macro apply_column_masks(relation, column_masks) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column masks are not supported for Hive Metastore\") }}\n  {%- endif %}\n  {{ log(\"Applying column masks to relation \" ~ relation) }}\n  {%- if column_masks.unset_column_masks %}\n    {%- for column in column_masks.unset_column_masks -%}\n      {%- call statement('main') -%}\n        {{ alter_drop_column_mask(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if column_masks.set_column_masks %}\n    {%- for column, mask in column_masks.set_column_masks.items() -%}\n      {%- call statement('main') -%}\n        {{ alter_set_column_mask(relation, column, mask) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_drop_column_mask", "macro.dbt_databricks.alter_set_column_mask"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5847785, "supported_languages": null}, "macro.dbt_databricks.alter_drop_column_mask": {"name": "alter_drop_column_mask", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.alter_drop_column_mask", "macro_sql": "{% macro alter_drop_column_mask(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }}\n  ALTER COLUMN `{{ column }}`\n  DROP MASK;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5850093, "supported_languages": null}, "macro.dbt_databricks.alter_set_column_mask": {"name": "alter_set_column_mask", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.alter_set_column_mask", "macro_sql": "{% macro alter_set_column_mask(relation, column, mask) -%}\n  ALTER {{ relation.type }} {{ relation.render() }}\n  ALTER COLUMN `{{ column }}`\n  SET MASK {{ mask.function }}\n  {%- if mask.using_columns %}\n  USING COLUMNS ({{ mask.using_columns }})\n  {%- endif %};\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5853376, "supported_languages": null}, "macro.dbt_databricks.column_mask_exists": {"name": "column_mask_exists", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.column_mask_exists", "macro_sql": "{% macro column_mask_exists() %}\n  {% for column_name, column in model.columns.items() %}\n    {% if column is mapping and column.get('column_mask') %}\n      {{ return(true) }}\n    {% endif %}\n  {% endfor %}\n  {{ return(false) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5857515, "supported_languages": null}, "macro.dbt_databricks.fetch_non_null_constraint_columns": {"name": "fetch_non_null_constraint_columns", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_non_null_constraint_columns", "macro_sql": "{% macro fetch_non_null_constraint_columns(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_non_null_constraint_columns', fetch_result=True) -%}\n    {{ fetch_non_null_constraint_columns_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_non_null_constraint_columns').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_non_null_constraint_columns_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.587043, "supported_languages": null}, "macro.dbt_databricks.fetch_non_null_constraint_columns_sql": {"name": "fetch_non_null_constraint_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_non_null_constraint_columns_sql", "macro_sql": "{% macro fetch_non_null_constraint_columns_sql(relation) -%}\n  SELECT column_name\n  FROM `{{ relation.database|lower }}`.`information_schema`.`columns`\n  WHERE table_catalog = '{{ relation.database|lower }}' \n    AND table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n    AND is_nullable = 'NO';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5873156, "supported_languages": null}, "macro.dbt_databricks.fetch_primary_key_constraints": {"name": "fetch_primary_key_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_primary_key_constraints", "macro_sql": "{% macro fetch_primary_key_constraints(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_primary_key_constraints', fetch_result=True) -%}\n    {{ fetch_primary_key_constraints_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_primary_key_constraints').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_primary_key_constraints_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.587744, "supported_languages": null}, "macro.dbt_databricks.fetch_primary_key_constraints_sql": {"name": "fetch_primary_key_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_primary_key_constraints_sql", "macro_sql": "{% macro fetch_primary_key_constraints_sql(relation) -%}\n  SELECT kcu.constraint_name, kcu.column_name\n  FROM `{{ relation.database|lower }}`.information_schema.key_column_usage kcu\n  WHERE kcu.table_catalog = '{{ relation.database|lower }}' \n    AND kcu.table_schema = '{{ relation.schema|lower }}'\n    AND kcu.table_name = '{{ relation.identifier|lower }}' \n    AND kcu.constraint_name = (\n      SELECT constraint_name\n      FROM `{{ relation.database|lower }}`.information_schema.table_constraints\n      WHERE table_catalog = '{{ relation.database|lower }}'\n        AND table_schema = '{{ relation.schema|lower }}'\n        AND table_name = '{{ relation.identifier|lower }}' \n        AND constraint_type = 'PRIMARY KEY'\n    )\n  ORDER BY kcu.ordinal_position;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5882518, "supported_languages": null}, "macro.dbt_databricks.fetch_foreign_key_constraints": {"name": "fetch_foreign_key_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_foreign_key_constraints", "macro_sql": "{% macro fetch_foreign_key_constraints(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_foreign_key_constraints', fetch_result=True) -%}\n    {{ fetch_foreign_key_constraints_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_foreign_key_constraints').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_foreign_key_constraints_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.588713, "supported_languages": null}, "macro.dbt_databricks.fetch_foreign_key_constraints_sql": {"name": "fetch_foreign_key_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_foreign_key_constraints_sql", "macro_sql": "{% macro fetch_foreign_key_constraints_sql(relation) -%}\n  SELECT\n    kcu.constraint_name,\n    kcu.column_name AS from_column,\n    ukcu.table_catalog AS to_catalog,\n    ukcu.table_schema AS to_schema,\n    ukcu.table_name AS to_table,\n    ukcu.column_name AS to_column\n  FROM `{{ relation.database|lower }}`.information_schema.key_column_usage kcu\n  JOIN `{{ relation.database|lower }}`.information_schema.referential_constraints rc\n    ON kcu.constraint_name = rc.constraint_name\n  JOIN `{{ relation.database|lower }}`.information_schema.key_column_usage ukcu\n    ON rc.unique_constraint_name = ukcu.constraint_name\n    AND kcu.ordinal_position = ukcu.ordinal_position\n  WHERE kcu.table_catalog = '{{ relation.database|lower }}'\n    AND kcu.table_schema = '{{ relation.schema|lower }}'\n    AND kcu.table_name = '{{ relation.identifier|lower }}'\n    AND kcu.constraint_name IN (\n      SELECT constraint_name\n      FROM `{{ relation.database|lower }}`.information_schema.table_constraints\n      WHERE table_catalog = '{{ relation.database|lower }}'\n        AND table_schema = '{{ relation.schema|lower }}'\n        AND table_name = '{{ relation.identifier|lower }}'\n        AND constraint_type = 'FOREIGN KEY'\n    )\n  ORDER BY kcu.ordinal_position;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5892332, "supported_languages": null}, "macro.dbt_databricks.apply_constraints": {"name": "apply_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.apply_constraints", "macro_sql": "{% macro apply_constraints(relation, constraints) -%}\n  {{ log(\"Applying constraints to relation \" ~ constraints) }}\n  {%- if constraints and relation.is_hive_metastore() -%}\n    {{ exceptions.raise_compiler_error(\"Constraints are only supported for Unity Catalog\") }}\n  {%- endif -%}\n  {# Order matters here because key constraints depend on non-null constraints #} \n  {%- if constraints.unset_constraints %}\n    {%- for constraint in constraints.unset_constraints -%}\n      {%- call statement('main') -%}\n        {{ alter_unset_constraint(relation, constraint) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.unset_non_nulls %}\n    {%- for column in constraints.unset_non_nulls -%}\n      {%- call statement('main') -%}\n        {{ alter_unset_non_null_constraint(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.set_non_nulls %}\n    {%- for column in constraints.set_non_nulls -%}\n      {%- call statement('main') -%}\n        {{ alter_set_non_null_constraint(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.set_constraints %}\n    {%- for constraint in constraints.set_constraints -%}\n      {%- call statement('main') -%}\n        {{ alter_set_constraint(relation, constraint) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_unset_constraint", "macro.dbt_databricks.alter_unset_non_null_constraint", "macro.dbt_databricks.alter_set_non_null_constraint", "macro.dbt_databricks.alter_set_constraint"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.590458, "supported_languages": null}, "macro.dbt_databricks.alter_set_non_null_constraint": {"name": "alter_set_non_null_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_set_non_null_constraint", "macro_sql": "{% macro alter_set_non_null_constraint(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ALTER COLUMN {{ column }} SET NOT NULL;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5906637, "supported_languages": null}, "macro.dbt_databricks.alter_unset_non_null_constraint": {"name": "alter_unset_non_null_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_unset_non_null_constraint", "macro_sql": "{% macro alter_unset_non_null_constraint(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ALTER COLUMN {{ column }} DROP NOT NULL;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.590863, "supported_languages": null}, "macro.dbt_databricks.alter_set_constraint": {"name": "alter_set_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_set_constraint", "macro_sql": "{% macro alter_set_constraint(relation, constraint) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ADD {{ constraint.render() }};\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5911024, "supported_languages": null}, "macro.dbt_databricks.alter_unset_constraint": {"name": "alter_unset_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_unset_constraint", "macro_sql": "{% macro alter_unset_constraint(relation, constraint) -%}\n  {% set constraint_type = constraint.type %}\n  {% if constraint_type == 'primary_key' %}\n    {# Need to only add CASCADE to PK constraints because dropping check constraints break when adding CASCADE #}\n    ALTER {{ relation.type }} {{ relation.render() }} DROP CONSTRAINT {{ constraint.name }} CASCADE;\n  {% else %}\n    ALTER {{ relation.type }} {{ relation.render() }} DROP CONSTRAINT IF EXISTS {{ constraint.name }};\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5915532, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_tblproperties": {"name": "get_create_sql_tblproperties", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/tblproperties.sql", "original_file_path": "macros/relations/components/tblproperties.sql", "unique_id": "macro.dbt_databricks.get_create_sql_tblproperties", "macro_sql": "{% macro get_create_sql_tblproperties(tblproperties) %}\n  {{ databricks__tblproperties_clause(tblproperties)}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5917544, "supported_languages": null}, "macro.dbt_databricks.apply_config_changeset": {"name": "apply_config_changeset", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/alter.sql", "original_file_path": "macros/relations/table/alter.sql", "unique_id": "macro.dbt_databricks.apply_config_changeset", "macro_sql": "{% macro apply_config_changeset(target_relation, model, configuration_changes) %}\n    {{ log(\"Applying configuration changes to relation \" ~ target_relation) }}\n    {% if configuration_changes %}\n      {% set comment = configuration_changes.changes.get(\"comment\") %}\n      {% set column_comments = configuration_changes.changes.get(\"column_comments\") %}\n      {% set column_tags = configuration_changes.changes.get(\"column_tags\") %}\n      {% set tags = configuration_changes.changes.get(\"tags\") %}\n      {% set tblproperties = configuration_changes.changes.get(\"tblproperties\") %}\n      {% set liquid_clustering = configuration_changes.changes.get(\"liquid_clustering\")%}\n      {% set constraints = configuration_changes.changes.get(\"constraints\") %}\n      {% set column_masks = configuration_changes.changes.get(\"column_masks\") %}\n      {% if tags is not none %}\n        {% do apply_tags(target_relation, tags.set_tags) %}\n      {%- endif -%}\n      {% if tblproperties is not none %}\n        {% do apply_tblproperties(target_relation, tblproperties.tblproperties) %}\n      {%- endif -%}\n      {% if liquid_clustering is not none %}\n        {% do apply_liquid_clustered_cols(target_relation, liquid_clustering) %}\n      {%- endif -%}\n      {% if comment %}\n        {{ run_query_as(alter_relation_comment_sql(target_relation, comment.comment), 'alter_relation_comment', fetch_result=False) }}\n      {% endif %}\n      {% if column_comments %}\n        {{ alter_column_comments(target_relation, column_comments.comments) }}\n      {% endif %}\n      {% if column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n      {% endif %}\n      {% if constraints %}\n        {{ apply_constraints(target_relation, constraints) }}\n      {% endif %}\n      {% if column_masks %}\n        {{ apply_column_masks(target_relation, column_masks) }}\n      {% endif %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.apply_liquid_clustered_cols", "macro.dbt_databricks.run_query_as", "macro.dbt_databricks.alter_relation_comment_sql", "macro.dbt_databricks.alter_column_comments", "macro.dbt_databricks.apply_column_tags", "macro.dbt_databricks.apply_constraints", "macro.dbt_databricks.apply_column_masks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5939896, "supported_languages": null}, "macro.dbt_databricks.databricks__get_rename_table_sql": {"name": "databricks__get_rename_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt_databricks.databricks__get_rename_table_sql", "macro_sql": "{% macro databricks__get_rename_table_sql(relation, new_name) %}\n  ALTER TABLE {{ relation.render() }} RENAME TO `{{ new_name }}`\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5942557, "supported_languages": null}, "macro.dbt_databricks.create_table_at": {"name": "create_table_at", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.create_table_at", "macro_sql": "{% macro create_table_at(relation, intermediate_relation, compiled_code) %}\n  {% set tags = config.get('databricks_tags') %}\n  {% set model_columns = model.get('columns', []) %}\n  {% set existing_columns = adapter.get_columns_in_relation(intermediate_relation) %}\n  {% set model_constraints = model.get('constraints', []) %}\n  {% set columns_and_constraints = adapter.parse_columns_and_constraints(existing_columns, model_columns, model_constraints) %}\n  {% set target_relation = relation.enrich(columns_and_constraints[1]) %}\n  \n  {% call statement('main') %}\n    {{ get_create_table_sql(target_relation, columns_and_constraints[0], compiled_code) }}\n  {% endcall %}\n\n  {{ apply_alter_constraints(target_relation) }}\n  {{ apply_tags(target_relation, tags) }}\n  {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n  {% if column_tags and column_tags.set_column_tags %}\n    {{ apply_column_tags(target_relation, column_tags) }}\n  {% endif %}\n\n  {% call statement('merge into target') %}\n    insert into {{ target_relation }} select * from {{ intermediate_relation }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_create_table_sql", "macro.dbt_databricks.apply_alter_constraints", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.5965307, "supported_languages": null}, "macro.dbt_databricks.get_create_table_sql": {"name": "get_create_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.get_create_table_sql", "macro_sql": "{% macro get_create_table_sql(target_relation, columns, compiled_code) %}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- set contract = config.get('contract') -%}\n  {%- set contract_enforced = contract and contract.enforced -%}\n  {%- if contract_enforced -%}\n    {{ get_assert_columns_equivalent(compiled_code) }}\n  {%- endif -%}\n\n  {%- if catalog_relation.file_format == 'delta' %}\n  create or replace table {{ target_relation.render() }}\n  {% else %}\n  create table {{ target_relation.render() }}\n  {% endif -%}\n  {{ get_column_and_constraints_sql(target_relation, columns) }}\n  {{ file_format_clause(catalog_relation) }}\n  {{ databricks__options_clause(catalog_relation) }}\n  {{ partition_cols(label=\"partitioned by\") }}\n  {{ liquid_clustered_cols() }}\n  {{ clustered_cols(label=\"clustered by\") }}\n  {{ location_clause(catalog_relation) }}\n  {{ comment_clause() }}\n  {{ tblproperties_clause() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.file_format_clause", "macro.dbt_databricks.databricks__options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_databricks.liquid_clustered_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.597599, "supported_languages": null}, "macro.dbt_databricks.databricks__create_table_as": {"name": "databricks__create_table_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.databricks__create_table_as", "macro_sql": "{% macro databricks__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if catalog_relation.file_format == 'delta' %}\n        create or replace table {{ relation.render() }}\n      {% else %}\n        create table {{ relation.render() }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {% if contract_config and contract_config.enforced %}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause(catalog_relation) }}\n      {{ databricks__options_clause(catalog_relation) }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ liquid_clustered_cols() }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause(catalog_relation) }}\n      {{ comment_clause() }}\n      {{ tblproperties_clause() }}\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ databricks__py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_databricks.file_format_clause", "macro.dbt_databricks.databricks__options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_databricks.liquid_clustered_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt_databricks.databricks__py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.599061, "supported_languages": null}, "macro.dbt_databricks.databricks__options_clause": {"name": "databricks__options_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.databricks__options_clause", "macro_sql": "{% macro databricks__options_clause(catalog_relation=none) -%}\n  {#-\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n    Additionally, since this rolls up to `options_clause` in `dbt-spark`, which does not have any arguments,\n    all calls to `options_clause` will take the second path. This macro needs to be called directly\n    via `databricks__options_clause`.\n  -#}\n  {%- if catalog_relation is not none -%}\n    {%- set file_format = catalog_relation.file_format -%}\n  {%- else -%}\n    {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- endif -%}\n\n  {%- set options = config.get('options') -%}\n  {%- if file_format == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6004856, "supported_languages": null}, "macro.dbt_databricks.get_create_intermediate_table": {"name": "get_create_intermediate_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.get_create_intermediate_table", "macro_sql": "{% macro get_create_intermediate_table(relation, compiled_code, language) %}\n  {%- if language == 'sql' -%}\n    {{ create_temporary_view(relation, compiled_code) }}\n  {%- else -%}\n    {{ create_python_intermediate_table(relation, compiled_code) }}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.create_python_intermediate_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6008017, "supported_languages": null}, "macro.dbt_databricks.safe_relation_replace": {"name": "safe_relation_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt_databricks.safe_relation_replace", "macro_sql": "{% macro safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) %}\n  \n  {{ create_table_at(staging_relation, intermediate_relation, compiled_code) }}\n\n  {{ create_backup(existing_relation) }}\n\n  {{ adapter.rename_relation(staging_relation, existing_relation) }}\n\n  {% call statement('main') %}\n    {{ get_drop_backup_sql(existing_relation) }}\n  {% endcall %}\n  \n  {{ adapter.cache_dropped(make_backup_relation(existing_relation, existing_relation.type)) }}\n\n  {{ drop_relation_if_exists(intermediate_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_table_at", "macro.dbt_databricks.create_backup", "macro.dbt.statement", "macro.dbt.get_drop_backup_sql", "macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6015396, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_table": {"name": "databricks__drop_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_table", "macro_sql": "{% macro databricks__drop_table(relation) -%}\n    drop table if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.601738, "supported_languages": null}, "macro.dbt_databricks.alter_view": {"name": "alter_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/alter.sql", "original_file_path": "macros/relations/view/alter.sql", "unique_id": "macro.dbt_databricks.alter_view", "macro_sql": "{% macro alter_view(target_relation, changes) %}\n  {{ log(\"Updating view via ALTER\") }}\n  {{ adapter.dispatch('alter_view', 'dbt')(target_relation, changes) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.602661, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_view": {"name": "databricks__alter_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/alter.sql", "original_file_path": "macros/relations/view/alter.sql", "unique_id": "macro.dbt_databricks.databricks__alter_view", "macro_sql": "{% macro databricks__alter_view(target_relation, changes) %}\n  {% set tags = changes.get(\"tags\") %}\n  {% set tblproperties = changes.get(\"tblproperties\") %}\n  {% set query = changes.get(\"query\") %}\n  {% set column_comments = changes.get(\"column_comments\") %}\n  {% if tags %}\n    {{ apply_tags(target_relation, tags.set_tags) }}\n  {% endif %}\n  {% if tblproperties %}\n    {{ apply_tblproperties(target_relation, tblproperties.tblproperties) }}\n  {% endif %}\n  {% if query %}\n    {{ alter_query(target_relation, query.query) }}\n  {% endif %}\n  {% if column_comments %}\n    {{ alter_column_comments(target_relation, column_comments.comments) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.alter_query", "macro.dbt_databricks.alter_column_comments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6049495, "supported_languages": null}, "macro.dbt_databricks.databricks__get_rename_view_sql": {"name": "databricks__get_rename_view_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt_databricks.databricks__get_rename_view_sql", "macro_sql": "{% macro databricks__get_rename_view_sql(relation, new_name) %}\n  ALTER VIEW {{ relation.render() }} RENAME TO {{ new_name }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6052334, "supported_languages": null}, "macro.dbt_databricks.databricks__create_view_as": {"name": "databricks__create_view_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.databricks__create_view_as", "macro_sql": "{% macro databricks__create_view_as(relation, sql) %}\n  {% if column_mask_exists() %}\n    {% do exceptions.raise_compiler_error(\"Column masks are not supported for views.\") %}\n  {% endif %}\n  {{ log(\"Creating view \" ~ relation) }}\n  create or replace view {{ relation.render() }}\n  {%- if config.persist_column_docs() -%}\n    {%- set model_columns = model.columns -%}\n    {%- set query_columns = get_columns_in_query(sql) -%}\n    {%- if query_columns %}\n  (\n    {{ get_persist_docs_column_list(model_columns, query_columns) }}\n  )\n    {%- endif -%}\n  {%- endif %}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {%- if contract_config and contract_config.enforced %}\n  {{ get_assert_columns_equivalent(sql) }}\n  {%- endif -%}\n  {{ tblproperties_clause() }}\n  as (\n    {{ sql }}\n  )\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.column_mask_exists", "macro.dbt.get_columns_in_query", "macro.dbt_databricks.get_persist_docs_column_list", "macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent", "macro.dbt_databricks.tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6065965, "supported_languages": null}, "macro.dbt_databricks.get_column_comment_sql": {"name": "get_column_comment_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.get_column_comment_sql", "macro_sql": "{% macro get_column_comment_sql(column_name, column_dict) -%}\n  {%- if column_name in column_dict and column_dict[column_name][\"description\"] -%}\n    {%- set escaped_description = column_dict[column_name][\"description\"] | replace(\"'\", \"\\\\'\") -%}\n    {%- set column_comment_clause = \"comment '\" ~ escaped_description ~ \"'\" -%}\n    {{ adapter.quote(column_name) }} {{ column_comment_clause }}\n  {%- else -%}\n    {{ adapter.quote(column_name) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.607195, "supported_languages": null}, "macro.dbt_databricks.get_persist_docs_column_list": {"name": "get_persist_docs_column_list", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.get_persist_docs_column_list", "macro_sql": "{% macro get_persist_docs_column_list(model_columns, query_columns) -%}\n  {%- for column_name in query_columns -%}\n    {{ get_column_comment_sql(column_name, model_columns) }}{{\",\\n\\t\" if not loop.last else \"\" }}\n  {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_column_comment_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.607571, "supported_languages": null}, "macro.dbt_databricks.databricks__get_replace_view_sql": {"name": "databricks__get_replace_view_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt_databricks.databricks__get_replace_view_sql", "macro_sql": "{% macro databricks__get_replace_view_sql(target_relation, sql) %}\n  {{ create_view_as(target_relation, sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6078453, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_view": {"name": "databricks__drop_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_view", "macro_sql": "{% macro databricks__drop_view(relation) -%}\n  DROP VIEW IF EXISTS {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6081252, "supported_languages": null}, "macro.dbt_databricks.get_alter_materialized_view_as_sql": {"name": "get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_materialized_view_as_sql", "macro_sql": "{% macro get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {%- do return(adapter.dispatch('get_alter_materialized_view_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    )) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.608986, "supported_languages": null}, "macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql": {"name": "databricks__get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql", "macro_sql": "{% macro databricks__get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    -- apply a full refresh immediately if needed\n    {% if configuration_changes.requires_full_refresh %}\n        {% do return(get_replace_sql(existing_relation, relation,  sql)) %}\n\n    -- otherwise apply individual changes as needed\n    {% else %}\n        {% do return(get_alter_mv_internal(relation, configuration_changes)) %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_alter_mv_internal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.609434, "supported_languages": null}, "macro.dbt_databricks.get_alter_mv_internal": {"name": "get_alter_mv_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_mv_internal", "macro_sql": "{% macro get_alter_mv_internal(relation, configuration_changes) %}\n    {%- set refresh = configuration_changes.changes[\"refresh\"] -%}\n    -- Currently only schedule can be altered\n    ALTER MATERIALIZED VIEW {{ relation.render() }}\n        {{ get_alter_sql_refresh_schedule(refresh.cron, refresh.time_zone_value, refresh.is_altered) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_alter_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6097531, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_materialized_view_as_sql": {"name": "databricks__get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_materialized_view_as_sql", "macro_sql": "{% macro databricks__get_create_materialized_view_as_sql(relation, sql) -%}\n  {# Column masks are supported in DBSQL, but not yet wired up to the adapter. Return a helpful error until supported. #}\n  {% if column_mask_exists() %}\n    {% do exceptions.raise_compiler_error(\"Column masks are not yet supported for materialized views.\") %}\n  {% endif %}\n  {%- set materialized_view = adapter.get_config_from_model(config.model) -%}\n  {%- set partition_by = materialized_view.config[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = materialized_view.config[\"tblproperties\"].tblproperties -%}\n  {%- set comment = materialized_view.config[\"comment\"].comment -%}\n  {%- set refresh = materialized_view.config[\"refresh\"] -%}\n\n  {#\n    TODO: When DESCRIBE QUERY EXTENDED is supported, this implementation should be simplified\n    to use that instead. For now, we work around this limitation by writing results to a\n    temporary view and using DESCRIBE TABLE EXTENDED on the temporary view.\n  #}\n  {%- set temp_relation = make_temp_relation(relation) -%}\n  {% call statement('create_temp_view') -%}\n    {%- set sql_with_limit = sql.rstrip('; \\n\\t') ~ ' LIMIT 10' -%}\n    {{ create_temporary_view(temp_relation, sql_with_limit) }}\n  {%- endcall %}\n\n  {%- set columns = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set model_columns = model.get('columns', {}) -%}\n  {%- set model_constraints = model.get('constraints', []) -%}\n  {%- set columns_and_constraints = adapter.parse_columns_and_constraints(columns, model_columns, model_constraints) -%}\n  {%- set target_relation = relation.enrich(columns_and_constraints[1]) -%}\n\n  create materialized view {{ target_relation.render() }}\n    {{ get_column_and_constraints_sql(target_relation, columns_and_constraints[0]) }}\n    {{ get_create_sql_partition_by(partition_by) }}\n    {{ get_create_sql_comment(comment) }}\n    {{ get_create_sql_tblproperties(tblproperties) }}\n    {{ get_create_sql_refresh_schedule(refresh.cron, refresh.time_zone_value) }}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.column_mask_exists", "macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties", "macro.dbt_databricks.get_create_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.612056, "supported_languages": null}, "macro.dbt_databricks.databricks__refresh_materialized_view": {"name": "databricks__refresh_materialized_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt_databricks.databricks__refresh_materialized_view", "macro_sql": "{% macro databricks__refresh_materialized_view(relation) -%}\n  refresh materialized view {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6123466, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_materialized_view": {"name": "databricks__drop_materialized_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_materialized_view", "macro_sql": "{% macro databricks__drop_materialized_view(relation) -%}\n    drop materialized view if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6125646, "supported_languages": null}, "macro.dbt_databricks.get_alter_streaming_table_as_sql": {"name": "get_alter_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_streaming_table_as_sql", "macro_sql": "{% macro get_alter_streaming_table_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {%- do return(adapter.dispatch('get_alter_streaming_table_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    )) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.613357, "supported_languages": null}, "macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql": {"name": "databricks__get_alter_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql", "macro_sql": "{% macro databricks__get_alter_streaming_table_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    -- apply a full refresh immediately if needed\n    {% if configuration_changes.requires_full_refresh %}\n        {% do return(get_replace_sql(existing_relation, relation,  sql)) %}\n\n    -- otherwise apply individual changes as needed\n    {% else %}\n        {%- set alter_statement = get_alter_st_internal(relation, configuration_changes) -%}\n        {%- set create_statement = get_create_st_internal(relation, configuration_changes, sql) -%}\n        {%- set return_statements = [] -%}\n        {%- if create_statement -%}\n            {{ return_statements.append(create_statement) }}\n        {%- endif -%}\n        {%- if alter_statement -%}\n            {{ return_statements.append(alter_statement) }}\n        {%- endif -%}\n        {% do return(return_statements) %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_alter_st_internal", "macro.dbt_databricks.get_create_st_internal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6143875, "supported_languages": null}, "macro.dbt_databricks.get_create_st_internal": {"name": "get_create_st_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_create_st_internal", "macro_sql": "{% macro get_create_st_internal(relation, configuration_changes, sql) %}\n  {%- set partition_by = configuration_changes.changes[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = configuration_changes.changes[\"tblproperties\"].tblproperties -%}\n  {%- set comment = configuration_changes.changes[\"comment\"].comment -%}\n  CREATE OR REFRESH STREAMING TABLE {{ relation.render() }}\n    {% if partition_by -%}\n        {{ get_create_sql_partition_by(partition_by) }}\n    {%- endif %}\n    {% if comment -%}\n        {{ get_create_sql_comment(comment) }}\n    {%- endif %}\n    {% if tblproperties -%}\n        {{ get_create_sql_tblproperties(tblproperties) }}\n    {%- endif %}\n    AS {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6152253, "supported_languages": null}, "macro.dbt_databricks.get_alter_st_internal": {"name": "get_alter_st_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_st_internal", "macro_sql": "{% macro get_alter_st_internal(relation, configuration_changes) %}\n  {%- set refresh = configuration_changes.changes[\"refresh\"] -%}\n  {%- if refresh and refresh.cron -%}\n    ALTER STREAMING TABLE {{ relation.render() }}\n        {{ get_alter_sql_refresh_schedule(refresh.cron, refresh.time_zone_value, False) -}}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_alter_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6156266, "supported_languages": null}, "macro.dbt_databricks.get_create_streaming_table_as_sql": {"name": "get_create_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/create.sql", "original_file_path": "macros/relations/streaming_table/create.sql", "unique_id": "macro.dbt_databricks.get_create_streaming_table_as_sql", "macro_sql": "{% macro get_create_streaming_table_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_streaming_table_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6163096, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_streaming_table_as_sql": {"name": "databricks__get_create_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/create.sql", "original_file_path": "macros/relations/streaming_table/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_streaming_table_as_sql", "macro_sql": "{% macro databricks__get_create_streaming_table_as_sql(relation, sql) -%}\n  {%- set streaming_table = adapter.get_config_from_model(config.model) -%}\n  {%- set partition_by = streaming_table.config[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = streaming_table.config[\"tblproperties\"].tblproperties -%}\n  {%- set comment = streaming_table.config[\"comment\"].comment -%}\n  {%- set refresh = streaming_table.config[\"refresh\"] -%}\n\n  {%- set analysis_sql = sql | replace('STREAM ', '') | replace('stream ', '') -%}\n\n  {#\n    TODO: When DESCRIBE QUERY EXTENDED is supported, this implementation should be simplified\n    to use that instead. For now, we work around this limitation by writing results to a\n    temporary view and using DESCRIBE TABLE EXTENDED on the temporary view.\n  #}\n  {%- set temp_relation = make_temp_relation(relation) -%}\n  {% call statement('create_temp_view') -%}\n    {%- set sql_with_limit = analysis_sql.rstrip('; \\n\\t') ~ ' LIMIT 10' -%}\n    {{ create_temporary_view(temp_relation, sql_with_limit) }}\n  {%- endcall %}\n\n  {%- set columns = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set model_columns = model.get('columns', {}) -%}\n  {%- set columns_and_constraints = adapter.parse_columns_and_constraints(columns, model_columns, []) -%}\n\n  {#-- We don't enrich the relation with model constraints because they are not supported for streaming tables --#}\n  CREATE STREAMING TABLE {{ relation.render() }}\n    {{ get_column_and_constraints_sql(relation, columns_and_constraints[0]) }}\n    {{ get_create_sql_partition_by(partition_by) }}\n    {{ get_create_sql_comment(comment) }}\n    {{ get_create_sql_tblproperties(tblproperties) }}\n    {{ get_create_sql_refresh_schedule(refresh.cron, refresh.time_zone_value) }}\n    AS {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties", "macro.dbt_databricks.get_create_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.617944, "supported_languages": null}, "macro.dbt_databricks.refresh_streaming_table": {"name": "refresh_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/refresh.sql", "original_file_path": "macros/relations/streaming_table/refresh.sql", "unique_id": "macro.dbt_databricks.refresh_streaming_table", "macro_sql": "{% macro refresh_streaming_table(relation, sql) -%}\n  {{ adapter.dispatch('refresh_streaming_table', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__refresh_streaming_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6182952, "supported_languages": null}, "macro.dbt_databricks.databricks__refresh_streaming_table": {"name": "databricks__refresh_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/refresh.sql", "original_file_path": "macros/relations/streaming_table/refresh.sql", "unique_id": "macro.dbt_databricks.databricks__refresh_streaming_table", "macro_sql": "{% macro databricks__refresh_streaming_table(relation, sql) -%}\n  create or refresh streaming table {{ relation.render() }}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6184871, "supported_languages": null}, "macro.dbt_databricks.drop_streaming_table": {"name": "drop_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/drop.sql", "original_file_path": "macros/relations/streaming_table/drop.sql", "unique_id": "macro.dbt_databricks.drop_streaming_table", "macro_sql": "{% macro drop_streaming_table(relation) -%}\n    {{ return(adapter.dispatch('drop_streaming_table', 'dbt')(relation)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.default__drop_streaming_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.61878, "supported_languages": null}, "macro.dbt_databricks.default__drop_streaming_table": {"name": "default__drop_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/drop.sql", "original_file_path": "macros/relations/streaming_table/drop.sql", "unique_id": "macro.dbt_databricks.default__drop_streaming_table", "macro_sql": "{% macro default__drop_streaming_table(relation) -%}\n    drop table if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6189184, "supported_languages": null}, "macro.dbt_databricks.databricks__datediff": {"name": "databricks__datediff", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_databricks.databricks__datediff", "macro_sql": "{% macro databricks__datediff(first_date, second_date, datepart) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampdiff({{datepart}}, {{date_trunc(datepart, first_date)}}, {{date_trunc(datepart, second_date)}})\n  {%- else -%}\n    {{ spark__datediff(first_date, second_date, datepart) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.date_trunc", "macro.dbt_spark.spark__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6194263, "supported_languages": null}, "macro.dbt_databricks.databricks__dateadd": {"name": "databricks__dateadd", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_databricks.databricks__dateadd", "macro_sql": "{% macro databricks__dateadd(datepart, interval, from_date_or_timestamp) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampadd({{datepart}}, {{interval}}, {{from_date_or_timestamp}})\n  {%- else -%}\n    {{ spark__dateadd(datepart, interval, from_date_or_timestamp) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.619961, "supported_languages": null}, "macro.dbt_databricks.databricks__split_part": {"name": "databricks__split_part", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt_databricks.databricks__split_part", "macro_sql": "{% macro databricks__split_part(string_text, delimiter_text, part_number) %}\n\n    {% set delimiter_expr %}\n\n        -- escape if starts with a special character\n        case when regexp_extract({{ delimiter_text }}, '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', {{ delimiter_text }})\n            else {{ delimiter_text }} end\n\n    {% endset %}\n\n    {% if part_number >= 0 %}\n\n        {% set split_part_expr %}\n\n        get(split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            ), {{ part_number - 1 if part_number > 0 else part_number }})\n\n        {% endset %}\n\n    {% else %}\n\n        {% set split_part_expr %}\n\n        get(split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            ), \n                length({{ string_text }})\n                - length(\n                    replace({{ string_text }},  {{ delimiter_text }}, '')\n                ) + 1 + {{ part_number }}\n            )\n\n        {% endset %}\n\n    {% endif %}\n\n    {{ return(split_part_expr) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.621028, "supported_languages": null}, "macro.dbt_databricks.statement_with_staging_table": {"name": "statement_with_staging_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.statement_with_staging_table", "macro_sql": "{% macro statement_with_staging_table(name=None, staging_table=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set res, table = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result, staging_table=staging_table) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.622268, "supported_languages": null}, "macro.dbt_databricks.execute_multiple_statements": {"name": "execute_multiple_statements", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.execute_multiple_statements", "macro_sql": "{% macro execute_multiple_statements(statements) %}\n  {%- if statements is string %}\n    {% call statement(name=\"main\") %}\n      {{ statements }}\n    {% endcall %}\n  {%- else %}\n    {%- for sql in statements %}\n      {% call statement(name=\"main\") %}\n        {{ sql }}\n      {% endcall %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6228192, "supported_languages": null}, "macro.dbt_databricks.run_query_as": {"name": "run_query_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.run_query_as", "macro_sql": "{% macro run_query_as(sql, name, fetch_result=True) %}\n  {% call statement(name, fetch_result, auto_begin=False) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% if fetch_result %}\n    {{ return(load_result(name).table) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6232467, "supported_languages": null}, "macro.dbt_databricks.databricks__generate_database_name": {"name": "databricks__generate_database_name", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt_databricks.databricks__generate_database_name", "macro_sql": "{% macro databricks__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n        {{ return(default_database) }}\n    {%- else -%}\n        {{ return(custom_database_name) }}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.623797, "supported_languages": null}, "macro.dbt_databricks.materialization_view_databricks": {"name": "materialization_view_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.materialization_view_databricks", "macro_sql": "{% materialization view, adapter='databricks' -%}\n  {{ log(\"MATERIALIZING VIEW\") }}\n  {%- set existing_relation = load_relation_with_metadata(this) -%}\n  {%- set target_relation = this.incorporate(type='view') -%}\n  {% set grant_config = config.get('grants') %}\n  {% set tags = config.get('databricks_tags') %}\n  {% set sql = adapter.clean_sql(sql) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ run_pre_hooks() }}\n    {% if existing_relation %}\n      {% if relation_should_be_altered(existing_relation) %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n        {% if configuration_changes and configuration_changes.changes %}\n          {% if configuration_changes.requires_full_refresh %}\n            {{ log('Using replace_with_view') }}\n            {{ replace_with_view(existing_relation, target_relation) }}\n          {% else %}\n            {{ log('Using alter_view') }}\n            {{ log(configuration_changes.changes) }}\n            {{ alter_view(target_relation, configuration_changes.changes) }}\n          {% endif %}\n        {% else %}\n          {{ execute_no_op(target_relation) }}\n        {% endif %}\n      {% else %}\n        {{ replace_with_view(existing_relation, target_relation) }}\n      {% endif %}\n    {% else %}\n      {% call statement('main') -%}\n        {{ get_create_view_as_sql(target_relation, sql) }}\n      {%- endcall %}\n      {{ apply_tags(target_relation, tags) }}\n      {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n      {% if column_tags and column_tags.set_column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n      {% endif %}\n    {% endif %}\n    {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=True) %}\n\n    {{ run_post_hooks() }}\n\n  {% else %}\n    {{ run_hooks(pre_hooks) }}\n\n    -- If there's a table with the same name and we weren't told to full refresh,\n    -- that's an error. If we were told to full refresh, drop it. This behavior differs\n    -- for Snowflake and BigQuery, so multiple dispatch is used.\n    {%- if existing_relation is not none and not existing_relation.is_view -%}\n      {{ handle_existing_table(should_full_refresh(), existing_relation) }}\n    {%- endif -%}\n\n    -- build model\n    {% call statement('main') -%}\n      {{ get_create_view_as_sql(target_relation, sql) }}\n    {%- endcall %}\n\n    {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=True) %}\n\n    {%- do apply_tags(target_relation, tags) -%}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags and column_tags.set_column_tags %}\n      {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.load_relation_with_metadata", "macro.dbt_databricks.run_pre_hooks", "macro.dbt_databricks.relation_should_be_altered", "macro.dbt_databricks.get_configuration_changes", "macro.dbt_databricks.replace_with_view", "macro.dbt_databricks.alter_view", "macro.dbt_databricks.execute_no_op", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.run_post_hooks", "macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.627894, "supported_languages": ["sql"]}, "macro.dbt_databricks.replace_with_view": {"name": "replace_with_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.replace_with_view", "macro_sql": "{% macro replace_with_view(existing_relation, target_relation) %}\n  {% set sql = adapter.clean_sql(sql) %}\n  {% set tags = config.get('databricks_tags') %}\n  {{ execute_multiple_statements(get_replace_sql(existing_relation, target_relation, sql)) }}\n  {%- do apply_tags(target_relation, tags) -%}\n  \n  {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n  {% if column_tags and column_tags.set_column_tags %}\n    {{ apply_column_tags(target_relation, column_tags) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.execute_multiple_statements", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.62873, "supported_languages": null}, "macro.dbt_databricks.relation_should_be_altered": {"name": "relation_should_be_altered", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.relation_should_be_altered", "macro_sql": "{% macro relation_should_be_altered(existing_relation) %}\n  {% set update_via_alter = config.get('view_update_via_alter', False) | as_bool %}\n  {% if existing_relation.is_view and update_via_alter %}\n    {% if existing_relation.is_hive_metastore() %}\n      {{ exceptions.raise_compiler_error(\"Cannot update a view in the Hive metastore via ALTER VIEW. Please set `view_update_via_alter: false` in your model configuration.\") }}\n    {% endif %}\n    {{ return(True) }}\n  {% endif %}\n  {{ return(False) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6293132, "supported_languages": null}, "macro.dbt_databricks.materialization_streaming_table_databricks": {"name": "materialization_streaming_table_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.materialization_streaming_table_databricks", "macro_sql": "{% materialization streaming_table, adapter='databricks' %}\n  {% set existing_relation = load_cached_relation(this) %}\n  {% set target_relation = this.incorporate(type=this.StreamingTable) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n{% set build_sql = streaming_table_get_build_sql(existing_relation, target_relation) %}\n\n    {% if build_sql == '' %}\n        {{ execute_no_op(target_relation) }}\n    {% else %}\n        {{ streaming_table_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.run_hooks", "macro.dbt_databricks.streaming_table_get_build_sql", "macro.dbt_databricks.execute_no_op", "macro.dbt_databricks.streaming_table_execute_build_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6308703, "supported_languages": ["sql"]}, "macro.dbt_databricks.streaming_table_get_build_sql": {"name": "streaming_table_get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.streaming_table_get_build_sql", "macro_sql": "{% macro streaming_table_get_build_sql(existing_relation, target_relation) %}\n    {% set sql = adapter.clean_sql(sql) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_streaming_table_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_streaming_table %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_streaming_table(target_relation, sql) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_streaming_table_as_sql(target_relation, configuration_changes, sql, existing_relation, None, None) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = \"\" %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt_databricks.get_create_streaming_table_as_sql", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_configuration_changes", "macro.dbt_databricks.refresh_streaming_table", "macro.dbt_databricks.get_alter_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6327214, "supported_languages": null}, "macro.dbt_databricks.streaming_table_execute_build_sql": {"name": "streaming_table_execute_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.streaming_table_execute_build_sql", "macro_sql": "{% macro streaming_table_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {{ execute_multiple_statements(build_sql) }}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags and column_tags.set_column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt_databricks.execute_multiple_statements", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.633617, "supported_languages": null}, "macro.dbt_databricks.materialization_table_databricks": {"name": "materialization_table_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_databricks.materialization_table_databricks", "macro_sql": "{% materialization table, adapter = 'databricks', supported_languages=['sql', 'python'] %}\n  {{ log(\"MATERIALIZING TABLE\") }}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- set tags = config.get('databricks_tags') -%}\n  {%- set safe_create = config.get('use_safer_relation_operations', False) %}\n  {% set existing_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) %}\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set compiled_code = adapter.clean_sql(compiled_code) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set staging_relation = make_staging_relation(target_relation) %}\n\n    {{ run_pre_hooks() }}\n    \n    {% call statement('main', language=language) %}\n      {{ get_create_intermediate_table(intermediate_relation, compiled_code, language) }}\n    {% endcall %}\n    {% if not existing_relation %}\n      {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n    {% else %}\n      {% if safe_create and existing_relation.can_be_renamed %}\n        {{ safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) }}\n      {% else %}\n        {% if existing_relation and (existing_relation.type != 'table' or not (existing_relation.can_be_replaced and config.get('file_format', default='delta') == 'delta')) -%}\n          {{ adapter.drop_relation(existing_relation) }}\n        {%- endif %}\n        {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n      {% endif %}\n    {% endif %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {{ apply_grants(target_relation, grant_config, should_revoke) }}\n\n    {% if language == 'python' %}\n      {{ drop_relation_if_exists(intermediate_relation) }}\n    {% endif %}\n    \n    {{ run_post_hooks() }}\n  {% else %}\n    {{ run_hooks(pre_hooks) }}\n    -- setup: if the target relation already exists, drop it\n    -- in case if the existing and future table is delta, we want to do a\n    -- create or replace table instead of dropping, so we don't have the table unavailable\n    {% if existing_relation and (existing_relation.type != 'table' or not (existing_relation.can_be_replaced and config.get('file_format', default='delta') == 'delta')) -%}\n      {{ adapter.drop_relation(existing_relation) }}\n    {%- endif %}\n\n    -- build model\n\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% if language==\"python\" %}\n      {% do apply_tblproperties(target_relation, tblproperties) %}\n    {% endif %}\n    {%- do apply_tags(target_relation, tags) -%}\n\n    {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n\n    {% do persist_constraints(target_relation, model) %}\n\n    {% do optimize(target_relation) %}\n\n    {{ run_hooks(post_hooks) }}\n\n  {% endif %}\n  {{ return({'relations': [target_relation]})}}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt_databricks.make_staging_relation", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.statement", "macro.dbt_databricks.get_create_intermediate_table", "macro.dbt_databricks.create_table_at", "macro.dbt_databricks.safe_relation_replace", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.drop_relation_if_exists", "macro.dbt_databricks.run_post_hooks", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.apply_tags", "macro.dbt.persist_docs", "macro.dbt_databricks.persist_constraints", "macro.dbt_databricks.optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.638221, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.materialization_materialized_view_databricks": {"name": "materialization_materialized_view_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialization_materialized_view_databricks", "macro_sql": "{% materialization materialized_view, adapter = 'databricks' %}\n    {% set existing_relation = load_cached_relation(this) %}\n    {% set target_relation = this.incorporate(type=this.MaterializedView) %}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    {% set build_sql = materialized_view_get_build_sql(existing_relation, target_relation) %}\n\n    {% if build_sql == '' %}\n        {{ execute_no_op(target_relation) }}\n    {% else %}\n        {{ materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.run_hooks", "macro.dbt_databricks.materialized_view_get_build_sql", "macro.dbt_databricks.execute_no_op", "macro.dbt_databricks.materialized_view_execute_build_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.639662, "supported_languages": ["sql"]}, "macro.dbt_databricks.materialized_view_get_build_sql": {"name": "materialized_view_get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialized_view_get_build_sql", "macro_sql": "{% macro materialized_view_get_build_sql(existing_relation, target_relation) %}\n    {% set sql = adapter.clean_sql(sql) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_materialized_view_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_materialized_view %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_materialized_view(target_relation) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_materialized_view_as_sql(target_relation, configuration_changes, sql, existing_relation, None, None) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = \"\" %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_configuration_changes", "macro.dbt.refresh_materialized_view", "macro.dbt_databricks.get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6414185, "supported_languages": null}, "macro.dbt_databricks.materialized_view_execute_build_sql": {"name": "materialized_view_execute_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialized_view_execute_build_sql", "macro_sql": "{% macro materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {{ execute_multiple_statements(build_sql) }}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags %}\n      {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt_databricks.execute_multiple_statements", "macro.dbt_databricks.apply_column_tags", "macro.dbt.should_revoke", "macro.dbt.apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6422837, "supported_languages": null}, "macro.dbt_databricks.run_pre_hooks": {"name": "run_pre_hooks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt_databricks.run_pre_hooks", "macro_sql": "{% macro run_pre_hooks() %}\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6426265, "supported_languages": null}, "macro.dbt_databricks.run_post_hooks": {"name": "run_post_hooks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt_databricks.run_post_hooks", "macro_sql": "{% macro run_post_hooks() %}\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6428676, "supported_languages": null}, "macro.dbt_databricks.materialization_snapshot_databricks": {"name": "materialization_snapshot_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_databricks.materialization_snapshot_databricks", "macro_sql": "{% materialization snapshot, adapter='databricks' %}\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n  {% set sql = adapter.clean_sql(sql) %}\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'delta') -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = databricks__get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table',\n          needs_information=True) -%}\n\n  {%- if file_format not in ['delta', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, adapter.clean_sql(model['compiled_code'])) %}\n      {% set build_or_select_sql = build_sql %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.assert_valid_snapshot_target_given_strategy(target_relation, columns, strategy) }}\n\n      {% set build_or_select_sql = snapshot_staging_table(strategy, sql, target_relation) %}\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set remove_columns = ['dbt_change_type', 'DBT_CHANGE_TYPE', 'dbt_unique_key', 'DBT_UNIQUE_KEY'] %}\n      {% if unique_key | is_list %}\n          {% for key in strategy.unique_key %}\n              {{ remove_columns.append('dbt_unique_key_' + loop.index|string) }}\n              {{ remove_columns.append('DBT_UNIQUE_KEY_' + loop.index|string) }}\n          {% endfor %}\n      {% endif %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n\n  {{ check_time_data_types(build_or_select_sql) }}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode=False) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_staging_table", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.check_time_data_types", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot", "macro.dbt_databricks.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6496363, "supported_languages": ["sql"]}, "macro.dbt_databricks.materialization_seed_databricks": {"name": "materialization_seed_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.materialization_seed_databricks", "macro_sql": "{% materialization seed, adapter='databricks' %}\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ create_seed_v2(target_relation) }}\n  {% else %}\n    {{ create_seed_v1(target_relation) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.create_seed_v2", "macro.dbt_databricks.create_seed_v1"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6510477, "supported_languages": ["sql"]}, "macro.dbt_databricks.create_seed_v2": {"name": "create_seed_v2", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.create_seed_v2", "macro_sql": "{% macro create_seed_v2(target_relation) %}\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and (old_relation.is_view or old_relation.is_materialized_view)) -%}\n  {%- set exists_as_streaming_table = (old_relation is not none and old_relation.is_streaming_table) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparision later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_pre_hooks() }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view or a materialized view\".format(old_relation)) }}\n  {% elif exists_as_streaming_table %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a streaming table\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {{ log_seed_operation(agate_table, full_refresh_mode, create_table_sql, sql) }}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n  -- No need to persist docs, already handled in seed create\n\n  {{ run_post_hooks() }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt_databricks.log_seed_operation", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.run_post_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.653864, "supported_languages": null}, "macro.dbt_databricks.create_seed_v1": {"name": "create_seed_v1", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.create_seed_v1", "macro_sql": "{% macro create_seed_v1(target_relation) %}\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and (old_relation.is_view or old_relation.is_materialized_view)) -%}\n  {%- set exists_as_streaming_table = (old_relation is not none and old_relation.is_streaming_table) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparision later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view or a materialized view\".format(old_relation)) }}\n  {% elif exists_as_streaming_table %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a streaming table\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n  -- No need to persist docs, already handled in seed create\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.get_csv_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.658459, "supported_languages": null}, "macro.dbt_databricks.databricks__get_binding_char": {"name": "databricks__get_binding_char", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__get_binding_char", "macro_sql": "{% macro databricks__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.659779, "supported_languages": null}, "macro.dbt_databricks.databricks__load_csv_rows": {"name": "databricks__load_csv_rows", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__load_csv_rows", "macro_sql": "{% macro databricks__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n  {% set must_cast = model['config'].get('file_format', 'delta') == 'parquet' %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert {% if loop.index0 == 0 -%} overwrite {% else -%} into {% endif -%} {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- if must_cast -%}\n                    {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                    {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- else -%}\n                    {{ get_binding_char() }}\n                  {%- endif -%}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True, close_cursor=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6617157, "supported_languages": null}, "macro.dbt_databricks.databricks__reset_csv_table": {"name": "databricks__reset_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__reset_csv_table", "macro_sql": "{% macro databricks__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n      {% if old_relation.is_delta and config.get('file_format', default='delta') == 'delta' %}\n        {% set sql = create_or_replace_csv_table(model, agate_table, True) %}\n      {% else %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n      {% endif %}\n    {% else %}\n      {% set sql = create_csv_table(model, agate_table) %}\n    {% endif %}\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_or_replace_csv_table", "macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.662743, "supported_languages": null}, "macro.dbt_databricks.create_or_replace_csv_table": {"name": "create_or_replace_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.create_or_replace_csv_table", "macro_sql": "{% macro create_or_replace_csv_table(model, agate_table, replace=False) %}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n  {%- set column_comment = config.persist_column_docs() and model.columns %}\n  {%- set identifier = model['alias'] -%}\n  {%- set relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n  {%- set replace_clause = \"\" -%}\n  {%- if replace -%}\n    {%- set replace_clause = \"or replace\" -%}\n  {%- endif -%}\n\n  {% set sql %}\n    create {{replace_clause}} table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {%- set column_comment_clause = \"\" -%}\n            {%- if column_comment and col_name in model.columns.keys() -%}   \n              {%- set comment = model.columns[col_name]['description'] | replace(\"'\", \"\\\\'\") -%}\n              {%- if comment and comment != \"\" -%}\n                {%- set column_comment_clause = \"comment '\" ~ comment ~ \"'\" -%}\n              {%- endif -%}\n            {%- endif -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {{ column_comment_clause }}{%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause(catalog_relation) }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause(catalog_relation) }}\n    {{ comment_clause() }}\n    {{ tblproperties_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.665292, "supported_languages": null}, "macro.dbt_databricks.databricks__create_csv_table": {"name": "databricks__create_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__create_csv_table", "macro_sql": "{% macro databricks__create_csv_table(model, agate_table) %}\n  {{ return(create_or_replace_csv_table(model, agate_table)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_or_replace_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6655033, "supported_languages": null}, "macro.dbt_databricks.log_seed_operation": {"name": "log_seed_operation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.log_seed_operation", "macro_sql": "{% macro log_seed_operation(agate_table, full_refresh_mode, create_table_sql, sql) %}\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.noop_statement", "macro.dbt.get_csv_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6659772, "supported_languages": null}, "macro.dbt_databricks.dbt_databricks_validate_get_file_format": {"name": "dbt_databricks_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_file_format", "macro_sql": "{% macro dbt_databricks_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6669347, "supported_languages": null}, "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy": {"name": "dbt_databricks_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_delta_only_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via warehouse\n    Use the 'merge' or 'replace_where' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in adapter.valid_incremental_strategies() %}\n    {{ log(\"WARNING - You are using an unsupported incremental strategy: \" ~ raw_strategy) }}\n    {{ log(\"You can ignore this warning if you are using a custom incremental strategy\") }}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n    {% if raw_strategy in ('replace_where', 'microbatch') and file_format not in ['delta'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6679978, "supported_languages": null}, "macro.dbt_databricks.materialization_incremental_databricks": {"name": "materialization_incremental_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.materialization_incremental_databricks", "macro_sql": "{% materialization incremental, adapter='databricks', supported_languages=['sql', 'python'] -%}\n  {{ log(\"MATERIALIZING INCREMENTAL\") }}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {% set existing_relation = load_relation_with_metadata(this) %}\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set incremental_strategy = get_incremental_strategy(catalog_relation.file_format) %}\n  {% set grant_config = config.get('grants') %}\n  {% set full_refresh = should_full_refresh() %}\n  {% set partition_by = config.get('partition_by') %}\n  {% set language = model['language'] %}\n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n  {% set is_delta = (catalog_relation.file_format == 'delta' and existing_relation.is_delta) %}\n  {% set compiled_code = adapter.clean_sql(model['compiled_code']) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ log(\"USING V2 MATERIALIZATION\") }}\n    {#-- Set vars --#}\n    {% set safe_create = config.get('use_safer_relation_operations', False) | as_bool  %}\n    {{ log(\"Safe create: \" ~ safe_create) }}\n    {% set should_replace = existing_relation.is_dlt or existing_relation.is_view or full_refresh %}\n    {% set is_replaceable = existing_relation.can_be_replaced and is_delta and config.get(\"location_root\") %}\n\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set staging_relation = make_staging_relation(target_relation) %}\n\n    {{ run_pre_hooks() }}\n\n    {% call statement('main', language=language) %}\n      {{ get_create_intermediate_table(intermediate_relation, compiled_code, language) }}\n    {% endcall %}\n\n    {#-- Incremental run logic --#}\n    {%- if existing_relation is none -%}\n      {{ log(\"No existing relation found\") }}\n      {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n    {%- elif should_replace -%}\n      {{ log(\"Existing relation found that requires replacement\") }}\n      {% if safe_create and existing_relation.can_be_renamed %}\n        {{ log(\"Safe create enabled and relation can be renamed\") }}\n        {{ safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) }}\n      {% else %}\n        {#-- Relation must be dropped & recreated --#}\n        {% if not is_replaceable %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n          {{ log(\"Dropping existing relation, as it is not replaceable\") }}\n          {% do adapter.drop_relation(existing_relation) %}\n        {% endif %}\n        {{ log(\"Replacing target relation\") }}\n        {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n      {% endif %}\n    {%- else -%}\n      {{ log(\"Existing relation found, proceeding with incremental work\")}}\n      {#-- Set Overwrite Mode to DYNAMIC for subsequent incremental operations --#}\n      {%- if incremental_strategy == 'insert_overwrite' and partition_by -%}\n        {{ set_overwrite_mode('DYNAMIC') }}\n      {%- endif -%}\n      {#-- Relation must be merged --#}\n      {%- do process_schema_changes(on_schema_change, intermediate_relation, existing_relation) -%}\n      {{ process_config_changes(target_relation) }}\n      {% set build_sql = get_build_sql(incremental_strategy, target_relation, intermediate_relation) %}\n      {%- if language == 'sql' -%}\n        {%- call statement('main') -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- elif language == 'python' -%}\n        {%- call statement_with_staging_table('main', intermediate_relation) -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- endif -%}\n    {%- endif -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% do optimize(target_relation) %}\n\n    {% if language == 'python' %}\n      {{ drop_relation_if_exists(intermediate_relation) }}\n    {% endif %}\n\n    {{ run_post_hooks() }}\n\n  {% else %}\n    {%- set tblproperties = config.get('tblproperties') -%}\n    {%- set tags = config.get('databricks_tags') -%}\n    {% set temp_relation = make_temp_relation(target_relation) %}\n    {% set incremental_predicates = config.get('predicates') or config.get('incremental_predicates') %}\n    {%- set unique_key = config.get('unique_key') -%}\n\n    {#-- Run pre-hooks --#}\n    {{ run_hooks(pre_hooks) }}\n    {#-- Incremental run logic --#}\n    {%- if existing_relation is none -%}\n      {#-- Relation must be created --#}\n      {%- call statement('main', language=language) -%}\n        {{ create_table_as(False, target_relation, compiled_code, language) }}\n      {%- endcall -%}\n      {% do persist_constraints(target_relation, model) %}\n      {% do apply_tags(target_relation, tags) %}\n      {%- if language == 'python' -%}\n        {%- do apply_tblproperties(target_relation, tblproperties) %}\n      {%- endif -%}\n\n      {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n    {%- elif existing_relation.is_view or existing_relation.is_materialized_view or existing_relation.is_streaming_table or should_full_refresh() -%}\n      {#-- Relation must be dropped & recreated --#}\n      {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n        {% do adapter.drop_relation(existing_relation) %}\n      {% endif %}\n      {%- call statement('main', language=language) -%}\n        {{ create_table_as(False, target_relation, compiled_code, language) }}\n      {%- endcall -%}\n\n      {% if not existing_relation.is_view %}\n        {% do persist_constraints(target_relation, model) %}\n      {% endif %}\n      {% do apply_tags(target_relation, tags) %}\n      {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n    {%- else -%}\n      {#-- Set Overwrite Mode to DYNAMIC for subsequent incremental operations --#}\n      {%- if incremental_strategy == 'insert_overwrite' and partition_by -%}\n        {{ set_overwrite_mode('DYNAMIC') }}\n      {%- endif -%}\n      {#-- Relation must be merged --#}\n      {%- set _existing_config = adapter.get_relation_config(existing_relation) -%}\n      {%- set model_config = adapter.get_config_from_model(config.model) -%}\n      {%- set _configuration_changes = model_config.get_changeset(_existing_config) -%}\n      {%- call statement('create_temp_relation', language=language) -%}\n        {{ create_table_as(True, temp_relation, compiled_code, language) }}\n      {%- endcall -%}\n      {%- do process_schema_changes(on_schema_change, temp_relation, existing_relation) -%}\n      {%- set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) -%}\n      {%- set strategy_arg_dict = ({\n              'target_relation': target_relation,\n              'temp_relation': temp_relation,\n              'unique_key': unique_key,\n              'dest_columns': none,\n              'incremental_predicates': incremental_predicates}) -%}\n      {%- set build_sql = strategy_sql_macro_func(strategy_arg_dict) -%}\n      {%- if language == 'sql' -%}\n        {%- call statement('main') -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- elif language == 'python' -%}\n        {%- call statement_with_staging_table('main', temp_relation) -%}\n          {{ build_sql }}\n        {%- endcall -%}\n        {#--\n        This is yucky.\n        See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n        re: python models and temporary views.\n\n        Also, why does not either drop_relation or adapter.drop_relation work here?!\n        --#}\n      {%- endif -%}\n      {% if _configuration_changes is not none %}\n        {% set tags = _configuration_changes.changes.get(\"tags\", None) %}\n        {% set tblproperties = _configuration_changes.changes.get(\"tblproperties\", None) %}\n        {% set liquid_clustering = _configuration_changes.changes.get(\"liquid_clustering\") %}\n        {% if tags is not none %}\n          {% do apply_tags(target_relation, tags.set_tags) %}\n        {%- endif -%}\n        {% if tblproperties is not none %}\n          {% do apply_tblproperties(target_relation, tblproperties.tblproperties) %}\n        {%- endif -%}\n        {% if liquid_clustering is not none %}\n          {% do apply_liquid_clustered_cols(target_relation, liquid_clustering) %}\n        {% endif %}\n      {%- endif -%}\n      {% do persist_docs(target_relation, model, for_relation=True) %}\n    {%- endif -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% do optimize(target_relation) %}\n\n    {{ run_hooks(post_hooks) }}\n  {%- endif -%}\n\n  {%- if incremental_strategy == 'insert_overwrite' and not full_refresh -%}\n    {{ set_overwrite_mode('STATIC') }}\n  {%- endif -%}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.load_relation_with_metadata", "macro.dbt_databricks.get_incremental_strategy", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.make_intermediate_relation", "macro.dbt_databricks.make_staging_relation", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.statement", "macro.dbt_databricks.get_create_intermediate_table", "macro.dbt_databricks.create_table_at", "macro.dbt_databricks.safe_relation_replace", "macro.dbt_databricks.set_overwrite_mode", "macro.dbt.process_schema_changes", "macro.dbt_databricks.process_config_changes", "macro.dbt_databricks.get_build_sql", "macro.dbt_databricks.statement_with_staging_table", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.optimize", "macro.dbt.drop_relation_if_exists", "macro.dbt_databricks.run_post_hooks", "macro.dbt.make_temp_relation", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_databricks.persist_constraints", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt.persist_docs", "macro.dbt_databricks.apply_liquid_clustered_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6780396, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.set_overwrite_mode": {"name": "set_overwrite_mode", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.set_overwrite_mode", "macro_sql": "{% macro set_overwrite_mode(value) %}\n  {% if adapter.is_cluster() %}\n    {%- call statement('Setting partitionOverwriteMode: ' ~ value) -%}\n      set spark.sql.sources.partitionOverwriteMode = {{ value }}\n    {%- endcall -%}\n  {% else %}\n    {{ exceptions.warn(\"INSERT OVERWRITE is only properly supported on all-purpose clusters.  On SQL Warehouses, this strategy would be equivalent to using the table materialization.\") }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.678623, "supported_languages": null}, "macro.dbt_databricks.get_build_sql": {"name": "get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.get_build_sql", "macro_sql": "{% macro get_build_sql(incremental_strategy, target_relation, intermediate_relation) %}\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set incremental_predicates = config.get('predicates') or config.get('incremental_predicates') -%}\n  {%- set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) -%}\n  {%- set strategy_arg_dict = ({\n          'target_relation': target_relation,\n          'temp_relation': intermediate_relation,\n          'unique_key': unique_key,\n          'dest_columns': none,\n          'incremental_predicates': incremental_predicates}) -%}\n  {{ strategy_sql_macro_func(strategy_arg_dict) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6793642, "supported_languages": null}, "macro.dbt_databricks.process_config_changes": {"name": "process_config_changes", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.process_config_changes", "macro_sql": "{% macro process_config_changes(target_relation) %}\n  {% set apply_config_changes = config.get('incremental_apply_config_changes', True) | as_bool %}\n  {% if apply_config_changes %}\n    {%- set existing_config = adapter.get_relation_config(target_relation) -%}\n    {%- set model_config = adapter.get_config_from_model(config.model) -%}\n    {%- set configuration_changes = model_config.get_changeset(existing_config) -%}\n    {{ apply_config_changeset(target_relation, model, configuration_changes) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_config_changeset"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6800134, "supported_languages": null}, "macro.dbt_databricks.get_incremental_strategy": {"name": "get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_incremental_strategy", "macro_sql": "{% macro get_incremental_strategy(file_format) %}\n  {% set raw_strategy = config.get('incremental_strategy') or 'merge' %}\n  {% do return(dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6816914, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_default_sql": {"name": "databricks__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_default_sql", "macro_sql": "{% macro databricks__get_incremental_default_sql(arg_dict) %}\n  {{ return(get_incremental_merge_sql(arg_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6818562, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_append_sql": {"name": "databricks__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_append_sql", "macro_sql": "{% macro databricks__get_incremental_append_sql(arg_dict) %}\n  {% do return(get_insert_into_sql(arg_dict[\"temp_relation\"], arg_dict[\"target_relation\"])) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6820784, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_replace_where_sql": {"name": "databricks__get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_replace_where_sql", "macro_sql": "{% macro databricks__get_incremental_replace_where_sql(arg_dict) %}\n  {% do return(get_replace_where_sql(arg_dict)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6822422, "supported_languages": null}, "macro.dbt_databricks.get_incremental_replace_where_sql": {"name": "get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_incremental_replace_where_sql", "macro_sql": "{% macro get_incremental_replace_where_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_replace_where_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6824403, "supported_languages": null}, "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql": {"name": "databricks__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql", "macro_sql": "{% macro databricks__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) %}\n    {{ return(get_insert_overwrite_sql(source, target)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.682649, "supported_languages": null}, "macro.dbt_databricks.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation) %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) | map(attribute='quoted') | list -%}\n    {%- set source_columns = adapter.get_columns_in_relation(source_relation) | map(attribute='quoted') | list -%}\n    {%- set common_columns = [] -%}\n    {%- for dest_col in dest_columns -%}\n      {%- if dest_col in source_columns -%}\n        {%- do common_columns.append(dest_col) -%}\n      {%- else -%}\n        {%- do common_columns.append('DEFAULT') -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- set dest_cols_csv = dest_columns | join(', ') -%}\n    {%- set source_cols_csv = common_columns | join(', ') -%}\n    insert overwrite table {{ target_relation }}\n    {{ partition_cols(label=\"partition\") }}\n    select {{source_cols_csv}} from {{ source_relation }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.683577, "supported_languages": null}, "macro.dbt_databricks.get_replace_where_sql": {"name": "get_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_replace_where_sql", "macro_sql": "{% macro get_replace_where_sql(args_dict) -%}\n  {%- set predicates = args_dict['incremental_predicates'] -%}\n  {%- set target_relation = args_dict['target_relation'] -%}\n  {%- set temp_relation = args_dict['temp_relation'] -%}\nINSERT INTO {{ target_relation.render() }}\n{% if predicates %}\n  {% if predicates is sequence and predicates is not string %}\nREPLACE WHERE {{ predicates | join(' and ') }}\n  {% else %}\nREPLACE WHERE {{ predicates }}\n  {% endif %}\n{% endif %}\nTABLE {{ temp_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.684282, "supported_languages": null}, "macro.dbt_databricks.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n    {%- set source_columns = adapter.get_columns_in_relation(source_relation) | map(attribute=\"quoted\") | list -%}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) | map(attribute=\"quoted\") | list -%}\n    {{ insert_into_sql_impl(target_relation, dest_columns, source_relation, source_columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.insert_into_sql_impl"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6847072, "supported_languages": null}, "macro.dbt_databricks.insert_into_sql_impl": {"name": "insert_into_sql_impl", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.insert_into_sql_impl", "macro_sql": "{% macro insert_into_sql_impl(target_relation, dest_columns, source_relation, source_columns) %}\n    {%- set common_columns = [] -%}\n    {%- for dest_col in dest_columns -%}\n      {%- if dest_col in source_columns -%}\n        {%- do common_columns.append(dest_col) -%}\n      {%- else -%}\n        {%- do common_columns.append('DEFAULT') -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- set dest_cols_csv = dest_columns | join(', ') -%}\n    {%- set source_cols_csv = common_columns | join(', ') -%}\ninsert into table {{ target_relation }} ({{ dest_cols_csv }})\nselect {{source_cols_csv}} from {{ source_relation }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6853595, "supported_languages": null}, "macro.dbt_databricks.databricks__get_merge_sql": {"name": "databricks__get_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_merge_sql", "macro_sql": "{% macro databricks__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n\n  {%- set target_alias = config.get('target_alias', 'DBT_INTERNAL_DEST') -%}\n  {%- set source_alias = config.get('source_alias', 'DBT_INTERNAL_SOURCE') -%}\n\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set source_columns = (adapter.get_columns_in_relation(source) | map(attribute='quoted') | list)-%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set merge_with_schema_evolution = (config.get('merge_with_schema_evolution') | lower == 'true') -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n  {%- set skip_matched_step = (config.get('skip_matched_step') | lower == 'true') -%}\n  {%- set skip_not_matched_step = (config.get('skip_not_matched_step') | lower == 'true') -%}\n\n  {%- set matched_condition = config.get('matched_condition') -%}\n  {%- set not_matched_condition = config.get('not_matched_condition') -%}\n\n  {%- set not_matched_by_source_action = config.get('not_matched_by_source_action') -%}\n  {%- set not_matched_by_source_condition = config.get('not_matched_by_source_condition') -%}\n\n  {%- set not_matched_by_source_action_trimmed = not_matched_by_source_action | lower | trim(' \\n\\t') %}\n  {%- set not_matched_by_source_action_is_set = (\n      not_matched_by_source_action_trimmed == 'delete'\n      or not_matched_by_source_action_trimmed.startswith('update')\n    )\n  %}\n  \n  \n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  {{ source_alias }}.{{ key }} <=> {{ target_alias }}.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              {{ source_alias }}.{{ unique_key }} <=> {{ target_alias }}.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n    merge\n        {%- if merge_with_schema_evolution %}\n        with schema evolution\n        {%- endif %}\n    into\n        {{ target }} as {{ target_alias }}\n    using\n        {{ source }} as {{ source_alias }}\n    on\n        {{ predicates | join('\\n    and ') }}\n    {%- if not skip_matched_step %}\n    when matched\n        {%- if matched_condition %}\n        and ({{ matched_condition }})\n        {%- endif %}\n        then update set\n            {{ get_merge_update_set(update_columns, on_schema_change, source_columns, source_alias) }}\n    {%- endif %}\n    {%- if not skip_not_matched_step %}\n    when not matched\n        {%- if not_matched_condition %}\n        and ({{ not_matched_condition }})\n        {%- endif %}\n        then insert\n            {{ get_merge_insert(on_schema_change, source_columns, source_alias) }}\n    {%- endif %}\n    {%- if not_matched_by_source_action_is_set %}\n    when not matched by source\n        {%- if not_matched_by_source_condition %}\n        and ({{ not_matched_by_source_condition }})\n        {%- endif %}\n        then {{ not_matched_by_source_action }}\n    {%- endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.incremental_validate_on_schema_change", "macro.dbt.get_merge_update_columns", "macro.dbt_databricks.get_merge_update_set", "macro.dbt_databricks.get_merge_insert"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6886992, "supported_languages": null}, "macro.dbt_databricks.get_merge_update_set": {"name": "get_merge_update_set", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_merge_update_set", "macro_sql": "{% macro get_merge_update_set(update_columns, on_schema_change, source_columns, source_alias='DBT_INTERNAL_SOURCE') %}\n  {%- if update_columns -%}\n    {%- for column_name in update_columns -%}\n      {{ column_name }} = {{ source_alias }}.{{ column_name }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  {%- elif on_schema_change == 'ignore' -%}\n    *\n  {%- else -%}\n    {%- for column in source_columns -%}\n      {{ column }} = {{ source_alias }}.{{ column }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6893504, "supported_languages": null}, "macro.dbt_databricks.get_merge_insert": {"name": "get_merge_insert", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_merge_insert", "macro_sql": "{% macro get_merge_insert(on_schema_change, source_columns, source_alias='DBT_INTERNAL_SOURCE') %}\n  {%- if on_schema_change == 'ignore' -%}\n    *\n  {%- else -%}\n    ({{ source_columns | join(\", \") }}) VALUES (\n    {%- for column in source_columns -%}\n      {{ source_alias }}.{{ column }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %})\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6898031, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_microbatch_sql": {"name": "databricks__get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_microbatch_sql", "macro_sql": "{% macro databricks__get_incremental_microbatch_sql(arg_dict) %}\n  {%- set incremental_predicates = [] if arg_dict.get('incremental_predicates') is none else arg_dict.get('incremental_predicates') -%}\n  {%- set event_time = model.config.event_time -%}\n  {%- set start_time = config.get(\"__dbt_internal_microbatch_event_time_start\") -%}\n  {%- set end_time = config.get(\"__dbt_internal_microbatch_event_time_end\") -%}\n  {%- if start_time -%}\n    {%- do incremental_predicates.append(\"cast(\" ~ event_time ~ \" as TIMESTAMP) >= '\" ~ start_time ~ \"'\") -%}\n  {%- endif -%}\n  {%- if end_time -%}\n    {%- do incremental_predicates.append(\"cast(\" ~ event_time ~ \" as TIMESTAMP) < '\" ~ end_time ~ \"'\") -%}\n  {%- endif -%}\n  {%- do arg_dict.update({'incremental_predicates': incremental_predicates}) -%}\n  {{ return(get_replace_where_sql(arg_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6906672, "supported_languages": null}, "macro.dbt_databricks.databricks__can_clone_table": {"name": "databricks__can_clone_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/clone.sql", "original_file_path": "macros/materializations/clone/clone.sql", "unique_id": "macro.dbt_databricks.databricks__can_clone_table", "macro_sql": "{% macro databricks__can_clone_table() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6912513, "supported_languages": null}, "macro.dbt_databricks.materialization_clone_databricks": {"name": "materialization_clone_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/clone.sql", "original_file_path": "macros/materializations/clone/clone.sql", "unique_id": "macro.dbt_databricks.materialization_clone_databricks", "macro_sql": "\n\n\n{%- materialization clone, adapter='databricks' -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% if other_existing_relation.is_external_table %}\n          {% call statement('main') %}\n              {{ create_or_replace_clone_external(target_relation, defer_relation) }}\n          {% endcall %}\n      {% else %}\n          {% call statement('main') %}\n              {{ create_or_replace_clone(target_relation, defer_relation) }}\n          {% endcall %}\n      {% endif %}\n\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n  {% endif %}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt_databricks.create_or_replace_clone_external", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6938312, "supported_languages": ["sql"]}, "macro.dbt_databricks.databricks__create_or_replace_clone": {"name": "databricks__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/strategies.sql", "original_file_path": "macros/materializations/clone/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__create_or_replace_clone", "macro_sql": "{% macro databricks__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace\n    table {{ this_relation.render() }}\n    shallow clone {{ defer_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.694161, "supported_languages": null}, "macro.dbt_databricks.create_or_replace_clone_external": {"name": "create_or_replace_clone_external", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/strategies.sql", "original_file_path": "macros/materializations/clone/strategies.sql", "unique_id": "macro.dbt_databricks.create_or_replace_clone_external", "macro_sql": "{% macro create_or_replace_clone_external(this_relation, defer_relation) %}\n\n    {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n    create or replace\n    table {{ this_relation.render() }}\n    shallow clone {{ defer_relation.render() }}\n    {{ location_clause(catalog_relation) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.location_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6945608, "supported_languages": null}, "macro.dbt_databricks.databricks__list_relations_without_caching": {"name": "databricks__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__list_relations_without_caching", "macro_sql": "{% macro databricks__list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.get_relations_without_caching(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6953282, "supported_languages": null}, "macro.dbt_databricks.show_table_extended": {"name": "show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_table_extended", "macro_sql": "{% macro show_table_extended(schema_relation) %}\n  {{ return(adapter.dispatch('show_table_extended', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_table_extended"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6955314, "supported_languages": null}, "macro.dbt_databricks.databricks__show_table_extended": {"name": "databricks__show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_table_extended", "macro_sql": "{% macro databricks__show_table_extended(schema_relation) %}\n  {{ return(run_query_as(show_table_extended_sql(schema_relation), 'show_table_extended')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_table_extended_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6957788, "supported_languages": null}, "macro.dbt_databricks.show_table_extended_sql": {"name": "show_table_extended_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_table_extended_sql", "macro_sql": "{% macro show_table_extended_sql(schema_relation) %}\nSHOW TABLE EXTENDED IN {{ schema_relation.without_identifier()|lower }} LIKE '{{ schema_relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6959848, "supported_languages": null}, "macro.dbt_databricks.show_tables": {"name": "show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_tables", "macro_sql": "{% macro show_tables(relation) %}\n  {{ return(adapter.dispatch('show_tables', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_tables"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6961854, "supported_languages": null}, "macro.dbt_databricks.databricks__show_tables": {"name": "databricks__show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_tables", "macro_sql": "{% macro databricks__show_tables(relation) %}\n  {{ return(run_query_as(show_tables_sql(relation), 'show_tables')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_tables_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.696373, "supported_languages": null}, "macro.dbt_databricks.show_tables_sql": {"name": "show_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_tables_sql", "macro_sql": "{% macro show_tables_sql(relation) %}\nSHOW TABLES IN {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6965077, "supported_languages": null}, "macro.dbt_databricks.show_views": {"name": "show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_views", "macro_sql": "{% macro show_views(relation) %}\n  {{ return(adapter.dispatch('show_views', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_views"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6967013, "supported_languages": null}, "macro.dbt_databricks.databricks__show_views": {"name": "databricks__show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_views", "macro_sql": "{% macro databricks__show_views(relation) %}\n  {{ return(run_query_as(show_views_sql(relation), 'show_views')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_views_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6968846, "supported_languages": null}, "macro.dbt_databricks.show_views_sql": {"name": "show_views_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_views_sql", "macro_sql": "{% macro show_views_sql(relation) %}\nSHOW VIEWS IN {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.697021, "supported_languages": null}, "macro.dbt_databricks.databricks__get_relation_last_modified": {"name": "databricks__get_relation_last_modified", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__get_relation_last_modified", "macro_sql": "{% macro databricks__get_relation_last_modified(information_schema, relations) -%}\n  {% call statement('last_modified', fetch_result=True) %}\n    {{ get_relation_last_modified_sql(information_schema, relations) }}\n  {% endcall %}\n  {{ return(load_result('last_modified')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_relation_last_modified_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.697359, "supported_languages": null}, "macro.dbt_databricks.get_relation_last_modified_sql": {"name": "get_relation_last_modified_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_relation_last_modified_sql", "macro_sql": "{% macro get_relation_last_modified_sql(information_schema, relations) %}\n  {% if information_schema.is_hive_metastore() %}\n    {%- for relation in relations -%}\nSELECT\n  '{{ relation.schema }}' AS schema,\n  '{{ relation.identifier }}' AS identifier,\n  max(timestamp) AS last_modified,\n  {{ current_timestamp() }} AS snapshotted_at\n  FROM (DESCRIBE HISTORY {{ relation.schema|lower }}.{{ relation.identifier|lower }})\n      {% if not loop.last %}\nUNION ALL\n      {% endif %}\n    {%- endfor -%}\n  {% else %}\nSELECT\n  table_schema AS schema,\n  table_name AS identifier,\n  last_altered AS last_modified,\n  {{ current_timestamp() }} AS snapshotted_at\nFROM `system`.`information_schema`.`tables`\nWHERE table_catalog = '{{ information_schema.database|lower }}'\n  AND (\n    {%- for relation in relations -%}\n    (table_schema = '{{ relation.schema|lower }}' AND\n    table_name = '{{ relation.identifier|lower }}'){%- if not loop.last %} OR {% endif -%}\n    {%- endfor -%}\n  )\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.698147, "supported_languages": null}, "macro.dbt_databricks.get_view_description": {"name": "get_view_description", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_view_description", "macro_sql": "{% macro get_view_description(relation) %}\n  {{ return(run_query_as(get_view_description_sql(relation), 'get_view_description')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_view_description_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6983461, "supported_languages": null}, "macro.dbt_databricks.get_view_description_sql": {"name": "get_view_description_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_view_description_sql", "macro_sql": "{% macro get_view_description_sql(relation) %}\nSELECT *\nFROM `system`.`information_schema`.`views`\nWHERE table_catalog = '{{ relation.database|lower }}'\n  AND table_schema = '{{ relation.schema|lower }}'\n  AND table_name = '{{ relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6985624, "supported_languages": null}, "macro.dbt_databricks.get_uc_tables": {"name": "get_uc_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_uc_tables", "macro_sql": "{% macro get_uc_tables(relation) %}\n  {{ return(run_query_as(get_uc_tables_sql(relation), 'get_uc_tables')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_uc_tables_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.698748, "supported_languages": null}, "macro.dbt_databricks.get_uc_tables_sql": {"name": "get_uc_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_uc_tables_sql", "macro_sql": "{% macro get_uc_tables_sql(relation) %}\nSELECT\n  table_name,\n  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,\n  lower(data_source_format) AS file_format,\n  table_owner,\n  if(\n    table_type IN (\n      'EXTERNAL',\n      'MANAGED',\n      'MANAGED_SHALLOW_CLONE',\n      'EXTERNAL_SHALLOW_CLONE'\n    ),\n    lower(table_type),\n    NULL\n  ) AS databricks_table_type\nFROM `system`.`information_schema`.`tables`\nWHERE table_catalog = '{{ relation.database|lower }}' \n  AND table_schema = '{{ relation.schema|lower }}'\n  {%- if relation.identifier %}\n  AND table_name = '{{ relation.identifier|lower }}'\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.6990569, "supported_languages": null}, "macro.dbt_databricks.make_staging_relation": {"name": "make_staging_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.make_staging_relation", "macro_sql": "{% macro make_staging_relation(base_relation, suffix='__dbt_stg', type='table') %}\n  {% set unique_tmp_table_suffix = config.get('unique_tmp_table_suffix', False) | as_bool %}\n  {% if unique_tmp_table_suffix %}\n    {% set suffix = adapter.generate_unique_temporary_table_suffix(suffix) %}\n  {% endif %}\n  {% set stg_identifier = base_relation.identifier ~ suffix %}\n  {% set stg_relation = api.Relation.create(database=base_relation.database, schema=base_relation.schema, identifier=stg_identifier, type=type) %}\n  {% do return(stg_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.70022, "supported_languages": null}, "macro.dbt_databricks.databricks__make_intermediate_relation": {"name": "databricks__make_intermediate_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__make_intermediate_relation", "macro_sql": "{% macro databricks__make_intermediate_relation(base_relation, suffix) %}\n    {{ return(databricks__make_temp_relation(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.700416, "supported_languages": null}, "macro.dbt_databricks.databricks__make_temp_relation": {"name": "databricks__make_temp_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__make_temp_relation", "macro_sql": "{% macro databricks__make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {% set unique_tmp_table_suffix = config.get('unique_tmp_table_suffix', False) | as_bool %}\n\n  {% if unique_tmp_table_suffix %}\n    {% set suffix = adapter.generate_unique_temporary_table_suffix() %}\n  {% endif %}\n  \n  {% if suffix == '__dbt_tmp' and model.batch %}\n    {% set suffix = suffix ~ '_' ~ model.batch.id %}\n  {% endif %}\n\n  {% set tmp_identifier = base_relation.identifier ~ suffix %}\n  {% set language = model['language'] %}\n  {%- if language == 'sql' -%}\n    {% set temporary = not base_relation.is_hive_metastore() %}\n    {% set tmp_relation = api.Relation.create(identifier=tmp_identifier, type='view', temporary=temporary) %}\n  {%- else -%}\n    {% set tmp_relation = api.Relation.create(database=base_relation.database, schema=base_relation.schema, identifier=tmp_identifier, type='table') %}\n  {%- endif -%}\n  {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7016106, "supported_languages": null}, "macro.dbt_databricks.databricks__get_or_create_relation": {"name": "databricks__get_or_create_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__get_or_create_relation", "macro_sql": "{% macro databricks__get_or_create_relation(database, schema, identifier, type, needs_information=False) %}\n  {%- set target_relation = adapter.get_relation(\n            database=database,\n            schema=schema,\n            identifier=identifier,\n            needs_information=needs_information) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type,\n      temporary=False\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7022827, "supported_languages": null}, "macro.dbt_databricks.get_column_and_constraints_sql": {"name": "get_column_and_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.get_column_and_constraints_sql", "macro_sql": "{% macro get_column_and_constraints_sql(relation, columns) %}\n  (\n    {% for column in columns %}\n      {{ column.render_for_create() }}{% if not loop.last or relation.create_constraints %},{% endif %}\n    {% endfor %}\n    {% if relation.create_constraints %}\n      {{ relation.render_constraints_for_create() }}\n    {% endif %}\n  )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7027051, "supported_languages": null}, "macro.dbt_databricks.load_relation_with_metadata": {"name": "load_relation_with_metadata", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.load_relation_with_metadata", "macro_sql": "{% macro load_relation_with_metadata(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier,\n    needs_information=True\n  )) -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7029698, "supported_languages": null}, "macro.dbt_databricks.current_catalog": {"name": "current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.current_catalog", "macro_sql": "{% macro current_catalog() -%}\n  {{ return(adapter.dispatch('current_catalog', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__current_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.703336, "supported_languages": null}, "macro.dbt_databricks.databricks__current_catalog": {"name": "databricks__current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.databricks__current_catalog", "macro_sql": "{% macro databricks__current_catalog() -%}\n  {{ return(run_query_as(current_catalog_sql(), 'current_catalog')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.current_catalog_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7035043, "supported_languages": null}, "macro.dbt_databricks.current_catalog_sql": {"name": "current_catalog_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.current_catalog_sql", "macro_sql": "{% macro current_catalog_sql() %}\nSELECT current_catalog()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.70359, "supported_languages": null}, "macro.dbt_databricks.use_catalog": {"name": "use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.use_catalog", "macro_sql": "{% macro use_catalog(catalog) -%}\n  {{ adapter.dispatch('use_catalog', 'dbt')(catalog) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__use_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7038193, "supported_languages": null}, "macro.dbt_databricks.databricks__use_catalog": {"name": "databricks__use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.databricks__use_catalog", "macro_sql": "{% macro databricks__use_catalog(catalog) -%}\n  {{ run_query_as(use_catalog_sql(catalog), 'use_catalog', fetch_result=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.use_catalog_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7040217, "supported_languages": null}, "macro.dbt_databricks.use_catalog_sql": {"name": "use_catalog_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.use_catalog_sql", "macro_sql": "{% macro use_catalog_sql(catalog) %}\nUSE CATALOG {{ adapter.quote(catalog)|lower }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7041805, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog": {"name": "databricks__get_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog", "macro_sql": "{% macro databricks__get_catalog(information_schema, schemas) -%}\n  {% set query %}\nWITH tables AS (\n  {{ databricks__get_catalog_tables_sql(information_schema) }}\n  {{ databricks__get_catalog_schemas_where_clause_sql(information_schema.database, schemas) }}\n),\ncolumns AS (\n  {{ databricks__get_catalog_columns_sql(information_schema) }}\n  {{ databricks__get_catalog_schemas_where_clause_sql(information_schema.database, schemas) }}\n)\n{{ databricks__get_catalog_results_sql() }}\n  {%- endset -%}\n\n  {{ return(run_query_as(query, 'get_catalog')) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql", "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.705023, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_relations": {"name": "databricks__get_catalog_relations", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_relations", "macro_sql": "{% macro databricks__get_catalog_relations(information_schema, relations) -%}\n  {% set query %}\nWITH tables AS (\n  {{ databricks__get_catalog_tables_sql(information_schema) }}\n  {{ databricks__get_catalog_relations_where_clause_sql(information_schema.database, relations) }}\n),\ncolumns AS (\n  {{ databricks__get_catalog_columns_sql(information_schema) }}\n  {{ databricks__get_catalog_relations_where_clause_sql(information_schema.database, relations) }}\n)\n{{ databricks__get_catalog_results_sql() }}\n  {%- endset -%}\n\n  {{ return(run_query_as(query, 'get_catalog_relations')) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql", "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7055092, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_tables_sql": {"name": "databricks__get_catalog_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro_sql": "{% macro databricks__get_catalog_tables_sql(information_schema) -%}\nSELECT\n  table_catalog AS table_database,\n  table_schema,\n  table_name,\n  lower(table_type) AS table_type,\n  comment AS table_comment,\n  table_owner,\n  'Last Modified' AS `stats:last_modified:label`,\n  last_altered AS `stats:last_modified:value`,\n  'The timestamp for last update/change' AS `stats:last_modified:description`,\n  (last_altered IS NOT NULL AND table_type NOT ILIKE '%VIEW%') AS `stats:last_modified:include`\nFROM `system`.`information_schema`.`tables`\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.705635, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_columns_sql": {"name": "databricks__get_catalog_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro_sql": "{% macro databricks__get_catalog_columns_sql(information_schema) -%}\nSELECT\n  table_catalog AS table_database,\n  table_schema,\n  table_name,\n  column_name,\n  ordinal_position AS column_index,\n  lower(full_data_type) AS column_type,\n  comment AS column_comment\nFROM `system`.`information_schema`.`columns`\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7057467, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_results_sql": {"name": "databricks__get_catalog_results_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro_sql": "{% macro databricks__get_catalog_results_sql() -%}\nSELECT *\nFROM tables\nJOIN columns USING (table_database, table_schema, table_name)\nORDER BY column_index\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7058506, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql": {"name": "databricks__get_catalog_schemas_where_clause_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql", "macro_sql": "{% macro databricks__get_catalog_schemas_where_clause_sql(catalog, schemas) -%}\nWHERE table_catalog = '{{ catalog|lower }}' AND (\n  {%- for relation in schemas -%}\n  table_schema = '{{ relation[1]|lower }}'{%- if not loop.last %} OR {% endif -%}\n  {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.706175, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql": {"name": "databricks__get_catalog_relations_where_clause_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql", "macro_sql": "{% macro databricks__get_catalog_relations_where_clause_sql(catalog, relations) -%}\nWHERE table_catalog = '{{ catalog|lower }}' AND (\n  {%- for relation in relations -%}\n    {%- if relation.schema and relation.identifier %}\n  (\n    table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n  )\n    {%- elif relation.schema %}\n  (\n    table_schema = '{{ relation.schema|lower }}'\n  )\n    {% else %}\n      {% do exceptions.raise_compiler_error(\n        '`get_catalog_relations` requires a list of relations, each with a schema'\n      ) %}\n    {% endif %}\n    {%- if not loop.last %} OR {% endif -%}\n  {%- endfor -%}\n)\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7067752, "supported_languages": null}, "macro.dbt_databricks.databricks_copy_into": {"name": "databricks_copy_into", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/copy_into.sql", "original_file_path": "macros/adapters/copy_into.sql", "unique_id": "macro.dbt_databricks.databricks_copy_into", "macro_sql": "{% macro databricks_copy_into(\n  target_table,\n  source,\n  file_format,\n  expression_list=none,\n  source_credential=none,\n  source_encryption=none,\n  validate=none,\n  files=none,\n  pattern=none,\n  format_options=none,\n  copy_options=none) -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n        database=target.database,\n        schema=target.schema,\n        identifier=target_table,\n        type='table') -%}\n\n  {%- set source_clause -%}\n    {%- if expression_list -%}\n      ( select {{ expression_list }} from '{{ source }}' )\n    {%- else -%}\n      '{{ source }}'\n    {%- endif -%}\n    {%- if source_credential or source_encryption %}\n      WITH (\n      {%- if source_credential %}\n        credential (\n          {%- for name in source_credential -%}\n            '{{ name }}' = '{{ source_credential[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      {%- if source_encryption %}\n        encryption (\n          {%- for name in source_encryption -%}\n            '{{ name }}' = '{{ source_encryption[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      )\n    {%- endif -%}\n  {%- endset -%}\n\n  {% set query %}\n    copy into {{ target_relation }}\n    from {{ source_clause }}\n    fileformat = {{ file_format }}\n    {% if validate -%} validate {{ validate }} {%- endif %}\n    {% if files and pattern %}\n        {{ exceptions.raise_compiler_error(\"You can only specify one of 'files' or 'pattern'\") }}\n    {% endif %}\n    {% if files -%}\n      files = (\n        {%- for file in files -%}\n          '{{ file }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if pattern -%}\n        pattern = '{{ pattern }}'\n    {%- endif %}\n    {% if format_options -%}\n      format_options (\n        {%- for key in format_options -%}\n          '{{ key }}' = '{{ format_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if copy_options -%}\n      copy_options (\n        {%- for key in copy_options -%}\n          '{{ key }}' = '{{ copy_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n  {% endset %}\n\n  {{ run_query_as(query, 'copy_into', fetch_result=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7096996, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_comment": {"name": "databricks__alter_column_comment", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_comment", "macro_sql": "{% macro databricks__alter_column_comment(relation, column_dict) %}\n  {% set file_format = config.get('file_format', default='delta') %}\n  {% if file_format in ['delta', 'hudi'] %}\n    {% for column in column_dict.values() %}\n      {% set comment = column['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set column_path = relation.render() ~ '.' ~ api.Column.get_name(column) %}\n      {{ run_query_as(comment_on_column_sql(column_path, escaped_comment), 'alter_column_comment', fetch_result=False) }}\n    {% endfor %}\n  {% else %}\n    {{ log('WARNING - requested to update column comments, but file format ' ~ file_format ~ ' does not support that.') }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.comment_on_column_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7109435, "supported_languages": null}, "macro.dbt_databricks.comment_on_column_sql": {"name": "comment_on_column_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.comment_on_column_sql", "macro_sql": "{% macro comment_on_column_sql(column_path, escaped_comment) %}\nCOMMENT ON COLUMN {{ column_path }} IS '{{ escaped_comment }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.711112, "supported_languages": null}, "macro.dbt_databricks.databricks__persist_docs": {"name": "databricks__persist_docs", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.databricks__persist_docs", "macro_sql": "{% macro databricks__persist_docs(relation, model, for_relation, for_columns) -%}\n  {%- if for_relation and config.persist_relation_docs() and model.description %}\n    {{ run_query_as(alter_relation_comment_sql(relation, model.description), 'alter_relation_comment', fetch_result=False) }}\n  {% endif %}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {%- set existing_columns = adapter.get_columns_in_relation(relation) -%}\n    {%- set columns_to_persist_docs = adapter.get_persist_doc_columns(existing_columns, model.columns) -%}\n    {{ alter_column_comment(relation, columns_to_persist_docs) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.alter_relation_comment_sql", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7118225, "supported_languages": null}, "macro.dbt_databricks.alter_relation_comment_sql": {"name": "alter_relation_comment_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.alter_relation_comment_sql", "macro_sql": "{% macro alter_relation_comment_sql(relation, description) %}\nCOMMENT ON {{ relation.type.upper() }} {{ relation.render() }} IS '{{ description | replace(\"'\", \"\\\\'\") }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7121024, "supported_languages": null}, "macro.dbt_databricks.alter_column_comments": {"name": "alter_column_comments", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.alter_column_comments", "macro_sql": "{% macro alter_column_comments(relation, column_dict) %}\n  {% for column, comment in column_dict.items() %}\n    {{ log('Updating comment for column ' ~ column ~ ' with comment ' ~ comment) }}\n    {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n    {% set column_path = relation.render() ~ '.' ~ column %}\n    {{ run_query_as(comment_on_column_sql(column_path, escaped_comment), 'main', fetch_result=False) }}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.comment_on_column_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7129955, "supported_languages": null}, "macro.dbt_databricks.databricks__py_write_table": {"name": "databricks__py_write_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.databricks__py_write_table", "macro_sql": "{% macro databricks__py_write_table(compiled_code, target_relation) %}\n{{ compiled_code }}\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\nimport pyspark\n\n{{ py_try_import('pyspark.sql.connect.dataframe', 'newer_pyspark_available') }}\n{{ py_try_import('pandas', 'pandas_available') }}\n{{ py_try_import('pyspark.pandas', 'pyspark_pandas_api_available') }}\n{{ py_try_import('databricks.koalas', 'koalas_available') }}\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\n\nif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    if pyspark_pandas_api_available:\n        df = pyspark.pandas.frame.DataFrame(df)\n    elif koalas_available:\n        df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif newer_pyspark_available and isinstance(df, pyspark.sql.connect.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n    df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n    df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    df = spark.createDataFrame(df)\nelse:\n    msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n    raise Exception(msg)\n\nwriter = (\n    df.write\n        .mode(\"overwrite\")\n        .option(\"overwriteSchema\", \"true\")\n{{ py_get_writer_options()|indent(8, True) }}\n)\n\nwriter.saveAsTable(\"{{ target_relation }}\")\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.py_try_import", "macro.dbt_databricks.py_get_writer_options"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7161455, "supported_languages": null}, "macro.dbt_databricks.py_get_writer_options": {"name": "py_get_writer_options", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.py_get_writer_options", "macro_sql": "\n\n{%- macro py_get_writer_options() -%}\n{%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n{%- set file_format = config.get('file_format', validator=validation.any[basestring])|default('delta', true) -%}\n{%- set partition_by = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n{%- set liquid_clustered_by = config.get('liquid_clustered_by', validator=validation.any[list, basestring]) -%}\n{%- set clustered_by = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n{%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n.format(\"{{ file_format }}\")\n{%- if location_root is not none %}\n{%- set model_path = adapter.compute_external_path(config, model, is_incremental()) %}\n.option(\"path\", \"{{ model_path }}\")\n{%- endif -%}\n{%- if partition_by is not none -%}\n    {%- if partition_by is string -%}\n        {%- set partition_by = [partition_by] -%}\n    {%- endif %}\n.partitionBy({{ partition_by }})\n{%- endif -%}\n{%- if liquid_clustered_by and not is_incremental() -%}\n    {%- if liquid_clustered_by is string -%}\n        {%- set liquid_clustered_by = [liquid_clustered_by] -%}\n    {%- endif %}\n.clusterBy({{ liquid_clustered_by }})\n{%- endif -%}\n{%- if (clustered_by is not none) and (buckets is not none) -%}\n    {%- if clustered_by is string -%}\n        {%- set clustered_by = [clustered_by] -%}\n    {%- endif %}\n.bucketBy({{ buckets }}, {{ clustered_by }})\n{%- endif -%}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.719834, "supported_languages": null}, "macro.dbt_databricks.py_try_import": {"name": "py_try_import", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.py_try_import", "macro_sql": "{% macro py_try_import(library, var_name) -%}\n# make sure {{ library }} exists before using it\ntry:\n    import {{ library }}\n    {{ var_name }} = True\nexcept ImportError:\n    {{ var_name }} = False\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7200878, "supported_languages": null}, "macro.dbt_databricks.create_python_intermediate_table": {"name": "create_python_intermediate_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.create_python_intermediate_table", "macro_sql": "{% macro create_python_intermediate_table(relation, compiled_code) %}\n{{ compiled_code }}\n\n{%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n{%- set file_format = config.get('file_format', validator=validation.any[basestring])|default('delta', true) -%}\n\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\nimport pyspark\n\n{{ py_try_import('pyspark.sql.connect.dataframe', 'newer_pyspark_available') }}\n{{ py_try_import('pandas', 'pandas_available') }}\n{{ py_try_import('pyspark.pandas', 'pyspark_pandas_api_available') }}\n{{ py_try_import('databricks.koalas', 'koalas_available') }}\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\n\nif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    if pyspark_pandas_api_available:\n        df = pyspark.pandas.frame.DataFrame(df)\n    elif koalas_available:\n        df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif newer_pyspark_available and isinstance(df, pyspark.sql.connect.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n    df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n    df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    df = spark.createDataFrame(df)\nelse:\n    msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n    raise Exception(msg)\n\nwriter = (\n    df.write\n        .mode(\"overwrite\")\n        .option(\"overwriteSchema\", \"true\")\n        .format(\"{{ file_format }}\")\n{%- if location_root is not none -%}\n{%- set model_path = adapter.compute_external_path(config, model, True) %}\n        .option(\"path\", \"{{ model_path }}\")\n{%- endif -%}\n)\n\nwriter.saveAsTable(\"{{ relation.render() }}\")\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.py_try_import"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7212417, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments": {"name": "get_columns_comments", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments", "macro_sql": "{% macro get_columns_comments(relation) -%}\n  {{ return(run_query_as(get_columns_comments_sql(relation), 'get_columns_comments')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_columns_comments_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.721861, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_sql": {"name": "get_columns_comments_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_sql", "macro_sql": "{% macro get_columns_comments_sql(relation) %}\nDESCRIBE TABLE {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7220278, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_as_json": {"name": "get_columns_comments_as_json", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_as_json", "macro_sql": "{% macro get_columns_comments_as_json(relation) -%}\n  {{ return(run_query_as(get_columns_comments_as_json_sql(relation), 'get_columns_comments_as_json')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_columns_comments_as_json_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7222438, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_as_json_sql": {"name": "get_columns_comments_as_json_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_as_json_sql", "macro_sql": "{% macro get_columns_comments_as_json_sql(relation) %}\n  DESCRIBE TABLE EXTENDED {{ relation.render() }} AS JSON\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.722402, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_via_information_schema": {"name": "get_columns_comments_via_information_schema", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_via_information_schema", "macro_sql": "{% macro get_columns_comments_via_information_schema(relation) -%}\n  {{ run_query_as(repair_table_sql(relation), 'repair_table', fetch_result=False) }}\n  {{ return(run_query_as(get_columns_comments_via_information_schema_sql(relation), 'get_columns_comments_via_information_schema')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.repair_table_sql", "macro.dbt_databricks.get_columns_comments_via_information_schema_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7227442, "supported_languages": null}, "macro.dbt_databricks.repair_table_sql": {"name": "repair_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.repair_table_sql", "macro_sql": "{% macro repair_table_sql(relation) %}\nREPAIR TABLE {{ relation.render() }} SYNC METADATA\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7228818, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_via_information_schema_sql": {"name": "get_columns_comments_via_information_schema_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_via_information_schema_sql", "macro_sql": "{% macro get_columns_comments_via_information_schema_sql(relation) %}\nSELECT\n  column_name,\n  full_data_type,\n  comment\nFROM `system`.`information_schema`.`columns`\nWHERE\n  table_catalog = '{{ relation.database|lower }}' and\n  table_schema = '{{ relation.schema|lower }}' and \n  table_name = '{{ relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.723104, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_relation_add_remove_columns": {"name": "databricks__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.databricks__alter_relation_add_remove_columns", "macro_sql": "{% macro databricks__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n  {% if remove_columns %}\n    {{ run_query_as(drop_columns_sql(relation, remove_columns), 'alter_relation_remove_columns', fetch_result=False) }}\n  {% endif %}\n\n  {% if add_columns %}\n    {{ run_query_as(add_columns_sql(relation, add_columns), 'alter_relation_add_columns', fetch_result=False) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.drop_columns_sql", "macro.dbt_databricks.add_columns_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7238343, "supported_languages": null}, "macro.dbt_databricks.drop_columns_sql": {"name": "drop_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.drop_columns_sql", "macro_sql": "{% macro drop_columns_sql(relation, remove_columns) %}\nALTER TABLE {{ relation.render() }} DROP COLUMNS ({{ api.Column.format_remove_column_list(remove_columns) }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7240508, "supported_languages": null}, "macro.dbt_databricks.add_columns_sql": {"name": "add_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.add_columns_sql", "macro_sql": "{% macro add_columns_sql(relation, add_columns) %}\nALTER TABLE {{ relation.render() }} ADD COLUMNS ({{ api.Column.format_add_column_list(add_columns) }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.72427, "supported_languages": null}, "macro.dbt_spark.spark__copy_grants": {"name": "spark__copy_grants", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__copy_grants", "macro_sql": "{% macro spark__copy_grants() %}\n\n    {% if config.materialized == 'view' %}\n        {#-- Spark views don't copy grants when they're replaced --#}\n        {{ return(False) }}\n\n    {% else %}\n      {#-- This depends on how we're replacing the table, which depends on its file format\n        -- Just play it safe by assuming that grants have been copied over, and need to be checked / possibly revoked\n        -- We can make this more efficient in the future\n      #}\n        {{ return(True) }}\n\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7249787, "supported_languages": null}, "macro.dbt_spark.spark__get_grant_sql": {"name": "spark__get_grant_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_grant_sql", "macro_sql": "\n\n\n{%- macro spark__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation }} to {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7252116, "supported_languages": null}, "macro.dbt_spark.spark__get_revoke_sql": {"name": "spark__get_revoke_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_revoke_sql", "macro_sql": "\n\n\n{%- macro spark__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation }} from {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7254338, "supported_languages": null}, "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement": {"name": "spark__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n\n{%- macro spark__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(False) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.72556, "supported_languages": null}, "macro.dbt_spark.spark__call_dcl_statements": {"name": "spark__call_dcl_statements", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__call_dcl_statements", "macro_sql": "{% macro spark__call_dcl_statements(dcl_statement_list) %}\n    {% for dcl_statement in dcl_statement_list %}\n        {% call statement('grant_or_revoke') %}\n            {{ dcl_statement }}\n        {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.72582, "supported_languages": null}, "macro.dbt_spark.tblproperties_clause": {"name": "tblproperties_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.tblproperties_clause", "macro_sql": "{% macro tblproperties_clause() %}\n  {{ return(adapter.dispatch('tblproperties_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7287717, "supported_languages": null}, "macro.dbt_spark.spark__tblproperties_clause": {"name": "spark__tblproperties_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__tblproperties_clause", "macro_sql": "{% macro spark__tblproperties_clause() -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- if tblproperties is not none %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7291968, "supported_languages": null}, "macro.dbt_spark.file_format_clause": {"name": "file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.file_format_clause", "macro_sql": "{% macro file_format_clause() %}\n  {{ return(adapter.dispatch('file_format_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__file_format_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.729388, "supported_languages": null}, "macro.dbt_spark.spark__file_format_clause": {"name": "spark__file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__file_format_clause", "macro_sql": "{% macro spark__file_format_clause() %}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7296762, "supported_languages": null}, "macro.dbt_spark.location_clause": {"name": "location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.location_clause", "macro_sql": "{% macro location_clause() %}\n  {{ return(adapter.dispatch('location_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__location_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7298558, "supported_languages": null}, "macro.dbt_spark.spark__location_clause": {"name": "spark__location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__location_clause", "macro_sql": "{% macro spark__location_clause() %}\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n    location '{{ location_root }}/{{ identifier }}'\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7302423, "supported_languages": null}, "macro.dbt_spark.options_clause": {"name": "options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.options_clause", "macro_sql": "{% macro options_clause() -%}\n  {{ return(adapter.dispatch('options_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__options_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.730419, "supported_languages": null}, "macro.dbt_spark.spark__options_clause": {"name": "spark__options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__options_clause", "macro_sql": "{% macro spark__options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7315898, "supported_languages": null}, "macro.dbt_spark.comment_clause": {"name": "comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.comment_clause", "macro_sql": "{% macro comment_clause() %}\n  {{ return(adapter.dispatch('comment_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7317855, "supported_languages": null}, "macro.dbt_spark.spark__comment_clause": {"name": "spark__comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__comment_clause", "macro_sql": "{% macro spark__comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {% endif %}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7323065, "supported_languages": null}, "macro.dbt_spark.partition_cols": {"name": "partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.partition_cols", "macro_sql": "{% macro partition_cols(label, required=false) %}\n  {{ return(adapter.dispatch('partition_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7325647, "supported_languages": null}, "macro.dbt_spark.spark__partition_cols": {"name": "spark__partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__partition_cols", "macro_sql": "{% macro spark__partition_cols(label, required=false) %}\n  {%- set cols = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7331588, "supported_languages": null}, "macro.dbt_spark.clustered_cols": {"name": "clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.clustered_cols", "macro_sql": "{% macro clustered_cols(label, required=false) %}\n  {{ return(adapter.dispatch('clustered_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__clustered_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7333913, "supported_languages": null}, "macro.dbt_spark.spark__clustered_cols": {"name": "spark__clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__clustered_cols", "macro_sql": "{% macro spark__clustered_cols(label, required=false) %}\n  {%- set cols = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n  {%- if (cols is not none) and (buckets is not none) %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    ) into {{ buckets }} buckets\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7341852, "supported_languages": null}, "macro.dbt_spark.fetch_tbl_properties": {"name": "fetch_tbl_properties", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.fetch_tbl_properties", "macro_sql": "{% macro fetch_tbl_properties(relation) -%}\n  {% call statement('list_properties', fetch_result=True) -%}\n    SHOW TBLPROPERTIES {{ relation }}\n  {% endcall %}\n  {% do return(load_result('list_properties').table) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.734471, "supported_languages": null}, "macro.dbt_spark.create_temporary_view": {"name": "create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.create_temporary_view", "macro_sql": "{% macro create_temporary_view(relation, compiled_code) -%}\n  {{ return(adapter.dispatch('create_temporary_view', 'dbt')(relation, compiled_code)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__create_temporary_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7346885, "supported_languages": null}, "macro.dbt_spark.spark__create_temporary_view": {"name": "spark__create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_temporary_view", "macro_sql": "{% macro spark__create_temporary_view(relation, compiled_code) -%}\n    create or replace temporary view {{ relation }} as\n      {{ compiled_code }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7348387, "supported_languages": null}, "macro.dbt_spark.spark__create_table_as": {"name": "spark__create_table_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_table_as", "macro_sql": "{%- macro spark__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'iceberg'] %}\n        create or replace table {{ relation }}\n      {% else %}\n        create table {{ relation }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {%- if contract_config.enforced -%}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause() }}\n      {{ options_clause() }}\n      {{ tblproperties_clause() }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause() }}\n      {{ comment_clause() }}\n\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_spark.file_format_clause", "macro.dbt_spark.options_clause", "macro.dbt_spark.tblproperties_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_spark.py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7360427, "supported_languages": null}, "macro.dbt_spark.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7362723, "supported_languages": null}, "macro.dbt_spark.spark__persist_constraints": {"name": "spark__persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_constraints", "macro_sql": "{% macro spark__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% if contract_config.enforced and config.get('file_format', 'delta') == 'delta' %}\n    {% do alter_table_add_constraints(relation, model.constraints) %}\n    {% do alter_column_set_constraints(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.alter_table_add_constraints", "macro.dbt_spark.alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7367132, "supported_languages": null}, "macro.dbt_spark.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7369344, "supported_languages": null}, "macro.dbt_spark.spark__alter_table_add_constraints": {"name": "spark__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_table_add_constraints", "macro_sql": "{% macro spark__alter_table_add_constraints(relation, constraints) %}\n  {% for constraint in constraints %}\n    {% if constraint.type == 'check' and not is_incremental() %}\n      {%- set constraint_hash = local_md5(column_name ~ \";\" ~ constraint.expression ~ \";\" ~ loop.index) -%}\n      {% call statement() %}\n        alter table {{ relation }} add constraint {{ constraint.name if constraint.name else constraint_hash }} check ({{ constraint.expression }});\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7375052, "supported_languages": null}, "macro.dbt_spark.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7377307, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_set_constraints": {"name": "spark__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_set_constraints", "macro_sql": "{% macro spark__alter_column_set_constraints(relation, column_dict) %}\n  {% for column_name in column_dict %}\n    {% set constraints = column_dict[column_name]['constraints'] %}\n    {% for constraint in constraints %}\n      {% if constraint.type != 'not_null' %}\n        {{ exceptions.warn('Invalid constraint for column ' ~ column_name ~ '. Only `not_null` is supported.') }}\n      {% else %}\n        {% set quoted_name = adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name %}\n        {% call statement() %}\n          alter table {{ relation }} change column {{ quoted_name }} set not null {{ constraint.expression or \"\" }};\n        {% endcall %}\n      {% endif %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7385387, "supported_languages": null}, "macro.dbt_spark.get_column_comment_sql": {"name": "get_column_comment_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_column_comment_sql", "macro_sql": "{% macro get_column_comment_sql(column_name, column_dict) -%}\n  {% if column_name in column_dict and column_dict[column_name][\"description\"] -%}\n    {% set escaped_description = column_dict[column_name][\"description\"] | replace(\"'\", \"\\\\'\") %}\n    {% set column_comment_clause = \"comment '\" ~ escaped_description ~ \"'\" %}\n  {%- endif -%}\n  {{ adapter.quote(column_name) }} {{ column_comment_clause }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7390227, "supported_languages": null}, "macro.dbt_spark.get_persist_docs_column_list": {"name": "get_persist_docs_column_list", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_persist_docs_column_list", "macro_sql": "{% macro get_persist_docs_column_list(model_columns, query_columns) %}\n  {% for column_name in query_columns %}\n    {{ get_column_comment_sql(column_name, model_columns) }}\n    {{- \", \" if not loop.last else \"\" }}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.get_column_comment_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7393172, "supported_languages": null}, "macro.dbt_spark.spark__create_view_as": {"name": "spark__create_view_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_view_as", "macro_sql": "{% macro spark__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {% if config.persist_column_docs() -%}\n    {% set model_columns = model.columns %}\n    {% set query_columns = get_columns_in_query(sql) %}\n    (\n    {{ get_persist_docs_column_list(model_columns, query_columns) }}\n    )\n  {% endif %}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {%- if contract_config.enforced -%}\n    {{ get_assert_columns_equivalent(sql) }}\n  {%- endif %}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query", "macro.dbt_spark.get_persist_docs_column_list", "macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.740071, "supported_languages": null}, "macro.dbt_spark.spark__create_schema": {"name": "spark__create_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_schema", "macro_sql": "{% macro spark__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{relation}}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7402868, "supported_languages": null}, "macro.dbt_spark.spark__drop_schema": {"name": "spark__drop_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_schema", "macro_sql": "{% macro spark__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation }} cascade\n  {%- endcall -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7404912, "supported_languages": null}, "macro.dbt_spark.get_columns_in_relation_raw": {"name": "get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_columns_in_relation_raw", "macro_sql": "{% macro get_columns_in_relation_raw(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation_raw', 'dbt')(relation)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation_raw"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7406864, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation_raw": {"name": "spark__get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation_raw", "macro_sql": "{% macro spark__get_columns_in_relation_raw(relation) -%}\n  {% call statement('get_columns_in_relation_raw', fetch_result=True) %}\n      describe extended {{ relation }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation_raw').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7410212, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation": {"name": "spark__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation", "macro_sql": "{% macro spark__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      describe extended {{ relation.include(schema=(schema is not none)) }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.741397, "supported_languages": null}, "macro.dbt_spark.spark__list_relations_without_caching": {"name": "spark__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_relations_without_caching", "macro_sql": "{% macro spark__list_relations_without_caching(relation) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    show table extended in {{ relation.schema }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7417397, "supported_languages": null}, "macro.dbt_spark.list_relations_show_tables_without_caching": {"name": "list_relations_show_tables_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.list_relations_show_tables_without_caching", "macro_sql": "{% macro list_relations_show_tables_without_caching(schema_relation) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('list_relations_without_caching_show_tables', fetch_result=True) -%}\n    show tables in {{ schema_relation.schema }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching_show_tables').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7420647, "supported_languages": null}, "macro.dbt_spark.describe_table_extended_without_caching": {"name": "describe_table_extended_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.describe_table_extended_without_caching", "macro_sql": "{% macro describe_table_extended_without_caching(table_name) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('describe_table_extended_without_caching', fetch_result=True) -%}\n    describe extended {{ table_name }}\n  {% endcall %}\n  {% do return(load_result('describe_table_extended_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7423754, "supported_languages": null}, "macro.dbt_spark.spark__list_schemas": {"name": "spark__list_schemas", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_schemas", "macro_sql": "{% macro spark__list_schemas(database) -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    show databases\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7426596, "supported_languages": null}, "macro.dbt_spark.spark__rename_relation": {"name": "spark__rename_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__rename_relation", "macro_sql": "{% macro spark__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    {% if not from_relation.type %}\n      {% do exceptions.raise_database_error(\"Cannot rename a relation with a blank type: \" ~ from_relation.identifier) %}\n    {% elif from_relation.type in ('table') %}\n        alter table {{ from_relation }} rename to {{ to_relation }}\n    {% elif from_relation.type == 'view' %}\n        alter view {{ from_relation }} rename to {{ to_relation }}\n    {% else %}\n      {% do exceptions.raise_database_error(\"Unknown type '\" ~ from_relation.type ~ \"' for relation: \" ~ from_relation.identifier) %}\n    {% endif %}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7433176, "supported_languages": null}, "macro.dbt_spark.spark__drop_relation": {"name": "spark__drop_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_relation", "macro_sql": "{% macro spark__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.743554, "supported_languages": null}, "macro.dbt_spark.spark__generate_database_name": {"name": "spark__generate_database_name", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__generate_database_name", "macro_sql": "{% macro spark__generate_database_name(custom_database_name=none, node=none) -%}\n  {% do return(None) %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7438002, "supported_languages": null}, "macro.dbt_spark.spark__persist_docs": {"name": "spark__persist_docs", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_docs", "macro_sql": "{% macro spark__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do alter_column_comment(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7441056, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_comment": {"name": "spark__alter_column_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_comment", "macro_sql": "{% macro spark__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'hudi', 'iceberg'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        {% if relation.is_iceberg %}\n          alter table {{ relation }} alter column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% else %}\n          alter table {{ relation }} change column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% endif %}\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7452095, "supported_languages": null}, "macro.dbt_spark.spark__make_temp_relation": {"name": "spark__make_temp_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__make_temp_relation", "macro_sql": "{% macro spark__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(path = {\n        \"identifier\": tmp_identifier\n    }) -%}\n\n    {%- set tmp_relation = tmp_relation.include(database=false, schema=false) -%}\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7456672, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_type": {"name": "spark__alter_column_type", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_type", "macro_sql": "{% macro spark__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter column {{ column_name }} type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.745928, "supported_languages": null}, "macro.dbt_spark.spark__alter_relation_add_remove_columns": {"name": "spark__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_relation_add_remove_columns", "macro_sql": "{% macro spark__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if remove_columns %}\n    {% if relation.is_delta %}\n      {% set platform_name = 'Delta Lake' %}\n    {% elif relation.is_iceberg %}\n      {% set platform_name = 'Iceberg' %}\n    {% else %}\n      {% set platform_name = 'Apache Spark' %}\n    {% endif %}\n    {{ exceptions.raise_compiler_error(platform_name + ' does not support dropping columns from tables') }}\n  {% endif %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation }}\n\n       {% if add_columns %} add columns {% endif %}\n            {% for column in add_columns %}\n               {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.746927, "supported_languages": null}, "macro.dbt_spark.spark__datediff": {"name": "spark__datediff", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_spark.spark__datediff", "macro_sql": "{% macro spark__datediff(first_date, second_date, datepart) %}\n\n    {%- if datepart in ['day', 'week', 'month', 'quarter', 'year'] -%}\n\n        {# make sure the dates are real, otherwise raise an error asap #}\n        {% set first_date = assert_not_null('date', first_date) %}\n        {% set second_date = assert_not_null('date', second_date) %}\n\n    {%- endif -%}\n\n    {%- if datepart == 'day' -%}\n\n        datediff({{second_date}}, {{first_date}})\n\n    {%- elif datepart == 'week' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(datediff({{second_date}}, {{first_date}})/7)\n            else ceil(datediff({{second_date}}, {{first_date}})/7)\n            end\n\n        -- did we cross a week boundary (Sunday)?\n        + case\n            when {{first_date}} < {{second_date}} and dayofweek({{second_date}}) < dayofweek({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofweek({{second_date}}) > dayofweek({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'month' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}})))\n            else ceil(months_between(date({{second_date}}), date({{first_date}})))\n            end\n\n        -- did we cross a month boundary?\n        + case\n            when {{first_date}} < {{second_date}} and dayofmonth({{second_date}}) < dayofmonth({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofmonth({{second_date}}) > dayofmonth({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'quarter' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}}))/3)\n            else ceil(months_between(date({{second_date}}), date({{first_date}}))/3)\n            end\n\n        -- did we cross a quarter boundary?\n        + case\n            when {{first_date}} < {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                < (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then 1\n            when {{first_date}} > {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                > (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then -1\n            else 0 end\n\n    {%- elif datepart == 'year' -%}\n\n        year({{second_date}}) - year({{first_date}})\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set divisor -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        case when {{first_date}} < {{second_date}}\n            then ceil((\n                {# make sure the timestamps are real, otherwise raise an error asap #}\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            else floor((\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            end\n\n            {% if datepart == 'millisecond' %}\n                + cast(date_format({{second_date}}, 'SSS') as int)\n                - cast(date_format({{first_date}}, 'SSS') as int)\n            {% endif %}\n\n            {% if datepart == 'microsecond' %}\n                {% set capture_str = '[0-9]{4}-[0-9]{2}-[0-9]{2}.[0-9]{2}:[0-9]{2}:[0-9]{2}.([0-9]{6})' %}\n                -- Spark doesn't really support microseconds, so this is a massive hack!\n                -- It will only work if the timestamp-string is of the format\n                -- 'yyyy-MM-dd-HH mm.ss.SSSSSS'\n                + cast(regexp_extract({{second_date}}, '{{capture_str}}', 1) as int)\n                - cast(regexp_extract({{first_date}}, '{{capture_str}}', 1) as int)\n            {% endif %}\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro datediff not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7506886, "supported_languages": null}, "macro.dbt_spark.spark__dateadd": {"name": "spark__dateadd", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_spark.spark__dateadd", "macro_sql": "{% macro spark__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {%- set clock_component -%}\n        {# make sure the dates + timestamps are real, otherwise raise an error asap #}\n        to_unix_timestamp({{ assert_not_null('to_timestamp', from_date_or_timestamp) }})\n        - to_unix_timestamp({{ assert_not_null('date', from_date_or_timestamp) }})\n    {%- endset -%}\n\n    {%- if datepart in ['day', 'week'] -%}\n\n        {%- set multiplier = 7 if datepart == 'week' else 1 -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                date_add(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ['month', 'quarter', 'year'] -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'month' -%} 1\n            {%- elif datepart == 'quarter' -%} 3\n            {%- elif datepart == 'year' -%} 12\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                add_months(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            {{ assert_not_null('to_unix_timestamp', from_date_or_timestamp) }}\n            + cast({{interval}} * {{multiplier}} as int)\n        )\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro dateadd not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7527368, "supported_languages": null}, "macro.dbt_spark.spark__concat": {"name": "spark__concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt_spark.spark__concat", "macro_sql": "{% macro spark__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7529511, "supported_languages": null}, "macro.dbt_spark.spark__date": {"name": "spark__date", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt_spark.spark__date", "macro_sql": "{% macro spark__date(year, month, day) -%}\n    {%- set dt = modules.datetime.date(year, month, day) -%}\n    {%- set iso_8601_formatted_date = dt.strftime('%Y-%m-%d') -%}\n    to_date('{{ iso_8601_formatted_date }}', 'yyyy-MM-dd')\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.753328, "supported_languages": null}, "macro.dbt_spark.spark__bool_or": {"name": "spark__bool_or", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt_spark.spark__bool_or", "macro_sql": "{% macro spark__bool_or(expression) -%}\n\n    max({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.753503, "supported_languages": null}, "macro.dbt_spark.spark__array_construct": {"name": "spark__array_construct", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt_spark.spark__array_construct", "macro_sql": "{% macro spark__array_construct(inputs, data_type) -%}\n    array( {{ inputs|join(' , ') }} )\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7537286, "supported_languages": null}, "macro.dbt_spark.assert_not_null": {"name": "assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.assert_not_null", "macro_sql": "{% macro assert_not_null(function, arg) -%}\n  {{ return(adapter.dispatch('assert_not_null', 'dbt')(function, arg)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7540429, "supported_languages": null}, "macro.dbt_spark.spark__assert_not_null": {"name": "spark__assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.spark__assert_not_null", "macro_sql": "{% macro spark__assert_not_null(function, arg) %}\n\n    coalesce({{function}}({{arg}}), nvl2({{function}}({{arg}}), assert_true({{function}}({{arg}}) is not null), null))\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.754274, "supported_languages": null}, "macro.dbt_spark.spark__split_part": {"name": "spark__split_part", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt_spark.spark__split_part", "macro_sql": "{% macro spark__split_part(string_text, delimiter_text, part_number) %}\n\n    {% set delimiter_expr %}\n\n        -- escape if starts with a special character\n        case when regexp_extract({{ delimiter_text }}, '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', {{ delimiter_text }})\n            else {{ delimiter_text }} end\n\n    {% endset %}\n\n    {% if part_number >= 0 %}\n\n        {% set split_part_expr %}\n\n        split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            )[({{ part_number - 1 if part_number > 0 else part_number }})]\n\n        {% endset %}\n\n    {% else %}\n\n        {% set split_part_expr %}\n\n        split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            )[(\n                length({{ string_text }})\n                - length(\n                    replace({{ string_text }},  {{ delimiter_text }}, '')\n                ) + 1 + {{ part_number }}\n            )]\n\n        {% endset %}\n\n    {% endif %}\n\n    {{ return(split_part_expr) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7551963, "supported_languages": null}, "macro.dbt_spark.spark__escape_single_quotes": {"name": "spark__escape_single_quotes", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt_spark.spark__escape_single_quotes", "macro_sql": "{% macro spark__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"\\\\'\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7554388, "supported_languages": null}, "macro.dbt_spark.spark__array_append": {"name": "spark__array_append", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt_spark.spark__array_append", "macro_sql": "{% macro spark__array_append(array, new_element) -%}\n    {{ array_concat(array, array_construct([new_element])) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.array_concat", "macro.dbt.array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7556734, "supported_languages": null}, "macro.dbt_spark.spark__current_timestamp": {"name": "spark__current_timestamp", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/timestamps.sql", "original_file_path": "macros/utils/timestamps.sql", "unique_id": "macro.dbt_spark.spark__current_timestamp", "macro_sql": "{% macro spark__current_timestamp() -%}\n    current_timestamp()\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7559447, "supported_languages": null}, "macro.dbt_spark.spark__safe_cast": {"name": "spark__safe_cast", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt_spark.spark__safe_cast", "macro_sql": "{% macro spark__safe_cast(field, type) %}\n{%- set field_clean = field.strip('\"').strip(\"'\") if (cast_from_string_unsupported_for(type) and field is string) else field -%}\ncast({{field_clean}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.cast_from_string_unsupported_for"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7564116, "supported_languages": null}, "macro.dbt_spark.cast_from_string_unsupported_for": {"name": "cast_from_string_unsupported_for", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt_spark.cast_from_string_unsupported_for", "macro_sql": "{% macro cast_from_string_unsupported_for(type) %}\n    {{ return(type.lower().startswith('struct') or type.lower().startswith('array') or type.lower().startswith('map')) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.756784, "supported_languages": null}, "macro.dbt_spark.spark__listagg": {"name": "spark__listagg", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt_spark.spark__listagg", "macro_sql": "{% macro spark__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n  {% if order_by_clause %}\n    {{ exceptions.warn(\"order_by_clause is not supported for listagg on Spark/Databricks\") }}\n  {% endif %}\n\n  {% set collect_list %} collect_list({{ measure }}) {% endset %}\n\n  {% set limited %} slice({{ collect_list }}, 1, {{ limit_num }}) {% endset %}\n\n  {% set collected = limited if limit_num else collect_list %}\n\n  {% set final %} array_join({{ collected }}, {{ delimiter_text }}) {% endset %}\n\n  {% do return(final) %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7575169, "supported_languages": null}, "macro.dbt_spark.spark__array_concat": {"name": "spark__array_concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt_spark.spark__array_concat", "macro_sql": "{% macro spark__array_concat(array_1, array_2) -%}\n    concat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7577593, "supported_languages": null}, "macro.dbt_spark.spark__any_value": {"name": "spark__any_value", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt_spark.spark__any_value", "macro_sql": "{% macro spark__any_value(expression) -%}\n    {#-- return any value (non-deterministic)  --#}\n    first({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7579472, "supported_languages": null}, "macro.dbt_spark.spark__can_clone_table": {"name": "spark__can_clone_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.spark__can_clone_table", "macro_sql": "{% macro spark__can_clone_table() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7585032, "supported_languages": null}, "macro.dbt_spark.spark__create_or_replace_clone": {"name": "spark__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.spark__create_or_replace_clone", "macro_sql": "{% macro spark__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace table {{ this_relation }} shallow clone {{ defer_relation }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.758663, "supported_languages": null}, "macro.dbt_spark.materialization_clone_spark": {"name": "materialization_clone_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.materialization_clone_spark", "macro_sql": "\n\n{%- materialization clone, adapter='spark' -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if file_format != 'delta' -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      shallow clone requires file_format be set to 'delta'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {%- elif other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% call statement('main') %}\n          {{ create_or_replace_clone(target_relation, defer_relation) }}\n      {% endcall %}\n\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n  {% endif %}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7613807, "supported_languages": ["sql"]}, "macro.dbt_spark.materialization_view_spark": {"name": "materialization_view_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_spark.materialization_view_spark", "macro_sql": "{% materialization view, adapter='spark' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7616253, "supported_languages": ["sql"]}, "macro.dbt_spark.materialization_table_spark": {"name": "materialization_table_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.materialization_table_spark", "macro_sql": "{% materialization table, adapter = 'spark', supported_languages=['sql', 'python'] %}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta or iceberg, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation is not none %}\n    {% set is_delta = (old_relation.is_delta and config.get('file_format', validator=validation.any[basestring]) == 'delta') %}\n    {% set is_iceberg = (old_relation.is_iceberg and config.get('file_format', validator=validation.any[basestring]) == 'iceberg') %}\n    {% set old_relation_type = old_relation.type %}\n  {% else %}\n    {% set is_delta = false %}\n    {% set is_iceberg = false %}\n    {% set old_relation_type = target_relation.type %}\n  {% endif %}\n\n  {% if not is_delta and not is_iceberg %}\n    {% set existing_relation = target_relation %}\n    {{ adapter.drop_relation(existing_relation.incorporate(type=old_relation_type)) }}\n  {% endif %}\n\n  -- build model\n  {%- call statement('main', language=language) -%}\n    {{ create_table_as(False, target_relation, compiled_code, language) }}\n  {%- endcall -%}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_spark.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.764173, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.py_write_table": {"name": "py_write_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_write_table", "macro_sql": "{% macro py_write_table(compiled_code, target_relation) %}\n{{ compiled_code }}\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\n# make sure pyspark exists in the namepace, for 7.3.x-scala2.12 it does not exist\nimport pyspark\n# make sure pandas exists before using it\ntry:\n  import pandas\n  pandas_available = True\nexcept ImportError:\n  pandas_available = False\n\n# make sure pyspark.pandas exists before using it\ntry:\n  import pyspark.pandas\n  pyspark_pandas_api_available = True\nexcept ImportError:\n  pyspark_pandas_api_available = False\n\n# make sure databricks.koalas exists before using it\ntry:\n  import databricks.koalas\n  koalas_available = True\nexcept ImportError:\n  koalas_available = False\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\nif pyspark_pandas_api_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = pyspark.pandas.frame.DataFrame(df)\nelif koalas_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n  pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n  df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n  df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = spark.createDataFrame(df)\nelse:\n  msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n  raise Exception(msg)\n\ndf.write.mode(\"overwrite\").format(\"{{ config.get('file_format', 'delta') }}\").option(\"overwriteSchema\", \"true\").saveAsTable(\"{{ target_relation }}\")\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7645237, "supported_languages": null}, "macro.dbt_spark.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n# how to execute python model in notebook\n# dbt = dbtObj(spark.table)\n# df = model(dbt, spark)\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.764618, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_hash_arguments": {"name": "spark__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_hash_arguments", "macro_sql": "{% macro spark__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as string ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7659688, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_string_as_time": {"name": "spark__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_string_as_time", "macro_sql": "{% macro spark__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7661812, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_merge_sql": {"name": "spark__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_merge_sql", "macro_sql": "{% macro spark__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    {% if target.is_iceberg %}\n      {# create view only supports a name (no catalog, or schema) #}\n      using {{ source.identifier }} as DBT_INTERNAL_SOURCE\n    {% else %}\n      using {{ source }} as DBT_INTERNAL_SOURCE\n    {% endif %}\n    on DBT_INTERNAL_SOURCE.{{ columns.dbt_scd_id }} = DBT_INTERNAL_DEST.{{ columns.dbt_scd_id }}\n    when matched\n     {% if config.get(\"dbt_valid_to_current\") %}\n       and ( DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} = {{ config.get('dbt_valid_to_current') }} or\n             DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null )\n     {% else %}\n       and DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null\n     {% endif %}\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set {{ columns.dbt_valid_to }} = DBT_INTERNAL_SOURCE.{{ columns.dbt_valid_to }}\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert *\n    ;\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7669399, "supported_languages": null}, "macro.dbt_spark.spark_build_snapshot_staging_table": {"name": "spark_build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark_build_snapshot_staging_table", "macro_sql": "{% macro spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n\n    {% if target_relation.is_iceberg %}\n      {# iceberg catalog does not support create view, but regular spark does. We removed the catalog and schema #}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=none,\n                                                    database=none,\n                                                    type='view') -%}\n    {% else %}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=target_relation.schema,\n                                                    database=none,\n                                                    type='view') -%}\n    {% endif %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7678275, "supported_languages": null}, "macro.dbt_spark.spark__post_snapshot": {"name": "spark__post_snapshot", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__post_snapshot", "macro_sql": "{% macro spark__post_snapshot(staging_relation) %}\n    {% do adapter.drop_relation(staging_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.767996, "supported_languages": null}, "macro.dbt_spark.spark__create_columns": {"name": "spark__create_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__create_columns", "macro_sql": "{% macro spark__create_columns(relation, columns) %}\n    {% if columns|length > 0 %}\n    {% call statement() %}\n      alter table {{ relation }} add columns (\n        {% for column in columns %}\n          `{{ column.name }}` {{ column.data_type }} {{- ',' if not loop.last -}}\n        {% endfor %}\n      );\n    {% endcall %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7684488, "supported_languages": null}, "macro.dbt_spark.materialization_snapshot_spark": {"name": "materialization_snapshot_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.materialization_snapshot_spark", "macro_sql": "{% materialization snapshot, adapter='spark' %}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format') or 'parquet' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=none,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if file_format not in ['delta', 'iceberg', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'iceberg' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_iceberg and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'iceberg' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.schema) %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.valid_snapshot_target(target_relation, columns) }}\n\n      {% set staging_table = spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.create_schema", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt_spark.spark_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.773523, "supported_languages": ["sql"]}, "macro.dbt_spark.spark__get_binding_char": {"name": "spark__get_binding_char", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__get_binding_char", "macro_sql": "{% macro spark__get_binding_char() %}\n  {{ return('?' if target.method == 'odbc' else '%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7742984, "supported_languages": null}, "macro.dbt_spark.spark__reset_csv_table": {"name": "spark__reset_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__reset_csv_table", "macro_sql": "{% macro spark__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n        {{ adapter.drop_relation(old_relation) }}\n    {% endif %}\n    {% set sql = create_csv_table(model, agate_table) %}\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7746763, "supported_languages": null}, "macro.dbt_spark.spark__load_csv_rows": {"name": "spark__load_csv_rows", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__load_csv_rows", "macro_sql": "{% macro spark__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                  {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7762616, "supported_languages": null}, "macro.dbt_spark.spark__create_csv_table": {"name": "spark__create_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__create_csv_table", "macro_sql": "{% macro spark__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7774813, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_file_format": {"name": "dbt_spark_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_file_format", "macro_sql": "{% macro dbt_spark_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'iceberg', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7784297, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy": {"name": "dbt_spark_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'append', 'merge', 'insert_overwrite', 'microbatch'\n  {%- endset %}\n\n  {% set invalid_merge_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta' or 'iceberg' or 'hudi'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via endpoint\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite', 'microbatch'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'iceberg', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_merge_msg) %}\n    {% endif %}\n    {% if raw_strategy in ['insert_overwrite', 'microbatch'] and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7794516, "supported_languages": null}, "macro.dbt_spark.materialization_incremental_spark": {"name": "materialization_incremental_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_spark.materialization_incremental_spark", "macro_sql": "{% materialization incremental, adapter='spark', supported_languages=['sql', 'python'] -%}\n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='parquet') -%}\n  {%- set raw_strategy = config.get('incremental_strategy') or 'append' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set file_format = dbt_spark_validate_get_file_format(raw_file_format) -%}\n  {%- set strategy = dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n\n  {#-- Set vars --#}\n\n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n  {%- set language = model['language'] -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) -%}\n  {%- set target_relation = this -%}\n  {%- set existing_relation = load_relation(this) -%}\n  {% set tmp_relation = this.incorporate(path = {\"identifier\": this.identifier ~ '__dbt_tmp'}) -%}\n\n  {#-- for SQL model we will create temp view that doesn't have database and schema --#}\n  {%- if language == 'sql'-%}\n    {%- set tmp_relation = tmp_relation.include(database=false, schema=false) -%}\n  {%- endif -%}\n\n  {#-- Set Overwrite Mode --#}\n  {%- if strategy in ['insert_overwrite', 'microbatch'] and partition_by -%}\n    {%- call statement() -%}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {%- endcall -%}\n  {%- endif -%}\n\n  {#-- Run pre-hooks --#}\n  {{ run_hooks(pre_hooks) }}\n\n  {#-- Incremental run logic --#}\n  {%- if existing_relation is none -%}\n    {#-- Relation must be created --#}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- elif existing_relation.is_view or should_full_refresh() -%}\n    {#-- Relation must be dropped & recreated --#}\n    {% set is_delta = (file_format == 'delta' and existing_relation.is_delta) %}\n    {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n      {% do adapter.drop_relation(existing_relation) %}\n    {% endif %}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- else -%}\n    {#-- Relation must be merged --#}\n    {%- call statement('create_tmp_relation', language=language) -%}\n      {{ create_table_as(True, tmp_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {%- do process_schema_changes(on_schema_change, tmp_relation, existing_relation) -%}\n    {%- call statement('main') -%}\n      {{ dbt_spark_get_incremental_sql(strategy, tmp_relation, target_relation, existing_relation, unique_key, incremental_predicates) }}\n    {%- endcall -%}\n    {%- if language == 'python' -%}\n      {#--\n      This is yucky.\n      See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n      re: python models and temporary views.\n\n      Also, why do neither drop_relation or adapter.drop_relation work here?!\n      --#}\n      {% call statement('drop_relation') -%}\n        drop table if exists {{ tmp_relation }}\n      {%- endcall %}\n    {%- endif -%}\n  {%- endif -%}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_spark.persist_constraints", "macro.dbt.should_full_refresh", "macro.dbt.process_schema_changes", "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7834358, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.spark__get_merge_update_columns": {"name": "spark__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/column_helpers.sql", "original_file_path": "macros/materializations/incremental/column_helpers.sql", "unique_id": "macro.dbt_spark.spark__get_merge_update_columns", "macro_sql": "{% macro spark__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = None -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7844312, "supported_languages": null}, "macro.dbt_spark.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation, existing_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    {% if existing_relation.is_iceberg %}\n      {# removed table from statement for iceberg #}\n      insert overwrite {{ target_relation }}\n      {# removed partition_cols for iceberg as well #}\n    {% else %}\n      insert overwrite table {{ target_relation }}\n      {{ partition_cols(label=\"partition\") }}\n    {% endif %}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7856307, "supported_languages": null}, "macro.dbt_spark.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.785982, "supported_languages": null}, "macro.dbt_spark.spark__get_merge_sql": {"name": "spark__get_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.spark__get_merge_sql", "macro_sql": "{% macro spark__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n\n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n  {{ sql_header if sql_header is not none }}\n\n  merge into {{ target }} as DBT_INTERNAL_DEST\n      using {{ source }} as DBT_INTERNAL_SOURCE\n      on {{ predicates | join(' and ') }}\n\n      when matched then update set\n        {% if update_columns -%}{%- for column_name in update_columns %}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n        {%- else %} * {% endif %}\n\n      when not matched then insert *\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7876105, "supported_languages": null}, "macro.dbt_spark.dbt_spark_get_incremental_sql": {"name": "dbt_spark_get_incremental_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro_sql": "{% macro dbt_spark_get_incremental_sql(strategy, source, target, existing, unique_key, incremental_predicates) %}\n  {%- if strategy == 'append' -%}\n    {#-- insert new records into existing table, without updating or overwriting #}\n    {{ get_insert_into_sql(source, target) }}\n  {%- elif strategy == 'insert_overwrite' -%}\n    {#-- insert statements don't like CTEs, so support them via a temp view #}\n    {{ get_insert_overwrite_sql(source, target, existing) }}\n  {%- elif strategy == 'microbatch' -%}\n    {#-- microbatch wraps insert_overwrite, and requires a partition_by config #}\n    {% set missing_partition_key_microbatch_msg -%}\n      dbt-spark 'microbatch' incremental strategy requires a `partition_by` config.\n      Ensure you are using a `partition_by` column that is of grain {{ config.get('batch_size') }}.\n    {%- endset %}\n\n    {%- if not config.get('partition_by') -%}\n      {{ exceptions.raise_compiler_error(missing_partition_key_microbatch_msg) }}\n    {%- endif -%}\n    {{ get_insert_overwrite_sql(source, target, existing) }}\n  {%- elif strategy == 'merge' -%}\n  {#-- merge all columns for datasources which implement MERGE INTO (e.g. databricks, iceberg) - schema changes are handled for us #}\n    {{ get_merge_sql(target, source, unique_key, dest_columns=none, incremental_predicates=incremental_predicates) }}\n  {%- else -%}\n    {% set no_sql_for_strategy_msg -%}\n      No known SQL for the incremental strategy provided: {{ strategy }}\n    {%- endset %}\n    {%- do exceptions.raise_compiler_error(no_sql_for_strategy_msg) -%}\n  {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.get_insert_into_sql", "macro.dbt_spark.get_insert_overwrite_sql", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7888715, "supported_languages": null}, "macro.dbt.get_fixture_sql": {"name": "get_fixture_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.get_fixture_sql", "macro_sql": "{% macro get_fixture_sql(rows, column_name_to_data_types) %}\n-- Fixture for {{ model.name }}\n{% set default_row = {} %}\n\n{%- if not column_name_to_data_types -%}\n{#-- Use defer_relation IFF it is available in the manifest and 'this' is missing from the database --#}\n{%-   set this_or_defer_relation = defer_relation if (defer_relation and not load_relation(this)) else this -%}\n{%-   set columns_in_relation = adapter.get_columns_in_relation(this_or_defer_relation) -%}\n\n{%-   set column_name_to_data_types = {} -%}\n{%-   for column in columns_in_relation -%}\n{#-- This needs to be a case-insensitive comparison --#}\n{%-     do column_name_to_data_types.update({column.name|lower: column.data_type}) -%}\n{%-   endfor -%}\n{%- endif -%}\n\n{%- if not column_name_to_data_types -%}\n    {{ exceptions.raise_compiler_error(\"Not able to get columns for unit test '\" ~ model.name ~ \"' from relation \" ~ this ~ \" because the relation doesn't exist\") }}\n{%- endif -%}\n\n{%- for column_name, column_type in column_name_to_data_types.items() -%}\n    {%- do default_row.update({column_name: (safe_cast(\"null\", column_type) | trim )}) -%}\n{%- endfor -%}\n\n{{ validate_fixture_rows(rows, row_number) }}\n\n{%- for row in rows -%}\n{%-   set formatted_row = format_row(row, column_name_to_data_types) -%}\n{%-   set default_row_copy = default_row.copy() -%}\n{%-   do default_row_copy.update(formatted_row) -%}\nselect\n{%-   for column_name, column_value in default_row_copy.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%}, {%- endif %}\n{%-   endfor %}\n{%-   if not loop.last %}\nunion all\n{%    endif %}\n{%- endfor -%}\n\n{%- if (rows | length) == 0 -%}\n    select\n    {%- for column_name, column_value in default_row.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%},{%- endif %}\n    {%- endfor %}\n    limit 0\n{%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.safe_cast", "macro.dbt.validate_fixture_rows", "macro.dbt.format_row"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.791627, "supported_languages": null}, "macro.dbt.get_expected_sql": {"name": "get_expected_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.get_expected_sql", "macro_sql": "{% macro get_expected_sql(rows, column_name_to_data_types) %}\n\n{%- if (rows | length) == 0 -%}\n    select * from dbt_internal_unit_test_actual\n    limit 0\n{%- else -%}\n{%- for row in rows -%}\n{%- set formatted_row = format_row(row, column_name_to_data_types) -%}\nselect\n{%- for column_name, column_value in formatted_row.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%}, {%- endif %}\n{%- endfor %}\n{%- if not loop.last %}\nunion all\n{% endif %}\n{%- endfor -%}\n{%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.format_row"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7924912, "supported_languages": null}, "macro.dbt.format_row": {"name": "format_row", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.format_row", "macro_sql": "\n\n{%- macro format_row(row, column_name_to_data_types) -%}\n    {#-- generate case-insensitive formatted row --#}\n    {% set formatted_row = {} %}\n    {%- for column_name, column_value in row.items() -%}\n        {% set column_name = column_name|lower %}\n\n        {%- if column_name not in column_name_to_data_types %}\n            {#-- if user-provided row contains column name that relation does not contain, raise an error --#}\n            {% set fixture_name = \"expected output\" if model.resource_type == 'unit_test' else (\"'\" ~ model.name ~ \"'\") %}\n            {{ exceptions.raise_compiler_error(\n                \"Invalid column name: '\" ~ column_name ~ \"' in unit test fixture for \" ~ fixture_name ~ \".\"\n                \"\\nAccepted columns for \" ~ fixture_name ~ \" are: \" ~ (column_name_to_data_types.keys()|list)\n            ) }}\n        {%- endif -%}\n\n        {%- set column_type = column_name_to_data_types[column_name] %}\n\n        {#-- sanitize column_value: wrap yaml strings in quotes, apply cast --#}\n        {%- set column_value_clean = column_value -%}\n        {%- if column_value is string -%}\n            {%- set column_value_clean = dbt.string_literal(dbt.escape_single_quotes(column_value)) -%}\n        {%- elif column_value is none -%}\n            {%- set column_value_clean = 'null' -%}\n        {%- endif -%}\n\n        {%- set row_update = {column_name: safe_cast(column_value_clean, column_type) } -%}\n        {%- do formatted_row.update(row_update) -%}\n    {%- endfor -%}\n    {{ return(formatted_row) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.string_literal", "macro.dbt.escape_single_quotes", "macro.dbt.safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7959259, "supported_languages": null}, "macro.dbt.validate_fixture_rows": {"name": "validate_fixture_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.validate_fixture_rows", "macro_sql": "{%- macro validate_fixture_rows(rows, row_number) -%}\n  {{ return(adapter.dispatch('validate_fixture_rows', 'dbt')(rows, row_number)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__validate_fixture_rows"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7966366, "supported_languages": null}, "macro.dbt.default__validate_fixture_rows": {"name": "default__validate_fixture_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.default__validate_fixture_rows", "macro_sql": "{%- macro default__validate_fixture_rows(rows, row_number) -%}\n  {# This is an abstract method for adapter overrides as needed #}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.796956, "supported_languages": null}, "macro.dbt.get_rename_intermediate_sql": {"name": "get_rename_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename_intermediate.sql", "original_file_path": "macros/relations/rename_intermediate.sql", "unique_id": "macro.dbt.get_rename_intermediate_sql", "macro_sql": "{%- macro get_rename_intermediate_sql(relation) -%}\n    {{- log('Applying RENAME INTERMEDIATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_rename_intermediate_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_rename_intermediate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.797913, "supported_languages": null}, "macro.dbt.default__get_rename_intermediate_sql": {"name": "default__get_rename_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename_intermediate.sql", "original_file_path": "macros/relations/rename_intermediate.sql", "unique_id": "macro.dbt.default__get_rename_intermediate_sql", "macro_sql": "{%- macro default__get_rename_intermediate_sql(relation) -%}\n\n    -- get the standard intermediate name\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    {{ get_rename_sql(intermediate_relation, relation.identifier) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7984195, "supported_languages": null}, "macro.dbt.get_create_intermediate_sql": {"name": "get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt.get_create_intermediate_sql", "macro_sql": "{%- macro get_create_intermediate_sql(relation, sql) -%}\n    {{- log('Applying CREATE INTERMEDIATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_intermediate_sql', 'dbt')(relation, sql) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_intermediate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7991776, "supported_languages": null}, "macro.dbt.default__get_create_intermediate_sql": {"name": "default__get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt.default__get_create_intermediate_sql", "macro_sql": "{%- macro default__get_create_intermediate_sql(relation, sql) -%}\n\n    -- get the standard intermediate name\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    -- drop any pre-existing intermediate\n    {{ get_drop_sql(intermediate_relation) }};\n\n    {{ get_create_sql(intermediate_relation, sql) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.7998338, "supported_languages": null}, "macro.dbt.get_rename_sql": {"name": "get_rename_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.get_rename_sql", "macro_sql": "{%- macro get_rename_sql(relation, new_name) -%}\n    {{- log('Applying RENAME to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_rename_sql', 'dbt')(relation, new_name) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8008037, "supported_languages": null}, "macro.dbt.default__get_rename_sql": {"name": "default__get_rename_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.default__get_rename_sql", "macro_sql": "{%- macro default__get_rename_sql(relation, new_name) -%}\n\n    {%- if relation.is_view -%}\n        {{ get_rename_view_sql(relation, new_name) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_rename_table_sql(relation, new_name) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_rename_materialized_view_sql(relation, new_name) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_rename_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.get_rename_view_sql", "macro.dbt.get_rename_table_sql", "macro.dbt.get_rename_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8014033, "supported_languages": null}, "macro.dbt.rename_relation": {"name": "rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation', 'dbt')(from_relation, to_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__rename_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.801677, "supported_languages": null}, "macro.dbt.default__rename_relation": {"name": "default__rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation.render() }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8021128, "supported_languages": null}, "macro.dbt.get_create_backup_sql": {"name": "get_create_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt.get_create_backup_sql", "macro_sql": "{%- macro get_create_backup_sql(relation) -%}\n    {{- log('Applying CREATE BACKUP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_backup_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_create_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.802536, "supported_languages": null}, "macro.dbt.default__get_create_backup_sql": {"name": "default__get_create_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt.default__get_create_backup_sql", "macro_sql": "{%- macro default__get_create_backup_sql(relation) -%}\n\n    -- get the standard backup name\n    {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n    -- drop any pre-existing backup\n    {{ get_drop_sql(backup_relation) }};\n\n    {{ get_rename_sql(relation, backup_relation.identifier) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.get_drop_sql", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8028915, "supported_languages": null}, "macro.dbt.get_drop_backup_sql": {"name": "get_drop_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop_backup.sql", "original_file_path": "macros/relations/drop_backup.sql", "unique_id": "macro.dbt.get_drop_backup_sql", "macro_sql": "{%- macro get_drop_backup_sql(relation) -%}\n    {{- log('Applying DROP BACKUP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_drop_backup_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8032699, "supported_languages": null}, "macro.dbt.default__get_drop_backup_sql": {"name": "default__get_drop_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop_backup.sql", "original_file_path": "macros/relations/drop_backup.sql", "unique_id": "macro.dbt.default__get_drop_backup_sql", "macro_sql": "{%- macro default__get_drop_backup_sql(relation) -%}\n\n    -- get the standard backup name\n    {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n    {{ get_drop_sql(backup_relation) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8036242, "supported_languages": null}, "macro.dbt.get_create_sql": {"name": "get_create_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt.get_create_sql", "macro_sql": "{%- macro get_create_sql(relation, sql) -%}\n    {{- log('Applying CREATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_sql', 'dbt')(relation, sql) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.804069, "supported_languages": null}, "macro.dbt.default__get_create_sql": {"name": "default__get_create_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt.default__get_create_sql", "macro_sql": "{%- macro default__get_create_sql(relation, sql) -%}\n\n    {%- if relation.is_view -%}\n        {{ get_create_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_create_table_as_sql(False, relation, sql) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_create_materialized_view_as_sql(relation, sql) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_create_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.get_create_view_as_sql", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_create_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8045838, "supported_languages": null}, "macro.dbt.get_replace_sql": {"name": "get_replace_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt.get_replace_sql", "macro_sql": "{% macro get_replace_sql(existing_relation, target_relation, sql) %}\n    {{- log('Applying REPLACE to: ' ~ existing_relation) -}}\n    {{- adapter.dispatch('get_replace_sql', 'dbt')(existing_relation, target_relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8051434, "supported_languages": null}, "macro.dbt.default__get_replace_sql": {"name": "default__get_replace_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt.default__get_replace_sql", "macro_sql": "{% macro default__get_replace_sql(existing_relation, target_relation, sql) %}\n\n    {# /* use a create or replace statement if possible */ #}\n\n    {% set is_replaceable = existing_relation.type == target_relation.type and existing_relation.can_be_replaced %}\n\n    {% if is_replaceable and existing_relation.is_view %}\n        {{ get_replace_view_sql(target_relation, sql) }}\n\n    {% elif is_replaceable and existing_relation.is_table %}\n        {{ get_replace_table_sql(target_relation, sql) }}\n\n    {% elif is_replaceable and existing_relation.is_materialized_view %}\n        {{ get_replace_materialized_view_sql(target_relation, sql) }}\n\n    {# /* a create or replace statement is not possible, so try to stage and/or backup to be safe */ #}\n\n    {# /* create target_relation as an intermediate relation, then swap it out with the existing one using a backup */ #}\n    {%- elif target_relation.can_be_renamed and existing_relation.can_be_renamed -%}\n        {{ get_create_intermediate_sql(target_relation, sql) }};\n        {{ get_create_backup_sql(existing_relation) }};\n        {{ get_rename_intermediate_sql(target_relation) }};\n        {{ get_drop_backup_sql(existing_relation) }}\n\n    {# /* create target_relation as an intermediate relation, then swap it out with the existing one without using a backup */ #}\n    {%- elif target_relation.can_be_renamed -%}\n        {{ get_create_intermediate_sql(target_relation, sql) }};\n        {{ get_drop_sql(existing_relation) }};\n        {{ get_rename_intermediate_sql(target_relation) }}\n\n    {# /* create target_relation in place by first backing up the existing relation */ #}\n    {%- elif existing_relation.can_be_renamed -%}\n        {{ get_create_backup_sql(existing_relation) }};\n        {{ get_create_sql(target_relation, sql) }};\n        {{ get_drop_backup_sql(existing_relation) }}\n\n    {# /* no renaming is allowed, so just drop and create */ #}\n    {%- else -%}\n        {{ get_drop_sql(existing_relation) }};\n        {{ get_create_sql(target_relation, sql) }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_replace_view_sql", "macro.dbt.get_replace_table_sql", "macro.dbt.get_replace_materialized_view_sql", "macro.dbt.get_create_intermediate_sql", "macro.dbt.get_create_backup_sql", "macro.dbt.get_rename_intermediate_sql", "macro.dbt.get_drop_backup_sql", "macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.806487, "supported_languages": null}, "macro.dbt.get_drop_sql": {"name": "get_drop_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.get_drop_sql", "macro_sql": "{%- macro get_drop_sql(relation) -%}\n    {{- log('Applying DROP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_drop_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8069813, "supported_languages": null}, "macro.dbt.default__get_drop_sql": {"name": "default__get_drop_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.default__get_drop_sql", "macro_sql": "{%- macro default__get_drop_sql(relation) -%}\n\n    {%- if relation.is_view -%}\n        {{ drop_view(relation) }}\n\n    {%- elif relation.is_table -%}\n        {{ drop_table(relation) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ drop_materialized_view(relation) }}\n\n    {%- else -%}\n        drop {{ relation.type }} if exists {{ relation.render() }} cascade\n\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.drop_view", "macro.dbt.drop_table", "macro.dbt.drop_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8074183, "supported_languages": null}, "macro.dbt.drop_relation": {"name": "drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n    {{ return(adapter.dispatch('drop_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8076391, "supported_languages": null}, "macro.dbt.default__drop_relation": {"name": "default__drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n    {% call statement('drop_relation', auto_begin=False) -%}\n        {{ get_drop_sql(relation) }}\n    {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8078902, "supported_languages": null}, "macro.dbt.drop_relation_if_exists": {"name": "drop_relation_if_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8081188, "supported_languages": null}, "macro.dbt.drop_schema_named": {"name": "drop_schema_named", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/schema.sql", "original_file_path": "macros/relations/schema.sql", "unique_id": "macro.dbt.drop_schema_named", "macro_sql": "{% macro drop_schema_named(schema_name) %}\n    {{ return(adapter.dispatch('drop_schema_named', 'dbt') (schema_name)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__drop_schema_named"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8084116, "supported_languages": null}, "macro.dbt.default__drop_schema_named": {"name": "default__drop_schema_named", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/schema.sql", "original_file_path": "macros/relations/schema.sql", "unique_id": "macro.dbt.default__drop_schema_named", "macro_sql": "{% macro default__drop_schema_named(schema_name) %}\n  {% set schema_relation = api.Relation.create(schema=schema_name) %}\n  {{ adapter.drop_schema(schema_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8086753, "supported_languages": null}, "macro.dbt.get_rename_table_sql": {"name": "get_rename_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt.get_rename_table_sql", "macro_sql": "{% macro get_rename_table_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_table_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_rename_table_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8089595, "supported_languages": null}, "macro.dbt.default__get_rename_table_sql": {"name": "default__get_rename_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt.default__get_rename_table_sql", "macro_sql": "{% macro default__get_rename_table_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_table_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.809126, "supported_languages": null}, "macro.dbt.get_create_table_as_sql": {"name": "get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.get_create_table_as_sql", "macro_sql": "{% macro get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ adapter.dispatch('get_create_table_as_sql', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.809736, "supported_languages": null}, "macro.dbt.default__get_create_table_as_sql": {"name": "default__get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_create_table_as_sql", "macro_sql": "{% macro default__get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ return(create_table_as(temporary, relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8099334, "supported_languages": null}, "macro.dbt.create_table_as": {"name": "create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {# backward compatibility for create_table_as that does not support language #}\n  {% if language == \"sql\" %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code)}}\n  {% else %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code, language) }}\n  {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8103988, "supported_languages": null}, "macro.dbt.default__create_table_as": {"name": "default__create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  {% set contract_config = config.get('contract') %}\n  {% if contract_config.enforced and (not temporary) %}\n    {{ get_assert_columns_equivalent(sql) }}\n    {{ get_table_columns_and_constraints() }}\n    {%- set sql = get_select_subquery(sql) %}\n  {% endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_table_columns_and_constraints", "macro.dbt.get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8111746, "supported_languages": null}, "macro.dbt.default__get_column_names": {"name": "default__get_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_column_names", "macro_sql": "{% macro default__get_column_names() %}\n  {#- loop through user_provided_columns to get column names -#}\n    {%- set user_provided_columns = model['columns'] -%}\n    {%- for i in user_provided_columns %}\n      {%- set col = user_provided_columns[i] -%}\n      {%- set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] -%}\n      {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.811718, "supported_languages": null}, "macro.dbt.get_select_subquery": {"name": "get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.get_select_subquery", "macro_sql": "{% macro get_select_subquery(sql) %}\n  {{ return(adapter.dispatch('get_select_subquery', 'dbt')(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8119206, "supported_languages": null}, "macro.dbt.default__get_select_subquery": {"name": "default__get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_select_subquery", "macro_sql": "{% macro default__get_select_subquery(sql) %}\n    select {{ adapter.dispatch('get_column_names', 'dbt')() }}\n    from (\n        {{ sql }}\n    ) as model_subq\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_column_names"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8121147, "supported_languages": null}, "macro.dbt.get_replace_table_sql": {"name": "get_replace_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt.get_replace_table_sql", "macro_sql": "{% macro get_replace_table_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_table_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_replace_table_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8123915, "supported_languages": null}, "macro.dbt.default__get_replace_table_sql": {"name": "default__get_replace_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt.default__get_replace_table_sql", "macro_sql": "{% macro default__get_replace_table_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_table_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8125808, "supported_languages": null}, "macro.dbt.drop_table": {"name": "drop_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt.drop_table", "macro_sql": "{% macro drop_table(relation) -%}\n    {{- adapter.dispatch('drop_table', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8128607, "supported_languages": null}, "macro.dbt.default__drop_table": {"name": "default__drop_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt.default__drop_table", "macro_sql": "{% macro default__drop_table(relation) -%}\n    drop table if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8130012, "supported_languages": null}, "macro.dbt.get_rename_view_sql": {"name": "get_rename_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt.get_rename_view_sql", "macro_sql": "{% macro get_rename_view_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_view_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_rename_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8132758, "supported_languages": null}, "macro.dbt.default__get_rename_view_sql": {"name": "default__get_rename_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt.default__get_rename_view_sql", "macro_sql": "{% macro default__get_rename_view_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8134398, "supported_languages": null}, "macro.dbt.get_create_view_as_sql": {"name": "get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.get_create_view_as_sql", "macro_sql": "{% macro get_create_view_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_view_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8138669, "supported_languages": null}, "macro.dbt.default__get_create_view_as_sql": {"name": "default__get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.default__get_create_view_as_sql", "macro_sql": "{% macro default__get_create_view_as_sql(relation, sql) -%}\n  {{ return(create_view_as(relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8140428, "supported_languages": null}, "macro.dbt.create_view_as": {"name": "create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8142362, "supported_languages": null}, "macro.dbt.default__create_view_as": {"name": "default__create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation.render() }}\n    {% set contract_config = config.get('contract') %}\n    {% if contract_config.enforced %}\n      {{ get_assert_columns_equivalent(sql) }}\n    {%- endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.815047, "supported_languages": null}, "macro.dbt.get_replace_view_sql": {"name": "get_replace_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.get_replace_view_sql", "macro_sql": "{% macro get_replace_view_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_view_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8156064, "supported_languages": null}, "macro.dbt.default__get_replace_view_sql": {"name": "default__get_replace_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.default__get_replace_view_sql", "macro_sql": "{% macro default__get_replace_view_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8161004, "supported_languages": null}, "macro.dbt.create_or_replace_view": {"name": "create_or_replace_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.create_or_replace_view", "macro_sql": "{% macro create_or_replace_view() %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(target_relation, sql) }}\n  {%- endcall %}\n\n  {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8173335, "supported_languages": null}, "macro.dbt.handle_existing_table": {"name": "handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch('handle_existing_table', 'dbt')(full_refresh, old_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__handle_existing_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8175585, "supported_languages": null}, "macro.dbt.default__handle_existing_table": {"name": "default__handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ log(\"Dropping relation \" ~ old_relation.render() ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8178189, "supported_languages": null}, "macro.dbt.drop_view": {"name": "drop_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt.drop_view", "macro_sql": "{% macro drop_view(relation) -%}\n    {{- adapter.dispatch('drop_view', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8180814, "supported_languages": null}, "macro.dbt.default__drop_view": {"name": "default__drop_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt.default__drop_view", "macro_sql": "{% macro default__drop_view(relation) -%}\n    drop view if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8182437, "supported_languages": null}, "macro.dbt.get_table_columns_and_constraints": {"name": "get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_table_columns_and_constraints", "macro_sql": "{%- macro get_table_columns_and_constraints() -%}\n  {{ adapter.dispatch('get_table_columns_and_constraints', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8189664, "supported_languages": null}, "macro.dbt.default__get_table_columns_and_constraints": {"name": "default__get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_table_columns_and_constraints", "macro_sql": "{% macro default__get_table_columns_and_constraints() -%}\n  {{ return(table_columns_and_constraints()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8191028, "supported_languages": null}, "macro.dbt.table_columns_and_constraints": {"name": "table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.table_columns_and_constraints", "macro_sql": "{% macro table_columns_and_constraints() %}\n  {# loop through user_provided_columns to create DDL with data types and constraints #}\n    {%- set raw_column_constraints = adapter.render_raw_columns_constraints(raw_columns=model['columns']) -%}\n    {%- set raw_model_constraints = adapter.render_raw_model_constraints(raw_constraints=model['constraints']) -%}\n    (\n    {% for c in raw_column_constraints -%}\n      {{ c }}{{ \",\" if not loop.last or raw_model_constraints }}\n    {% endfor %}\n    {% for c in raw_model_constraints -%}\n        {{ c }}{{ \",\" if not loop.last }}\n    {% endfor -%}\n    )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.819691, "supported_languages": null}, "macro.dbt.get_assert_columns_equivalent": {"name": "get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_assert_columns_equivalent", "macro_sql": "\n\n{%- macro get_assert_columns_equivalent(sql) -%}\n  {{ adapter.dispatch('get_assert_columns_equivalent', 'dbt')(sql) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8198838, "supported_languages": null}, "macro.dbt.default__get_assert_columns_equivalent": {"name": "default__get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_assert_columns_equivalent", "macro_sql": "{% macro default__get_assert_columns_equivalent(sql) -%}\n  {{ return(assert_columns_equivalent(sql)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.82003, "supported_languages": null}, "macro.dbt.assert_columns_equivalent": {"name": "assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.assert_columns_equivalent", "macro_sql": "{% macro assert_columns_equivalent(sql) %}\n\n  {#-- First ensure the user has defined 'columns' in yaml specification --#}\n  {%- set user_defined_columns = model['columns'] -%}\n  {%- if not user_defined_columns -%}\n      {{ exceptions.raise_contract_error([], []) }}\n  {%- endif -%}\n\n  {#-- Obtain the column schema provided by sql file. #}\n  {%- set sql_file_provided_columns = get_column_schema_from_query(sql, config.get('sql_header', none)) -%}\n  {#--Obtain the column schema provided by the schema file by generating an 'empty schema' query from the model's columns. #}\n  {%- set schema_file_provided_columns = get_column_schema_from_query(get_empty_schema_sql(user_defined_columns)) -%}\n\n  {#-- create dictionaries with name and formatted data type and strings for exception #}\n  {%- set sql_columns = format_columns(sql_file_provided_columns) -%}\n  {%- set yaml_columns = format_columns(schema_file_provided_columns)  -%}\n\n  {%- if sql_columns|length != yaml_columns|length -%}\n    {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n  {%- endif -%}\n\n  {%- for sql_col in sql_columns -%}\n    {%- set yaml_col = [] -%}\n    {%- for this_col in yaml_columns -%}\n      {%- if this_col['name'] == sql_col['name'] -%}\n        {%- do yaml_col.append(this_col) -%}\n        {%- break -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- if not yaml_col -%}\n      {#-- Column with name not found in yaml #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n    {%- if sql_col['formatted'] != yaml_col[0]['formatted'] -%}\n      {#-- Column data types don't match #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n  {%- endfor -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_column_schema_from_query", "macro.dbt.get_empty_schema_sql", "macro.dbt.format_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.821447, "supported_languages": null}, "macro.dbt.format_columns": {"name": "format_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.format_columns", "macro_sql": "{% macro format_columns(columns) %}\n  {% set formatted_columns = [] %}\n  {% for column in columns %}\n    {%- set formatted_column = adapter.dispatch('format_column', 'dbt')(column) -%}\n    {%- do formatted_columns.append(formatted_column) -%}\n  {% endfor %}\n  {{ return(formatted_columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__format_column"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.821885, "supported_languages": null}, "macro.dbt.default__format_column": {"name": "default__format_column", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__format_column", "macro_sql": "{% macro default__format_column(column) -%}\n  {% set data_type = column.dtype %}\n  {% set formatted = column.column.lower() ~ \" \" ~ data_type %}\n  {{ return({'name': column.name, 'data_type': data_type, 'formatted': formatted}) }}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8222785, "supported_languages": null}, "macro.dbt.get_alter_materialized_view_as_sql": {"name": "get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.get_alter_materialized_view_as_sql", "macro_sql": "{% macro get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_alter_materialized_view_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    ) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8228462, "supported_languages": null}, "macro.dbt.default__get_alter_materialized_view_as_sql": {"name": "default__get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.default__get_alter_materialized_view_as_sql", "macro_sql": "{% macro default__get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{ exceptions.raise_compiler_error(\"Materialized views have not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8230567, "supported_languages": null}, "macro.dbt.get_materialized_view_configuration_changes": {"name": "get_materialized_view_configuration_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.get_materialized_view_configuration_changes", "macro_sql": "{% macro get_materialized_view_configuration_changes(existing_relation, new_config) %}\n    /* {#\n    It's recommended that configuration changes be formatted as follows:\n    {\"<change_category>\": [{\"action\": \"<name>\", \"context\": ...}]}\n\n    For example:\n    {\n        \"indexes\": [\n            {\"action\": \"drop\", \"context\": \"index_abc\"},\n            {\"action\": \"create\", \"context\": {\"columns\": [\"column_1\", \"column_2\"], \"type\": \"hash\", \"unique\": True}},\n        ],\n    }\n\n    Either way, `get_materialized_view_configuration_changes` needs to align with `get_alter_materialized_view_as_sql`.\n    #} */\n    {{- log('Determining configuration changes on: ' ~ existing_relation) -}}\n    {%- do return(adapter.dispatch('get_materialized_view_configuration_changes', 'dbt')(existing_relation, new_config)) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_materialized_view_configuration_changes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8233902, "supported_languages": null}, "macro.dbt.default__get_materialized_view_configuration_changes": {"name": "default__get_materialized_view_configuration_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.default__get_materialized_view_configuration_changes", "macro_sql": "{% macro default__get_materialized_view_configuration_changes(existing_relation, new_config) %}\n    {{ exceptions.raise_compiler_error(\"Materialized views have not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8235676, "supported_languages": null}, "macro.dbt.get_rename_materialized_view_sql": {"name": "get_rename_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/rename.sql", "original_file_path": "macros/relations/materialized_view/rename.sql", "unique_id": "macro.dbt.get_rename_materialized_view_sql", "macro_sql": "{% macro get_rename_materialized_view_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_materialized_view_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_rename_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8238711, "supported_languages": null}, "macro.dbt.default__get_rename_materialized_view_sql": {"name": "default__get_rename_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/rename.sql", "original_file_path": "macros/relations/materialized_view/rename.sql", "unique_id": "macro.dbt.default__get_rename_materialized_view_sql", "macro_sql": "{% macro default__get_rename_materialized_view_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_materialized_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8240466, "supported_languages": null}, "macro.dbt.get_create_materialized_view_as_sql": {"name": "get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt.get_create_materialized_view_as_sql", "macro_sql": "{% macro get_create_materialized_view_as_sql(relation, sql) -%}\n    {{- adapter.dispatch('get_create_materialized_view_as_sql', 'dbt')(relation, sql) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8243434, "supported_languages": null}, "macro.dbt.default__get_create_materialized_view_as_sql": {"name": "default__get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt.default__get_create_materialized_view_as_sql", "macro_sql": "{% macro default__get_create_materialized_view_as_sql(relation, sql) -%}\n    {{ exceptions.raise_compiler_error(\n        \"`get_create_materialized_view_as_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8245168, "supported_languages": null}, "macro.dbt.refresh_materialized_view": {"name": "refresh_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt.refresh_materialized_view", "macro_sql": "{% macro refresh_materialized_view(relation) %}\n    {{- log('Applying REFRESH to: ' ~ relation) -}}\n    {{- adapter.dispatch('refresh_materialized_view', 'dbt')(relation) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__refresh_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8248565, "supported_languages": null}, "macro.dbt.default__refresh_materialized_view": {"name": "default__refresh_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt.default__refresh_materialized_view", "macro_sql": "{% macro default__refresh_materialized_view(relation) %}\n    {{ exceptions.raise_compiler_error(\"`refresh_materialized_view` has not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8250282, "supported_languages": null}, "macro.dbt.get_replace_materialized_view_sql": {"name": "get_replace_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/replace.sql", "original_file_path": "macros/relations/materialized_view/replace.sql", "unique_id": "macro.dbt.get_replace_materialized_view_sql", "macro_sql": "{% macro get_replace_materialized_view_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_materialized_view_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_replace_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8253086, "supported_languages": null}, "macro.dbt.default__get_replace_materialized_view_sql": {"name": "default__get_replace_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/replace.sql", "original_file_path": "macros/relations/materialized_view/replace.sql", "unique_id": "macro.dbt.default__get_replace_materialized_view_sql", "macro_sql": "{% macro default__get_replace_materialized_view_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_materialized_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8254733, "supported_languages": null}, "macro.dbt.drop_materialized_view": {"name": "drop_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt.drop_materialized_view", "macro_sql": "{% macro drop_materialized_view(relation) -%}\n    {{- adapter.dispatch('drop_materialized_view', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8257275, "supported_languages": null}, "macro.dbt.default__drop_materialized_view": {"name": "default__drop_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt.default__drop_materialized_view", "macro_sql": "{% macro default__drop_materialized_view(relation) -%}\n    drop materialized view if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8258667, "supported_languages": null}, "macro.dbt.default__test_relationships": {"name": "default__test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/relationships.sql", "original_file_path": "macros/generic_test_sql/relationships.sql", "unique_id": "macro.dbt.default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, column_name, to, field) %}\n\nwith child as (\n    select {{ column_name }} as from_field\n    from {{ model }}\n    where {{ column_name }} is not null\n),\n\nparent as (\n    select {{ field }} as to_field\n    from {{ to }}\n)\n\nselect\n    from_field\n\nfrom child\nleft join parent\n    on child.from_field = parent.to_field\n\nwhere parent.to_field is null\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8261998, "supported_languages": null}, "macro.dbt.default__test_accepted_values": {"name": "default__test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/accepted_values.sql", "original_file_path": "macros/generic_test_sql/accepted_values.sql", "unique_id": "macro.dbt.default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, column_name, values, quote=True) %}\n\nwith all_values as (\n\n    select\n        {{ column_name }} as value_field,\n        count(*) as n_records\n\n    from {{ model }}\n    group by {{ column_name }}\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    {% for value in values -%}\n        {% if quote -%}\n        '{{ value }}'\n        {%- else -%}\n        {{ value }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n    {%- endfor %}\n)\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.826778, "supported_languages": null}, "macro.dbt.default__test_not_null": {"name": "default__test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/not_null.sql", "original_file_path": "macros/generic_test_sql/not_null.sql", "unique_id": "macro.dbt.default__test_not_null", "macro_sql": "{% macro default__test_not_null(model, column_name) %}\n\n{% set column_list = '*' if should_store_failures() else column_name %}\n\nselect {{ column_list }}\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_store_failures"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8271048, "supported_languages": null}, "macro.dbt.default__test_unique": {"name": "default__test_unique", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/unique.sql", "original_file_path": "macros/generic_test_sql/unique.sql", "unique_id": "macro.dbt.default__test_unique", "macro_sql": "{% macro default__test_unique(model, column_name) %}\n\nselect\n    {{ column_name }} as unique_field,\n    count(*) as n_records\n\nfrom {{ model }}\nwhere {{ column_name }} is not null\ngroup by {{ column_name }}\nhaving count(*) > 1\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8273551, "supported_languages": null}, "macro.dbt.datediff": {"name": "datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', 'dbt')(first_date, second_date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8276784, "supported_languages": null}, "macro.dbt.default__datediff": {"name": "default__datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) -%}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8278992, "supported_languages": null}, "macro.dbt.dateadd": {"name": "dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', 'dbt')(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8282404, "supported_languages": null}, "macro.dbt.default__dateadd": {"name": "default__dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8284323, "supported_languages": null}, "macro.dbt.concat": {"name": "concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', 'dbt')(fields)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8286934, "supported_languages": null}, "macro.dbt.default__concat": {"name": "default__concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    {{ fields|join(' || ') }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8288338, "supported_languages": null}, "macro.dbt.except": {"name": "except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__except"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.829087, "supported_languages": null}, "macro.dbt.default__except": {"name": "default__except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8291748, "supported_languages": null}, "macro.dbt.cast_bool_to_text": {"name": "cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.cast_bool_to_text", "macro_sql": "{% macro cast_bool_to_text(field) %}\n  {{ adapter.dispatch('cast_bool_to_text', 'dbt') (field) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8294234, "supported_languages": null}, "macro.dbt.default__cast_bool_to_text": {"name": "default__cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.default__cast_bool_to_text", "macro_sql": "{% macro default__cast_bool_to_text(field) %}\n    cast({{ field }} as {{ api.Column.translate_type('string') }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8295994, "supported_languages": null}, "macro.dbt.date": {"name": "date", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt.date", "macro_sql": "{% macro date(year, month, day) %}\n  {{ return(adapter.dispatch('date', 'dbt') (year, month, day)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__date"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8299844, "supported_languages": null}, "macro.dbt.default__date": {"name": "default__date", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt.default__date", "macro_sql": "{% macro default__date(year, month, day) -%}\n    {%- set dt = modules.datetime.date(year, month, day) -%}\n    {%- set iso_8601_formatted_date = dt.strftime('%Y-%m-%d') -%}\n    to_date('{{ iso_8601_formatted_date }}', 'YYYY-MM-DD')\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8303351, "supported_languages": null}, "macro.dbt.get_intervals_between": {"name": "get_intervals_between", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', 'dbt')(start_date, end_date, datepart)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_intervals_between"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8308353, "supported_languages": null}, "macro.dbt.default__get_intervals_between": {"name": "default__get_intervals_between", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.default__get_intervals_between", "macro_sql": "{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{ dbt.datediff(start_date, end_date, datepart) }}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8314872, "supported_languages": null}, "macro.dbt.date_spine": {"name": "date_spine", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', 'dbt')(datepart, start_date, end_date)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__date_spine"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.831744, "supported_languages": null}, "macro.dbt.default__date_spine": {"name": "default__date_spine", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.default__date_spine", "macro_sql": "{% macro default__date_spine(datepart, start_date, end_date) %}\n\n\n    {# call as follows:\n\n    date_spine(\n        \"day\",\n        \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n        \"dbt.dateadd(week, 1, current_date)\"\n    ) #}\n\n\n    with rawdata as (\n\n        {{dbt.generate_series(\n            dbt.get_intervals_between(start_date, end_date, datepart)\n        )}}\n\n    ),\n\n    all_periods as (\n\n        select (\n            {{\n                dbt.dateadd(\n                    datepart,\n                    \"row_number() over (order by 1) - 1\",\n                    start_date\n                )\n            }}\n        ) as date_{{datepart}}\n        from rawdata\n\n    ),\n\n    filtered as (\n\n        select *\n        from all_periods\n        where date_{{datepart}} <= {{ end_date }}\n\n    )\n\n    select * from filtered\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.generate_series", "macro.dbt.get_intervals_between", "macro.dbt.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8321502, "supported_languages": null}, "macro.dbt.cast": {"name": "cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast.sql", "original_file_path": "macros/utils/cast.sql", "unique_id": "macro.dbt.cast", "macro_sql": "{% macro cast(field, type) %}\n  {{ return(adapter.dispatch('cast', 'dbt') (field, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8324854, "supported_languages": null}, "macro.dbt.default__cast": {"name": "default__cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast.sql", "original_file_path": "macros/utils/cast.sql", "unique_id": "macro.dbt.default__cast", "macro_sql": "{% macro default__cast(field, type) %}\n    cast({{field}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8326347, "supported_languages": null}, "macro.dbt.bool_or": {"name": "bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.bool_or", "macro_sql": "{% macro bool_or(expression) -%}\n    {{ return(adapter.dispatch('bool_or', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__bool_or"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8328912, "supported_languages": null}, "macro.dbt.default__bool_or": {"name": "default__bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.default__bool_or", "macro_sql": "{% macro default__bool_or(expression) -%}\n\n    bool_or({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8330169, "supported_languages": null}, "macro.dbt.date_trunc": {"name": "date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', 'dbt') (datepart, date)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8332982, "supported_languages": null}, "macro.dbt.default__date_trunc": {"name": "default__date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) -%}\n    date_trunc('{{datepart}}', {{date}})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.833446, "supported_languages": null}, "macro.dbt.array_construct": {"name": "array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.array_construct", "macro_sql": "{% macro array_construct(inputs=[], data_type=api.Column.translate_type('integer')) -%}\n  {{ return(adapter.dispatch('array_construct', 'dbt')(inputs, data_type)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8338287, "supported_languages": null}, "macro.dbt.default__array_construct": {"name": "default__array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.default__array_construct", "macro_sql": "{% macro default__array_construct(inputs, data_type) -%}\n    {% if inputs|length > 0 %}\n    array[ {{ inputs|join(' , ') }} ]\n    {% else %}\n    array[]::{{data_type}}[]\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8341017, "supported_languages": null}, "macro.dbt.position": {"name": "position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', 'dbt') (substring_text, string_text)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__position"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.834429, "supported_languages": null}, "macro.dbt.default__position": {"name": "default__position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8345866, "supported_languages": null}, "macro.dbt.get_powers_of_two": {"name": "get_powers_of_two", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', 'dbt')(upper_bound)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8350215, "supported_languages": null}, "macro.dbt.default__get_powers_of_two": {"name": "default__get_powers_of_two", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.default__get_powers_of_two", "macro_sql": "{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8354988, "supported_languages": null}, "macro.dbt.generate_series": {"name": "generate_series", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', 'dbt')(upper_bound)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_series"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.835723, "supported_languages": null}, "macro.dbt.default__generate_series": {"name": "default__generate_series", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.default__generate_series", "macro_sql": "{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8364208, "supported_languages": null}, "macro.dbt.split_part": {"name": "split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', 'dbt') (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__split_part"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8368185, "supported_languages": null}, "macro.dbt.default__split_part": {"name": "default__split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8370078, "supported_languages": null}, "macro.dbt._split_part_negative": {"name": "_split_part_negative", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt._split_part_negative", "macro_sql": "{% macro _split_part_negative(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n          length({{ string_text }})\n          - length(\n              replace({{ string_text }},  {{ delimiter_text }}, '')\n          ) + 2 + {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.837258, "supported_languages": null}, "macro.dbt.type_string": {"name": "type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_string"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8379445, "supported_languages": null}, "macro.dbt.default__type_string": {"name": "default__type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_string", "macro_sql": "{% macro default__type_string() %}\n    {{ return(api.Column.translate_type(\"string\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8381126, "supported_languages": null}, "macro.dbt.type_timestamp": {"name": "type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8383126, "supported_languages": null}, "macro.dbt.default__type_timestamp": {"name": "default__type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    {{ return(api.Column.translate_type(\"timestamp\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8384855, "supported_languages": null}, "macro.dbt.type_float": {"name": "type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_float"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8386738, "supported_languages": null}, "macro.dbt.default__type_float": {"name": "default__type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_float", "macro_sql": "{% macro default__type_float() %}\n    {{ return(api.Column.translate_type(\"float\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8388393, "supported_languages": null}, "macro.dbt.type_numeric": {"name": "type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.839014, "supported_languages": null}, "macro.dbt.default__type_numeric": {"name": "default__type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    {{ return(api.Column.numeric_type(\"numeric\", 28, 6)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8392026, "supported_languages": null}, "macro.dbt.type_bigint": {"name": "type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8397057, "supported_languages": null}, "macro.dbt.default__type_bigint": {"name": "default__type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    {{ return(api.Column.translate_type(\"bigint\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8398972, "supported_languages": null}, "macro.dbt.type_int": {"name": "type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_int"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.840074, "supported_languages": null}, "macro.dbt.default__type_int": {"name": "default__type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_int", "macro_sql": "{%- macro default__type_int() -%}\n  {{ return(api.Column.translate_type(\"integer\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.840251, "supported_languages": null}, "macro.dbt.type_boolean": {"name": "type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_boolean", "macro_sql": "\n\n{%- macro type_boolean() -%}\n  {{ return(adapter.dispatch('type_boolean', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_boolean"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.840428, "supported_languages": null}, "macro.dbt.default__type_boolean": {"name": "default__type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_boolean", "macro_sql": "{%- macro default__type_boolean() -%}\n  {{ return(api.Column.translate_type(\"boolean\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8405855, "supported_languages": null}, "macro.dbt.replace": {"name": "replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', 'dbt') (field, old_chars, new_chars)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__replace"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8409176, "supported_languages": null}, "macro.dbt.default__replace": {"name": "default__replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8411002, "supported_languages": null}, "macro.dbt.escape_single_quotes": {"name": "escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.escape_single_quotes", "macro_sql": "{% macro escape_single_quotes(expression) %}\n      {{ return(adapter.dispatch('escape_single_quotes', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__escape_single_quotes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.84138, "supported_languages": null}, "macro.dbt.default__escape_single_quotes": {"name": "default__escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.default__escape_single_quotes", "macro_sql": "{% macro default__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"''\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8415334, "supported_languages": null}, "macro.dbt.array_append": {"name": "array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.array_append", "macro_sql": "{% macro array_append(array, new_element) -%}\n  {{ return(adapter.dispatch('array_append', 'dbt')(array, new_element)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_append"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8418353, "supported_languages": null}, "macro.dbt.default__array_append": {"name": "default__array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.default__array_append", "macro_sql": "{% macro default__array_append(array, new_element) -%}\n    array_append({{ array }}, {{ new_element }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8419874, "supported_languages": null}, "macro.dbt.length": {"name": "length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__length"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.842267, "supported_languages": null}, "macro.dbt.default__length": {"name": "default__length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.default__length", "macro_sql": "{% macro default__length(expression) %}\n\n    length(\n        {{ expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.842393, "supported_languages": null}, "macro.dbt.right": {"name": "right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', 'dbt') (string_text, length_expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__right"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8426793, "supported_languages": null}, "macro.dbt.default__right": {"name": "default__right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8428319, "supported_languages": null}, "macro.dbt.last_day": {"name": "last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', 'dbt') (date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8431447, "supported_languages": null}, "macro.dbt.default_last_day": {"name": "default_last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default_last_day", "macro_sql": "\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt.dateadd('day', '-1',\n        dbt.dateadd(datepart, '1', dbt.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.dateadd", "macro.dbt.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8434267, "supported_languages": null}, "macro.dbt.default__last_day": {"name": "default__last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt.default_last_day(date, datepart)}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8436012, "supported_languages": null}, "macro.dbt.string_literal": {"name": "string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', 'dbt') (value)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__string_literal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8438592, "supported_languages": null}, "macro.dbt.default__string_literal": {"name": "default__string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.843976, "supported_languages": null}, "macro.dbt.hash": {"name": "hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', 'dbt') (field)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8442547, "supported_languages": null}, "macro.dbt.default__hash": {"name": "default__hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{ field }} as {{ api.Column.translate_type('string') }}))\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8444417, "supported_languages": null}, "macro.dbt.safe_cast": {"name": "safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', 'dbt') (field, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8447387, "supported_languages": null}, "macro.dbt.default__safe_cast": {"name": "default__safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8449206, "supported_languages": null}, "macro.dbt.listagg": {"name": "listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.listagg", "macro_sql": "{% macro listagg(measure, delimiter_text=\"','\", order_by_clause=none, limit_num=none) -%}\n    {{ return(adapter.dispatch('listagg', 'dbt') (measure, delimiter_text, order_by_clause, limit_num)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__listagg"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8455248, "supported_languages": null}, "macro.dbt.default__listagg": {"name": "default__listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.default__listagg", "macro_sql": "{% macro default__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n    {% if limit_num -%}\n    array_to_string(\n        array_slice(\n            array_agg(\n                {{ measure }}\n            ){% if order_by_clause -%}\n            within group ({{ order_by_clause }})\n            {%- endif %}\n            ,0\n            ,{{ limit_num }}\n        ),\n        {{ delimiter_text }}\n        )\n    {%- else %}\n    listagg(\n        {{ measure }},\n        {{ delimiter_text }}\n        )\n        {% if order_by_clause -%}\n        within group ({{ order_by_clause }})\n        {%- endif %}\n    {%- endif %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8460088, "supported_languages": null}, "macro.dbt.intersect": {"name": "intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__intersect"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8462772, "supported_languages": null}, "macro.dbt.default__intersect": {"name": "default__intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8463714, "supported_languages": null}, "macro.dbt.array_concat": {"name": "array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.array_concat", "macro_sql": "{% macro array_concat(array_1, array_2) -%}\n  {{ return(adapter.dispatch('array_concat', 'dbt')(array_1, array_2)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8466568, "supported_languages": null}, "macro.dbt.default__array_concat": {"name": "default__array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.default__array_concat", "macro_sql": "{% macro default__array_concat(array_1, array_2) -%}\n    array_cat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.84681, "supported_languages": null}, "macro.dbt.any_value": {"name": "any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.any_value", "macro_sql": "{% macro any_value(expression) -%}\n    {{ return(adapter.dispatch('any_value', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__any_value"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8470645, "supported_languages": null}, "macro.dbt.default__any_value": {"name": "default__any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.default__any_value", "macro_sql": "{% macro default__any_value(expression) -%}\n\n    any_value({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.847184, "supported_languages": null}, "macro.dbt.equals": {"name": "equals", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/equals.sql", "original_file_path": "macros/utils/equals.sql", "unique_id": "macro.dbt.equals", "macro_sql": "{% macro equals(expr1, expr2) %}\n    {{ return(adapter.dispatch('equals', 'dbt') (expr1, expr2)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8475418, "supported_languages": null}, "macro.dbt.default__equals": {"name": "default__equals", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/equals.sql", "original_file_path": "macros/utils/equals.sql", "unique_id": "macro.dbt.default__equals", "macro_sql": "{% macro default__equals(expr1, expr2) -%}\n{%- if adapter.behavior.enable_truthy_nulls_equals_macro.no_warn %}\n    case when (({{ expr1 }} = {{ expr2 }}) or ({{ expr1 }} is null and {{ expr2 }} is null))\n        then 0\n        else 1\n    end = 0\n{%- else -%}\n    ({{ expr1 }} = {{ expr2 }})\n{%- endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8479347, "supported_languages": null}, "macro.dbt.convert_datetime": {"name": "convert_datetime", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8487763, "supported_languages": null}, "macro.dbt.dates_in_range": {"name": "dates_in_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partition start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.convert_datetime"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8503044, "supported_languages": null}, "macro.dbt.partition_range": {"name": "partition_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.dates_in_range"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8512309, "supported_languages": null}, "macro.dbt.py_current_timestring": {"name": "py_current_timestring", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8514898, "supported_languages": null}, "macro.dbt.statement": {"name": "statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.statement", "macro_sql": "\n{%- macro statement(name=None, fetch_result=False, auto_begin=True, language='sql') -%}\n  {%- if execute: -%}\n    {%- set compiled_code = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime {} for node \"{}\"'.format(language, model['unique_id'])) }}\n      {{ write(compiled_code) }}\n    {%- endif -%}\n    {%- if language == 'sql'-%}\n      {%- set res, table = adapter.execute(compiled_code, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- elif language == 'python' -%}\n      {%- set res = submit_python_job(model, compiled_code) -%}\n      {#-- TODO: What should table be for python models? --#}\n      {%- set table = None -%}\n    {%- else -%}\n      {% do exceptions.raise_compiler_error(\"statement macro didn't get supported language\") %}\n    {%- endif -%}\n\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8530395, "supported_languages": null}, "macro.dbt.noop_statement": {"name": "noop_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.noop_statement", "macro_sql": "{% macro noop_statement(name=None, message=None, code=None, rows_affected=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_raw_result(name, message=message, code=code, rows_affected=rows_affected, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8537269, "supported_languages": null}, "macro.dbt.run_query": {"name": "run_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8540738, "supported_languages": null}, "macro.dbt.generate_alias_name": {"name": "generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_alias_name', 'dbt')(custom_alias_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_alias_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.854513, "supported_languages": null}, "macro.dbt.default__generate_alias_name": {"name": "default__generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.default__generate_alias_name", "macro_sql": "{% macro default__generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- elif node.version -%}\n\n        {{ return(node.name ~ \"_v\" ~ (node.version | replace(\".\", \"_\"))) }}\n\n    {%- else -%}\n\n        {{ node.name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8550057, "supported_languages": null}, "macro.dbt.generate_schema_name": {"name": "generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name=none, node=none) -%}\n    {{ return(adapter.dispatch('generate_schema_name', 'dbt')(custom_schema_name, node)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8554811, "supported_languages": null}, "macro.dbt.default__generate_schema_name": {"name": "default__generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.default__generate_schema_name", "macro_sql": "{% macro default__generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.855865, "supported_languages": null}, "macro.dbt.generate_schema_name_for_env": {"name": "generate_schema_name_for_env", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.856236, "supported_languages": null}, "macro.dbt.generate_database_name": {"name": "generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name', 'dbt')(custom_database_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.85671, "supported_languages": null}, "macro.dbt.default__generate_database_name": {"name": "default__generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8570452, "supported_languages": null}, "macro.dbt.resolve_model_name": {"name": "resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.resolve_model_name", "macro_sql": "{% macro resolve_model_name(input_model_name) %}\n    {{ return(adapter.dispatch('resolve_model_name', 'dbt')(input_model_name)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8578289, "supported_languages": null}, "macro.dbt.default__resolve_model_name": {"name": "default__resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.default__resolve_model_name", "macro_sql": "\n\n{%- macro default__resolve_model_name(input_model_name) -%}\n    {{  input_model_name | string | replace('\"', '\\\"') }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.858025, "supported_languages": null}, "macro.dbt.build_ref_function": {"name": "build_ref_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_ref_function", "macro_sql": "{% macro build_ref_function(model) %}\n\n    {%- set ref_dict = {} -%}\n    {%- for _ref in model.refs -%}\n        {% set _ref_args = [_ref.get('package'), _ref['name']] if _ref.get('package') else [_ref['name'],] %}\n        {%- set resolved = ref(*_ref_args, v=_ref.get('version')) -%}\n\n        {#\n            We want to get the string of the returned relation by calling .render() in order to skip sample/empty\n            mode rendering logic. However, people override the default ref macro, and often return a string instead\n            of a relation (like the ref macro does by default). Thus, to make sure we dont blow things up, we have\n            to ensure the resolved relation has a .render() method.\n        #}\n        {%- if resolved.render is defined and resolved.render is callable -%}\n            {%- set resolved = resolved.render() -%}\n        {%- endif -%}\n\n        {%- if _ref.get('version') -%}\n            {% do _ref_args.extend([\"v\" ~ _ref['version']]) %}\n        {%- endif -%}\n       {%- do ref_dict.update({_ref_args | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef ref(*args, **kwargs):\n    refs = {{ ref_dict | tojson }}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8592982, "supported_languages": null}, "macro.dbt.build_source_function": {"name": "build_source_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_source_function", "macro_sql": "{% macro build_source_function(model) %}\n\n    {%- set source_dict = {} -%}\n    {%- for _source in model.sources -%}\n        {%- set resolved = source(*_source) -%}\n        {%- do source_dict.update({_source | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef source(*args, dbt_load_df_function):\n    sources = {{ source_dict | tojson }}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.859856, "supported_languages": null}, "macro.dbt.build_config_dict": {"name": "build_config_dict", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_config_dict", "macro_sql": "{% macro build_config_dict(model) %}\n    {%- set config_dict = {} -%}\n    {% set config_dbt_used = zip(model.config.config_keys_used, model.config.config_keys_defaults) | list %}\n    {%- for key, default in config_dbt_used -%}\n        {# weird type testing with enum, would be much easier to write this logic in Python! #}\n        {%- if key == \"language\" -%}\n          {%- set value = \"python\" -%}\n        {%- endif -%}\n        {%- set value = model.config.get(key, default) -%}\n        {%- do config_dict.update({key: value}) -%}\n    {%- endfor -%}\nconfig_dict = {{ config_dict }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.860975, "supported_languages": null}, "macro.dbt.py_script_postfix": {"name": "py_script_postfix", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_postfix", "macro_sql": "{% macro py_script_postfix(model) %}\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\n{{ build_ref_function(model ) }}\n{{ build_source_function(model ) }}\n{{ build_config_dict(model) }}\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"{{ this.database }}\"\n    schema = \"{{ this.schema }}\"\n    identifier = \"{{ this.identifier }}\"\n    {% set this_relation_name = resolve_model_name(this) %}\n    def __repr__(self):\n        return '{{ this_relation_name  }}'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = {{ is_incremental() }}\n\n# COMMAND ----------\n{{py_script_comment()}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.build_ref_function", "macro.dbt.build_source_function", "macro.dbt.build_config_dict", "macro.dbt.resolve_model_name", "macro.dbt.is_incremental", "macro.dbt.py_script_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8617647, "supported_languages": null}, "macro.dbt.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8619153, "supported_languages": null}, "macro.dbt.run_hooks": {"name": "run_hooks", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8639333, "supported_languages": null}, "macro.dbt.make_hook_config": {"name": "make_hook_config", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8644388, "supported_languages": null}, "macro.dbt.before_begin": {"name": "before_begin", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8647962, "supported_languages": null}, "macro.dbt.in_transaction": {"name": "in_transaction", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8650794, "supported_languages": null}, "macro.dbt.after_commit": {"name": "after_commit", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8654237, "supported_languages": null}, "macro.dbt.set_sql_header": {"name": "set_sql_header", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8662028, "supported_languages": null}, "macro.dbt.should_full_refresh": {"name": "should_full_refresh", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8669276, "supported_languages": null}, "macro.dbt.should_store_failures": {"name": "should_store_failures", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_store_failures", "macro_sql": "{% macro should_store_failures() %}\n  {% set config_store_failures = config.get('store_failures') %}\n  {% if config_store_failures is none %}\n    {% set config_store_failures = flags.STORE_FAILURES %}\n  {% endif %}\n  {% do return(config_store_failures) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8673713, "supported_languages": null}, "macro.dbt.snapshot_merge_sql": {"name": "snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql', 'dbt')(target, source, insert_cols) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.867953, "supported_languages": null}, "macro.dbt.default__snapshot_merge_sql": {"name": "default__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    {%- set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() -%}\n\n    merge into {{ target.render() }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.{{ columns.dbt_scd_id }} = DBT_INTERNAL_DEST.{{ columns.dbt_scd_id }}\n\n    when matched\n     {% if config.get(\"dbt_valid_to_current\") %}\n\t{% set source_unique_key = (\"DBT_INTERNAL_DEST.\" ~ columns.dbt_valid_to) | trim %}\n\t{% set target_unique_key = config.get('dbt_valid_to_current') | trim %}\n\tand ({{ equals(source_unique_key, target_unique_key) }} or {{ source_unique_key }} is null)\n\n     {% else %}\n       and DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null\n     {% endif %}\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set {{ columns.dbt_valid_to }} = DBT_INTERNAL_SOURCE.{{ columns.dbt_valid_to }}\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8690598, "supported_languages": null}, "macro.dbt.materialization_snapshot_default": {"name": "materialization_snapshot_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot.sql", "original_file_path": "macros/materializations/snapshots/snapshot.sql", "unique_id": "macro.dbt.materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  -- grab current tables grants config for comparision later on\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {# The model['config'] parameter below is no longer used, but passing anyway for compatibility #}\n  {# It was a dictionary of config, instead of the config object from the context #}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set build_or_select_sql = build_sql %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.assert_valid_snapshot_target_given_strategy(target_relation, columns, strategy) }}\n\n      {% set build_or_select_sql = snapshot_staging_table(strategy, sql, target_relation) %}\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set remove_columns = ['dbt_change_type', 'DBT_CHANGE_TYPE', 'dbt_unique_key', 'DBT_UNIQUE_KEY'] %}\n      {% if unique_key | is_list %}\n          {% for key in strategy.unique_key %}\n              {{ remove_columns.append('dbt_unique_key_' + loop.index|string) }}\n              {{ remove_columns.append('DBT_UNIQUE_KEY_' + loop.index|string) }}\n          {% endfor %}\n      {% endif %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n\n  {{ check_time_data_types(build_or_select_sql) }}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode=False) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_staging_table", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.check_time_data_types", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8745668, "supported_languages": ["sql"]}, "macro.dbt.strategy_dispatch": {"name": "strategy_dispatch", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8775222, "supported_languages": null}, "macro.dbt.snapshot_hash_arguments": {"name": "snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments', 'dbt')(args) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8777623, "supported_languages": null}, "macro.dbt.default__snapshot_hash_arguments": {"name": "default__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8782187, "supported_languages": null}, "macro.dbt.snapshot_timestamp_strategy": {"name": "snapshot_timestamp_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, model_config, target_exists) %}\n    {# The model_config parameter is no longer used, but is passed in anyway for compatibility. #}\n    {% set primary_key = config.get('unique_key') %}\n    {% set updated_at = config.get('updated_at') %}\n    {% set hard_deletes = adapter.get_hard_deletes_behavior(config) %}\n    {% set invalidate_hard_deletes = hard_deletes == 'invalidate' %}\n    {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/dbt-labs/dbt-core/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ columns.dbt_valid_from }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_args = api.Relation.scd_args(primary_key, updated_at) %}\n    {% set scd_id_expr = snapshot_hash_arguments(scd_args) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes,\n        \"hard_deletes\": hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8801003, "supported_languages": null}, "macro.dbt.snapshot_string_as_time": {"name": "snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time', 'dbt')(timestamp) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_string_as_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8803349, "supported_languages": null}, "macro.dbt.default__snapshot_string_as_time": {"name": "default__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.880547, "supported_languages": null}, "macro.dbt.snapshot_check_all_get_existing_columns": {"name": "snapshot_check_all_get_existing_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) -%}\n    {%- if not target_exists -%}\n        {#-- no table yet -> return whatever the query does --#}\n        {{ return((false, query_columns)) }}\n    {%- endif -%}\n\n    {#-- handle any schema changes --#}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=node.alias) -%}\n\n    {% if check_cols_config == 'all' %}\n        {%- set query_columns = get_columns_in_query(node['compiled_code']) -%}\n\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {#-- query for proper casing/quoting, to support comparison below --#}\n        {%- set select_check_cols_from_target -%}\n            {#-- N.B. The whitespace below is necessary to avoid edge case issue with comments --#}\n            {#-- See: https://github.com/dbt-labs/dbt-core/issues/6781 --#}\n            select {{ check_cols_config | join(', ') }} from (\n                {{ node['compiled_code'] }}\n            ) subq\n        {%- endset -%}\n        {% set query_columns = get_columns_in_query(select_check_cols_from_target) %}\n\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set existing_cols = adapter.get_columns_in_relation(target_relation) | map(attribute = 'name') | list -%}\n    {%- set ns = namespace() -%} {#-- handle for-loop scoping with a namespace --#}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(adapter.quote(col)) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return((ns.column_added, intersection)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8822265, "supported_languages": null}, "macro.dbt.snapshot_check_strategy": {"name": "snapshot_check_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, model_config, target_exists) %}\n    {# The model_config parameter is no longer used, but is passed in anyway for compatibility. #}\n    {% set check_cols_config = config.get('check_cols') %}\n    {% set primary_key = config.get('unique_key') %}\n    {% set hard_deletes = adapter.get_hard_deletes_behavior(config) %}\n    {% set invalidate_hard_deletes = hard_deletes == 'invalidate' %}\n    {% set updated_at = config.get('updated_at') or snapshot_get_time() %}\n\n    {% set column_added = false %}\n\n    {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        {{ get_true_sql() }}\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        (\n            (({{ snapshotted_rel }}.{{ col }} is null) and not ({{ current_rel }}.{{ col }} is null))\n            or\n            ((not {{ snapshotted_rel }}.{{ col }} is null) and ({{ current_rel }}.{{ col }} is null))\n        )\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_args = api.Relation.scd_args(primary_key, updated_at) %}\n    {% set scd_id_expr = snapshot_hash_arguments(scd_args) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes,\n        \"hard_deletes\": hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.get_true_sql", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8841386, "supported_languages": null}, "macro.dbt.create_columns": {"name": "create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns', 'dbt')(relation, columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8866694, "supported_languages": null}, "macro.dbt.default__create_columns": {"name": "default__create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation.render() }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8871078, "supported_languages": null}, "macro.dbt.post_snapshot": {"name": "post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot', 'dbt')(staging_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8873787, "supported_languages": null}, "macro.dbt.default__post_snapshot": {"name": "default__post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.887504, "supported_languages": null}, "macro.dbt.get_true_sql": {"name": "get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_true_sql", "macro_sql": "{% macro get_true_sql() %}\n  {{ adapter.dispatch('get_true_sql', 'dbt')() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_true_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8876848, "supported_languages": null}, "macro.dbt.default__get_true_sql": {"name": "default__get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__get_true_sql", "macro_sql": "{% macro default__get_true_sql() %}\n    {{ return('TRUE') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8878586, "supported_languages": null}, "macro.dbt.snapshot_staging_table": {"name": "snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n  {{ adapter.dispatch('snapshot_staging_table', 'dbt')(strategy, source_sql, target_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__snapshot_staging_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8881037, "supported_languages": null}, "macro.dbt.get_snapshot_table_column_names": {"name": "get_snapshot_table_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_snapshot_table_column_names", "macro_sql": "{% macro get_snapshot_table_column_names() %}\n    {{ return({'dbt_valid_to': 'dbt_valid_to', 'dbt_valid_from': 'dbt_valid_from', 'dbt_scd_id': 'dbt_scd_id', 'dbt_updated_at': 'dbt_updated_at', 'dbt_is_deleted': 'dbt_is_deleted'}) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8883953, "supported_languages": null}, "macro.dbt.default__snapshot_staging_table": {"name": "default__snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__snapshot_staging_table", "macro_sql": "{% macro default__snapshot_staging_table(strategy, source_sql, target_relation) -%}\n    {% set columns = config.get('snapshot_table_column_names') or get_snapshot_table_column_names() %}\n    {% if strategy.hard_deletes == 'new_record' %}\n        {% set new_scd_id = snapshot_hash_arguments([columns.dbt_scd_id, snapshot_get_time()]) %}\n    {% endif %}\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }}\n        from {{ target_relation }}\n        where\n            {% if config.get('dbt_valid_to_current') %}\n\t\t{% set source_unique_key = columns.dbt_valid_to | trim %}\n\t\t{% set target_unique_key = config.get('dbt_valid_to_current') | trim %}\n\n\t\t{# The exact equals semantics between NULL values depends on the current behavior flag set. Also, update records if the source field is null #}\n                ( {{ equals(source_unique_key, target_unique_key) }} or {{ source_unique_key }} is null )\n            {% else %}\n                {{ columns.dbt_valid_to }} is null\n            {% endif %}\n\n    ),\n\n    insertions_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }},\n            {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n            {{ get_dbt_valid_to_current(strategy, columns) }},\n            {{ strategy.scd_id }} as {{ columns.dbt_scd_id }}\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }},\n            {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_to }}\n\n        from snapshot_query\n    ),\n\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n\n    deletes_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }}\n        from snapshot_query\n    ),\n    {% endif %}\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            ,'False' as {{ columns.dbt_is_deleted }}\n          {%- endif %}\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n            where {{ unique_key_is_null(strategy.unique_key, \"snapshotted_data\") }}\n            or ({{ unique_key_is_not_null(strategy.unique_key, \"snapshotted_data\") }} and (\n               {{ strategy.row_changed }} {%- if strategy.hard_deletes == 'new_record' -%} or snapshotted_data.{{ columns.dbt_is_deleted }} = 'True' {% endif %}\n            )\n\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.{{ columns.dbt_scd_id }}\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            , snapshotted_data.{{ columns.dbt_is_deleted }}\n          {%- endif %}\n\n        from updates_source_data as source_data\n        join snapshotted_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n        where (\n            {{ strategy.row_changed }}  {%- if strategy.hard_deletes == 'new_record' -%} or snapshotted_data.{{ columns.dbt_is_deleted }} = 'True' {% endif %}\n        )\n    )\n\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n    ,\n    deletes as (\n\n        select\n            'delete' as dbt_change_type,\n            source_data.*,\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_from }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_updated_at }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_to }},\n            snapshotted_data.{{ columns.dbt_scd_id }}\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            , snapshotted_data.{{ columns.dbt_is_deleted }}\n          {%- endif %}\n        from snapshotted_data\n        left join deletes_source_data as source_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n            where {{ unique_key_is_null(strategy.unique_key, \"source_data\") }}\n\n            {%- if strategy.hard_deletes == 'new_record' %}\n            and not (\n                --avoid updating the record's valid_to if the latest entry is marked as deleted\n                snapshotted_data.{{ columns.dbt_is_deleted }} = 'True'\n                and snapshotted_data.{{ columns.dbt_valid_to }} is null\n            )\n            {%- endif %}\n    )\n    {%- endif %}\n\n    {%- if strategy.hard_deletes == 'new_record' %}\n        {% set snapshotted_cols = get_list_of_column_names(get_columns_in_relation(target_relation)) %}\n        {% set source_sql_cols = get_column_schema_from_query(source_sql) %}\n    ,\n    deletion_records as (\n\n        select\n            'insert' as dbt_change_type,\n            {#\n                If a column has been added to the source it won't yet exist in the\n                snapshotted table so we insert a null value as a placeholder for the column.\n             #}\n            {%- for col in source_sql_cols -%}\n            {%- if col.name in snapshotted_cols -%}\n            snapshotted_data.{{ adapter.quote(col.column) }},\n            {%- else -%}\n            NULL as {{ adapter.quote(col.column) }},\n            {%- endif -%}\n            {% endfor -%}\n            {%- if strategy.unique_key | is_list -%}\n                {%- for key in strategy.unique_key -%}\n            snapshotted_data.{{ key }} as dbt_unique_key_{{ loop.index }},\n                {% endfor -%}\n            {%- else -%}\n            snapshotted_data.dbt_unique_key as dbt_unique_key,\n            {% endif -%}\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_from }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_updated_at }},\n            snapshotted_data.{{ columns.dbt_valid_to }} as {{ columns.dbt_valid_to }},\n            {{ new_scd_id }} as {{ columns.dbt_scd_id }},\n            'True' as {{ columns.dbt_is_deleted }}\n        from snapshotted_data\n        left join deletes_source_data as source_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n        where {{ unique_key_is_null(strategy.unique_key, \"source_data\") }}\n        and not (\n            --avoid inserting a new record if the latest one is marked as deleted\n            snapshotted_data.{{ columns.dbt_is_deleted }} = 'True'\n            and snapshotted_data.{{ columns.dbt_valid_to }} is null\n            )\n\n    )\n    {%- endif %}\n\n    select * from insertions\n    union all\n    select * from updates\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n    union all\n    select * from deletes\n    {%- endif %}\n    {%- if strategy.hard_deletes == 'new_record' %}\n    union all\n    select * from deletion_records\n    {%- endif %}\n\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_hash_arguments", "macro.dbt.snapshot_get_time", "macro.dbt.unique_key_fields", "macro.dbt.equals", "macro.dbt.get_dbt_valid_to_current", "macro.dbt.unique_key_join_on", "macro.dbt.unique_key_is_null", "macro.dbt.unique_key_is_not_null", "macro.dbt.get_list_of_column_names", "macro.dbt.get_columns_in_relation", "macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.893799, "supported_languages": null}, "macro.dbt.build_snapshot_table": {"name": "build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) -%}\n  {{ adapter.dispatch('build_snapshot_table', 'dbt')(strategy, sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__build_snapshot_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8941429, "supported_languages": null}, "macro.dbt.default__build_snapshot_table": {"name": "default__build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__build_snapshot_table", "macro_sql": "{% macro default__build_snapshot_table(strategy, sql) %}\n    {% set columns = config.get('snapshot_table_column_names') or get_snapshot_table_column_names() %}\n\n    select *,\n        {{ strategy.scd_id }} as {{ columns.dbt_scd_id }},\n        {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n        {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n        {{ get_dbt_valid_to_current(strategy, columns) }}\n      {%- if strategy.hard_deletes == 'new_record' -%}\n        , 'False' as {{ columns.dbt_is_deleted }}\n      {% endif -%}\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.get_dbt_valid_to_current"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8948202, "supported_languages": null}, "macro.dbt.build_snapshot_staging_table": {"name": "build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set temp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, temp_relation, select) }}\n    {% endcall %}\n\n    {% do return(temp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8953986, "supported_languages": null}, "macro.dbt.get_updated_at_column_data_type": {"name": "get_updated_at_column_data_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_updated_at_column_data_type", "macro_sql": "{% macro get_updated_at_column_data_type(snapshot_sql) %}\n    {% set snapshot_sql_column_schema = get_column_schema_from_query(snapshot_sql) %}\n    {% set dbt_updated_at_data_type = null %}\n    {% set ns = namespace() -%} {#-- handle for-loop scoping with a namespace --#}\n    {% set ns.dbt_updated_at_data_type = null -%}\n    {% for column in snapshot_sql_column_schema %}\n    {%   if ((column.column == 'dbt_updated_at') or (column.column == 'DBT_UPDATED_AT')) %}\n    {%     set ns.dbt_updated_at_data_type = column.dtype %}\n    {%   endif %}\n    {% endfor %}\n    {{ return(ns.dbt_updated_at_data_type or none)  }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8961794, "supported_languages": null}, "macro.dbt.check_time_data_types": {"name": "check_time_data_types", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.check_time_data_types", "macro_sql": "{% macro check_time_data_types(sql) %}\n  {% set dbt_updated_at_data_type = get_updated_at_column_data_type(sql) %}\n  {% set snapshot_get_time_data_type = get_snapshot_get_time_data_type() %}\n  {% if snapshot_get_time_data_type is not none and dbt_updated_at_data_type is not none and snapshot_get_time_data_type != dbt_updated_at_data_type %}\n  {%   if exceptions.warn_snapshot_timestamp_data_types %}\n  {{     exceptions.warn_snapshot_timestamp_data_types(snapshot_get_time_data_type, dbt_updated_at_data_type) }}\n  {%   endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_updated_at_column_data_type", "macro.dbt.get_snapshot_get_time_data_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8967876, "supported_languages": null}, "macro.dbt.get_dbt_valid_to_current": {"name": "get_dbt_valid_to_current", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_dbt_valid_to_current", "macro_sql": "{% macro get_dbt_valid_to_current(strategy, columns) %}\n  {% set dbt_valid_to_current = config.get('dbt_valid_to_current') or \"null\" %}\n  coalesce(nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}), {{dbt_valid_to_current}})\n  as {{ columns.dbt_valid_to }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.897173, "supported_languages": null}, "macro.dbt.unique_key_fields": {"name": "unique_key_fields", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_fields", "macro_sql": "{% macro unique_key_fields(unique_key) %}\n    {% if unique_key | is_list %}\n        {% for key in unique_key %}\n            {{ key }} as dbt_unique_key_{{ loop.index }}\n            {%- if not loop.last %} , {%- endif %}\n        {% endfor %}\n    {% else %}\n        {{ unique_key }} as dbt_unique_key\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8976865, "supported_languages": null}, "macro.dbt.unique_key_join_on": {"name": "unique_key_join_on", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_join_on", "macro_sql": "{% macro unique_key_join_on(unique_key, identifier, from_identifier) %}\n    {% if unique_key | is_list %}\n        {% for key in unique_key %}\n\t    {% set source_unique_key = (identifier ~ \".dbt_unique_key_\" ~ loop.index) | trim %}\n\t    {% set target_unique_key = (from_identifier ~ \".dbt_unique_key_\" ~ loop.index) | trim %}\n\t    {{ equals(source_unique_key, target_unique_key) }}\n            {%- if not loop.last %} and {%- endif %}\n        {% endfor %}\n    {% else %}\n        {{ identifier }}.dbt_unique_key = {{ from_identifier }}.dbt_unique_key\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8984742, "supported_languages": null}, "macro.dbt.unique_key_is_null": {"name": "unique_key_is_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_is_null", "macro_sql": "{% macro unique_key_is_null(unique_key, identifier) %}\n    {% if unique_key | is_list %}\n        {{ identifier }}.dbt_unique_key_1 is null\n    {% else %}\n        {{ identifier }}.dbt_unique_key is null\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8987908, "supported_languages": null}, "macro.dbt.unique_key_is_not_null": {"name": "unique_key_is_not_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_is_not_null", "macro_sql": "{% macro unique_key_is_not_null(unique_key, identifier) %}\n    {% if unique_key | is_list %}\n        {{ identifier }}.dbt_unique_key_1 is not null\n    {% else %}\n        {{ identifier }}.dbt_unique_key is not null\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.8990974, "supported_languages": null}, "macro.dbt.materialization_seed_default": {"name": "materialization_seed_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/seed.sql", "original_file_path": "macros/materializations/seeds/seed.sql", "unique_id": "macro.dbt.materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparison later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation.render())) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.get_csv_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.90226, "supported_languages": ["sql"]}, "macro.dbt.create_csv_table": {"name": "create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9033694, "supported_languages": null}, "macro.dbt.default__create_csv_table": {"name": "default__create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9046285, "supported_languages": null}, "macro.dbt.reset_csv_table": {"name": "reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table', 'dbt')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__reset_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9049723, "supported_languages": null}, "macro.dbt.default__reset_csv_table": {"name": "default__reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation.render() %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.906107, "supported_languages": null}, "macro.dbt.get_csv_sql": {"name": "get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_csv_sql", "macro_sql": "{% macro get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ adapter.dispatch('get_csv_sql', 'dbt')(create_or_truncate_sql, insert_sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_csv_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9063811, "supported_languages": null}, "macro.dbt.default__get_csv_sql": {"name": "default__get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_csv_sql", "macro_sql": "{% macro default__get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ create_or_truncate_sql }};\n    -- dbt seed --\n    {{ insert_sql }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9065561, "supported_languages": null}, "macro.dbt.get_binding_char": {"name": "get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_binding_char", "macro_sql": "{% macro get_binding_char() -%}\n  {{ adapter.dispatch('get_binding_char', 'dbt')() }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9067671, "supported_languages": null}, "macro.dbt.default__get_binding_char": {"name": "default__get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_binding_char", "macro_sql": "{% macro default__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9070203, "supported_languages": null}, "macro.dbt.get_batch_size": {"name": "get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_batch_size", "macro_sql": "{% macro get_batch_size() -%}\n  {{ return(adapter.dispatch('get_batch_size', 'dbt')()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_batch_size"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9072676, "supported_languages": null}, "macro.dbt.default__get_batch_size": {"name": "default__get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_batch_size", "macro_sql": "{% macro default__get_batch_size() %}\n  {{ return(10000) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9074543, "supported_languages": null}, "macro.dbt.get_seed_column_quoted_csv": {"name": "get_seed_column_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9080825, "supported_languages": null}, "macro.dbt.load_csv_rows": {"name": "load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__load_csv_rows"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9083073, "supported_languages": null}, "macro.dbt.default__load_csv_rows": {"name": "default__load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n\n  {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n  {% set bindings = [] %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} ({{ cols_sql }}) values\n          {% for row in chunk -%}\n              ({%- for column in agate_table.column_names -%}\n                  {{ get_binding_char() }}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9102838, "supported_languages": null}, "macro.dbt.materialization_view_default": {"name": "materialization_view_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view.sql", "original_file_path": "macros/materializations/models/view.sql", "unique_id": "macro.dbt.materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='view') -%}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"existing_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the existing_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the existing_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if existing_relation is not none %}\n     /* Do the equivalent of rename_if_exists. 'existing_relation' could have been dropped\n        since the variable was first set. */\n    {% set existing_relation = load_cached_relation(existing_relation) %}\n    {% if existing_relation is not none %}\n        {{ adapter.rename_relation(existing_relation, backup_relation) }}\n    {% endif %}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.run_hooks", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9141204, "supported_languages": ["sql"]}, "macro.dbt.materialization_table_default": {"name": "materialization_table_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table.sql", "original_file_path": "macros/materializations/models/table.sql", "unique_id": "macro.dbt.materialization_table_default", "macro_sql": "{% materialization table, default %}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') %}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_table_as_sql(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  {% do create_indexes(intermediate_relation) %}\n\n  -- cleanup\n  {% if existing_relation is not none %}\n     /* Do the equivalent of rename_if_exists. 'existing_relation' could have been dropped\n        since the variable was first set. */\n    {% set existing_relation = load_cached_relation(existing_relation) %}\n    {% if existing_relation is not none %}\n        {{ adapter.rename_relation(existing_relation, backup_relation) }}\n    {% endif %}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.get_create_table_as_sql", "macro.dbt.create_indexes", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9189668, "supported_languages": ["sql"]}, "macro.dbt.materialization_materialized_view_default": {"name": "materialization_materialized_view_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialization_materialized_view_default", "macro_sql": "{% materialization materialized_view, default %}\n    {% set existing_relation = load_cached_relation(this) %}\n    {% set target_relation = this.incorporate(type=this.MaterializedView) %}\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set backup_relation_type = target_relation.MaterializedView if existing_relation is none else existing_relation.type %}\n    {% set backup_relation = make_backup_relation(target_relation, backup_relation_type) %}\n\n    {{ materialized_view_setup(backup_relation, intermediate_relation, pre_hooks) }}\n\n        {% set build_sql = materialized_view_get_build_sql(existing_relation, target_relation, backup_relation, intermediate_relation) %}\n\n        {% if build_sql == '' %}\n            {{ materialized_view_execute_no_op(target_relation) }}\n        {% else %}\n            {{ materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n        {% endif %}\n\n    {{ materialized_view_teardown(backup_relation, intermediate_relation, post_hooks) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.materialized_view_setup", "macro.dbt.materialized_view_get_build_sql", "macro.dbt.materialized_view_execute_no_op", "macro.dbt.materialized_view_execute_build_sql", "macro.dbt.materialized_view_teardown"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9226, "supported_languages": ["sql"]}, "macro.dbt.materialized_view_setup": {"name": "materialized_view_setup", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_setup", "macro_sql": "{% macro materialized_view_setup(backup_relation, intermediate_relation, pre_hooks) %}\n\n    -- backup_relation and intermediate_relation should not already exist in the database\n    -- it's possible these exist because of a previous run that exited unexpectedly\n    {% set preexisting_backup_relation = load_cached_relation(backup_relation) %}\n    {% set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) %}\n\n    -- drop the temp relations if they exist already in the database\n    {{ drop_relation_if_exists(preexisting_backup_relation) }}\n    {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9235952, "supported_languages": null}, "macro.dbt.materialized_view_teardown": {"name": "materialized_view_teardown", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_teardown", "macro_sql": "{% macro materialized_view_teardown(backup_relation, intermediate_relation, post_hooks) %}\n\n    -- drop the temp relations if they exist to leave the database clean for the next run\n    {{ drop_relation_if_exists(backup_relation) }}\n    {{ drop_relation_if_exists(intermediate_relation) }}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9242513, "supported_languages": null}, "macro.dbt.materialized_view_get_build_sql": {"name": "materialized_view_get_build_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_get_build_sql", "macro_sql": "{% macro materialized_view_get_build_sql(existing_relation, target_relation, backup_relation, intermediate_relation) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_materialized_view_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_materialized_view %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_materialized_view_configuration_changes(existing_relation, config) %}\n\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_materialized_view(target_relation) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_materialized_view_as_sql(target_relation, configuration_changes, sql, existing_relation, backup_relation, intermediate_relation) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = '' %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation.render() ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation.render() ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt.get_replace_sql", "macro.dbt.get_materialized_view_configuration_changes", "macro.dbt.refresh_materialized_view", "macro.dbt.get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9271886, "supported_languages": null}, "macro.dbt.materialized_view_execute_no_op": {"name": "materialized_view_execute_no_op", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_execute_no_op", "macro_sql": "{% macro materialized_view_execute_no_op(target_relation) %}\n    {% do store_raw_result(\n        name=\"main\",\n        message=\"skip \" ~ target_relation,\n        code=\"skip\",\n        rows_affected=\"-1\"\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9278002, "supported_languages": null}, "macro.dbt.materialized_view_execute_build_sql": {"name": "materialized_view_execute_build_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_execute_build_sql", "macro_sql": "{% macro materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {% call statement(name=\"main\") %}\n        {{ build_sql }}\n    {% endcall %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {% do persist_docs(target_relation, model) %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {{ adapter.commit() }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9296093, "supported_languages": null}, "macro.dbt.is_incremental": {"name": "is_incremental", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/is_incremental.sql", "original_file_path": "macros/materializations/models/incremental/is_incremental.sql", "unique_id": "macro.dbt.is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9310937, "supported_languages": null}, "macro.dbt.incremental_validate_on_schema_change": {"name": "incremental_validate_on_schema_change", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.incremental_validate_on_schema_change", "macro_sql": "{% macro incremental_validate_on_schema_change(on_schema_change, default='ignore') %}\n\n   {% if on_schema_change not in ['sync_all_columns', 'append_new_columns', 'fail', 'ignore'] %}\n\n     {% set log_message = 'Invalid value for on_schema_change (%s) specified. Setting default value of %s.' % (on_schema_change, default) %}\n     {% do log(log_message) %}\n\n     {{ return(default) }}\n\n   {% else %}\n\n     {{ return(on_schema_change) }}\n\n   {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9328983, "supported_languages": null}, "macro.dbt.check_for_schema_changes": {"name": "check_for_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.check_for_schema_changes", "macro_sql": "{% macro check_for_schema_changes(source_relation, target_relation) %}\n\n  {% set schema_changed = False %}\n\n  {%- set source_columns = adapter.get_columns_in_relation(source_relation) -%}\n  {%- set target_columns = adapter.get_columns_in_relation(target_relation) -%}\n  {%- set source_not_in_target = diff_columns(source_columns, target_columns) -%}\n  {%- set target_not_in_source = diff_columns(target_columns, source_columns) -%}\n\n  {% set new_target_types = diff_column_data_types(source_columns, target_columns) %}\n\n  {% if source_not_in_target != [] %}\n    {% set schema_changed = True %}\n  {% elif target_not_in_source != [] or new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% elif new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% endif %}\n\n  {% set changes_dict = {\n    'schema_changed': schema_changed,\n    'source_not_in_target': source_not_in_target,\n    'target_not_in_source': target_not_in_source,\n    'source_columns': source_columns,\n    'target_columns': target_columns,\n    'new_target_types': new_target_types\n  } %}\n\n  {% set msg %}\n    In {{ target_relation }}:\n        Schema changed: {{ schema_changed }}\n        Source columns not in target: {{ source_not_in_target }}\n        Target columns not in source: {{ target_not_in_source }}\n        New column types: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(msg) %}\n\n  {{ return(changes_dict) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.diff_columns", "macro.dbt.diff_column_data_types"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9346175, "supported_languages": null}, "macro.dbt.sync_column_schemas": {"name": "sync_column_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.sync_column_schemas", "macro_sql": "{% macro sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n  {%- set add_to_target_arr = schema_changes_dict['source_not_in_target'] -%}\n\n  {%- if on_schema_change == 'append_new_columns'-%}\n     {%- if add_to_target_arr | length > 0 -%}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, none) -%}\n     {%- endif -%}\n\n  {% elif on_schema_change == 'sync_all_columns' %}\n     {%- set remove_from_target_arr = schema_changes_dict['target_not_in_source'] -%}\n     {%- set new_target_types = schema_changes_dict['new_target_types'] -%}\n\n     {% if add_to_target_arr | length > 0 or remove_from_target_arr | length > 0 %}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, remove_from_target_arr) -%}\n     {% endif %}\n\n     {% if new_target_types != [] %}\n       {% for ntt in new_target_types %}\n         {% set column_name = ntt['column_name'] %}\n         {% set new_type = ntt['new_type'] %}\n         {% do alter_column_type(target_relation, column_name, new_type) %}\n       {% endfor %}\n     {% endif %}\n\n  {% endif %}\n\n  {% set schema_change_message %}\n    In {{ target_relation }}:\n        Schema change approach: {{ on_schema_change }}\n        Columns added: {{ add_to_target_arr }}\n        Columns removed: {{ remove_from_target_arr }}\n        Data types changed: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(schema_change_message) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_relation_add_remove_columns", "macro.dbt.alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9372606, "supported_languages": null}, "macro.dbt.process_schema_changes": {"name": "process_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.process_schema_changes", "macro_sql": "{% macro process_schema_changes(on_schema_change, source_relation, target_relation) %}\n\n    {% if on_schema_change == 'ignore' %}\n\n     {{ return({}) }}\n\n    {% else %}\n\n      {% set schema_changes_dict = check_for_schema_changes(source_relation, target_relation) %}\n\n      {% if schema_changes_dict['schema_changed'] %}\n\n        {% if on_schema_change == 'fail' %}\n\n          {% set fail_msg %}\n              The source and target schemas on this incremental model are out of sync!\n              They can be reconciled in several ways:\n                - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.\n                - Re-run the incremental model with `full_refresh: True` to update the target schema.\n                - update the schema manually and re-run the process.\n\n              Additional troubleshooting context:\n                 Source columns not in target: {{ schema_changes_dict['source_not_in_target'] }}\n                 Target columns not in source: {{ schema_changes_dict['target_not_in_source'] }}\n                 New column types: {{ schema_changes_dict['new_target_types'] }}\n          {% endset %}\n\n          {% do exceptions.raise_compiler_error(fail_msg) %}\n\n        {# -- unless we ignore, run the sync operation per the config #}\n        {% else %}\n\n          {% do sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n        {% endif %}\n\n      {% endif %}\n\n      {{ return(schema_changes_dict['source_columns']) }}\n\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.check_for_schema_changes", "macro.dbt.sync_column_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.938918, "supported_languages": null}, "macro.dbt.get_merge_sql": {"name": "get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n   -- back compat for old kwarg name\n  {% set incremental_predicates = kwargs.get('predicates', incremental_predicates) %}\n  {{ adapter.dispatch('get_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.941306, "supported_languages": null}, "macro.dbt.default__get_merge_sql": {"name": "default__get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n    {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set merge_update_columns = config.get('merge_update_columns') -%}\n    {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n    {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n            {% for key in unique_key %}\n                {% set this_key_match %}\n                    DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n                {% endset %}\n                {% do predicates.append(this_key_match) %}\n            {% endfor %}\n        {% else %}\n            {% set source_unique_key = (\"DBT_INTERNAL_SOURCE.\" ~ unique_key) | trim %}\n\t    {% set target_unique_key = (\"DBT_INTERNAL_DEST.\" ~ unique_key) | trim %}\n\t    {% set unique_key_match = equals(source_unique_key, target_unique_key) | trim %}\n            {% do predicates.append(unique_key_match) %}\n        {% endif %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{\"(\" ~ predicates | join(\") and (\") ~ \")\"}}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column_name in update_columns -%}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv", "macro.dbt.get_merge_update_columns", "macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9449632, "supported_languages": null}, "macro.dbt.get_delete_insert_merge_sql": {"name": "get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9455664, "supported_languages": null}, "macro.dbt.default__get_delete_insert_merge_sql": {"name": "default__get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% if unique_key is string %}\n        {% set unique_key = [unique_key] %}\n        {% endif %}\n\n        {%- set unique_key_str = unique_key|join(', ') -%}\n\n        delete from {{ target }} as DBT_INTERNAL_DEST\n        where ({{ unique_key_str }}) in (\n            select distinct {{ unique_key_str }}\n            from {{ source }} as DBT_INTERNAL_SOURCE\n        )\n        {%- if incremental_predicates %}\n            {% for predicate in incremental_predicates %}\n                and {{ predicate }}\n            {% endfor %}\n        {%- endif -%};\n\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    )\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9469333, "supported_languages": null}, "macro.dbt.get_insert_overwrite_merge_sql": {"name": "get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql', 'dbt')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.947276, "supported_languages": null}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"name": "default__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {#-- The only time include_sql_header is True: --#}\n    {#-- BigQuery + insert_overwrite strategy + \"static\" partitions config --#}\n    {#-- We should consider including the sql header at the materialization level instead --#}\n\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9480588, "supported_languages": null}, "macro.dbt.materialization_incremental_default": {"name": "materialization_incremental_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/incremental.sql", "original_file_path": "macros/materializations/models/incremental/incremental.sql", "unique_id": "macro.dbt.materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  -- relations\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') -%}\n  {%- set temp_relation = make_temp_relation(target_relation)-%}\n  {%- set intermediate_relation = make_intermediate_relation(target_relation)-%}\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n\n  -- configs\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()  or existing_relation.is_view) -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n\n  -- the temp_ and backup_ relations should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation. This has to happen before\n  -- BEGIN, in a separate transaction\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation)-%}\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n   -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n\n  {% set incremental_strategy = config.get('incremental_strategy') or 'default' %}\n  {% set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) %}\n\n  {% if existing_relation is none %}\n      {% set build_sql = get_create_table_as_sql(False, target_relation, sql) %}\n      {% set relation_for_indexes = target_relation %}\n  {% elif full_refresh_mode %}\n      {% set build_sql = get_create_table_as_sql(False, intermediate_relation, sql) %}\n      {% set relation_for_indexes = intermediate_relation %}\n      {% set need_swap = true %}\n  {% else %}\n    {% do run_query(get_create_table_as_sql(True, temp_relation, sql)) %}\n    {% set relation_for_indexes = temp_relation %}\n    {% set contract_config = config.get('contract') %}\n    {% if not contract_config or not contract_config.enforced %}\n      {% do adapter.expand_target_column_types(\n               from_relation=temp_relation,\n               to_relation=target_relation) %}\n    {% endif %}\n    {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n    {% set dest_columns = process_schema_changes(on_schema_change, temp_relation, existing_relation) %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n\n    {#-- Get the incremental_strategy, the macro to use for the strategy, and build the sql --#}\n    {% set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) %}\n    {% set strategy_arg_dict = ({'target_relation': target_relation, 'temp_relation': temp_relation, 'unique_key': unique_key, 'dest_columns': dest_columns, 'incremental_predicates': incremental_predicates }) %}\n    {% set build_sql = strategy_sql_macro_func(strategy_arg_dict) %}\n\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% if existing_relation is none or existing_relation.is_view or should_full_refresh() %}\n    {% do create_indexes(relation_for_indexes) %}\n  {% endif %}\n\n  {% if need_swap %}\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% do adapter.rename_relation(intermediate_relation, target_relation) %}\n      {% do to_drop.append(backup_relation) %}\n  {% endif %}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_temp_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.get_create_table_as_sql", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt.statement", "macro.dbt.create_indexes", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.953274, "supported_languages": ["sql"]}, "macro.dbt.get_quoted_csv": {"name": "get_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.955127, "supported_languages": null}, "macro.dbt.diff_columns": {"name": "diff_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_columns", "macro_sql": "{% macro diff_columns(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% set source_names = source_columns | map(attribute = 'column') | list %}\n  {% set target_names = target_columns | map(attribute = 'column') | list %}\n\n   {# --check whether the name attribute exists in the target - this does not perform a data type check #}\n   {% for sc in source_columns %}\n     {% if sc.name not in target_names %}\n        {{ result.append(sc) }}\n     {% endif %}\n   {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9565983, "supported_languages": null}, "macro.dbt.diff_column_data_types": {"name": "diff_column_data_types", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_column_data_types", "macro_sql": "{% macro diff_column_data_types(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% for sc in source_columns %}\n    {% set tc = target_columns | selectattr(\"name\", \"equalto\", sc.name) | list | first %}\n    {% if tc %}\n      {% if sc.data_type != tc.data_type and not sc.can_expand_to(other_column=tc) %}\n        {{ result.append( { 'column_name': tc.name, 'new_type': sc.data_type } ) }}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9581523, "supported_languages": null}, "macro.dbt.get_merge_update_columns": {"name": "get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_merge_update_columns", "macro_sql": "{% macro get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {{ return(adapter.dispatch('get_merge_update_columns', 'dbt')(merge_update_columns, merge_exclude_columns, dest_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.958721, "supported_languages": null}, "macro.dbt.default__get_merge_update_columns": {"name": "default__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.default__get_merge_update_columns", "macro_sql": "{% macro default__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = dest_columns | map(attribute=\"quoted\") | list -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9601598, "supported_languages": null}, "macro.dbt.get_incremental_append_sql": {"name": "get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_append_sql", "macro_sql": "{% macro get_incremental_append_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_append_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.960959, "supported_languages": null}, "macro.dbt.default__get_incremental_append_sql": {"name": "default__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_append_sql", "macro_sql": "{% macro default__get_incremental_append_sql(arg_dict) %}\n\n  {% do return(get_insert_into_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9612682, "supported_languages": null}, "macro.dbt.get_incremental_delete_insert_sql": {"name": "get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_delete_insert_sql", "macro_sql": "{% macro get_incremental_delete_insert_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_delete_insert_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_delete_insert_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9614801, "supported_languages": null}, "macro.dbt.default__get_incremental_delete_insert_sql": {"name": "default__get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_delete_insert_sql", "macro_sql": "{% macro default__get_incremental_delete_insert_sql(arg_dict) %}\n\n  {% do return(get_delete_insert_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.961828, "supported_languages": null}, "macro.dbt.get_incremental_merge_sql": {"name": "get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_merge_sql", "macro_sql": "{% macro get_incremental_merge_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_merge_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.962035, "supported_languages": null}, "macro.dbt.default__get_incremental_merge_sql": {"name": "default__get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_merge_sql", "macro_sql": "{% macro default__get_incremental_merge_sql(arg_dict) %}\n\n  {% do return(get_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.962349, "supported_languages": null}, "macro.dbt.get_incremental_insert_overwrite_sql": {"name": "get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_insert_overwrite_sql", "macro_sql": "{% macro get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_insert_overwrite_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.962553, "supported_languages": null}, "macro.dbt.default__get_incremental_insert_overwrite_sql": {"name": "default__get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_insert_overwrite_sql", "macro_sql": "{% macro default__get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {% do return(get_insert_overwrite_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9628289, "supported_languages": null}, "macro.dbt.get_incremental_default_sql": {"name": "get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_default_sql", "macro_sql": "{% macro get_incremental_default_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_default_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_default_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9630525, "supported_languages": null}, "macro.dbt.default__get_incremental_default_sql": {"name": "default__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_default_sql", "macro_sql": "{% macro default__get_incremental_default_sql(arg_dict) %}\n\n  {% do return(get_incremental_append_sql(arg_dict)) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9632928, "supported_languages": null}, "macro.dbt.get_incremental_microbatch_sql": {"name": "get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_microbatch_sql", "macro_sql": "{% macro get_incremental_microbatch_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_microbatch_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_microbatch_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9636705, "supported_languages": null}, "macro.dbt.default__get_incremental_microbatch_sql": {"name": "default__get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_microbatch_sql", "macro_sql": "{% macro default__get_incremental_microbatch_sql(arg_dict) %}\n\n  {{ exceptions.raise_not_implemented('microbatch materialization strategy not implemented for adapter ' + adapter.type()) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.964077, "supported_languages": null}, "macro.dbt.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(target_relation, temp_relation, dest_columns) %}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ temp_relation }}\n    )\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9646673, "supported_languages": null}, "macro.dbt.materialization_clone_default": {"name": "materialization_clone_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/clone.sql", "original_file_path": "macros/materializations/models/clone/clone.sql", "unique_id": "macro.dbt.materialization_clone_default", "macro_sql": "{%- materialization clone, default -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation.render() ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% if target_relation.database == defer_relation.database and\n            target_relation.schema == defer_relation.schema and\n            target_relation.identifier == defer_relation.identifier %}\n        {{ log(\"Target relation and defer relation are the same, skipping clone for relation: \" ~ target_relation.render()) }}\n      {% else %}\n        {% call statement('main') %}\n            {{ create_or_replace_clone(target_relation, defer_relation) }}\n        {% endcall %}\n      {% endif %}\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n\n  {%- endif -%}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9698918, "supported_languages": ["sql"]}, "macro.dbt.can_clone_table": {"name": "can_clone_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/can_clone_table.sql", "original_file_path": "macros/materializations/models/clone/can_clone_table.sql", "unique_id": "macro.dbt.can_clone_table", "macro_sql": "{% macro can_clone_table() %}\n    {{ return(adapter.dispatch('can_clone_table', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__can_clone_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9704738, "supported_languages": null}, "macro.dbt.default__can_clone_table": {"name": "default__can_clone_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/can_clone_table.sql", "original_file_path": "macros/materializations/models/clone/can_clone_table.sql", "unique_id": "macro.dbt.default__can_clone_table", "macro_sql": "{% macro default__can_clone_table() %}\n    {{ return(False) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9707072, "supported_languages": null}, "macro.dbt.create_or_replace_clone": {"name": "create_or_replace_clone", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/create_or_replace_clone.sql", "original_file_path": "macros/materializations/models/clone/create_or_replace_clone.sql", "unique_id": "macro.dbt.create_or_replace_clone", "macro_sql": "{% macro create_or_replace_clone(this_relation, defer_relation) %}\n    {{ return(adapter.dispatch('create_or_replace_clone', 'dbt')(this_relation, defer_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_or_replace_clone"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.971276, "supported_languages": null}, "macro.dbt.default__create_or_replace_clone": {"name": "default__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/create_or_replace_clone.sql", "original_file_path": "macros/materializations/models/clone/create_or_replace_clone.sql", "unique_id": "macro.dbt.default__create_or_replace_clone", "macro_sql": "{% macro default__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace table {{ this_relation.render() }} clone {{ defer_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.971617, "supported_languages": null}, "macro.dbt.get_where_subquery": {"name": "get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.get_where_subquery", "macro_sql": "{% macro get_where_subquery(relation) -%}\n    {% do return(adapter.dispatch('get_where_subquery', 'dbt')(relation)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_where_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9722698, "supported_languages": null}, "macro.dbt.default__get_where_subquery": {"name": "default__get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.default__get_where_subquery", "macro_sql": "{% macro default__get_where_subquery(relation) -%}\n    {% set where = config.get('where', '') %}\n    {% if where %}\n        {%- set filtered -%}\n            (select * from {{ relation }} where {{ where }}) dbt_subquery\n        {%- endset -%}\n        {% do return(filtered) %}\n    {%- else -%}\n        {% do return(relation) %}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9730022, "supported_languages": null}, "macro.dbt.materialization_test_default": {"name": "materialization_test_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/test.sql", "original_file_path": "macros/materializations/tests/test.sql", "unique_id": "macro.dbt.materialization_test_default", "macro_sql": "{%- materialization test, default -%}\n\n  {% set relations = [] %}\n  {% set limit = config.get('limit') %}\n\n  {% set sql_with_limit %}\n    {{ get_limit_subquery_sql(sql, limit) }}\n  {% endset %}\n\n  {% if should_store_failures() %}\n\n    {% set identifier = model['alias'] %}\n    {% set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n    {% set store_failures_as = config.get('store_failures_as') %}\n    -- if `--store-failures` is invoked via command line and `store_failures_as` is not set,\n    -- config.get('store_failures_as', 'table') returns None, not 'table'\n    {% if store_failures_as == none %}{% set store_failures_as = 'table' %}{% endif %}\n    {% if store_failures_as not in ['table', 'view'] %}\n        {{ exceptions.raise_compiler_error(\n            \"'\" ~ store_failures_as ~ \"' is not a valid value for `store_failures_as`. \"\n            \"Accepted values are: ['ephemeral', 'table', 'view']\"\n        ) }}\n    {% endif %}\n\n    {% set target_relation = api.Relation.create(\n        identifier=identifier, schema=schema, database=database, type=store_failures_as) -%} %}\n\n    {% if old_relation %}\n        {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n\n    {% call statement(auto_begin=True) %}\n        {{ get_create_sql(target_relation, sql_with_limit) }}\n    {% endcall %}\n\n    {% do relations.append(target_relation) %}\n\n    {# Since the test failures have already been saved to the database, reuse that result rather than querying again #}\n    {% set main_sql %}\n        select *\n        from {{ target_relation }}\n    {% endset %}\n\n    {{ adapter.commit() }}\n\n  {% else %}\n\n      {% set main_sql = sql_with_limit %}\n\n  {% endif %}\n\n  {% set fail_calc = config.get('fail_calc') %}\n  {% set warn_if = config.get('warn_if') %}\n  {% set error_if = config.get('error_if') %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {# The limit has already been included above, and we do not want to duplicate it again. We also want to be safe for macro overrides treating `limit` as a required parameter. #}\n    {{ get_test_sql(main_sql, fail_calc, warn_if, error_if, limit=none)}}\n\n  {%- endcall %}\n\n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.get_limit_subquery_sql", "macro.dbt.should_store_failures", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt.get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9778447, "supported_languages": ["sql"]}, "macro.dbt.materialization_unit_default": {"name": "materialization_unit_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/unit.sql", "original_file_path": "macros/materializations/tests/unit.sql", "unique_id": "macro.dbt.materialization_unit_default", "macro_sql": "{%- materialization unit, default -%}\n\n  {% set relations = [] %}\n\n  {% set expected_rows = config.get('expected_rows') %}\n  {% set expected_sql = config.get('expected_sql') %}\n  {% set tested_expected_column_names = expected_rows[0].keys() if (expected_rows | length ) > 0 else get_columns_in_query(sql) %} %}\n\n  {%- set target_relation = this.incorporate(type='table') -%}\n  {%- set temp_relation = make_temp_relation(target_relation)-%}\n  {% do run_query(get_create_table_as_sql(True, temp_relation, get_empty_subquery_sql(sql))) %}\n  {%- set columns_in_relation = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set column_name_to_data_types = {} -%}\n  {%- for column in columns_in_relation -%}\n  {%-   do column_name_to_data_types.update({column.name|lower: column.data_type}) -%}\n  {%- endfor -%}\n\n  {% if not expected_sql %}\n  {%   set expected_sql = get_expected_sql(expected_rows, column_name_to_data_types) %}\n  {% endif %}\n  {% set unit_test_sql = get_unit_test_sql(sql, expected_sql, tested_expected_column_names) %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {{ unit_test_sql }}\n\n  {%- endcall %}\n\n  {% do adapter.drop_relation(temp_relation) %}\n\n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query", "macro.dbt.make_temp_relation", "macro.dbt.run_query", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_empty_subquery_sql", "macro.dbt.get_expected_sql", "macro.dbt.get_unit_test_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.98098, "supported_languages": ["sql"]}, "macro.dbt.get_test_sql": {"name": "get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.get_test_sql", "macro_sql": "{% macro get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n  {{ adapter.dispatch('get_test_sql', 'dbt')(main_sql, fail_calc, warn_if, error_if, limit) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9820805, "supported_languages": null}, "macro.dbt.default__get_test_sql": {"name": "default__get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.default__get_test_sql", "macro_sql": "{% macro default__get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n    select\n      {{ fail_calc }} as failures,\n      {{ fail_calc }} {{ warn_if }} as should_warn,\n      {{ fail_calc }} {{ error_if }} as should_error\n    from (\n      {{ main_sql }}\n      {{ \"limit \" ~ limit if limit != none }}\n    ) dbt_internal_test\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9827373, "supported_languages": null}, "macro.dbt.get_unit_test_sql": {"name": "get_unit_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.get_unit_test_sql", "macro_sql": "{% macro get_unit_test_sql(main_sql, expected_fixture_sql, expected_column_names) -%}\n  {{ adapter.dispatch('get_unit_test_sql', 'dbt')(main_sql, expected_fixture_sql, expected_column_names) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_unit_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9833164, "supported_languages": null}, "macro.dbt.default__get_unit_test_sql": {"name": "default__get_unit_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.default__get_unit_test_sql", "macro_sql": "{% macro default__get_unit_test_sql(main_sql, expected_fixture_sql, expected_column_names) -%}\n-- Build actual result given inputs\nwith dbt_internal_unit_test_actual as (\n  select\n    {% for expected_column_name in expected_column_names %}{{expected_column_name}}{% if not loop.last -%},{% endif %}{%- endfor -%}, {{ dbt.string_literal(\"actual\") }} as {{ adapter.quote(\"actual_or_expected\") }}\n  from (\n    {{ main_sql }}\n  ) _dbt_internal_unit_test_actual\n),\n-- Build expected result\ndbt_internal_unit_test_expected as (\n  select\n    {% for expected_column_name in expected_column_names %}{{expected_column_name}}{% if not loop.last -%}, {% endif %}{%- endfor -%}, {{ dbt.string_literal(\"expected\") }} as {{ adapter.quote(\"actual_or_expected\") }}\n  from (\n    {{ expected_fixture_sql }}\n  ) _dbt_internal_unit_test_expected\n)\n-- Union actual and expected results\nselect * from dbt_internal_unit_test_actual\nunion all\nselect * from dbt_internal_unit_test_expected\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.string_literal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9846935, "supported_languages": null}, "macro.dbt.get_catalog_relations": {"name": "get_catalog_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog_relations", "macro_sql": "{% macro get_catalog_relations(information_schema, relations) -%}\n  {{ return(adapter.dispatch('get_catalog_relations', 'dbt')(information_schema, relations)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_relations"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.985658, "supported_languages": null}, "macro.dbt.default__get_catalog_relations": {"name": "default__get_catalog_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog_relations", "macro_sql": "{% macro default__get_catalog_relations(information_schema, relations) -%}\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog_relations not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9860053, "supported_languages": null}, "macro.dbt.get_catalog": {"name": "get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog', 'dbt')(information_schema, schemas)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9862535, "supported_languages": null}, "macro.dbt.default__get_catalog": {"name": "default__get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.986575, "supported_languages": null}, "macro.dbt.information_schema_name": {"name": "information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__information_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9868407, "supported_languages": null}, "macro.dbt.default__information_schema_name": {"name": "default__information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9870443, "supported_languages": null}, "macro.dbt.list_schemas": {"name": "list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__list_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9872627, "supported_languages": null}, "macro.dbt.default__list_schemas": {"name": "default__list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.information_schema_name", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9875648, "supported_languages": null}, "macro.dbt.check_schema_exists": {"name": "check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists', 'dbt')(information_schema, schema)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__check_schema_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.98786, "supported_languages": null}, "macro.dbt.default__check_schema_exists": {"name": "default__check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9882338, "supported_languages": null}, "macro.dbt.list_relations_without_caching": {"name": "list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9884558, "supported_languages": null}, "macro.dbt.default__list_relations_without_caching": {"name": "default__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.988673, "supported_languages": null}, "macro.dbt.get_catalog_for_single_relation": {"name": "get_catalog_for_single_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog_for_single_relation", "macro_sql": "{% macro get_catalog_for_single_relation(relation) %}\n  {{ return(adapter.dispatch('get_catalog_for_single_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_catalog_for_single_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9888904, "supported_languages": null}, "macro.dbt.default__get_catalog_for_single_relation": {"name": "default__get_catalog_for_single_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog_for_single_relation", "macro_sql": "{% macro default__get_catalog_for_single_relation(relation) %}\n  {{ exceptions.raise_not_implemented(\n    'get_catalog_for_single_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9890864, "supported_languages": null}, "macro.dbt.get_relations": {"name": "get_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_relations", "macro_sql": "{% macro get_relations() %}\n  {{ return(adapter.dispatch('get_relations', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_relations"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9892821, "supported_languages": null}, "macro.dbt.default__get_relations": {"name": "default__get_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_relations", "macro_sql": "{% macro default__get_relations() %}\n  {{ exceptions.raise_not_implemented(\n    'get_relations macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9894714, "supported_languages": null}, "macro.dbt.get_relation_last_modified": {"name": "get_relation_last_modified", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_relation_last_modified", "macro_sql": "{% macro get_relation_last_modified(information_schema, relations) %}\n  {{ return(adapter.dispatch('get_relation_last_modified', 'dbt')(information_schema, relations)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_relation_last_modified"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.989745, "supported_languages": null}, "macro.dbt.default__get_relation_last_modified": {"name": "default__get_relation_last_modified", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_relation_last_modified", "macro_sql": "{% macro default__get_relation_last_modified(information_schema, relations) %}\n  {{ exceptions.raise_not_implemented(\n    'get_relation_last_modified macro not implemented for adapter ' + adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9899564, "supported_languages": null}, "macro.dbt.make_intermediate_relation": {"name": "make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_intermediate_relation", "macro_sql": "{% macro make_intermediate_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_intermediate_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_intermediate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.991028, "supported_languages": null}, "macro.dbt.default__make_intermediate_relation": {"name": "default__make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_intermediate_relation", "macro_sql": "{% macro default__make_intermediate_relation(base_relation, suffix) %}\n    {{ return(default__make_temp_relation(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9913065, "supported_languages": null}, "macro.dbt.make_temp_relation": {"name": "make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {#-- This ensures microbatch batches get unique temp relations to avoid clobbering --#}\n  {% if suffix == '__dbt_tmp' and model.batch %}\n    {% set suffix = suffix ~ '_' ~ model.batch.id %}\n  {% endif %}\n\n  {{ return(adapter.dispatch('make_temp_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.991916, "supported_languages": null}, "macro.dbt.default__make_temp_relation": {"name": "default__make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {%- set temp_identifier = base_relation.identifier ~ suffix -%}\n    {%- set temp_relation = base_relation.incorporate(\n                                path={\"identifier\": temp_identifier}) -%}\n\n    {{ return(temp_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9922733, "supported_languages": null}, "macro.dbt.make_backup_relation": {"name": "make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_backup_relation", "macro_sql": "{% macro make_backup_relation(base_relation, backup_relation_type, suffix='__dbt_backup') %}\n    {{ return(adapter.dispatch('make_backup_relation', 'dbt')(base_relation, backup_relation_type, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_backup_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9925435, "supported_languages": null}, "macro.dbt.default__make_backup_relation": {"name": "default__make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_backup_relation", "macro_sql": "{% macro default__make_backup_relation(base_relation, backup_relation_type, suffix) %}\n    {%- set backup_identifier = base_relation.identifier ~ suffix -%}\n    {%- set backup_relation = base_relation.incorporate(\n                                  path={\"identifier\": backup_identifier},\n                                  type=backup_relation_type\n    ) -%}\n    {{ return(backup_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9928968, "supported_languages": null}, "macro.dbt.truncate_relation": {"name": "truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__truncate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9930954, "supported_languages": null}, "macro.dbt.default__truncate_relation": {"name": "default__truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation.render() }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9933443, "supported_languages": null}, "macro.dbt.get_or_create_relation": {"name": "get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) -%}\n  {{ return(adapter.dispatch('get_or_create_relation', 'dbt')(database, schema, identifier, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9936225, "supported_languages": null}, "macro.dbt.default__get_or_create_relation": {"name": "default__get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__get_or_create_relation", "macro_sql": "{% macro default__get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9942312, "supported_languages": null}, "macro.dbt.load_cached_relation": {"name": "load_cached_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_cached_relation", "macro_sql": "{% macro load_cached_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9944766, "supported_languages": null}, "macro.dbt.load_relation": {"name": "load_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_relation", "macro_sql": "{% macro load_relation(relation) %}\n    {{ return(load_cached_relation(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9946358, "supported_languages": null}, "macro.dbt.get_create_index_sql": {"name": "get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_create_index_sql", "macro_sql": "{% macro get_create_index_sql(relation, index_dict) -%}\n  {{ return(adapter.dispatch('get_create_index_sql', 'dbt')(relation, index_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9952216, "supported_languages": null}, "macro.dbt.default__get_create_index_sql": {"name": "default__get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_create_index_sql", "macro_sql": "{% macro default__get_create_index_sql(relation, index_dict) -%}\n  {% do return(None) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9954197, "supported_languages": null}, "macro.dbt.create_indexes": {"name": "create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.create_indexes", "macro_sql": "{% macro create_indexes(relation) -%}\n  {{ adapter.dispatch('create_indexes', 'dbt')(relation) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9956045, "supported_languages": null}, "macro.dbt.default__create_indexes": {"name": "default__create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__create_indexes", "macro_sql": "{% macro default__create_indexes(relation) -%}\n  {%- set _indexes = config.get('indexes', default=[]) -%}\n\n  {% for _index_dict in _indexes %}\n    {% set create_index_sql = get_create_index_sql(relation, _index_dict) %}\n    {% if create_index_sql %}\n      {% do run_query(create_index_sql) %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_create_index_sql", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.996071, "supported_languages": null}, "macro.dbt.get_drop_index_sql": {"name": "get_drop_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_drop_index_sql", "macro_sql": "{% macro get_drop_index_sql(relation, index_name) -%}\n    {{ adapter.dispatch('get_drop_index_sql', 'dbt')(relation, index_name) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_drop_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.996283, "supported_languages": null}, "macro.dbt.default__get_drop_index_sql": {"name": "default__get_drop_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_drop_index_sql", "macro_sql": "{% macro default__get_drop_index_sql(relation, index_name) -%}\n    {{ exceptions.raise_compiler_error(\"`get_drop_index_sql has not been implemented for this adapter.\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.996439, "supported_languages": null}, "macro.dbt.get_show_indexes_sql": {"name": "get_show_indexes_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_show_indexes_sql", "macro_sql": "{% macro get_show_indexes_sql(relation) -%}\n    {{ adapter.dispatch('get_show_indexes_sql', 'dbt')(relation) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_show_indexes_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9966128, "supported_languages": null}, "macro.dbt.default__get_show_indexes_sql": {"name": "default__get_show_indexes_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_show_indexes_sql", "macro_sql": "{% macro default__get_show_indexes_sql(relation) -%}\n    {{ exceptions.raise_compiler_error(\"`get_show_indexes_sql has not been implemented for this adapter.\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9967563, "supported_languages": null}, "macro.dbt.copy_grants": {"name": "copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.copy_grants", "macro_sql": "{% macro copy_grants() %}\n    {{ return(adapter.dispatch('copy_grants', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9980025, "supported_languages": null}, "macro.dbt.default__copy_grants": {"name": "default__copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__copy_grants", "macro_sql": "{% macro default__copy_grants() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9981544, "supported_languages": null}, "macro.dbt.support_multiple_grantees_per_dcl_statement": {"name": "support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.support_multiple_grantees_per_dcl_statement", "macro_sql": "{% macro support_multiple_grantees_per_dcl_statement() %}\n    {{ return(adapter.dispatch('support_multiple_grantees_per_dcl_statement', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141601.9983447, "supported_languages": null}, "macro.dbt.default__support_multiple_grantees_per_dcl_statement": {"name": "default__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n{%- macro default__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(True) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0005388, "supported_languages": null}, "macro.dbt.should_revoke": {"name": "should_revoke", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.should_revoke", "macro_sql": "{% macro should_revoke(existing_relation, full_refresh_mode=True) %}\n\n    {% if not existing_relation %}\n        {#-- The table doesn't already exist, so no grants to copy over --#}\n        {{ return(False) }}\n    {% elif full_refresh_mode %}\n        {#-- The object is being REPLACED -- whether grants are copied over depends on the value of user config --#}\n        {{ return(copy_grants()) }}\n    {% else %}\n        {#-- The table is being merged/upserted/inserted -- grants will be carried over --#}\n        {{ return(True) }}\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0009925, "supported_languages": null}, "macro.dbt.get_show_grant_sql": {"name": "get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_show_grant_sql", "macro_sql": "{% macro get_show_grant_sql(relation) %}\n    {{ return(adapter.dispatch(\"get_show_grant_sql\", \"dbt\")(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_show_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0012217, "supported_languages": null}, "macro.dbt.default__get_show_grant_sql": {"name": "default__get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_show_grant_sql", "macro_sql": "{% macro default__get_show_grant_sql(relation) %}\n    show grants on {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.001404, "supported_languages": null}, "macro.dbt.get_grant_sql": {"name": "get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_grant_sql", "macro_sql": "{% macro get_grant_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_grant_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0016568, "supported_languages": null}, "macro.dbt.default__get_grant_sql": {"name": "default__get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_grant_sql", "macro_sql": "\n\n{%- macro default__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation.render() }} to {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0018904, "supported_languages": null}, "macro.dbt.get_revoke_sql": {"name": "get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_revoke_sql", "macro_sql": "{% macro get_revoke_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_revoke_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_revoke_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.002136, "supported_languages": null}, "macro.dbt.default__get_revoke_sql": {"name": "default__get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_revoke_sql", "macro_sql": "\n\n{%- macro default__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation.render() }} from {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0023637, "supported_languages": null}, "macro.dbt.get_dcl_statement_list": {"name": "get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_dcl_statement_list", "macro_sql": "{% macro get_dcl_statement_list(relation, grant_config, get_dcl_macro) %}\n    {{ return(adapter.dispatch('get_dcl_statement_list', 'dbt')(relation, grant_config, get_dcl_macro)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_dcl_statement_list"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.002603, "supported_languages": null}, "macro.dbt.default__get_dcl_statement_list": {"name": "default__get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_dcl_statement_list", "macro_sql": "\n\n{%- macro default__get_dcl_statement_list(relation, grant_config, get_dcl_macro) -%}\n    {#\n      -- Unpack grant_config into specific privileges and the set of users who need them granted/revoked.\n      -- Depending on whether this database supports multiple grantees per statement, pass in the list of\n      -- all grantees per privilege, or (if not) template one statement per privilege-grantee pair.\n      -- `get_dcl_macro` will be either `get_grant_sql` or `get_revoke_sql`\n    #}\n    {%- set dcl_statements = [] -%}\n    {%- for privilege, grantees in grant_config.items() %}\n        {%- if support_multiple_grantees_per_dcl_statement() and grantees -%}\n          {%- set dcl = get_dcl_macro(relation, privilege, grantees) -%}\n          {%- do dcl_statements.append(dcl) -%}\n        {%- else -%}\n          {%- for grantee in grantees -%}\n              {% set dcl = get_dcl_macro(relation, privilege, [grantee]) %}\n              {%- do dcl_statements.append(dcl) -%}\n          {% endfor -%}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return(dcl_statements) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0033798, "supported_languages": null}, "macro.dbt.call_dcl_statements": {"name": "call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.call_dcl_statements", "macro_sql": "{% macro call_dcl_statements(dcl_statement_list) %}\n    {{ return(adapter.dispatch(\"call_dcl_statements\", \"dbt\")(dcl_statement_list)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0035918, "supported_languages": null}, "macro.dbt.default__call_dcl_statements": {"name": "default__call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__call_dcl_statements", "macro_sql": "{% macro default__call_dcl_statements(dcl_statement_list) %}\n    {#\n      -- By default, supply all grant + revoke statements in a single semicolon-separated block,\n      -- so that they're all processed together.\n\n      -- Some databases do not support this. Those adapters will need to override this macro\n      -- to run each statement individually.\n    #}\n    {% call statement('grants') %}\n        {% for dcl_statement in dcl_statement_list %}\n            {{ dcl_statement }};\n        {% endfor %}\n    {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0038867, "supported_languages": null}, "macro.dbt.apply_grants": {"name": "apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.apply_grants", "macro_sql": "{% macro apply_grants(relation, grant_config, should_revoke) %}\n    {{ return(adapter.dispatch(\"apply_grants\", \"dbt\")(relation, grant_config, should_revoke)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.00413, "supported_languages": null}, "macro.dbt.default__apply_grants": {"name": "default__apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__apply_grants", "macro_sql": "{% macro default__apply_grants(relation, grant_config, should_revoke=True) %}\n    {#-- If grant_config is {} or None, this is a no-op --#}\n    {% if grant_config %}\n        {% if should_revoke %}\n            {#-- We think previous grants may have carried over --#}\n            {#-- Show current grants and calculate diffs --#}\n            {% set current_grants_table = run_query(get_show_grant_sql(relation)) %}\n            {% set current_grants_dict = adapter.standardize_grants_dict(current_grants_table) %}\n            {% set needs_granting = diff_of_two_dicts(grant_config, current_grants_dict) %}\n            {% set needs_revoking = diff_of_two_dicts(current_grants_dict, grant_config) %}\n            {% if not (needs_granting or needs_revoking) %}\n                {{ log('On ' ~ relation.render() ~': All grants are in place, no revocation or granting needed.')}}\n            {% endif %}\n        {% else %}\n            {#-- We don't think there's any chance of previous grants having carried over. --#}\n            {#-- Jump straight to granting what the user has configured. --#}\n            {% set needs_revoking = {} %}\n            {% set needs_granting = grant_config %}\n        {% endif %}\n        {% if needs_granting or needs_revoking %}\n            {% set revoke_statement_list = get_dcl_statement_list(relation, needs_revoking, get_revoke_sql) %}\n            {% set grant_statement_list = get_dcl_statement_list(relation, needs_granting, get_grant_sql) %}\n            {% set dcl_statement_list = revoke_statement_list + grant_statement_list %}\n            {% if dcl_statement_list %}\n                {{ call_dcl_statements(dcl_statement_list) }}\n            {% endif %}\n        {% endif %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.get_show_grant_sql", "macro.dbt.get_dcl_statement_list", "macro.dbt.call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.005427, "supported_languages": null}, "macro.dbt.validate_sql": {"name": "validate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/validate_sql.sql", "original_file_path": "macros/adapters/validate_sql.sql", "unique_id": "macro.dbt.validate_sql", "macro_sql": "{% macro validate_sql(sql) -%}\n  {{ return(adapter.dispatch('validate_sql', 'dbt')(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__validate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0057795, "supported_languages": null}, "macro.dbt.default__validate_sql": {"name": "default__validate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/validate_sql.sql", "original_file_path": "macros/adapters/validate_sql.sql", "unique_id": "macro.dbt.default__validate_sql", "macro_sql": "{% macro default__validate_sql(sql) -%}\n  {% call statement('validate_sql') -%}\n    explain {{ sql }}\n  {% endcall %}\n  {{ return(load_result('validate_sql')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.006034, "supported_languages": null}, "macro.dbt.alter_column_comment": {"name": "alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0065045, "supported_languages": null}, "macro.dbt.default__alter_column_comment": {"name": "default__alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0067983, "supported_languages": null}, "macro.dbt.alter_relation_comment": {"name": "alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment', 'dbt')(relation, relation_comment)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__alter_relation_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0070844, "supported_languages": null}, "macro.dbt.default__alter_relation_comment": {"name": "default__alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0072951, "supported_languages": null}, "macro.dbt.persist_docs": {"name": "persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs', 'dbt')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0076308, "supported_languages": null}, "macro.dbt.default__persist_docs": {"name": "default__persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.alter_relation_comment", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.008319, "supported_languages": null}, "macro.dbt.create_schema": {"name": "create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.008724, "supported_languages": null}, "macro.dbt.default__create_schema": {"name": "default__create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0090437, "supported_languages": null}, "macro.dbt.drop_schema": {"name": "drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__drop_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0092516, "supported_languages": null}, "macro.dbt.default__drop_schema": {"name": "default__drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0095367, "supported_languages": null}, "macro.dbt.get_columns_in_relation": {"name": "get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0112078, "supported_languages": null}, "macro.dbt.default__get_columns_in_relation": {"name": "default__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0114603, "supported_languages": null}, "macro.dbt.sql_convert_columns_in_relation": {"name": "sql_convert_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.011932, "supported_languages": null}, "macro.dbt.get_list_of_column_names": {"name": "get_list_of_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_list_of_column_names", "macro_sql": "\n\n{%- macro get_list_of_column_names(columns) -%}\n  {% set col_names = [] %}\n  {% for col in columns %}\n    {% do col_names.append(col.name) %}\n  {% endfor %}\n  {{ return(col_names) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0123284, "supported_languages": null}, "macro.dbt.get_empty_subquery_sql": {"name": "get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_subquery_sql", "macro_sql": "{% macro get_empty_subquery_sql(select_sql, select_sql_header=none) -%}\n  {{ return(adapter.dispatch('get_empty_subquery_sql', 'dbt')(select_sql, select_sql_header)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0126102, "supported_languages": null}, "macro.dbt.default__get_empty_subquery_sql": {"name": "default__get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_subquery_sql", "macro_sql": "{% macro default__get_empty_subquery_sql(select_sql, select_sql_header=none) %}\n    {%- if select_sql_header is not none -%}\n    {{ select_sql_header }}\n    {%- endif -%}\n    select * from (\n        {{ select_sql }}\n    ) as __dbt_sbq\n    where false\n    limit 0\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0129352, "supported_languages": null}, "macro.dbt.get_empty_schema_sql": {"name": "get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_schema_sql", "macro_sql": "{% macro get_empty_schema_sql(columns) -%}\n  {{ return(adapter.dispatch('get_empty_schema_sql', 'dbt')(columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_schema_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0131707, "supported_languages": null}, "macro.dbt.default__get_empty_schema_sql": {"name": "default__get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_schema_sql", "macro_sql": "{% macro default__get_empty_schema_sql(columns) %}\n    {%- set col_err = [] -%}\n    {%- set col_naked_numeric = [] -%}\n    select\n    {% for i in columns %}\n      {%- set col = columns[i] -%}\n      {%- if col['data_type'] is not defined -%}\n        {%- do col_err.append(col['name']) -%}\n      {#-- If this column's type is just 'numeric' then it is missing precision/scale, raise a warning --#}\n      {%- elif col['data_type'].strip().lower() in ('numeric', 'decimal', 'number') -%}\n        {%- do col_naked_numeric.append(col['name']) -%}\n      {%- endif -%}\n      {% set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] %}\n      {{ cast('null', col['data_type']) }} as {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n    {%- if (col_err | length) > 0 -%}\n      {{ exceptions.column_type_missing(column_names=col_err) }}\n    {%- elif (col_naked_numeric | length) > 0 -%}\n      {{ exceptions.warn(\"Detected columns with numeric type and unspecified precision/scale, this can lead to unintended rounding: \" ~ col_naked_numeric ~ \"`\") }}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0146823, "supported_languages": null}, "macro.dbt.get_column_schema_from_query": {"name": "get_column_schema_from_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_column_schema_from_query", "macro_sql": "{% macro get_column_schema_from_query(select_sql, select_sql_header=none) -%}\n    {% set columns = [] %}\n    {# -- Using an 'empty subquery' here to get the same schema as the given select_sql statement, without necessitating a data scan.#}\n    {% set sql = get_empty_subquery_sql(select_sql, select_sql_header) %}\n    {% set column_schema = adapter.get_column_schema_from_query(sql) %}\n    {{ return(column_schema) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0151534, "supported_languages": null}, "macro.dbt.get_columns_in_query": {"name": "get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query', 'dbt')(select_sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0154083, "supported_languages": null}, "macro.dbt.default__get_columns_in_query": {"name": "default__get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        {{ get_empty_subquery_sql(select_sql) }}\n    {% endcall %}\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0158587, "supported_languages": null}, "macro.dbt.alter_column_type": {"name": "alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type', 'dbt')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0161345, "supported_languages": null}, "macro.dbt.default__alter_column_type": {"name": "default__alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation.render() }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation.render() }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation.render() }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation.render() }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0169497, "supported_languages": null}, "macro.dbt.alter_relation_add_remove_columns": {"name": "alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_relation_add_remove_columns", "macro_sql": "{% macro alter_relation_add_remove_columns(relation, add_columns = none, remove_columns = none) -%}\n  {{ return(adapter.dispatch('alter_relation_add_remove_columns', 'dbt')(relation, add_columns, remove_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_relation_add_remove_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0173383, "supported_languages": null}, "macro.dbt.default__alter_relation_add_remove_columns": {"name": "default__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_relation_add_remove_columns", "macro_sql": "{% macro default__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  {% if remove_columns is none %}\n    {% set remove_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation.render() }}\n\n            {% for column in add_columns %}\n               add column {{ column.quoted }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}{{ ',' if add_columns and remove_columns }}\n\n            {% for column in remove_columns %}\n                drop column {{ column.quoted }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0184407, "supported_languages": null}, "macro.dbt.current_timestamp": {"name": "current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp", "macro_sql": "{%- macro current_timestamp() -%}\n    {{ adapter.dispatch('current_timestamp', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0190542, "supported_languages": null}, "macro.dbt.default__current_timestamp": {"name": "default__current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter ' + adapter.type()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.019277, "supported_languages": null}, "macro.dbt.snapshot_get_time": {"name": "snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.snapshot_get_time", "macro_sql": "\n\n{%- macro snapshot_get_time() -%}\n    {{ adapter.dispatch('snapshot_get_time', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0194643, "supported_languages": null}, "macro.dbt.default__snapshot_get_time": {"name": "default__snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() %}\n    {{ current_timestamp() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0196264, "supported_languages": null}, "macro.dbt.get_snapshot_get_time_data_type": {"name": "get_snapshot_get_time_data_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.get_snapshot_get_time_data_type", "macro_sql": "{% macro get_snapshot_get_time_data_type() %}\n    {% set snapshot_time = adapter.dispatch('snapshot_get_time', 'dbt')() %}\n    {% set time_data_type_sql = 'select ' ~ snapshot_time ~ ' as dbt_snapshot_time' %}\n    {% set snapshot_time_column_schema = get_column_schema_from_query(time_data_type_sql) %}\n    {% set time_data_type = snapshot_time_column_schema[0].dtype %}\n    {{ return(time_data_type or none) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.default__snapshot_get_time", "macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.020292, "supported_languages": null}, "macro.dbt.current_timestamp_backcompat": {"name": "current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_backcompat", "macro_sql": "{% macro current_timestamp_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0205255, "supported_languages": null}, "macro.dbt.default__current_timestamp_backcompat": {"name": "default__current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_backcompat", "macro_sql": "{% macro default__current_timestamp_backcompat() %}\n    current_timestamp::timestamp\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.020629, "supported_languages": null}, "macro.dbt.current_timestamp_in_utc_backcompat": {"name": "current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_in_utc_backcompat", "macro_sql": "{% macro current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_in_utc_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_in_utc_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0208356, "supported_languages": null}, "macro.dbt.default__current_timestamp_in_utc_backcompat": {"name": "default__current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_in_utc_backcompat", "macro_sql": "{% macro default__current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp_backcompat", "macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0210402, "supported_languages": null}, "macro.dbt.collect_freshness": {"name": "collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness', 'dbt')(source, loaded_at_field, filter))}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0216424, "supported_languages": null}, "macro.dbt.default__collect_freshness": {"name": "default__collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0221624, "supported_languages": null}, "macro.dbt.collect_freshness_custom_sql": {"name": "collect_freshness_custom_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.collect_freshness_custom_sql", "macro_sql": "{% macro collect_freshness_custom_sql(source, loaded_at_query) %}\n  {{ return(adapter.dispatch('collect_freshness_custom_sql', 'dbt')(source, loaded_at_query))}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__collect_freshness_custom_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0224137, "supported_languages": null}, "macro.dbt.default__collect_freshness_custom_sql": {"name": "default__collect_freshness_custom_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.default__collect_freshness_custom_sql", "macro_sql": "{% macro default__collect_freshness_custom_sql(source, loaded_at_query) %}\n  {% call statement('collect_freshness_custom_sql', fetch_result=True, auto_begin=False) -%}\n  with source_query as (\n    {{ loaded_at_query }}\n  )\n  select\n    (select * from source_query) as max_loaded_at,\n    {{ current_timestamp() }} as snapshotted_at\n  {% endcall %}\n  {{ return(load_result('collect_freshness_custom_sql')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0229378, "supported_languages": null}, "macro.dbt.get_show_sql": {"name": "get_show_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.get_show_sql", "macro_sql": "{% macro get_show_sql(compiled_code, sql_header, limit) -%}\n  {%- if sql_header is not none -%}\n  {{ sql_header }}\n  {%- endif %}\n  {{ get_limit_subquery_sql(compiled_code, limit) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_limit_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.02382, "supported_languages": null}, "macro.dbt.get_limit_subquery_sql": {"name": "get_limit_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.get_limit_subquery_sql", "macro_sql": "\n{%- macro get_limit_subquery_sql(sql, limit) -%}\n  {{ adapter.dispatch('get_limit_sql', 'dbt')(sql, limit) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_limit_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0242484, "supported_languages": null}, "macro.dbt.default__get_limit_sql": {"name": "default__get_limit_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.default__get_limit_sql", "macro_sql": "{% macro default__get_limit_sql(sql, limit) %}\n  {{ sql }}\n  {% if limit is not none %}\n  limit {{ limit }}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0246503, "supported_languages": null}, "macro.dbt.test_unique": {"name": "test_unique", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_unique", "macro_sql": "{% test unique(model, column_name) %}\n    {% set macro = adapter.dispatch('test_unique', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_unique"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.025626, "supported_languages": null}, "macro.dbt.test_not_null": {"name": "test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_not_null", "macro_sql": "{% test not_null(model, column_name) %}\n    {% set macro = adapter.dispatch('test_not_null', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0261586, "supported_languages": null}, "macro.dbt.test_accepted_values": {"name": "test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_accepted_values", "macro_sql": "{% test accepted_values(model, column_name, values, quote=True) %}\n    {% set macro = adapter.dispatch('test_accepted_values', 'dbt') %}\n    {{ macro(model, column_name, values, quote) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.0269487, "supported_languages": null}, "macro.dbt.test_relationships": {"name": "test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_relationships", "macro_sql": "{% test relationships(model, column_name, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships', 'dbt') %}\n    {{ macro(model, column_name, to, field) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_relationships"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1759141602.027437, "supported_languages": null}}, "docs": {"doc.dbt.__overview__": {"name": "__overview__", "resource_type": "doc", "package_name": "dbt", "path": "overview.md", "original_file_path": "docs/overview.md", "unique_id": "doc.dbt.__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--select` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/introduction)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [dbt Community](https://www.getdbt.com/community/) for questions and discussion"}}, "exposures": {}, "metrics": {}, "groups": {}, "selectors": {}, "disabled": {}, "parent_map": {"model.dbt_dbx.silver_orders": ["model.dbt_dbx.bronze_orders"], "model.dbt_dbx.silver_products": ["model.dbt_dbx.bronze_products"], "model.dbt_dbx.silver_users": ["model.dbt_dbx.bronze_users"], "model.dbt_dbx.bronze_reviews": ["source.dbt_dbx.landing_s.reviews"], "model.dbt_dbx.bronze_orders": ["source.dbt_dbx.landing_s.orders"], "model.dbt_dbx.bronze_users": ["source.dbt_dbx.landing_s.users"], "model.dbt_dbx.bronze_products": ["source.dbt_dbx.landing_s.products"], "source.dbt_dbx.landing_s.orders": [], "source.dbt_dbx.landing_s.users": [], "source.dbt_dbx.landing_s.products": [], "source.dbt_dbx.landing_s.reviews": []}, "child_map": {"model.dbt_dbx.silver_orders": [], "model.dbt_dbx.silver_products": [], "model.dbt_dbx.silver_users": [], "model.dbt_dbx.bronze_reviews": [], "model.dbt_dbx.bronze_orders": ["model.dbt_dbx.silver_orders"], "model.dbt_dbx.bronze_users": ["model.dbt_dbx.silver_users"], "model.dbt_dbx.bronze_products": ["model.dbt_dbx.silver_products"], "source.dbt_dbx.landing_s.orders": ["model.dbt_dbx.bronze_orders"], "source.dbt_dbx.landing_s.users": ["model.dbt_dbx.bronze_users"], "source.dbt_dbx.landing_s.products": ["model.dbt_dbx.bronze_products"], "source.dbt_dbx.landing_s.reviews": ["model.dbt_dbx.bronze_reviews"]}, "group_map": {}, "saved_queries": {}, "semantic_models": {}, "unit_tests": {}}
\ No newline at end of file
+{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/manifest/v12.json", "dbt_version": "1.10.13", "generated_at": "2025-10-14T05:39:45.746774Z", "invocation_id": "c6202908-203b-463d-9d3e-e7258446cf15", "invocation_started_at": "2025-10-14T05:32:46.218420+00:00", "env": {}, "project_name": "dbt_dbx", "project_id": "0d3e7ae267c3d80e5b0e9b0a8e99ced4", "user_id": "f669694c-f891-4809-bbf7-b029e2154962", "send_anonymous_usage_stats": true, "adapter_type": "databricks", "quoting": {"database": true, "schema": true, "identifier": true, "column": null}}, "nodes": {"model.dbt_dbx.silver_orders": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_orders", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_orders.sql", "original_file_path": "models/silver/silver_orders.sql", "unique_id": "model.dbt_dbx.silver_orders", "fqn": ["dbt_dbx", "silver", "silver_orders"], "alias": "silver_orders", "checksum": {"name": "sha256", "checksum": "ac34d7aa6482f47d9b19f60f9f3536d8eeb7fafc697dd467a648facbd8183807"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_orders.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1760419970.0478535, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_orders`", "raw_code": "select\n    id,\n    date(created_at) as order_date,\n    user_id,\n    product_id\n    quantity,\n    unit_price,\n    quantity * unit_price as order_amount\nfrom {{ ref('bronze_orders') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_orders", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_orders"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_orders.sql", "compiled": true, "compiled_code": "select\n    id,\n    date(created_at) as order_date,\n    user_id,\n    product_id\n    quantity,\n    unit_price,\n    quantity * unit_price as order_amount\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_orders`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.silver_products": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_products", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_products.sql", "original_file_path": "models/silver/silver_products.sql", "unique_id": "model.dbt_dbx.silver_products", "fqn": ["dbt_dbx", "silver", "silver_products"], "alias": "silver_products", "checksum": {"name": "sha256", "checksum": "e67de830b944747fdbea721729d0cdaf232694cc89dbb08cc339b339d347b759"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_products.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1760419970.0681777, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_products`", "raw_code": "select\n    id,\n    created_at,\n    title as product_name,\n    category,\n    ean,\n    vendor,\n    price\nfrom {{ ref('bronze_products') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_products", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_products"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_products.sql", "compiled": true, "compiled_code": "select\n    id,\n    created_at,\n    title as product_name,\n    category,\n    ean,\n    vendor,\n    price\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_products`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.silver_users": {"database": "dbt_project_catalog", "schema": "dbt_kisara_silver", "name": "silver_users", "resource_type": "model", "package_name": "dbt_dbx", "path": "silver/silver_users.sql", "original_file_path": "models/silver/silver_users.sql", "unique_id": "model.dbt_dbx.silver_users", "fqn": ["dbt_dbx", "silver", "silver_users"], "alias": "silver_users", "checksum": {"name": "sha256", "checksum": "34396beb97d2d52a1c634b1dd5ac954c2392a1f37ba48a596d5d6c9137dc59b7"}, "config": {"enabled": true, "alias": null, "schema": "silver", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/silver/silver_users.sql", "unrendered_config": {"schema": "silver", "materialized": "view"}, "created_at": 1760419970.0703168, "relation_name": "`dbt_project_catalog`.`dbt_kisara_silver`.`silver_users`", "raw_code": "select\n    id,\n    created_at,\n    city,\n    state,\n    year(birth_date) as birth_year,\n    source as sales_channel\nfrom {{ ref('bronze_users') }}", "doc_blocks": [], "language": "sql", "refs": [{"name": "bronze_users", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_dbx.bronze_users"]}, "compiled_path": "target/compiled/dbt_dbx/models/silver/silver_users.sql", "compiled": true, "compiled_code": "select\n    id,\n    created_at,\n    city,\n    state,\n    year(birth_date) as birth_year,\n    source as sales_channel\nfrom `dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_users`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_reviews": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_reviews", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_reviews.sql", "original_file_path": "models/bronze/bronze_reviews.sql", "unique_id": "model.dbt_dbx.bronze_reviews", "fqn": ["dbt_dbx", "bronze", "bronze_reviews"], "alias": "bronze_reviews", "checksum": {"name": "sha256", "checksum": "684b27d5196aee450cec81eb584d9fefaff2a073342eff92131d84bc950ce086"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/bronze/bronze_reviews.sql", "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1760419970.072189, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_reviews`", "raw_code": "select *\nfrom {{ source('landing_s', 'reviews') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "reviews"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.reviews"]}, "compiled_path": "target/compiled/dbt_dbx/models/bronze/bronze_reviews.sql", "compiled": true, "compiled_code": "select *\nfrom `dbt_project_catalog`.`landing`.`reviews`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_orders": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_orders", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_orders.sql", "original_file_path": "models/bronze/bronze_orders.sql", "unique_id": "model.dbt_dbx.bronze_orders", "fqn": ["dbt_dbx", "bronze", "bronze_orders"], "alias": "bronze_orders", "checksum": {"name": "sha256", "checksum": "7a5182df216c04629f2c75fc418f18bbf1b3eeecd28db5bd52e78ca364fe8491"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/bronze/bronze_orders.sql", "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1760419970.0740929, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_orders`", "raw_code": "select *\nfrom {{ source('landing_s', 'orders') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "orders"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.orders"]}, "compiled_path": "target/compiled/dbt_dbx/models/bronze/bronze_orders.sql", "compiled": true, "compiled_code": "select *\nfrom `dbt_project_catalog`.`landing`.`orders`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_users": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_users", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_users.sql", "original_file_path": "models/bronze/bronze_users.sql", "unique_id": "model.dbt_dbx.bronze_users", "fqn": ["dbt_dbx", "bronze", "bronze_users"], "alias": "bronze_users", "checksum": {"name": "sha256", "checksum": "f7b4283d3247d927f9f21a526e7bc79a3f414314e6562cf1dae7d5ba3aabc916"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/bronze/bronze_users.sql", "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1760419970.075881, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_users`", "raw_code": "select *\nfrom {{ source('landing_s', 'users') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "users"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.users"]}, "compiled_path": "target/compiled/dbt_dbx/models/bronze/bronze_users.sql", "compiled": true, "compiled_code": "select *\nfrom `dbt_project_catalog`.`landing`.`users`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_dbx.bronze_products": {"database": "dbt_project_catalog", "schema": "dbt_kisara_bronze", "name": "bronze_products", "resource_type": "model", "package_name": "dbt_dbx", "path": "bronze/bronze_products.sql", "original_file_path": "models/bronze/bronze_products.sql", "unique_id": "model.dbt_dbx.bronze_products", "fqn": ["dbt_dbx", "bronze", "bronze_products"], "alias": "bronze_products", "checksum": {"name": "sha256", "checksum": "8b27fb6c3fab7a376bc8595371164f69a2072cc9e29d119f67b4b6dc0345bb8a"}, "config": {"enabled": true, "alias": null, "schema": "bronze", "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null}, "tags": [], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": "target/run/dbt_dbx/models/bronze/bronze_products.sql", "unrendered_config": {"schema": "bronze", "materialized": "view"}, "created_at": 1760419970.0784664, "relation_name": "`dbt_project_catalog`.`dbt_kisara_bronze`.`bronze_products`", "raw_code": "select *\nfrom {{ source('landing_s', 'products') }}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [["landing_s", "products"]], "metrics": [], "depends_on": {"macros": [], "nodes": ["source.dbt_dbx.landing_s.products"]}, "compiled_path": "target/compiled/dbt_dbx/models/bronze/bronze_products.sql", "compiled": true, "compiled_code": "select *\nfrom `dbt_project_catalog`.`landing`.`products`", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "operation.dbt_dbx.dbt_dbx-on-run-end-0": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dbt_dbx-on-run-end-0", "resource_type": "operation", "package_name": "dbt_dbx", "path": "hooks/dbt_dbx-on-run-end-0.sql", "original_file_path": "./dbt_project.yml", "unique_id": "operation.dbt_dbx.dbt_dbx-on-run-end-0", "fqn": ["dbt_dbx", "hooks", "dbt_dbx-on-run-end-0"], "alias": "dbt_dbx-on-run-end-0", "checksum": {"name": "sha256", "checksum": "7d436ab596c52be3b52a00ba296bc87303b57150406dba49263654ceaf3f6d8e"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null}, "tags": ["on-run-end"], "description": "", "columns": {}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": null, "build_path": null, "unrendered_config": {}, "created_at": 1760419970.180283, "relation_name": null, "raw_code": "{% if target.name == 'dev' %}{{ dbt_artifacts.upload_results(results) }}{% endif %}", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.upload_results"], "nodes": []}, "compiled_path": "target/compiled/dbt_dbx/./dbt_project.yml/hooks/dbt_dbx-on-run-end-0.sql", "compiled": true, "compiled_code": "\n\n        \n        \n            \n            \n        \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n                \n\n                \n                \n\n    \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n                \n\n                \n                \n\n    \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n                \n\n                \n                \n\n    \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n\n        \n        \n\n            \n\n            \n            \n\n            \n            \n                \n            \n\n            \n            \n                \n\n                \n                \n\n    \n\n            \n            \n\n        \n        \n\n    ", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "index": 1}, "model.dbt_artifacts.dim_dbt__sources": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__sources", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__sources.sql", "original_file_path": "models/dim_dbt__sources.sql", "unique_id": "model.dbt_artifacts.dim_dbt__sources", "fqn": ["dbt_artifacts", "dim_dbt__sources"], "alias": "dim_dbt__sources", "checksum": {"name": "sha256", "checksum": "fcf65769af44ca0e464606f2e055503488445e76cf6eb041c9ab4b33c6e0211b"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about sources.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "freshness": {"name": "freshness", "description": "The specified freshness of the source model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.freshness"]}, "identifier": {"name": "identifier", "description": "Source identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.identifier"]}, "loaded_at_field": {"name": "loaded_at_field", "description": "A column name (or expression) that returns a timestamp indicating freshness.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loaded_at_field"]}, "loader": {"name": "loader", "description": "Describes the tool that loads this source into your warehouse.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loader"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "source_execution_id": {"name": "source_execution_id", "description": "Execution ID of the source node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.source_execution_id"]}, "source_name": {"name": "source_name", "description": "Source name.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.source_name"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__sources.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__sources.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.679443, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__sources`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__sources\") }}),\n\n    sources as (\n\n        select\n            source_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            source_name,\n            loader,\n            name,\n            identifier,\n            loaded_at_field,\n            freshness\n        from base\n\n    )\n\nselect *\nfrom sources", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__sources", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__sources"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__sources.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__sources`),\n\n    sources as (\n\n        select\n            source_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n             database\n            ,\n             schema\n            ,\n            source_name,\n            loader,\n            name,\n            identifier,\n            loaded_at_field,\n            freshness\n        from base\n\n    )\n\nselect *\nfrom sources", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__tests": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__tests", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__tests.sql", "original_file_path": "models/dim_dbt__tests.sql", "unique_id": "model.dbt_artifacts.dim_dbt__tests", "fqn": ["dbt_artifacts", "dim_dbt__tests"], "alias": "dim_dbt__tests", "checksum": {"name": "sha256", "checksum": "2dbed3a57ed86dd23ffa45f99ecb5af989151519a32e2d98ddaac3e370ce86b9"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about tests.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "test_execution_id": {"name": "test_execution_id", "description": "Execution ID of the test node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_execution_id"]}, "test_path": {"name": "test_path", "description": "Path to the yaml (SQL in case of a singular test) file describing the test.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_path"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__tests.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__tests.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6749887, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__tests`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('stg_dbt__tests') }}\n\n    )\n\n    , tests as (\n\n        select\n            test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , depends_on_nodes\n            , package_name\n            , test_path\n            , tags\n        from base\n\n    )\n\nselect * from tests", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__tests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__tests"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__tests.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__tests`\n\n    )\n\n    , tests as (\n\n        select\n            test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , depends_on_nodes\n            , package_name\n            , test_path\n            , tags\n        from base\n\n    )\n\nselect * from tests", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.fct_dbt__seed_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "fct_dbt__seed_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "fct_dbt__seed_executions.sql", "original_file_path": "models/fct_dbt__seed_executions.sql", "unique_id": "model.dbt_artifacts.fct_dbt__seed_executions", "fqn": ["dbt_artifacts", "fct_dbt__seed_executions"], "alias": "fct_dbt__seed_executions", "checksum": {"name": "sha256", "checksum": "4a02f05b7adec3c030c556f9780ab14f0ac1e32ad5ae190229b0bf44d5bb6570"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Fact model that contains data about seed executions.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "seed_execution_id": {"name": "seed_execution_id", "description": "Execution ID of the seed node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.seed_execution_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/fct_dbt__seed_executions.yml", "build_path": "target/run/dbt_artifacts/models/fct_dbt__seed_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.669476, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`fct_dbt__seed_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__seed_executions\") }}),\n\n    seed_executions as (\n\n        select\n            seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom seed_executions", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__seed_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__seed_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/fct_dbt__seed_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__seed_executions`),\n\n    seed_executions as (\n\n        select\n            seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n             schema\n            ,\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom seed_executions", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.fct_dbt__test_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "fct_dbt__test_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "fct_dbt__test_executions.sql", "original_file_path": "models/fct_dbt__test_executions.sql", "unique_id": "model.dbt_artifacts.fct_dbt__test_executions", "fqn": ["dbt_artifacts", "fct_dbt__test_executions"], "alias": "fct_dbt__test_executions", "checksum": {"name": "sha256", "checksum": "6b3951ed267e9004fe0ee7b9d339d2b3cd77a807eb8ca25d1d37b55b4c0037aa"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Fact model that contains data about test executions.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "failures": {"name": "failures", "description": "Test failures. Value is 1 if the test failed, 0 if successful.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.failures"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "test_execution_id": {"name": "test_execution_id", "description": "Execution ID of the test node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_execution_id"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/fct_dbt__test_executions.yml", "build_path": "target/run/dbt_artifacts/models/fct_dbt__test_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6759706, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`fct_dbt__test_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__test_executions\") }}),\n\n    test_executions as (\n\n        select\n            test_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            failures,\n            message\n        from base\n\n    )\n\nselect *\nfrom test_executions", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__test_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__test_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/fct_dbt__test_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__test_executions`),\n\n    test_executions as (\n\n        select\n            test_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            failures,\n            message\n        from base\n\n    )\n\nselect *\nfrom test_executions", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__current_models": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__current_models", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__current_models.sql", "original_file_path": "models/dim_dbt__current_models.sql", "unique_id": "model.dbt_artifacts.dim_dbt__current_models", "fqn": ["dbt_artifacts", "dim_dbt__current_models"], "alias": "dim_dbt__current_models", "checksum": {"name": "sha256", "checksum": "f68f88bd7ade582c716c002b8ed332777e056eeab562edc01523557dce0e7b72"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about models' most recent successful runs", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "last_full_refresh_run_completed_at": {"name": "last_full_refresh_run_completed_at", "description": "Timestamp when the node's SQL query completed on the last full (non-incremental) run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_full_refresh_run_completed_at"]}, "last_full_refresh_run_rows_affected": {"name": "last_full_refresh_run_rows_affected", "description": "Number of rows affected by the node's last full (non-incremental) run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_full_refresh_run_rows_affected"]}, "last_full_refresh_run_bytes_processed": {"name": "last_full_refresh_run_bytes_processed", "description": "Number of bytes processed by the node's last full (non-incremental) run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_full_refresh_run_bytes_processed"]}, "last_full_refresh_run_total_runtime": {"name": "last_full_refresh_run_total_runtime", "description": "Total time spent executing the node's last full (non-incremental) run (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_full_refresh_run_total_runtime"]}, "last_run_completed_at": {"name": "last_run_completed_at", "description": "Timestamp when the node's SQL query completed on the last run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_run_completed_at"]}, "last_run_rows_affected": {"name": "last_run_rows_affected", "description": "Number of rows affected by the node's last run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_run_rows_affected"]}, "last_run_bytes_processed": {"name": "last_run_bytes_processed", "description": "Number of bytes processed by the node's last run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_run_bytes_processed"]}, "last_run_total_runtime": {"name": "last_run_total_runtime", "description": "Total time spent executing the node's last run (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.last_run_total_runtime"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "model_execution_id": {"name": "model_execution_id", "description": "Execution ID of the model node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.model_execution_id"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__current_models.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__current_models.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6819932, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__current_models`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__models\") }}),\n    model_executions as (select * from {{ ref(\"stg_dbt__model_executions\") }}),\n    latest_models as (\n\n        /* Retrieves the models present in the most recent run */\n        select * from base where run_started_at = (select max(run_started_at) from base)\n\n    ),\n\n    latest_models_runs as (\n\n        /* Retreives all successful run information for the models present in the most\n        recent run and ranks them based on query completion time */\n        select\n            model_executions.node_id,\n            model_executions.was_full_refresh,\n            model_executions.query_completed_at,\n            model_executions.total_node_runtime,\n            model_executions.rows_affected\n            {% if target.type == \"bigquery\" %}, model_executions.bytes_processed {% endif %},\n            /* Row number by refresh and node ID */\n            row_number() over (\n                partition by latest_models.node_id, model_executions.was_full_refresh\n                order by model_executions.query_completed_at desc  /* most recent ranked first */\n            ) as run_idx,\n            /* Row number by node ID */\n            row_number() over (\n                partition by latest_models.node_id order by model_executions.query_completed_at desc  /* most recent ranked first */\n            ) as run_idx_id_only\n        from model_executions\n        inner join latest_models on model_executions.node_id = latest_models.node_id\n        where model_executions.status = 'success'\n\n    ),\n\n    latest_model_stats as (\n\n        select\n            node_id,\n            max(\n                case\n                    when was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then query_completed_at\n                end\n            ) as last_full_refresh_run_completed_at,\n            max(\n                case\n                    when was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then total_node_runtime\n                end\n            ) as last_full_refresh_run_total_runtime,\n            max(\n                case\n                    when was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then rows_affected\n                end\n            ) as last_full_refresh_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                ,\n                max(\n                    case when was_full_refresh then bytes_processed end\n                ) as last_full_refresh_run_bytes_processed\n            {% endif %},\n            max(case when run_idx_id_only = 1 then query_completed_at end) as last_run_completed_at,\n            max(\n                case when run_idx_id_only = 1 then total_node_runtime end\n            ) as last_run_total_runtime,\n            max(case when run_idx_id_only = 1 then rows_affected end) as last_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                ,\n                max(\n                    case when run_idx_id_only = 1 then bytes_processed end\n                ) as last_run_bytes_processed\n            {% endif %},\n            max(\n                case\n                    when not was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then query_completed_at\n                end\n            ) as last_incremental_run_completed_at,\n            max(\n                case\n                    when not was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then total_node_runtime\n                end\n            ) as last_incremental_run_total_runtime,\n            max(\n                case\n                    when not was_full_refresh {% if target.type == \"sqlserver\" %} = 1 {% endif %}\n                    then rows_affected\n                end\n            ) as last_incremental_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                ,\n                max(\n                    case when not was_full_refresh then bytes_processed end\n                ) as last_incremental_run_bytes_processed\n            {% endif %}\n        from latest_models_runs\n        where run_idx = 1\n        group by node_id\n\n    ),\n\n    final as (\n\n        select\n            latest_models.*,\n            latest_model_stats.last_full_refresh_run_completed_at,\n            latest_model_stats.last_full_refresh_run_total_runtime,\n            latest_model_stats.last_full_refresh_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                , latest_model_stats.last_full_refresh_run_bytes_processed\n            {% endif %},\n            latest_model_stats.last_run_completed_at,\n            latest_model_stats.last_run_total_runtime,\n            latest_model_stats.last_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                , latest_model_stats.last_run_bytes_processed\n            {% endif %},\n            latest_model_stats.last_incremental_run_completed_at,\n            latest_model_stats.last_incremental_run_total_runtime,\n            latest_model_stats.last_incremental_run_rows_affected\n            {% if target.type == \"bigquery\" %}\n                , latest_model_stats.last_incremental_run_bytes_processed\n            {% endif %}\n        from latest_models\n        left join latest_model_stats on latest_models.node_id = latest_model_stats.node_id\n\n    )\n\nselect *\nfrom final", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__models", "package": null, "version": null}, {"name": "stg_dbt__model_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__models", "model.dbt_artifacts.stg_dbt__model_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__current_models.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__models`),\n    model_executions as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__model_executions`),\n    latest_models as (\n\n        /* Retrieves the models present in the most recent run */\n        select * from base where run_started_at = (select max(run_started_at) from base)\n\n    ),\n\n    latest_models_runs as (\n\n        /* Retreives all successful run information for the models present in the most\n        recent run and ranks them based on query completion time */\n        select\n            model_executions.node_id,\n            model_executions.was_full_refresh,\n            model_executions.query_completed_at,\n            model_executions.total_node_runtime,\n            model_executions.rows_affected\n            ,\n            /* Row number by refresh and node ID */\n            row_number() over (\n                partition by latest_models.node_id, model_executions.was_full_refresh\n                order by model_executions.query_completed_at desc  /* most recent ranked first */\n            ) as run_idx,\n            /* Row number by node ID */\n            row_number() over (\n                partition by latest_models.node_id order by model_executions.query_completed_at desc  /* most recent ranked first */\n            ) as run_idx_id_only\n        from model_executions\n        inner join latest_models on model_executions.node_id = latest_models.node_id\n        where model_executions.status = 'success'\n\n    ),\n\n    latest_model_stats as (\n\n        select\n            node_id,\n            max(\n                case\n                    when was_full_refresh \n                    then query_completed_at\n                end\n            ) as last_full_refresh_run_completed_at,\n            max(\n                case\n                    when was_full_refresh \n                    then total_node_runtime\n                end\n            ) as last_full_refresh_run_total_runtime,\n            max(\n                case\n                    when was_full_refresh \n                    then rows_affected\n                end\n            ) as last_full_refresh_run_rows_affected\n            ,\n            max(case when run_idx_id_only = 1 then query_completed_at end) as last_run_completed_at,\n            max(\n                case when run_idx_id_only = 1 then total_node_runtime end\n            ) as last_run_total_runtime,\n            max(case when run_idx_id_only = 1 then rows_affected end) as last_run_rows_affected\n            ,\n            max(\n                case\n                    when not was_full_refresh \n                    then query_completed_at\n                end\n            ) as last_incremental_run_completed_at,\n            max(\n                case\n                    when not was_full_refresh \n                    then total_node_runtime\n                end\n            ) as last_incremental_run_total_runtime,\n            max(\n                case\n                    when not was_full_refresh \n                    then rows_affected\n                end\n            ) as last_incremental_run_rows_affected\n            \n        from latest_models_runs\n        where run_idx = 1\n        group by node_id\n\n    ),\n\n    final as (\n\n        select\n            latest_models.*,\n            latest_model_stats.last_full_refresh_run_completed_at,\n            latest_model_stats.last_full_refresh_run_total_runtime,\n            latest_model_stats.last_full_refresh_run_rows_affected\n            ,\n            latest_model_stats.last_run_completed_at,\n            latest_model_stats.last_run_total_runtime,\n            latest_model_stats.last_run_rows_affected\n            ,\n            latest_model_stats.last_incremental_run_completed_at,\n            latest_model_stats.last_incremental_run_total_runtime,\n            latest_model_stats.last_incremental_run_rows_affected\n            \n        from latest_models\n        left join latest_model_stats on latest_models.node_id = latest_model_stats.node_id\n\n    )\n\nselect *\nfrom final", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__snapshots": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__snapshots", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__snapshots.sql", "original_file_path": "models/dim_dbt__snapshots.sql", "unique_id": "model.dbt_artifacts.dim_dbt__snapshots", "fqn": ["dbt_artifacts", "dim_dbt__snapshots"], "alias": "dim_dbt__snapshots", "checksum": {"name": "sha256", "checksum": "b07e93126a605ff99283bf160074bad77dfd3b7d757415151c12853cda6a4f78"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about snapshots.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "snapshot_execution_id": {"name": "snapshot_execution_id", "description": "Execution ID of the snapshot node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.snapshot_execution_id"]}, "strategy": {"name": "strategy", "description": "Snapshot \"strategies\" define how dbt knows if a row has changed. There are two strategies built-in to dbt \u2014 timestamp\nand check.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.strategy"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__snapshots.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__snapshots.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6770592, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__snapshots`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__snapshots\") }}),\n\n    snapshots as (\n\n        select\n            snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            strategy,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom snapshots", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__snapshots", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__snapshots"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__snapshots.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__snapshots`),\n\n    snapshots as (\n\n        select\n            snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n             database\n            ,\n             schema\n            ,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            strategy,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom snapshots", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.fct_dbt__snapshot_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "fct_dbt__snapshot_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "fct_dbt__snapshot_executions.sql", "original_file_path": "models/fct_dbt__snapshot_executions.sql", "unique_id": "model.dbt_artifacts.fct_dbt__snapshot_executions", "fqn": ["dbt_artifacts", "fct_dbt__snapshot_executions"], "alias": "fct_dbt__snapshot_executions", "checksum": {"name": "sha256", "checksum": "e997da5c15898b408ff49efe46475eacece9103733b6d9a4db5eeb086eece8eb"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Fact model that contains data about snapshot executions.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "snapshot_execution_id": {"name": "snapshot_execution_id", "description": "Execution ID of the snapshot node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.snapshot_execution_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/fct_dbt__snapshot_executions.yml", "build_path": "target/run/dbt_artifacts/models/fct_dbt__snapshot_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6603127, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`fct_dbt__snapshot_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__snapshot_executions\") }}),\n\n    snapshot_executions as (\n\n        select\n            snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom snapshot_executions", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__snapshot_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__snapshot_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/fct_dbt__snapshot_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__snapshot_executions`),\n\n    snapshot_executions as (\n\n        select\n            snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n             schema\n            ,\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom snapshot_executions", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__models": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__models", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__models.sql", "original_file_path": "models/dim_dbt__models.sql", "unique_id": "model.dbt_artifacts.dim_dbt__models", "fqn": ["dbt_artifacts", "dim_dbt__models"], "alias": "dim_dbt__models", "checksum": {"name": "sha256", "checksum": "69233fcb40c166f3e85c36073c06e3148bc3e409944e9943e0e65427e06ba033"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about models.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "model_execution_id": {"name": "model_execution_id", "description": "Execution ID of the model node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.model_execution_id"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "meta": {"name": "meta", "description": "The meta field of the config associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.meta"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__models.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__models.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6686168, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__models`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__models\") }}),\n\n    models as (\n\n        select\n            model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            materialization,\n            tags,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom models", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__models", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__models"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__models.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__models`),\n\n    models as (\n\n        select\n            model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n             database\n            ,\n             schema\n            ,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            materialization,\n            tags,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom models", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.fct_dbt__model_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "fct_dbt__model_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "fct_dbt__model_executions.sql", "original_file_path": "models/fct_dbt__model_executions.sql", "unique_id": "model.dbt_artifacts.fct_dbt__model_executions", "fqn": ["dbt_artifacts", "fct_dbt__model_executions"], "alias": "fct_dbt__model_executions", "checksum": {"name": "sha256", "checksum": "3d42fb62de124f57e6d5320bd0c6c1e5b60604d1d17d69ca4f76cde0c9127fd5"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Fact model that contains data about model executions.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "model_execution_id": {"name": "model_execution_id", "description": "Execution ID of the model node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.model_execution_id"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "bytes_affected": {"name": "bytes_affected", "description": "Number of bytes processed by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.bytes_processed"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/fct_dbt__model_executions.yml", "build_path": "target/run/dbt_artifacts/models/fct_dbt__model_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6619918, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`fct_dbt__model_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__model_executions\") }}),\n\n    model_executions as (\n\n        select\n            model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected\n            {% if target.type == \"bigquery\" %}, bytes_processed {% endif %},\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom model_executions", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__model_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__model_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/fct_dbt__model_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__model_executions`),\n\n    model_executions as (\n\n        select\n            model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected\n            ,\n            materialization,\n             schema\n            ,\n            name,\n            alias,\n            message\n        from base\n\n    )\n\nselect *\nfrom model_executions", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.fct_dbt__invocations": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "fct_dbt__invocations", "resource_type": "model", "package_name": "dbt_artifacts", "path": "fct_dbt__invocations.sql", "original_file_path": "models/fct_dbt__invocations.sql", "unique_id": "model.dbt_artifacts.fct_dbt__invocations", "fqn": ["dbt_artifacts", "fct_dbt__invocations"], "alias": "fct_dbt__invocations", "checksum": {"name": "sha256", "checksum": "1b43bc26b556d6d3e3a665ab3d1986a9d6f04ffea64e9584269d1046fc712588"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Fact model that contains data about invocations.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "dbt_version": {"name": "dbt_version", "description": "Installed version of dbt that is currently running.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_version"]}, "project_name": {"name": "project_name", "description": "Name for the root-level project which is being run by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.project_name"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "dbt_command": {"name": "dbt_command", "description": "dbt command of this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_command"]}, "full_refresh_flag": {"name": "full_refresh_flag", "description": "Boolean flag indicating whether the dbt run was in full refresh mode or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.full_refresh_flag"]}, "target_profile_name": {"name": "target_profile_name", "description": "The name of the active profile.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_profile_name"]}, "target_name": {"name": "target_name", "description": "The name of the active target.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_name"]}, "target_schema": {"name": "target_schema", "description": "The name of the target dbt schema.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_schema"]}, "target_threads": {"name": "target_threads", "description": "The number of threads in use by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_threads"]}, "dbt_cloud_project_id": {"name": "dbt_cloud_project_id", "description": "The ID of the dbt Cloud Project for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_project_id"]}, "dbt_cloud_job_id": {"name": "dbt_cloud_job_id", "description": "The ID of the dbt Cloud Job for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_job_id"]}, "dbt_cloud_run_id": {"name": "dbt_cloud_run_id", "description": "The ID of this particular run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_id"]}, "dbt_cloud_run_reason_category": {"name": "dbt_cloud_run_reason_category", "description": "The \"category\" of the trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason_category"]}, "dbt_cloud_run_reason": {"name": "dbt_cloud_run_reason", "description": "The specific trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason"]}, "env_vars": {"name": "env_vars", "description": "Key-value pairs of environment variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.env_vars"]}, "dbt_vars": {"name": "dbt_vars", "description": "Key-value pairs of project variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_vars"]}, "invocation_args": {"name": "invocation_args", "description": "Key-value pairs of args passed to invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.invocation_args"]}, "dbt_custom_envs": {"name": "dbt_custom_envs", "description": "Key-value pairs of environment variables passed to invocation that have the prefix DBT_ENV_CUSTOM_ENV_", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_custom_envs"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/fct_dbt__invocations.yml", "build_path": "target/run/dbt_artifacts/models/fct_dbt__invocations.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6738217, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`fct_dbt__invocations`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('stg_dbt__invocations') }}\n\n    )\n\n    , invocations as (\n\n        select\n            command_invocation_id\n            , dbt_version\n            , project_name\n            , run_started_at\n            , dbt_command\n            , full_refresh_flag\n            , target_profile_name\n            , target_name\n            , target_schema\n            , target_threads\n            , dbt_cloud_project_id\n            , dbt_cloud_job_id\n            , dbt_cloud_run_id\n            , dbt_cloud_run_reason_category\n            , dbt_cloud_run_reason\n            , env_vars\n            , dbt_vars\n            , invocation_args\n            , dbt_custom_envs\n        from base\n\n    )\n\nselect * from invocations", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__invocations", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__invocations"]}, "compiled_path": "target/compiled/dbt_artifacts/models/fct_dbt__invocations.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__invocations`\n\n    )\n\n    , invocations as (\n\n        select\n            command_invocation_id\n            , dbt_version\n            , project_name\n            , run_started_at\n            , dbt_command\n            , full_refresh_flag\n            , target_profile_name\n            , target_name\n            , target_schema\n            , target_threads\n            , dbt_cloud_project_id\n            , dbt_cloud_job_id\n            , dbt_cloud_run_id\n            , dbt_cloud_run_reason_category\n            , dbt_cloud_run_reason\n            , env_vars\n            , dbt_vars\n            , invocation_args\n            , dbt_custom_envs\n        from base\n\n    )\n\nselect * from invocations", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__seeds": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__seeds", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__seeds.sql", "original_file_path": "models/dim_dbt__seeds.sql", "unique_id": "model.dbt_artifacts.dim_dbt__seeds", "fqn": ["dbt_artifacts", "dim_dbt__seeds"], "alias": "dim_dbt__seeds", "checksum": {"name": "sha256", "checksum": "bba033b0278e2660b00d5d639b2b7e1ad449005a67d89612cce0152cede324c1"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about seeds.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "seed_execution_id": {"name": "seed_execution_id", "description": "Execution ID of the seed node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.seed_execution_id"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__seeds.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__seeds.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6640413, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__seeds`", "raw_code": "with\n    base as (select * from {{ ref(\"stg_dbt__seeds\") }}),\n\n    seeds as (\n\n        select\n            seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            package_name,\n            path,\n            checksum,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom seeds", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__seeds", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__seeds"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__seeds.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__seeds`),\n\n    seeds as (\n\n        select\n            seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n             database\n            ,\n             schema\n            ,\n            package_name,\n            path,\n            checksum,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom seeds", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.dim_dbt__exposures": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "dim_dbt__exposures", "resource_type": "model", "package_name": "dbt_artifacts", "path": "dim_dbt__exposures.sql", "original_file_path": "models/dim_dbt__exposures.sql", "unique_id": "model.dbt_artifacts.dim_dbt__exposures", "fqn": ["dbt_artifacts", "dim_dbt__exposures"], "alias": "dim_dbt__exposures", "checksum": {"name": "sha256", "checksum": "bcafbdb6c73042f8f4fe484c23f2d52d4fbeba03a1254a86aedda7f6b36e27c1"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Dimension model that contains data about exposures.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "description": {"name": "description", "description": "Node description.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.description"]}, "exposure_execution_id": {"name": "exposure_execution_id", "description": "Execution ID of the exposure node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.exposure_execution_id"]}, "maturity": {"name": "maturity", "description": "Exposure maturity; one of high, medium, low.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.maturity"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "owner": {"name": "owner", "description": "Owner of the exposure, usually an email address.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.owner"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "type": {"name": "type", "description": "Exposure type; one of dashboard, notebook, analysis, ml, application (used to organize on docs site)", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.type"]}, "url": {"name": "url", "description": "The URL of the BI tool where the data defined by the exposure can be viewed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.url"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/dim_dbt__exposures.yml", "build_path": "target/run/dbt_artifacts/models/dim_dbt__exposures.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6674778, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`dim_dbt__exposures`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('stg_dbt__exposures') }}\n\n    )\n\n    , exposures as (\n\n        select\n            exposure_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , type\n            , owner\n            , maturity\n            , path\n            , description\n            , url\n            , package_name\n            , depends_on_nodes\n            , tags\n        from base\n\n    )\n\nselect * from exposures", "doc_blocks": [], "language": "sql", "refs": [{"name": "stg_dbt__exposures", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.stg_dbt__exposures"]}, "compiled_path": "target/compiled/dbt_artifacts/models/dim_dbt__exposures.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`stg_dbt__exposures`\n\n    )\n\n    , exposures as (\n\n        select\n            exposure_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , type\n            , owner\n            , maturity\n            , path\n            , description\n            , url\n            , package_name\n            , depends_on_nodes\n            , tags\n        from base\n\n    )\n\nselect * from exposures", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__seed_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__seed_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__seed_executions.sql", "original_file_path": "models/staging/stg_dbt__seed_executions.sql", "unique_id": "model.dbt_artifacts.stg_dbt__seed_executions", "fqn": ["dbt_artifacts", "staging", "stg_dbt__seed_executions"], "alias": "stg_dbt__seed_executions", "checksum": {"name": "sha256", "checksum": "e59370319eb9ca05daaa7c025f7edd043815d90bea8748333bd7729542710791"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about seed executions. One row per seed execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "seed_execution_id": {"name": "seed_execution_id", "description": "Execution ID of the seed node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.seed_execution_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__seed_executions.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__seed_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6883118, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__seed_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"seed_executions\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            {{ split_part(\"thread_id\", \"'-'\", 2) }} as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "seed_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key", "macro.dbt.split_part"], "nodes": ["model.dbt_artifacts.seed_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__seed_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`seed_executions`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            \n\n        get(split(\n            thread_id,\n            \n\n        -- escape if starts with a special character\n        case when regexp_extract('-', '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', '-')\n            else '-' end\n\n    \n            ), 1)\n\n         as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n             schema\n            ,  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__snapshots": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__snapshots", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__snapshots.sql", "original_file_path": "models/staging/stg_dbt__snapshots.sql", "unique_id": "model.dbt_artifacts.stg_dbt__snapshots", "fqn": ["dbt_artifacts", "staging", "stg_dbt__snapshots"], "alias": "stg_dbt__snapshots", "checksum": {"name": "sha256", "checksum": "81784e538ca1e7e5b6b549c6a27ae0c69c042080f37ce6696baf07da3612c268"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains metadata about seed executions. One row per node per run.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "snapshot_execution_id": {"name": "snapshot_execution_id", "description": "Execution ID of the snapshot node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.snapshot_execution_id"]}, "strategy": {"name": "strategy", "description": "Snapshot \"strategies\" define how dbt knows if a row has changed. There are two strategies built-in to dbt \u2014 timestamp\nand check.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.strategy"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__snapshots.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__snapshots.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6859438, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__snapshots`", "raw_code": "with\n    base as (select * from {{ ref(\"snapshots\") }}),\n\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            strategy,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "snapshots", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.snapshots"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__snapshots.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`snapshots`),\n\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n             database\n            ,\n             schema\n            ,\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            strategy,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__seeds": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__seeds", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__seeds.sql", "original_file_path": "models/staging/stg_dbt__seeds.sql", "unique_id": "model.dbt_artifacts.stg_dbt__seeds", "fqn": ["dbt_artifacts", "staging", "stg_dbt__seeds"], "alias": "stg_dbt__seeds", "checksum": {"name": "sha256", "checksum": "261dfe943232fdc03311294378c50403db5421b112df494c4cf2e6d9c7f311ef"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Stageing model that contains metadata about seed executions. One row per node per run.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "seed_execution_id": {"name": "seed_execution_id", "description": "Execution ID of the seed node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.seed_execution_id"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__seeds.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__seeds.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6851668, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__seeds`", "raw_code": "with\n    base as (select * from {{ ref(\"seeds\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            name,\n            package_name,\n            path,\n            checksum,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "seeds", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.seeds"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__seeds.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`seeds`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as seed_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n             database\n            ,\n             schema\n            ,\n            name,\n            package_name,\n            path,\n            checksum,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__invocations": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__invocations", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__invocations.sql", "original_file_path": "models/staging/stg_dbt__invocations.sql", "unique_id": "model.dbt_artifacts.stg_dbt__invocations", "fqn": ["dbt_artifacts", "staging", "stg_dbt__invocations"], "alias": "stg_dbt__invocations", "checksum": {"name": "sha256", "checksum": "6fc43c1e8d091f6b49c6b3c20145525f9a8334383c4d74bf3c38b69b3302baf2"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about the invocations of dbt. One row per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "dbt_version": {"name": "dbt_version", "description": "Installed version of dbt that is currently running.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_version"]}, "project_name": {"name": "project_name", "description": "Name for the root-level project which is being run by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.project_name"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "dbt_command": {"name": "dbt_command", "description": "dbt command of this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_command"]}, "full_refresh_flag": {"name": "full_refresh_flag", "description": "Boolean flag indicating whether the dbt run was in full refresh mode or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.full_refresh_flag"]}, "target_profile_name": {"name": "target_profile_name", "description": "The name of the active profile.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_profile_name"]}, "target_name": {"name": "target_name", "description": "The name of the active target.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_name"]}, "target_schema": {"name": "target_schema", "description": "The name of the target dbt schema.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_schema"]}, "target_threads": {"name": "target_threads", "description": "The number of threads in use by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_threads"]}, "dbt_cloud_project_id": {"name": "dbt_cloud_project_id", "description": "The ID of the dbt Cloud Project for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_project_id"]}, "dbt_cloud_job_id": {"name": "dbt_cloud_job_id", "description": "The ID of the dbt Cloud Job for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_job_id"]}, "dbt_cloud_run_id": {"name": "dbt_cloud_run_id", "description": "The ID of this particular run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_id"]}, "dbt_cloud_run_reason_category": {"name": "dbt_cloud_run_reason_category", "description": "The \"category\" of the trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason_category"]}, "dbt_cloud_run_reason": {"name": "dbt_cloud_run_reason", "description": "The specific trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason"]}, "env_vars": {"name": "env_vars", "description": "Key-value pairs of environment variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.env_vars"]}, "dbt_vars": {"name": "dbt_vars", "description": "Key-value pairs of project variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_vars"]}, "invocation_args": {"name": "invocation_args", "description": "Key-value pairs of args passed to invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.invocation_args"]}, "dbt_custom_envs": {"name": "dbt_custom_envs", "description": "Key-value pairs of environment variables passed to invocation that have the prefix DBT_ENV_CUSTOM_ENV_", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_custom_envs"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__invocations.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__invocations.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6909473, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__invocations`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('invocations') }}\n\n    )\n\n    , enhanced as (\n\n        select\n            command_invocation_id\n            , dbt_version\n            , project_name\n            , run_started_at\n            , dbt_command\n            , full_refresh_flag\n            , target_profile_name\n            , target_name\n            , target_schema\n            , target_threads\n            , dbt_cloud_project_id\n            , dbt_cloud_job_id\n            , dbt_cloud_run_id\n            , dbt_cloud_run_reason_category\n            , dbt_cloud_run_reason\n            , env_vars\n            , dbt_vars\n            , invocation_args\n            , dbt_custom_envs\n        from base\n\n    )\n\nselect * from enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "invocations", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": [], "nodes": ["model.dbt_artifacts.invocations"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__invocations.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`invocations`\n\n    )\n\n    , enhanced as (\n\n        select\n            command_invocation_id\n            , dbt_version\n            , project_name\n            , run_started_at\n            , dbt_command\n            , full_refresh_flag\n            , target_profile_name\n            , target_name\n            , target_schema\n            , target_threads\n            , dbt_cloud_project_id\n            , dbt_cloud_job_id\n            , dbt_cloud_run_id\n            , dbt_cloud_run_reason_category\n            , dbt_cloud_run_reason\n            , env_vars\n            , dbt_vars\n            , invocation_args\n            , dbt_custom_envs\n        from base\n\n    )\n\nselect * from enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__test_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__test_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__test_executions.sql", "original_file_path": "models/staging/stg_dbt__test_executions.sql", "unique_id": "model.dbt_artifacts.stg_dbt__test_executions", "fqn": ["dbt_artifacts", "staging", "stg_dbt__test_executions"], "alias": "stg_dbt__test_executions", "checksum": {"name": "sha256", "checksum": "8a91f14e35465f9717434ae161955f5f0ba4558a2d0d32265955bdc4437d8369"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains metadata about test executions. One row per test execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "failures": {"name": "failures", "description": "Test failures. Value is 1 if the test failed, 0 if successful.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.failures"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "test_execution_id": {"name": "test_execution_id", "description": "Execution ID of the test node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_execution_id"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__test_executions.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__test_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.690078, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__test_executions`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('test_executions') }}\n\n    )\n\n    , enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key(['command_invocation_id', 'node_id']) }} as test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , was_full_refresh\n            , {{ split_part('thread_id', \"'-'\", 2) }} as thread_id\n            , status\n            , compile_started_at\n            , query_completed_at\n            , total_node_runtime\n            , rows_affected\n            , failures\n            , message\n        from base\n\n    )\n\nselect * from enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "test_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key", "macro.dbt.split_part"], "nodes": ["model.dbt_artifacts.test_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__test_executions.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`test_executions`\n\n    )\n\n    , enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string)) as test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , was_full_refresh\n            , \n\n        get(split(\n            thread_id,\n            \n\n        -- escape if starts with a special character\n        case when regexp_extract('-', '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', '-')\n            else '-' end\n\n    \n            ), 1)\n\n         as thread_id\n            , status\n            , compile_started_at\n            , query_completed_at\n            , total_node_runtime\n            , rows_affected\n            , failures\n            , message\n        from base\n\n    )\n\nselect * from enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__snapshot_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__snapshot_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__snapshot_executions.sql", "original_file_path": "models/staging/stg_dbt__snapshot_executions.sql", "unique_id": "model.dbt_artifacts.stg_dbt__snapshot_executions", "fqn": ["dbt_artifacts", "staging", "stg_dbt__snapshot_executions"], "alias": "stg_dbt__snapshot_executions", "checksum": {"name": "sha256", "checksum": "ef4b8bb86d218dc1fff046c57c4b3980efc1cae08d6e1bc1fcffa9d1089f39b4"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about snapshot executions. One row per snapshot execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "snapshot_execution_id": {"name": "snapshot_execution_id", "description": "Execution ID of the snapshot node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.snapshot_execution_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__snapshot_executions.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__snapshot_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6875284, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__snapshot_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"snapshot_executions\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            {{ split_part(\"thread_id\", \"'-'\", 2) }} as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "snapshot_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key", "macro.dbt.split_part"], "nodes": ["model.dbt_artifacts.snapshot_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__snapshot_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`snapshot_executions`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as snapshot_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            \n\n        get(split(\n            thread_id,\n            \n\n        -- escape if starts with a special character\n        case when regexp_extract('-', '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', '-')\n            else '-' end\n\n    \n            ), 1)\n\n         as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n             schema\n            ,  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__exposures": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__exposures", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__exposures.sql", "original_file_path": "models/staging/stg_dbt__exposures.sql", "unique_id": "model.dbt_artifacts.stg_dbt__exposures", "fqn": ["dbt_artifacts", "staging", "stg_dbt__exposures"], "alias": "stg_dbt__exposures", "checksum": {"name": "sha256", "checksum": "5a158398fdfc4023e14790b1b39458438ee83bb9ba02018b8a361abf825fad08"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about exposure exections. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "description": {"name": "description", "description": "Node description.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.description"]}, "exposure_execution_id": {"name": "exposure_execution_id", "description": "Execution ID of the exposure node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.exposure_execution_id"]}, "maturity": {"name": "maturity", "description": "Exposure maturity; one of high, medium, low.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.maturity"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "owner": {"name": "owner", "description": "Owner of the exposure, usually an email address.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.owner"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "type": {"name": "type", "description": "Exposure type; one of dashboard, notebook, analysis, ml, application (used to organize on docs site)", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.type"]}, "url": {"name": "url", "description": "The URL of the BI tool where the data defined by the exposure can be viewed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.url"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__exposures.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__exposures.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.686688, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__exposures`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('exposures') }}\n\n    )\n\n    , enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key(['command_invocation_id', 'node_id']) }} as exposure_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , type\n            , owner\n            , maturity\n            , path\n            , description\n            , url\n            , package_name\n            , depends_on_nodes\n            , tags\n        from base\n\n    )\n\nselect * from enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "exposures", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.exposures"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__exposures.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`exposures`\n\n    )\n\n    , enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string)) as exposure_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , type\n            , owner\n            , maturity\n            , path\n            , description\n            , url\n            , package_name\n            , depends_on_nodes\n            , tags\n        from base\n\n    )\n\nselect * from enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__models": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__models", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__models.sql", "original_file_path": "models/staging/stg_dbt__models.sql", "unique_id": "model.dbt_artifacts.stg_dbt__models", "fqn": ["dbt_artifacts", "staging", "stg_dbt__models"], "alias": "stg_dbt__models", "checksum": {"name": "sha256", "checksum": "33169cecb1eb3fbd113f8907b42c48afd2386894ee3b76e459f7fec9c9a8f536"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains metadata about model executions. One row per node per run.", "columns": {"checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "model_execution_id": {"name": "model_execution_id", "description": "Execution ID of the model node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.model_execution_id"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "meta": {"name": "meta", "description": "The meta field of the config associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.meta"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__models.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__models.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6893425, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__models`", "raw_code": "with\n    base as (select * from {{ ref(\"models\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},  -- noqa\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            materialization,\n            tags,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "models", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.models"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__models.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`models`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n             database\n            ,\n             schema\n            ,  -- noqa\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            materialization,\n            tags,\n            meta,\n            alias\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__model_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__model_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__model_executions.sql", "original_file_path": "models/staging/stg_dbt__model_executions.sql", "unique_id": "model.dbt_artifacts.stg_dbt__model_executions", "fqn": ["dbt_artifacts", "staging", "stg_dbt__model_executions"], "alias": "stg_dbt__model_executions", "checksum": {"name": "sha256", "checksum": "5229f75787915d2cc709ba7fa736fca888708eedc06dabc88266ebc9564dc490"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about model executions. One row per model execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "model_execution_id": {"name": "model_execution_id", "description": "Execution ID of the model node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.model_execution_id"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "bytes_processed": {"name": "bytes_processed", "description": "Number of bytes processed by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.bytes_processed"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__model_executions.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__model_executions.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6842988, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__model_executions`", "raw_code": "with\n    base as (select * from {{ ref(\"model_executions\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            {{ split_part(\"thread_id\", \"'-'\", 2) }} as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected\n            {% if target.type == \"bigquery\" %}, bytes_processed {% endif %},\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "model_executions", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key", "macro.dbt.split_part"], "nodes": ["model.dbt_artifacts.model_executions"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__model_executions.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`model_executions`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as model_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            \n\n        get(split(\n            thread_id,\n            \n\n        -- escape if starts with a special character\n        case when regexp_extract('-', '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', '-')\n            else '-' end\n\n    \n            ), 1)\n\n         as thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected\n            ,\n            materialization,\n             schema\n            ,  -- noqa\n            name,\n            alias,\n            message,\n            adapter_response\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__sources": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__sources", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__sources.sql", "original_file_path": "models/staging/stg_dbt__sources.sql", "unique_id": "model.dbt_artifacts.stg_dbt__sources", "fqn": ["dbt_artifacts", "staging", "stg_dbt__sources"], "alias": "stg_dbt__sources", "checksum": {"name": "sha256", "checksum": "e131caeae51cb64b62dc8819923a56c88b8dcf19e13fcff0c877e1989ec912a5"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains data about sources. One row per node per execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "freshness": {"name": "freshness", "description": "The specified freshness of the source model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.freshness"]}, "identifier": {"name": "identifier", "description": "Source identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.identifier"]}, "loaded_at_field": {"name": "loaded_at_field", "description": "A column name (or expression) that returns a timestamp indicating freshness.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loaded_at_field"]}, "loader": {"name": "loader", "description": "Describes the tool that loads this source into your warehouse.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loader"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "source_execution_id": {"name": "source_execution_id", "description": "Execution ID of the source node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.source_execution_id"]}, "source_name": {"name": "source_name", "description": "Source name.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.source_name"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__sources.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__sources.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6916943, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__sources`", "raw_code": "with\n    base as (select * from {{ ref(\"sources\") }}),\n    enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key([\"command_invocation_id\", \"node_id\"]) }}\n            as source_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\"\n            {% else %} database\n            {% endif %},\n            {% if target.type == \"sqlserver\" %} \"schema\"\n            {% else %} schema\n            {% endif %},\n            source_name,\n            loader,\n            name,\n            identifier,\n            loaded_at_field,\n            freshness\n        from base\n\n    )\n\nselect *\nfrom enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "sources", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.sources"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__sources.sql", "compiled": true, "compiled_code": "with\n    base as (select * from `dbt_project_catalog`.`dbt_kisara`.`sources`),\n    enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string))\n            as source_execution_id,\n            command_invocation_id,\n            node_id,\n            run_started_at,\n             database\n            ,\n             schema\n            ,\n            source_name,\n            loader,\n            name,\n            identifier,\n            loaded_at_field,\n            freshness\n        from base\n\n    )\n\nselect *\nfrom enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.stg_dbt__tests": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "stg_dbt__tests", "resource_type": "model", "package_name": "dbt_artifacts", "path": "staging/stg_dbt__tests.sql", "original_file_path": "models/staging/stg_dbt__tests.sql", "unique_id": "model.dbt_artifacts.stg_dbt__tests", "fqn": ["dbt_artifacts", "staging", "stg_dbt__tests"], "alias": "stg_dbt__tests", "checksum": {"name": "sha256", "checksum": "cd8c3b40b6a38b81c73da870fcb2a92f8eacbd6e60fa835a9d3d0598a73e5336"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "view", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": null, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": ""}, "tags": [], "description": "Staging model that contains metadata about test executions. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "test_execution_id": {"name": "test_execution_id", "description": "Execution ID of the test node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_execution_id"]}, "test_path": {"name": "test_path", "description": "Path to the yaml (SQL in case of a singular test) file describing the test.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_path"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/staging/stg_dbt__tests.yml", "build_path": "target/run/dbt_artifacts/models/staging/stg_dbt__tests.sql", "unrendered_config": {"materialized": "view", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}"}, "created_at": 1760419970.6826227, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`stg_dbt__tests`", "raw_code": "with\n    base as (\n\n        select *\n        from {{ ref('tests') }}\n\n    )\n\n    , enhanced as (\n\n        select\n            {{ dbt_artifacts.generate_surrogate_key(['command_invocation_id', 'node_id']) }} as test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , depends_on_nodes\n            , package_name\n            , test_path\n            , tags\n        from base\n\n    )\n\nselect * from enhanced", "doc_blocks": [], "language": "sql", "refs": [{"name": "tests", "package": null, "version": null}], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt_artifacts.generate_surrogate_key"], "nodes": ["model.dbt_artifacts.tests"]}, "compiled_path": "target/compiled/dbt_artifacts/models/staging/stg_dbt__tests.sql", "compiled": true, "compiled_code": "with\n    base as (\n\n        select *\n        from `dbt_project_catalog`.`dbt_kisara`.`tests`\n\n    )\n\n    , enhanced as (\n\n        select\n            \nmd5(cast(concat(coalesce(cast(command_invocation_id as string), ''), '-', coalesce(cast(node_id as string), '')) as string)) as test_execution_id\n            , command_invocation_id\n            , node_id\n            , run_started_at\n            , name\n            , depends_on_nodes\n            , package_name\n            , test_path\n            , tags\n        from base\n\n    )\n\nselect * from enhanced", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.seed_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "seed_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/seed_executions.sql", "original_file_path": "models/sources/seed_executions.sql", "unique_id": "model.dbt_artifacts.seed_executions", "fqn": ["dbt_artifacts", "sources", "seed_executions"], "alias": "seed_executions", "checksum": {"name": "sha256", "checksum": "340e68f20c1e4a74dca5268b4f788ea72df5a329cd1bcfb2ccd200a4fec14620"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about seed executions. One row per seed execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/seed_executions.yml", "build_path": "target/run/dbt_artifacts/models/sources/seed_executions.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6983664, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`seed_executions`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_boolean() }}) as was_full_refresh,\n    cast(null as {{ type_string() }}) as thread_id,\n    cast(null as {{ type_string() }}) as status,\n    cast(null as {{ type_timestamp() }}) as compile_started_at,\n    cast(null as {{ type_timestamp() }}) as query_completed_at,\n    cast(null as {{ type_float() }}) as total_node_runtime,\n    cast(null as {{ type_int() }}) as rows_affected,\n    cast(null as {{ type_string() }}) as materialization,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_string() }}) as message,\n    cast(null as {{ type_json() }}) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_boolean", "macro.dbt.type_float", "macro.dbt.type_int", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/seed_executions.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as boolean) as was_full_refresh,\n    cast(null as string) as thread_id,\n    cast(null as string) as status,\n    cast(null as timestamp) as compile_started_at,\n    cast(null as timestamp) as query_completed_at,\n    cast(null as float) as total_node_runtime,\n    cast(null as integer) as rows_affected,\n    cast(null as string) as materialization,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as alias,\n    cast(null as string) as message,\n    cast(null as string) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.test_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "test_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/test_executions.sql", "original_file_path": "models/sources/test_executions.sql", "unique_id": "model.dbt_artifacts.test_executions", "fqn": ["dbt_artifacts", "sources", "test_executions"], "alias": "test_executions", "checksum": {"name": "sha256", "checksum": "ea0963858fc794426ca5d25e7de53212016c740266beea88f5b122ebeefb9558"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for metadata about test executions. One row per test execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "failures": {"name": "failures", "description": "Test failures. Value is 1 if the test failed, 0 if successful.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.failures"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/test_executions.yml", "build_path": "target/run/dbt_artifacts/models/sources/test_executions.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6943665, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`test_executions`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n    )\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id\n    , cast(null as {{ type_string() }}) as node_id\n    , cast(null as {{ type_timestamp() }}) as run_started_at\n    , cast(null as {{ type_boolean() }}) as was_full_refresh\n    , cast(null as {{ type_string() }}) as thread_id\n    , cast(null as {{ type_string() }}) as status\n    , cast(null as {{ type_timestamp() }}) as compile_started_at\n    , cast(null as {{ type_timestamp() }}) as query_completed_at\n    , cast(null as {{ type_float() }}) as total_node_runtime\n    , cast(null as {{ type_int() }}) as rows_affected\n    , cast(null as {{ type_int() }}) as failures\n    , cast(null as {{ type_string() }}) as message\n    , cast(null as {{ type_json() }}) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_boolean", "macro.dbt.type_float", "macro.dbt.type_int", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/test_executions.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n    )\n\nselect\n    cast(null as string) as command_invocation_id\n    , cast(null as string) as node_id\n    , cast(null as timestamp) as run_started_at\n    , cast(null as boolean) as was_full_refresh\n    , cast(null as string) as thread_id\n    , cast(null as string) as status\n    , cast(null as timestamp) as compile_started_at\n    , cast(null as timestamp) as query_completed_at\n    , cast(null as float) as total_node_runtime\n    , cast(null as integer) as rows_affected\n    , cast(null as integer) as failures\n    , cast(null as string) as message\n    , cast(null as string) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.model_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "model_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/model_executions.sql", "original_file_path": "models/sources/model_executions.sql", "unique_id": "model.dbt_artifacts.model_executions", "fqn": ["dbt_artifacts", "sources", "model_executions"], "alias": "model_executions", "checksum": {"name": "sha256", "checksum": "ff3be2dff4a30d6dd6ed487bf216750160a40d2d875a561698569ade42f54384"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about model executions. One row per model execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/model_executions.yml", "build_path": "target/run/dbt_artifacts/models/sources/model_executions.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6955833, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`model_executions`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_boolean() }}) as was_full_refresh,\n    cast(null as {{ type_string() }}) as thread_id,\n    cast(null as {{ type_string() }}) as status,\n    cast(null as {{ type_timestamp() }}) as compile_started_at,\n    cast(null as {{ type_timestamp() }}) as query_completed_at,\n    cast(null as {{ type_float() }}) as total_node_runtime,\n    cast(null as {{ type_int() }}) as rows_affected,\n    {% if target.type == \"bigquery\" %}\n        cast(null as {{ type_int() }}) as bytes_processed,\n    {% endif %}\n    cast(null as {{ type_string() }}) as materialization,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_string() }}) as message,\n    cast(null as {{ type_json() }}) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_boolean", "macro.dbt.type_float", "macro.dbt.type_int", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/model_executions.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as boolean) as was_full_refresh,\n    cast(null as string) as thread_id,\n    cast(null as string) as status,\n    cast(null as timestamp) as compile_started_at,\n    cast(null as timestamp) as query_completed_at,\n    cast(null as float) as total_node_runtime,\n    cast(null as integer) as rows_affected,\n    \n    cast(null as string) as materialization,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as alias,\n    cast(null as string) as message,\n    cast(null as string) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.sources": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "sources", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/sources.sql", "original_file_path": "models/sources/sources.sql", "unique_id": "model.dbt_artifacts.sources", "fqn": ["dbt_artifacts", "sources", "sources"], "alias": "sources", "checksum": {"name": "sha256", "checksum": "a9fd2c53df27df03d8d375962482ced2513fd7fcf582213b5eecef37fa8a7626"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about sources. One row per node per execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "source_name": {"name": "source_name", "description": "Source name.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.source_name"]}, "loader": {"name": "loader", "description": "Describes the tool that loads this source into your warehouse.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loader"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "identifier": {"name": "identifier", "description": "Source identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.identifier"]}, "loaded_at_field": {"name": "loaded_at_field", "description": "A column name (or expression) that returns a timestamp indicating freshness.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.loaded_at_field"]}, "freshness": {"name": "freshness", "description": "The specified freshness of the source model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.freshness"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/sources.yml", "build_path": "target/run/dbt_artifacts/models/sources/sources.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6926374, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`sources`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"database\"\n    {% else %} database\n    {% endif %},\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as source_name,\n    cast(null as {{ type_string() }}) as loader,\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_string() }}) as identifier,\n    cast(null as {{ type_string() }}) as loaded_at_field\n    {% if target.type == \"snowflake\" %}, cast(null as {{ type_array() }}) as freshness\n    {% else %}, cast(null as {{ type_json() }}) as freshness\n    {% endif %},\n    cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/sources.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as string) as  database\n    ,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as source_name,\n    cast(null as string) as loader,\n    cast(null as string) as name,\n    cast(null as string) as identifier,\n    cast(null as string) as loaded_at_field\n    , cast(null as string) as freshness\n    ,\n    cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.exposures": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "exposures", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/exposures.sql", "original_file_path": "models/sources/exposures.sql", "unique_id": "model.dbt_artifacts.exposures", "fqn": ["dbt_artifacts", "sources", "exposures"], "alias": "exposures", "checksum": {"name": "sha256", "checksum": "9870dccc41f3a0ba10c7607972d865e275c70fac256fe0855844dd1a7aec0f8c"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about exposure exections. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "type": {"name": "type", "description": "Exposure type; one of dashboard, notebook, analysis, ml, application (used to organize on docs site)", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.type"]}, "owner": {"name": "owner", "description": "Owner of the exposure, usually an email address.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.owner"]}, "maturity": {"name": "maturity", "description": "Exposure maturity; one of high, medium, low.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.maturity"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "description": {"name": "description", "description": "Node description.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.description"]}, "url": {"name": "url", "description": "The URL of the BI tool where the data defined by the exposure can be viewed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.url"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/exposures.yml", "build_path": "target/run/dbt_artifacts/models/sources/exposures.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.7013721, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`exposures`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id\n    , cast(null as {{ type_string() }}) as node_id\n    , cast(null as {{ type_timestamp() }}) as run_started_at\n    , cast(null as {{ type_string() }}) as name\n    , cast(null as {{ type_string() }}) as type\n    , cast(null as {{ type_json() }}) as owner\n    , cast(null as {{ type_string() }}) as maturity\n    , cast(null as {{ type_string() }}) as path\n    , cast(null as {{ type_string() }}) as description\n    , cast(null as {{ type_string() }}) as url\n    , cast(null as {{ type_string() }}) as package_name\n    , cast(null as {{ type_array() }}) as depends_on_nodes\n    , cast(null as {{ type_array() }}) as tags\n    , cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_json", "macro.dbt_artifacts.type_array"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/exposures.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as string) as command_invocation_id\n    , cast(null as string) as node_id\n    , cast(null as timestamp) as run_started_at\n    , cast(null as string) as name\n    , cast(null as string) as type\n    , cast(null as string) as owner\n    , cast(null as string) as maturity\n    , cast(null as string) as path\n    , cast(null as string) as description\n    , cast(null as string) as url\n    , cast(null as string) as package_name\n    , cast(null as string) as depends_on_nodes\n    , cast(null as string) as tags\n    , cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.seeds": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "seeds", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/seeds.sql", "original_file_path": "models/sources/seeds.sql", "unique_id": "model.dbt_artifacts.seeds", "fqn": ["dbt_artifacts", "sources", "seeds"], "alias": "seeds", "checksum": {"name": "sha256", "checksum": "29e6002f7c42765eb29795ae41d62cbd2c91461488e718a27eaab23c78458399"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for metadata about seed executions. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "meta": {"name": "meta", "description": "The meta field of the config associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.meta"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/seeds.yml", "build_path": "target/run/dbt_artifacts/models/sources/seeds.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.693621, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`seeds`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"database\"\n    {% else %} database\n    {% endif %},\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_string() }}) as package_name,\n    cast(null as {{ type_string() }}) as path,\n    cast(null as {{ type_string() }}) as checksum,\n    cast(null as {{ type_json() }}) as meta,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/seeds.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as string) as  database\n    ,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as package_name,\n    cast(null as string) as path,\n    cast(null as string) as checksum,\n    cast(null as string) as meta,\n    cast(null as string) as alias,\n    cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.invocations": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "invocations", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/invocations.sql", "original_file_path": "models/sources/invocations.sql", "unique_id": "model.dbt_artifacts.invocations", "fqn": ["dbt_artifacts", "sources", "invocations"], "alias": "invocations", "checksum": {"name": "sha256", "checksum": "e42914f0d8c046d1fca713033f9351e81b62d9596e3ca25989064929bfe6eb53"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about the invocations of dbt. One row per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "dbt_version": {"name": "dbt_version", "description": "Installed version of dbt that is currently running.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_version"]}, "project_name": {"name": "project_name", "description": "Name for the root-level project which is being run by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.project_name"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "dbt_command": {"name": "dbt_command", "description": "dbt command of this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_command"]}, "full_refresh_flag": {"name": "full_refresh_flag", "description": "Boolean flag indicating whether the dbt run was in full refresh mode or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.full_refresh_flag"]}, "target_profile_name": {"name": "target_profile_name", "description": "The name of the active profile.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_profile_name"]}, "target_name": {"name": "target_name", "description": "The name of the active target.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_name"]}, "target_schema": {"name": "target_schema", "description": "The name of the target dbt schema.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_schema"]}, "target_threads": {"name": "target_threads", "description": "The number of threads in use by dbt.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.target_threads"]}, "dbt_cloud_project_id": {"name": "dbt_cloud_project_id", "description": "The ID of the dbt Cloud Project for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_project_id"]}, "dbt_cloud_job_id": {"name": "dbt_cloud_job_id", "description": "The ID of the dbt Cloud Job for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_job_id"]}, "dbt_cloud_run_id": {"name": "dbt_cloud_run_id", "description": "The ID of this particular run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_id"]}, "dbt_cloud_run_reason_category": {"name": "dbt_cloud_run_reason_category", "description": "The \"category\" of the trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason_category"]}, "dbt_cloud_run_reason": {"name": "dbt_cloud_run_reason", "description": "The specific trigger for this run.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_cloud_run_reason"]}, "env_vars": {"name": "env_vars", "description": "Key-value pairs of environment variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.env_vars"]}, "dbt_vars": {"name": "dbt_vars", "description": "Key-value pairs of project variables to be capture.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_vars"]}, "invocation_args": {"name": "invocation_args", "description": "Key-value pairs of args passed to invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.invocation_args"]}, "dbt_custom_envs": {"name": "dbt_custom_envs", "description": "Key-value pairs of environment variables passed to invocation that have the prefix DBT_ENV_CUSTOM_ENV_", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.dbt_custom_envs"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/invocations.yml", "build_path": "target/run/dbt_artifacts/models/sources/invocations.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6996539, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`invocations`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id\n    , cast(null as {{ type_string() }}) as dbt_version\n    , cast(null as {{ type_string() }}) as project_name\n    , cast(null as {{ type_timestamp() }}) as run_started_at\n    , cast(null as {{ type_string() }}) as dbt_command\n    , cast(null as {{ type_boolean() }}) as full_refresh_flag\n    , cast(null as {{ type_string() }}) as target_profile_name\n    , cast(null as {{ type_string() }}) as target_name\n    , cast(null as {{ type_string() }}) as target_schema\n    , cast(null as {{ type_int() }}) as target_threads\n    , cast(null as {{ type_string() }}) as dbt_cloud_project_id\n    , cast(null as {{ type_string() }}) as dbt_cloud_job_id\n    , cast(null as {{ type_string() }}) as dbt_cloud_run_id\n    , cast(null as {{ type_string() }}) as dbt_cloud_run_reason_category\n    , cast(null as {{ type_string() }}) as dbt_cloud_run_reason\n    , cast(null as {{ type_json() }}) as env_vars\n    , cast(null as {{ type_json() }}) as dbt_vars\n    , cast(null as {{ type_json() }}) as invocation_args\n    , cast(null as {{ type_json() }}) as dbt_custom_envs\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_boolean", "macro.dbt.type_int", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/invocations.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as string) as command_invocation_id\n    , cast(null as string) as dbt_version\n    , cast(null as string) as project_name\n    , cast(null as timestamp) as run_started_at\n    , cast(null as string) as dbt_command\n    , cast(null as boolean) as full_refresh_flag\n    , cast(null as string) as target_profile_name\n    , cast(null as string) as target_name\n    , cast(null as string) as target_schema\n    , cast(null as integer) as target_threads\n    , cast(null as string) as dbt_cloud_project_id\n    , cast(null as string) as dbt_cloud_job_id\n    , cast(null as string) as dbt_cloud_run_id\n    , cast(null as string) as dbt_cloud_run_reason_category\n    , cast(null as string) as dbt_cloud_run_reason\n    , cast(null as string) as env_vars\n    , cast(null as string) as dbt_vars\n    , cast(null as string) as invocation_args\n    , cast(null as string) as dbt_custom_envs\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.tests": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "tests", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/tests.sql", "original_file_path": "models/sources/tests.sql", "unique_id": "model.dbt_artifacts.tests", "fqn": ["dbt_artifacts", "sources", "tests"], "alias": "tests", "checksum": {"name": "sha256", "checksum": "7dc17d36b8429eb004b0a1a04b3918cf9dbd5aaf79dfd426b84905d5c7374128"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for metadata about test executions. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "test_path": {"name": "test_path", "description": "Path to the yaml (SQL in case of a singular test) file describing the test.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.test_path"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/tests.yml", "build_path": "target/run/dbt_artifacts/models/sources/tests.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6961899, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`tests`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id\n    , cast(null as {{ type_string() }}) as node_id\n    , cast(null as {{ type_timestamp() }}) as run_started_at\n    , cast(null as {{ type_string() }}) as name\n    , cast(null as {{ type_array() }}) as depends_on_nodes\n    , cast(null as {{ type_string() }}) as package_name\n    , cast(null as {{ type_string() }}) as test_path\n    , cast(null as {{ type_array() }}) as tags\n    , cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_array", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/tests.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith\n    dummy_cte as (\n\n        select 1 as foo\n\n    )\n\nselect\n    cast(null as string) as command_invocation_id\n    , cast(null as string) as node_id\n    , cast(null as timestamp) as run_started_at\n    , cast(null as string) as name\n    , cast(null as string) as depends_on_nodes\n    , cast(null as string) as package_name\n    , cast(null as string) as test_path\n    , cast(null as string) as tags\n    , cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.snapshots": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "snapshots", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/snapshots.sql", "original_file_path": "models/sources/snapshots.sql", "unique_id": "model.dbt_artifacts.snapshots", "fqn": ["dbt_artifacts", "sources", "snapshots"], "alias": "snapshots", "checksum": {"name": "sha256", "checksum": "57c9b692d21dc6f0e83a959b2a6c6441ca6aaa36bb56c9317b35e6fa2c59162a"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for metadata about seed executions. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "strategy": {"name": "strategy", "description": "Snapshot \"strategies\" define how dbt knows if a row has changed. There are two strategies built-in to dbt \u2014 timestamp\nand check.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.strategy"]}, "meta": {"name": "meta", "description": "The meta field of the config associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.meta"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/snapshots.yml", "build_path": "target/run/dbt_artifacts/models/sources/snapshots.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6968951, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`snapshots`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"database\"\n    {% else %} database\n    {% endif %},\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_array() }}) as depends_on_nodes,\n    cast(null as {{ type_string() }}) as package_name,\n    cast(null as {{ type_string() }}) as path,\n    cast(null as {{ type_string() }}) as checksum,\n    cast(null as {{ type_string() }}) as strategy,\n    cast(null as {{ type_json() }}) as meta,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_array", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/snapshots.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as string) as  database\n    ,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as depends_on_nodes,\n    cast(null as string) as package_name,\n    cast(null as string) as path,\n    cast(null as string) as checksum,\n    cast(null as string) as strategy,\n    cast(null as string) as meta,\n    cast(null as string) as alias,\n    cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.snapshot_executions": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "snapshot_executions", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/snapshot_executions.sql", "original_file_path": "models/sources/snapshot_executions.sql", "unique_id": "model.dbt_artifacts.snapshot_executions", "fqn": ["dbt_artifacts", "sources", "snapshot_executions"], "alias": "snapshot_executions", "checksum": {"name": "sha256", "checksum": "340e68f20c1e4a74dca5268b4f788ea72df5a329cd1bcfb2ccd200a4fec14620"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Base model for data about snapshot executions. One row per snapshot execution.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "was_full_refresh": {"name": "was_full_refresh", "description": "Boolean flag indicating whether the nodes run was a full refresh or not.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.was_full_refresh"]}, "thread_id": {"name": "thread_id", "description": "Which thread executed this node? E.g. Thread-1", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.thread_id"]}, "status": {"name": "status", "description": "Represents the execution status of a node, can be success, failure, or error.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.status"]}, "compile_started_at": {"name": "compile_started_at", "description": "Timestamp when the node started compiling.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.compile_started_at"]}, "query_completed_at": {"name": "query_completed_at", "description": "Timestamp when the node's SQL query completed.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.query_completed_at"]}, "total_node_runtime": {"name": "total_node_runtime", "description": "Total time spent executing this node (seconds).", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.total_node_runtime"]}, "rows_affected": {"name": "rows_affected", "description": "Number of rows affected by the model execution.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.rows_affected"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "message": {"name": "message", "description": "Result report, based on information returned from the database", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.message"]}, "adapter_response": {"name": "adapter_response", "description": "Response provided by the adapter as JSON.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.adapter_response"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/snapshot_executions.yml", "build_path": "target/run/dbt_artifacts/models/sources/snapshot_executions.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.700583, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`snapshot_executions`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_boolean() }}) as was_full_refresh,\n    cast(null as {{ type_string() }}) as thread_id,\n    cast(null as {{ type_string() }}) as status,\n    cast(null as {{ type_timestamp() }}) as compile_started_at,\n    cast(null as {{ type_timestamp() }}) as query_completed_at,\n    cast(null as {{ type_float() }}) as total_node_runtime,\n    cast(null as {{ type_int() }}) as rows_affected,\n    cast(null as {{ type_string() }}) as materialization,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_string() }}) as message,\n    cast(null as {{ type_json() }}) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_boolean", "macro.dbt.type_float", "macro.dbt.type_int", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/snapshot_executions.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as boolean) as was_full_refresh,\n    cast(null as string) as thread_id,\n    cast(null as string) as status,\n    cast(null as timestamp) as compile_started_at,\n    cast(null as timestamp) as query_completed_at,\n    cast(null as float) as total_node_runtime,\n    cast(null as integer) as rows_affected,\n    cast(null as string) as materialization,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as alias,\n    cast(null as string) as message,\n    cast(null as string) as adapter_response\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}, "model.dbt_artifacts.models": {"database": "dbt_project_catalog", "schema": "dbt_kisara", "name": "models", "resource_type": "model", "package_name": "dbt_artifacts", "path": "sources/models.sql", "original_file_path": "models/sources/models.sql", "unique_id": "model.dbt_artifacts.models", "fqn": ["dbt_artifacts", "sources", "models"], "alias": "models", "checksum": {"name": "sha256", "checksum": "4ac8ffcf615bf6a4677fb5b9ca69c67fbcc911093e9e13ca174385aaf715d39d"}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "group": null, "materialized": "incremental", "incremental_strategy": null, "batch_size": null, "lookback": 1, "begin": null, "persist_docs": {"columns": true, "relation": true}, "post-hook": [], "pre-hook": [], "quoting": {}, "column_types": {}, "full_refresh": false, "unique_key": null, "on_schema_change": "ignore", "on_configuration_change": "apply", "grants": {}, "packages": [], "docs": {"show": true, "node_color": null}, "contract": {"enforced": false, "alias_types": true}, "event_time": null, "concurrent_batches": null, "access": "protected", "freshness": null, "file_format": "", "as_columnstore": false}, "tags": [], "description": "Staging model that contains metadata about model executions. One row per node per run.", "columns": {"command_invocation_id": {"name": "command_invocation_id", "description": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.command_invocation_id"]}, "node_id": {"name": "node_id", "description": "Unique node identifier.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.node_id"]}, "run_started_at": {"name": "run_started_at", "description": "The start timestamp of the dbt execution which generated the record.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.run_started_at"]}, "database": {"name": "database", "description": "The configured database for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.database"]}, "schema": {"name": "schema", "description": "Configured schema for the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.schema"]}, "name": {"name": "name", "description": "Name of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.name"]}, "depends_on_nodes": {"name": "depends_on_nodes", "description": "Array of node identifiers that this node depends on in the execution graph.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.depends_on_nodes"]}, "package_name": {"name": "package_name", "description": "Name of the dbt package which contains the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.package_name"]}, "path": {"name": "path", "description": "Path to the model on the local filesystem.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.path"]}, "checksum": {"name": "checksum", "description": "Checksum of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.checksum"]}, "materialization": {"name": "materialization", "description": "The materialization of the model.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.materialization"]}, "tags": {"name": "tags", "description": "Tags used in resource selection associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.tags"]}, "meta": {"name": "meta", "description": "The meta field of the config associated with the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.meta"]}, "alias": {"name": "alias", "description": "Alias of the node.", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.alias"]}, "all_results": {"name": "all_results", "description": "All results as a JSON blob", "meta": {}, "data_type": null, "constraints": [], "quote": null, "config": {"meta": {}, "tags": []}, "tags": [], "granularity": null, "doc_blocks": ["doc.dbt_artifacts.all_results"]}}, "meta": {}, "group": null, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://models/sources/models.yml", "build_path": "target/run/dbt_artifacts/models/sources/models.sql", "unrendered_config": {"materialized": "incremental", "file_format": "{{ \"delta\" if target.name == \"databricks\" else \"\" }}", "full_refresh": false, "persist_docs": {"columns": "{{ target.name != \"databricks\" and target.type != \"sqlserver\" }}", "relation": "{{ target.type != \"sqlserver\" }}"}, "as_columnstore": false}, "created_at": 1760419970.6931765, "relation_name": "`dbt_project_catalog`.`dbt_kisara`.`models`", "raw_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as {{ type_string() }}) as command_invocation_id,\n    cast(null as {{ type_string() }}) as node_id,\n    cast(null as {{ type_timestamp() }}) as run_started_at,\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"database\"\n    {% else %} database\n    {% endif %},\n    cast(null as {{ type_string() }}) as {% if target.type == \"sqlserver\" %} \"schema\"\n    {% else %} schema\n    {% endif %},\n    cast(null as {{ type_string() }}) as name,\n    cast(null as {{ type_array() }}) as depends_on_nodes,\n    cast(null as {{ type_string() }}) as package_name,\n    cast(null as {{ type_string() }}) as path,\n    cast(null as {{ type_string() }}) as checksum,\n    cast(null as {{ type_string() }}) as materialization,\n    cast(null as {{ type_array() }}) as tags,\n    cast(null as {{ type_json() }}) as meta,\n    cast(null as {{ type_string() }}) as alias,\n    cast(null as {{ type_json() }}) as all_results\nfrom dummy_cte\nwhere 1 = 0", "doc_blocks": [], "language": "sql", "refs": [], "sources": [], "metrics": [], "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.type_timestamp", "macro.dbt_artifacts.type_array", "macro.dbt_artifacts.type_json"], "nodes": []}, "compiled_path": "target/compiled/dbt_artifacts/models/sources/models.sql", "compiled": true, "compiled_code": "/* Bigquery won't let us `where` without `from` so we use this workaround */\nwith dummy_cte as (select 1 as foo)\n\nselect\n    cast(null as string) as command_invocation_id,\n    cast(null as string) as node_id,\n    cast(null as timestamp) as run_started_at,\n    cast(null as string) as  database\n    ,\n    cast(null as string) as  schema\n    ,\n    cast(null as string) as name,\n    cast(null as string) as depends_on_nodes,\n    cast(null as string) as package_name,\n    cast(null as string) as path,\n    cast(null as string) as checksum,\n    cast(null as string) as materialization,\n    cast(null as string) as tags,\n    cast(null as string) as meta,\n    cast(null as string) as alias,\n    cast(null as string) as all_results\nfrom dummy_cte\nwhere 1 = 0", "extra_ctes_injected": true, "extra_ctes": [], "contract": {"enforced": false, "alias_types": true, "checksum": null}, "access": "protected", "constraints": [], "version": null, "latest_version": null, "deprecation_date": null, "primary_key": [], "time_spine": null}}, "sources": {"source.dbt_dbx.landing_s.orders": {"database": "dbt_project_catalog", "schema": "landing", "name": "orders", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.orders", "fqn": ["dbt_dbx", "landing_s", "orders"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "orders", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`orders`", "created_at": 1760419970.7451396, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.users": {"database": "dbt_project_catalog", "schema": "landing", "name": "users", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.users", "fqn": ["dbt_dbx", "landing_s", "users"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "users", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`users`", "created_at": 1760419970.746524, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.products": {"database": "dbt_project_catalog", "schema": "landing", "name": "products", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.products", "fqn": ["dbt_dbx", "landing_s", "products"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "products", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`products`", "created_at": 1760419970.7468917, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}, "source.dbt_dbx.landing_s.reviews": {"database": "dbt_project_catalog", "schema": "landing", "name": "reviews", "resource_type": "source", "package_name": "dbt_dbx", "path": "models/sources.yml", "original_file_path": "models/sources.yml", "unique_id": "source.dbt_dbx.landing_s.reviews", "fqn": ["dbt_dbx", "landing_s", "reviews"], "source_name": "landing_s", "source_description": "", "loader": "", "identifier": "reviews", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "loaded_at_query": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true, "event_time": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "patch_path": null, "unrendered_config": {"loaded_at_field": null, "loaded_at_query": null, "meta": {}, "tags": []}, "relation_name": "`dbt_project_catalog`.`landing`.`reviews`", "created_at": 1760419970.7472398, "unrendered_database": "dbt_project_catalog", "unrendered_schema": "landing", "doc_blocks": []}}, "macros": {"macro.dbt_databricks.databricks__comment_clause": {"name": "databricks__comment_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/comment.sql", "original_file_path": "macros/relations/comment.sql", "unique_id": "macro.dbt_databricks.databricks__comment_clause", "macro_sql": "{% macro databricks__comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation and model.description -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {%- endif -%}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6211545, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_intermediate_sql": {"name": "databricks__get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_intermediate_sql", "macro_sql": "{%- macro databricks__get_create_intermediate_sql(relation, sql) -%}\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    -- drop any pre-existing intermediate\n    {{ drop_relation(intermediate_relation) }}\n\n    {{ return(get_create_sql(intermediate_relation, sql)) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.drop_relation", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6218867, "supported_languages": null}, "macro.dbt_databricks.location_clause": {"name": "location_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/location.sql", "original_file_path": "macros/relations/location.sql", "unique_id": "macro.dbt_databricks.location_clause", "macro_sql": "{% macro location_clause(relation) %}\n  {#--\n    Moving forward, `relation` should be a `CatalogRelation`, which is covered by the first condition.\n    However, there could be existing macros that are still passing in a `BaseRelation`, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  --#}\n  {%- if relation.catalog_type is not none -%}\n\n    {%- if relation.location is not none -%}\n    location '{{ relation.location }}{% if is_incremental() %}_tmp{% endif %}'\n    {%- endif -%}\n\n  {%- else -%}\n\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n  {%- set model_path = adapter.compute_external_path(config, model, is_incremental()) %}\n    location '{{ model_path }}'\n  {%- elif (not relation.is_hive_metastore()) and file_format != 'delta' -%}\n    {{ exceptions.raise_compiler_error(\n        'Incompatible configuration: `location_root` must be set when using a non-delta file format with Unity Catalog'\n    ) }}\n  {%- endif %}\n\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6241474, "supported_languages": null}, "macro.dbt_databricks.create_backup": {"name": "create_backup", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt_databricks.create_backup", "macro_sql": "{%- macro create_backup(relation) -%}\n  -- get the standard backup name\n  {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n  -- drop any pre-existing backup\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ adapter.rename_relation(relation, backup_relation) }}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6248267, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_sql": {"name": "databricks__get_create_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_sql", "macro_sql": "{%- macro databricks__get_create_sql(relation, sql) -%}\n    {%- if relation.is_view -%}\n        {{ get_create_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_create_table_as_sql(False, relation, sql) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_create_materialized_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_streaming_table -%}\n        {{ get_create_streaming_table_as_sql(relation, sql) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_create_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.get_create_view_as_sql", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt_databricks.get_create_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6256597, "supported_languages": null}, "macro.dbt_databricks.file_format_clause": {"name": "file_format_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/file_format.sql", "original_file_path": "macros/relations/file_format.sql", "unique_id": "macro.dbt_databricks.file_format_clause", "macro_sql": "{% macro file_format_clause(catalog_relation=none) %}\n  {#--\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  --#}\n  {% if catalog_relation is not none %}\n    {%- set file_format = catalog_relation.file_format -%}\n  {% else %}\n    {%- set file_format = config.get('file_format', default='delta') -%}\n  {% endif %}\n  using {{ file_format }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6262865, "supported_languages": null}, "macro.dbt_databricks.get_file_format": {"name": "get_file_format", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/file_format.sql", "original_file_path": "macros/relations/file_format.sql", "unique_id": "macro.dbt_databricks.get_file_format", "macro_sql": "{% macro get_file_format(catalog_relation=none) %}\n  {#-\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n  -#}\n  {% if catalog_relation is not none %}\n    {%- set raw_file_format = catalog_relation.file_format -%}\n  {% else %}\n    {%- set raw_file_format = config.get('file_format', default='delta') -%}\n  {% endif %}\n  {% do return(dbt_databricks_validate_get_file_format(raw_file_format)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_validate_get_file_format"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.626752, "supported_languages": null}, "macro.dbt_databricks.optimize": {"name": "optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.optimize", "macro_sql": "{% macro optimize(relation) %}\n  {{ return(adapter.dispatch('optimize', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6273453, "supported_languages": null}, "macro.dbt_databricks.databricks__optimize": {"name": "databricks__optimize", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.databricks__optimize", "macro_sql": "\n\n{%- macro databricks__optimize(relation) -%}\n  {%- if var('DATABRICKS_SKIP_OPTIMIZE', 'false')|lower != 'true' and\n        var('databricks_skip_optimize', 'false')|lower != 'true' and\n        config.get('file_format', 'delta') == 'delta' -%}\n    {%- if (config.get('zorder', False) or config.get('liquid_clustered_by', False)) or config.get('auto_liquid_cluster', False) -%}\n      {%- call statement('run_optimize_stmt') -%}\n        {{ get_optimize_sql(relation) }}\n      {%- endcall -%}\n    {%- endif -%}\n  {%- endif -%}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_optimize_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6283112, "supported_languages": null}, "macro.dbt_databricks.get_optimize_sql": {"name": "get_optimize_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/optimize.sql", "original_file_path": "macros/relations/optimize.sql", "unique_id": "macro.dbt_databricks.get_optimize_sql", "macro_sql": "{%- macro get_optimize_sql(relation) %}\n  optimize {{ relation.render() }}\n  {%- if config.get('zorder', False) and config.get('file_format', 'delta') == 'delta' %}\n    {%- if config.get('liquid_clustered_by', False) or config.get('auto_liquid_cluster', False) %}\n      {{ exceptions.warn(\"Both zorder and liquid_clustering are set but they are incompatible. zorder will be ignored.\") }}\n    {%- else %}\n      {%- set zorder = config.get('zorder', none) %}\n      {# TODO: predicates here? WHERE ...  #}\n      {%- if zorder is sequence and zorder is not string %}\n        zorder by (\n        {%- for col in zorder %}\n        {{ col }}{% if not loop.last %}, {% endif %}\n        {%- endfor %}\n        )\n      {%- else %}\n        zorder by ({{zorder}})\n      {%- endif %}\n    {%- endif %}\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6293652, "supported_languages": null}, "macro.dbt_databricks.execute_no_op": {"name": "execute_no_op", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/execute.sql", "original_file_path": "macros/relations/execute.sql", "unique_id": "macro.dbt_databricks.execute_no_op", "macro_sql": "{% macro execute_no_op(target_relation) %}\n    {% do store_raw_result(\n        name=\"main\",\n        message=\"skip \" ~ target_relation,\n        code=\"skip\",\n        rows_affected=\"-1\"\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6299856, "supported_languages": null}, "macro.dbt_databricks.get_replace_sql": {"name": "get_replace_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.get_replace_sql", "macro_sql": "{% macro get_replace_sql(existing_relation, target_relation, sql) %}\n  {{- log('Applying REPLACE to: ' ~ existing_relation) -}}\n  {% do return(adapter.dispatch('get_replace_sql', 'dbt')(existing_relation, target_relation, sql)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6316733, "supported_languages": null}, "macro.dbt_databricks.databricks__get_replace_sql": {"name": "databricks__get_replace_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.databricks__get_replace_sql", "macro_sql": "{% macro databricks__get_replace_sql(existing_relation, target_relation, sql) %}\n  {# /* if safe_relation_replace, prefer renaming */ #}\n  {% if target_relation.type == \"table\" %}\n    {{ exceptions.raise_not_implemented('get_replace_sql not implemented for target of table') }}\n  {% endif %}\n\n  {% set safe_replace = config.get('use_safer_relation_operations', False) | as_bool  %}\n  {% set file_format = config.get('file_format', default='delta') %}\n  {% set is_replaceable = existing_relation.type == target_relation.type and existing_relation.can_be_replaced and file_format == \"delta\" %}\n\n  {% if not safe_replace %}\n    {# Prioritize 'create or replace' for speed #}\n    {% if is_replaceable and existing_relation.is_view %}\n      {{ return(get_replace_view_sql(target_relation, sql)) }}\n    {% elif is_replaceable and existing_relation.is_table %}\n      {{ return(get_replace_table_sql(target_relation, sql)) }}\n    {% endif %}\n  {% endif %}\n\n  {# If safe_replace, then we know that anything that would have been caught above is instead caught here #}\n  {% if target_relation.can_be_renamed and existing_relation.can_be_renamed %}\n    {{ return(safely_replace(existing_relation, target_relation, sql)) }}\n  {% elif target_relation.can_be_renamed %}\n    {{ return(stage_then_replace(existing_relation, target_relation, sql)) }}\n  {% elif existing_relation.can_be_renamed %}\n    {{ return(backup_and_create_in_place(existing_relation, target_relation, sql)) }}\n  {% else %}\n    {{ return(drop_and_create(existing_relation, target_relation, sql)) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_replace_view_sql", "macro.dbt.get_replace_table_sql", "macro.dbt_databricks.safely_replace", "macro.dbt_databricks.stage_then_replace", "macro.dbt_databricks.backup_and_create_in_place", "macro.dbt_databricks.drop_and_create"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6347444, "supported_languages": null}, "macro.dbt_databricks.safely_replace": {"name": "safely_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.safely_replace", "macro_sql": "{% macro safely_replace(existing_relation, target_relation, sql) %}\n  {{ log('Using safely_replace') }}\n  {% set staging_relation = make_staging_relation(target_relation, type='view') %}\n  {{ drop_relation_if_exists(staging_relation) }}\n  {% call statement(name=\"main\") %}\n    {{ get_create_sql(staging_relation, sql) }}\n  {% endcall %}\n  {{ create_backup(existing_relation) }}\n  {{ return([\n    get_rename_sql(staging_relation, existing_relation.render()),\n    get_drop_backup_sql(existing_relation)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.make_staging_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt_databricks.create_backup", "macro.dbt.get_rename_sql", "macro.dbt.get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6360784, "supported_languages": null}, "macro.dbt_databricks.stage_then_replace": {"name": "stage_then_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.stage_then_replace", "macro_sql": "{% macro stage_then_replace(existing_relation, target_relation, sql) %}\n  {{ log('Using stage_then_replace') }}\n  {% set staging_relation = make_staging_relation(target_relation, type='view') %}\n  {{ drop_relation_if_exists(staging_relation) }}\n  {% call statement(name=\"main\") %}\n    {{ get_create_sql(staging_relation, sql) }}\n  {% endcall %}\n\n  {{ return([\n    get_drop_sql(existing_relation),\n    get_rename_sql(staging_relation, existing_relation.render()),\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.make_staging_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt.get_drop_sql", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6373317, "supported_languages": null}, "macro.dbt_databricks.backup_and_create_in_place": {"name": "backup_and_create_in_place", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.backup_and_create_in_place", "macro_sql": "{% macro backup_and_create_in_place(existing_relation, target_relation, sql) %}\n  {{ log('Using backup_and_create_in_place') }}\n  {{ create_backup(existing_relation) }}\n  {{ return([\n    get_create_sql(target_relation, sql),\n    get_drop_backup_sql(existing_relation)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_backup", "macro.dbt.get_create_sql", "macro.dbt.get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6380625, "supported_languages": null}, "macro.dbt_databricks.drop_and_create": {"name": "drop_and_create", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt_databricks.drop_and_create", "macro_sql": "{% macro drop_and_create(existing_relation, target_relation, sql) %}\n  {{ log('Using drop_and_create') }}\n  {{ return([\n    get_drop_sql(existing_relation),\n    get_create_sql(target_relation, sql)\n  ]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.638634, "supported_languages": null}, "macro.dbt_databricks.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.643816, "supported_languages": null}, "macro.dbt_databricks.databricks__persist_constraints": {"name": "databricks__persist_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__persist_constraints", "macro_sql": "{% macro databricks__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% set has_model_contract = contract_config and contract_config.enforced %}\n  {% set has_databricks_constraints = config.get('persist_constraints', False) %}\n\n  {% if (has_model_contract or has_databricks_constraints) %}\n    {% if config.get('file_format', 'delta') != 'delta' %}\n      {# Constraints are only supported for delta tables #}\n      {{ exceptions.warn(\"Constraints not supported for file format: \" ~ config.get('file_format')) }}\n    {% elif relation.is_view %}\n      {# Constraints are not supported for views. This point in the code should not have been reached. #}\n      {{ exceptions.raise_compiler_error(\"Constraints not supported for views.\") }}\n    {% elif is_incremental() %}\n      {# Constraints are not applied for incremental updates. This point in the code should not have been reached #}\n      {{ exceptions.raise_compiler_error(\"Constraints are not applied for incremental updates. Full refresh is required to update constraints.\") }}\n    {% else %}\n      {% do alter_column_set_constraints(relation, model) %}\n      {% do alter_table_add_constraints(relation, model) %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt_databricks.alter_column_set_constraints", "macro.dbt_databricks.alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6451862, "supported_languages": null}, "macro.dbt_databricks.apply_alter_constraints": {"name": "apply_alter_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.apply_alter_constraints", "macro_sql": "{% macro apply_alter_constraints(relation) %}\n  {%- for constraint in relation.alter_constraints -%}\n    {% call statement('add constraint') %}\n      ALTER TABLE {{ relation.render() }} ADD {{ constraint.render() }}\n    {% endcall %}\n  {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6459339, "supported_languages": null}, "macro.dbt_databricks.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6463456, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_table_add_constraints": {"name": "databricks__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__alter_table_add_constraints", "macro_sql": "{% macro databricks__alter_table_add_constraints(relation, model) %}\n    {% set constraints = get_model_constraints(model) %}\n    {% set statements = get_constraints_sql(relation, constraints, model) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_model_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6468427, "supported_languages": null}, "macro.dbt_databricks.get_model_constraints": {"name": "get_model_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_model_constraints", "macro_sql": "{% macro get_model_constraints(model) %}\n  {% set constraints = model.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and model.get('meta', {}).get('constraints') is sequence %}\n    {# Databricks constraints implementation.  Constraints are in the meta property. #}\n    {% set db_constraints = model.get('meta', {}).get('constraints', []) %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6475728, "supported_languages": null}, "macro.dbt_databricks.get_column_constraints": {"name": "get_column_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_column_constraints", "macro_sql": "{% macro get_column_constraints(column) %}\n  {% set constraints = column.get('constraints', []) %}\n  {% if config.get('persist_constraints', False) and column.get('meta', {}).get('constraint') %}\n    {# Databricks constraints implementation.  Constraint is in the meta property. #}\n    {% set db_constraints = [column.get('meta', {}).get('constraint')] %}\n    {% set constraints = databricks_constraints_to_dbt(db_constraints, column) %}\n  {% endif %}\n  {{ return(constraints) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks_constraints_to_dbt"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6483362, "supported_languages": null}, "macro.dbt_databricks.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6486516, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_set_constraints": {"name": "databricks__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_set_constraints", "macro_sql": "{% macro databricks__alter_column_set_constraints(relation, model) %}\n  {% set column_dict = model.columns %}\n  {% for column_name in column_dict %}\n    {% set column = column_dict[column_name] %}\n    {% set constraints = get_column_constraints(column)  %}\n    {% set statements = get_constraints_sql(relation, constraints, model, column) %}\n    {% for stmt in statements %}\n      {% call statement() %}\n        {{ stmt }}\n      {% endcall %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_column_constraints", "macro.dbt_databricks.get_constraints_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6493273, "supported_languages": null}, "macro.dbt_databricks.get_constraints_sql": {"name": "get_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_constraints_sql", "macro_sql": "{% macro get_constraints_sql(relation, constraints, model, column={}) %}\n  {% set statements = [] %}\n  -- Hack so that not null constraints will be applied before other constraints\n  {% for constraint in constraints|selectattr('type', 'eq', 'not_null') %}\n    {% if constraint %}\n      {% set constraint_statements = get_constraint_sql(relation, constraint, model, column) %}\n      {% for statement in constraint_statements %}\n        {% if statement %}\n          {% do statements.append(statement) %}\n        {% endif %}\n      {% endfor %}\n    {% endif %}\n  {% endfor %}\n  {% for constraint in constraints|rejectattr('type', 'eq', 'not_null') %}\n    {% if constraint %}\n      {% set constraint_statements = get_constraint_sql(relation, constraint, model, column) %}\n      {% for statement in constraint_statements %}\n        {% if statement %}\n          {% do statements.append(statement) %}\n        {% endif %}\n      {% endfor %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_constraint_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6506324, "supported_languages": null}, "macro.dbt_databricks.get_constraint_sql": {"name": "get_constraint_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.get_constraint_sql", "macro_sql": "{% macro get_constraint_sql(relation, constraint, model, column={}) %}\n  {% set statements = [] %}\n  {% set type = constraint.get('type', '') %}\n\n  {% if type == 'check' %}\n    {% set expression = constraint.get('expression', '') %}\n    {% if not expression %}\n      {{ exceptions.raise_compiler_error('Invalid check constraint expression') }}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5 (relation.identifier ~ \";\" ~ column.get('name', '') ~ \";\" ~ expression ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" check (\" ~ expression ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'not_null' %}\n    {% set column_names = constraint.get('columns', []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if column %}\n        {% set quoted_name = api.Column.get_name(column) %}\n        {% set stmt = \"alter table \" ~ relation.render() ~ \" change column \" ~ quoted_name ~ \" set not null \" ~ (constraint.expression or \"\") ~ \";\" %}\n        {% do statements.append(stmt) %}\n      {% else %}\n        {{ exceptions.warn('not_null constraint on invalid column: ' ~ column_name) }}\n      {% endif %}\n    {% endfor %}\n  {% elif type == 'primary_key' %}\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ type)}}\n    {% endif %}\n    {% set column_names = constraint.get('columns', []) %}\n    {% if column and not column_names %}\n      {% set column_names = [column['name']] %}\n    {% endif %}\n    {% set quoted_names = [] %}\n    {% for column_name in column_names %}\n      {% set column = model.get('columns', {}).get(column_name) %}\n      {% if not column %}\n        {{ exceptions.warn('Invalid primary key column: ' ~ column_name) }}\n      {% else %}\n        {% set quoted_name = api.Column.get_name(column) %}\n        {% do quoted_names.append(quoted_name) %}\n      {% endif %}\n    {% endfor %}\n\n    {% set joined_names = quoted_names|join(\", \") %}\n\n    {% set name = constraint.get('name') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5(\"primary_key;\" ~ relation.identifier ~ \";\" ~ column_names ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" primary key(\" ~ joined_names ~ \");\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'foreign_key' %}\n\n    {% if constraint.get('warn_unenforced') %}\n      {{ exceptions.warn(\"unenforced constraint type: \" ~ constraint.type)}}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    \n    {% if constraint.get('expression') %}\n\n      {% if not name %}\n        {% if local_md5 %}\n          {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n          {%- set name = local_md5(\"foreign_key;\" ~ relation.identifier ~ \";\" ~ constraint.get('expression') ~ \";\") -%}\n        {% else %}\n          {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n        {% endif %}    \n      {% endif %}\n\n      {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" foreign key\" ~ constraint.get('expression') %}\n    {% else %}\n      {% set column_names = constraint.get('columns', []) %}\n      {% if column and not column_names %}\n        {% set column_names = [column['name']] %}\n      {% endif %}\n      {% set quoted_names = [] %}\n      {% for column_name in column_names %}\n        {% set column = model.get('columns', {}).get(column_name) %}\n        {% if not column %}\n          {{ exceptions.warn('Invalid foreign key column: ' ~ column_name) }}\n        {% else %}\n          {% set quoted_name = api.Column.get_name(column) %}\n          {% do quoted_names.append(quoted_name) %}\n        {% endif %}\n      {% endfor %}\n\n      {% set joined_names = quoted_names|join(\", \") %}\n\n      {% set parent = constraint.get('to') %}\n      {% if not parent %}\n        {{ exceptions.raise_compiler_error('No parent table defined for foreign key: ' ~ expression) }}\n      {% endif %}\n      {% if not \".\" in parent %}\n        {% set parent = relation.schema ~ \".\" ~ parent%}\n      {% endif %}\n\n      {% if not name %}\n        {% if local_md5 %}\n          {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n          {%- set name = local_md5(\"foreign_key;\" ~ relation.identifier ~ \";\" ~ column_names ~ \";\" ~ parent ~ \";\") -%}\n        {% else %}\n          {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n        {% endif %}    \n      {% endif %}\n\n      {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" foreign key(\" ~ joined_names ~ \") references \" ~ parent %}\n      {% set parent_columns = constraint.get('to_columns') %}\n      {% if parent_columns %}\n        {% set stmt = stmt ~ \"(\" ~ parent_columns|join(\", \") ~ \")\"%}\n      {% endif %}\n    {% endif %}\n    {% set stmt = stmt ~ \";\" %}\n    {% do statements.append(stmt) %}\n  {% elif type == 'custom' %}\n    {% set expression = constraint.get('expression', '') %}\n    {% if not expression %}\n      {{ exceptions.raise_compiler_error('Missing custom constraint expression') }}\n    {% endif %}\n\n    {% set name = constraint.get('name') %}\n    {% set expression = constraint.get('expression') %}\n    {% if not name %}\n      {% if local_md5 %}\n        {{ exceptions.warn(\"Constraint of type \" ~ type ~ \" with no `name` provided. Generating hash instead for relation \" ~ relation.identifier) }}\n        {%- set name = local_md5 (relation.identifier ~ \";\" ~ expression ~ \";\") -%}\n      {% else %}\n        {{ exceptions.raise_compiler_error(\"Constraint of type \" ~ type ~ \" with no `name` provided, and no md5 utility.\") }}\n      {% endif %}\n    {% endif %}\n    {% set stmt = \"alter table \" ~ relation.render() ~ \" add constraint \" ~ name ~ \" \" ~ expression ~ \";\" %}\n    {% do statements.append(stmt) %}\n  {% elif constraint.get('warn_unsupported') %}\n    {{ exceptions.warn(\"unsupported constraint type: \" ~ constraint.type)}}\n  {% endif %}\n\n  {{ return(statements) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.660289, "supported_languages": null}, "macro.dbt_databricks.databricks_constraints_to_dbt": {"name": "databricks_constraints_to_dbt", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/constraints.sql", "original_file_path": "macros/relations/constraints.sql", "unique_id": "macro.dbt_databricks.databricks_constraints_to_dbt", "macro_sql": "{% macro databricks_constraints_to_dbt(constraints, column) %}\n  {# convert constraints defined using the original databricks format #}\n  {% set dbt_constraints = [] %}\n  {% for constraint in constraints %}\n    {% if constraint.get and constraint.get('type') %}\n      {# already in model contract format #}\n      {% do dbt_constraints.append(constraint) %}\n    {% else %}\n      {% if column %}\n        {% if constraint == \"not_null\" %}\n          {% do dbt_constraints.append({\"type\": \"not_null\", \"columns\": [column.get('name')]}) %}\n        {% else %}\n          {{ exceptions.raise_compiler_error('Invalid constraint for column ' ~ column.get('name', \"\") ~ '. Only `not_null` is supported.') }}\n        {% endif %}\n      {% else %}\n        {% set name = constraint['name'] %}\n        {% if not name %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint name') }}\n        {% endif %}\n        {% set condition = constraint['condition'] %}\n        {% if not condition %}\n          {{ exceptions.raise_compiler_error('Invalid check constraint condition') }}\n        {% endif %}\n        {% do dbt_constraints.append({\"name\": name, \"type\": \"check\", \"expression\": condition}) %}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(dbt_constraints) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6622155, "supported_languages": null}, "macro.dbt_databricks.databricks__get_drop_sql": {"name": "databricks__get_drop_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt_databricks.databricks__get_drop_sql", "macro_sql": "{% macro databricks__get_drop_sql(relation) -%}\n    {%- if relation.is_materialized_view -%}\n        {{ drop_materialized_view(relation) }}\n    {%- elif relation.is_streaming_table-%}\n        {{ drop_streaming_table(relation) }}\n    {%- elif relation.is_view -%}\n        {{ drop_view(relation) }}\n    {%- else -%}\n        {{ drop_table(relation) }}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.drop_materialized_view", "macro.dbt_databricks.drop_streaming_table", "macro.dbt.drop_view", "macro.dbt.drop_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.662863, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_relation": {"name": "databricks__drop_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_relation", "macro_sql": "{% macro databricks__drop_relation(relation) -%}\n    {% call statement('drop_relation', auto_begin=False) -%}\n        {{ get_drop_sql(relation) }}\n    {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6631277, "supported_languages": null}, "macro.dbt_databricks.tblproperties_clause": {"name": "tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.tblproperties_clause", "macro_sql": "{% macro tblproperties_clause() -%}\n  {{ return(adapter.dispatch('tblproperties_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6635334, "supported_languages": null}, "macro.dbt_databricks.databricks__tblproperties_clause": {"name": "databricks__tblproperties_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.databricks__tblproperties_clause", "macro_sql": "{% macro databricks__tblproperties_clause(tblproperties=None) -%}\n  {%- set tblproperties = adapter.update_tblproperties_for_iceberg(config, tblproperties) -%}\n  {%- if tblproperties != {} %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6640654, "supported_languages": null}, "macro.dbt_databricks.apply_tblproperties": {"name": "apply_tblproperties", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tblproperties.sql", "original_file_path": "macros/relations/tblproperties.sql", "unique_id": "macro.dbt_databricks.apply_tblproperties", "macro_sql": "{% macro apply_tblproperties(relation, tblproperties) -%}\n  {% set tblproperty_statment = databricks__tblproperties_clause(tblproperties) %}\n  {% if tblproperty_statment %}\n    {%- call statement('main') -%}\n      ALTER {{ relation.type }} {{ relation.render() }} SET {{ tblproperty_statment}}\n    {%- endcall -%}\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6645384, "supported_languages": null}, "macro.dbt_databricks.liquid_clustered_cols": {"name": "liquid_clustered_cols", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/liquid_clustering.sql", "original_file_path": "macros/relations/liquid_clustering.sql", "unique_id": "macro.dbt_databricks.liquid_clustered_cols", "macro_sql": "{% macro liquid_clustered_cols() -%}\n  {%- set cols = config.get('liquid_clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set auto_cluster = config.get('auto_liquid_cluster', validator=validation.any[boolean]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    CLUSTER BY ({{ cols | join(', ') }})\n    {%- elif auto_cluster -%}\n    CLUSTER BY AUTO\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6654844, "supported_languages": null}, "macro.dbt_databricks.apply_liquid_clustered_cols": {"name": "apply_liquid_clustered_cols", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/liquid_clustering.sql", "original_file_path": "macros/relations/liquid_clustering.sql", "unique_id": "macro.dbt_databricks.apply_liquid_clustered_cols", "macro_sql": "{% macro apply_liquid_clustered_cols(target_relation, liquid_clustering) -%}\n  {%- set cols = liquid_clustering.cluster_by -%}\n  {%- set auto_cluster = liquid_clustering.auto_cluster -%}\n  {%- if cols and cols != [] %}\n    {%- call statement('set_cluster_by_columns') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY ({{ cols | join(', ') }})\n    {%- endcall -%}\n  {%- elif auto_cluster -%}\n    {%- call statement('set_cluster_by_auto') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY AUTO\n    {%- endcall -%}\n  {% else %}\n    {%- call statement('unset_cluster_by') -%}\n      ALTER {{ target_relation.type }} {{ target_relation.render() }} CLUSTER BY NONE\n    {%- endcall -%}\n  {%- endif %}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.666369, "supported_languages": null}, "macro.dbt_databricks.fetch_tags": {"name": "fetch_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.fetch_tags", "macro_sql": "{% macro fetch_tags(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {% call statement('list_tags', fetch_result=True) -%}\n    {{ fetch_tags_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_tags').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_tags_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6671188, "supported_languages": null}, "macro.dbt_databricks.fetch_tags_sql": {"name": "fetch_tags_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.fetch_tags_sql", "macro_sql": "{% macro fetch_tags_sql(relation) -%}\n  SELECT tag_name, tag_value\n  FROM `system`.`information_schema`.`table_tags`\n  WHERE catalog_name = '{{ relation.database|lower }}' \n    AND schema_name = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6674278, "supported_languages": null}, "macro.dbt_databricks.apply_tags": {"name": "apply_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.apply_tags", "macro_sql": "{% macro apply_tags(relation, set_tags) -%}\n  {{ log(\"Applying tags to relation \" ~ set_tags) }}\n  {%- if set_tags and relation.is_hive_metastore() -%}\n    {{ exceptions.raise_compiler_error(\"Tags are only supported for Unity Catalog\") }}\n  {%- endif -%}\n  {%- if set_tags %}\n    {%- call statement('main') -%}\n       {{ alter_set_tags(relation, set_tags) }}\n    {%- endcall -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_set_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6679597, "supported_languages": null}, "macro.dbt_databricks.alter_set_tags": {"name": "alter_set_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/tags.sql", "original_file_path": "macros/relations/tags.sql", "unique_id": "macro.dbt_databricks.alter_set_tags", "macro_sql": "{% macro alter_set_tags(relation, tags) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} SET TAGS (\n    {% for tag in tags -%}\n      '{{ tag }}' = '{{ tags[tag] }}' {%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  )\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6683779, "supported_languages": null}, "macro.dbt_databricks.get_configuration_changes": {"name": "get_configuration_changes", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/config.sql", "original_file_path": "macros/relations/config.sql", "unique_id": "macro.dbt_databricks.get_configuration_changes", "macro_sql": "{%- macro get_configuration_changes(existing_relation) -%}\n    {%- set existing_config = adapter.get_relation_config(existing_relation) -%}\n    {%- set model_config = adapter.get_config_from_model(config.model) -%}\n    {%- set configuration_changes = model_config.get_changeset(existing_config) -%}\n    {% do return(configuration_changes) %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6688352, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_partition_by": {"name": "get_create_sql_partition_by", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/partitioning.sql", "original_file_path": "macros/relations/components/partitioning.sql", "unique_id": "macro.dbt_databricks.get_create_sql_partition_by", "macro_sql": "{% macro get_create_sql_partition_by(partition_by) -%}\n{%- if partition_by -%}\n  PARTITIONED BY ({%- for col in partition_by -%}{{ col }}{% if not loop.last %}, {% endif %}{%- endfor %})\n{%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6692224, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_comment": {"name": "get_create_sql_comment", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/comment.sql", "original_file_path": "macros/relations/components/comment.sql", "unique_id": "macro.dbt_databricks.get_create_sql_comment", "macro_sql": "{%- macro get_create_sql_comment(comment) -%}\n{% if comment is string -%}\n  COMMENT '{{ comment }}'\n{%- endif -%}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6694782, "supported_languages": null}, "macro.dbt_databricks.fetch_column_tags": {"name": "fetch_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.fetch_column_tags", "macro_sql": "{% macro fetch_column_tags(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {% call statement('list_column_tags', fetch_result=True) -%}\n    {{ fetch_column_tags_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_column_tags').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_column_tags_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6703873, "supported_languages": null}, "macro.dbt_databricks.fetch_column_tags_sql": {"name": "fetch_column_tags_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.fetch_column_tags_sql", "macro_sql": "{% macro fetch_column_tags_sql(relation) -%}\n  SELECT \n    column_name,\n    tag_name,\n    tag_value\n  FROM `system`.`information_schema`.`column_tags`\n  WHERE catalog_name = '{{ relation.database|lower }}'\n    AND schema_name = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6706405, "supported_languages": null}, "macro.dbt_databricks.apply_column_tags": {"name": "apply_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.apply_column_tags", "macro_sql": "{% macro apply_column_tags(relation, column_tags) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column tags are only supported for Unity Catalog\") }}\n  {%- endif %}\n  {{ log(\"Applying column tags to relation \" ~ relation) }}\n  {%- if column_tags.set_column_tags %}\n    {%- for column, tags in column_tags.set_column_tags.items() -%}\n      {%- call statement('main') -%}\n        {{ alter_set_column_tags(relation, column, tags) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_set_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6712627, "supported_languages": null}, "macro.dbt_databricks.alter_set_column_tags": {"name": "alter_set_column_tags", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.alter_set_column_tags", "macro_sql": "{% macro alter_set_column_tags(relation, column, tags) -%}\n  {# ALTER VIEW does not support setting column tags, but ALTER TABLE works for views #}\n  {%- if relation.type == 'view' -%}\n    ALTER TABLE {{ relation.render() }}\n  {%- else -%}\n    ALTER {{ relation.type | replace('_', ' ') }} {{ relation.render() }}\n  {%- endif -%}\n  ALTER COLUMN `{{ column }}`\n  SET TAGS (\n    {%- for tag_name, tag_value in tags.items() -%}\n      '{{ tag_name }}' = '{{ tag_value }}'{%- if not loop.last %}, {% endif -%}\n    {%- endfor -%}\n  )\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6719587, "supported_languages": null}, "macro.dbt_databricks.column_tags_exist": {"name": "column_tags_exist", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_tags.sql", "original_file_path": "macros/relations/components/column_tags.sql", "unique_id": "macro.dbt_databricks.column_tags_exist", "macro_sql": "{% macro column_tags_exist() %}\n  {% for column_name, column in model.columns.items() %}\n    {% if column is mapping and column.get('databricks_tags') %}\n      {{ return(true) }}\n    {% endif %}\n  {% endfor %}\n  {{ return(false) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.672414, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_refresh_schedule": {"name": "get_create_sql_refresh_schedule", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/refresh_schedule.sql", "original_file_path": "macros/relations/components/refresh_schedule.sql", "unique_id": "macro.dbt_databricks.get_create_sql_refresh_schedule", "macro_sql": "{% macro get_create_sql_refresh_schedule(cron, time_zone_value) %}\n  {%- if cron -%}\n    SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6728694, "supported_languages": null}, "macro.dbt_databricks.get_alter_sql_refresh_schedule": {"name": "get_alter_sql_refresh_schedule", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/refresh_schedule.sql", "original_file_path": "macros/relations/components/refresh_schedule.sql", "unique_id": "macro.dbt_databricks.get_alter_sql_refresh_schedule", "macro_sql": "{% macro get_alter_sql_refresh_schedule(cron, time_zone_value, is_altered) %}\n  {%- if cron -%}\n    {%- if is_altered -%}\n      ALTER SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n    {%- else -%}\n      ADD SCHEDULE CRON '{{ cron }}'{%- if time_zone_value %} AT TIME ZONE '{{ time_zone_value }}'{%- endif -%}\n    {%- endif -%}\n  {%- else -%}\n    DROP SCHEDULE\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6733341, "supported_languages": null}, "macro.dbt_databricks.alter_query": {"name": "alter_query", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/query.sql", "original_file_path": "macros/relations/components/query.sql", "unique_id": "macro.dbt_databricks.alter_query", "macro_sql": "{% macro alter_query(target_relation, query) %}\n  {{ log(\"Altering query\") }}\n  {% if query %}\n    {% call statement('main') %}\n      {{- get_alter_query_sql(target_relation, query) }}\n    {% endcall %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_alter_query_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.673817, "supported_languages": null}, "macro.dbt_databricks.get_alter_query_sql": {"name": "get_alter_query_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/query.sql", "original_file_path": "macros/relations/components/query.sql", "unique_id": "macro.dbt_databricks.get_alter_query_sql", "macro_sql": "{% macro get_alter_query_sql(target_relation, query) -%}\n  ALTER {{ target_relation.type|upper }} {{ target_relation.render() }} AS (\n    {{ query }}\n  )\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6740878, "supported_languages": null}, "macro.dbt_databricks.fetch_column_masks": {"name": "fetch_column_masks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.fetch_column_masks", "macro_sql": "{% macro fetch_column_masks(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column masks are not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_column_masks', fetch_result=True) -%}\n    {{ fetch_column_masks_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_column_masks').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_column_masks_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6749766, "supported_languages": null}, "macro.dbt_databricks.fetch_column_masks_sql": {"name": "fetch_column_masks_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.fetch_column_masks_sql", "macro_sql": "{% macro fetch_column_masks_sql(relation) -%}\n  SELECT \n    column_name,\n    mask_name,\n    using_columns\n  FROM `system`.`information_schema`.`column_masks`\n  WHERE table_catalog = '{{ relation.database|lower }}'\n    AND table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6752322, "supported_languages": null}, "macro.dbt_databricks.apply_column_masks": {"name": "apply_column_masks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.apply_column_masks", "macro_sql": "{% macro apply_column_masks(relation, column_masks) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Column masks are not supported for Hive Metastore\") }}\n  {%- endif %}\n  {{ log(\"Applying column masks to relation \" ~ relation) }}\n  {%- if column_masks.unset_column_masks %}\n    {%- for column in column_masks.unset_column_masks -%}\n      {%- call statement('main') -%}\n        {{ alter_drop_column_mask(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if column_masks.set_column_masks %}\n    {%- for column, mask in column_masks.set_column_masks.items() -%}\n      {%- call statement('main') -%}\n        {{ alter_set_column_mask(relation, column, mask) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_drop_column_mask", "macro.dbt_databricks.alter_set_column_mask"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.676115, "supported_languages": null}, "macro.dbt_databricks.alter_drop_column_mask": {"name": "alter_drop_column_mask", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.alter_drop_column_mask", "macro_sql": "{% macro alter_drop_column_mask(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }}\n  ALTER COLUMN `{{ column }}`\n  DROP MASK;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6763396, "supported_languages": null}, "macro.dbt_databricks.alter_set_column_mask": {"name": "alter_set_column_mask", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.alter_set_column_mask", "macro_sql": "{% macro alter_set_column_mask(relation, column, mask) -%}\n  ALTER {{ relation.type }} {{ relation.render() }}\n  ALTER COLUMN `{{ column }}`\n  SET MASK {{ mask.function }}\n  {%- if mask.using_columns %}\n  USING COLUMNS ({{ mask.using_columns }})\n  {%- endif %};\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.676706, "supported_languages": null}, "macro.dbt_databricks.column_mask_exists": {"name": "column_mask_exists", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/column_mask.sql", "original_file_path": "macros/relations/components/column_mask.sql", "unique_id": "macro.dbt_databricks.column_mask_exists", "macro_sql": "{% macro column_mask_exists() %}\n  {% for column_name, column in model.columns.items() %}\n    {% if column is mapping and column.get('column_mask') %}\n      {{ return(true) }}\n    {% endif %}\n  {% endfor %}\n  {{ return(false) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6772819, "supported_languages": null}, "macro.dbt_databricks.fetch_non_null_constraint_columns": {"name": "fetch_non_null_constraint_columns", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_non_null_constraint_columns", "macro_sql": "{% macro fetch_non_null_constraint_columns(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_non_null_constraint_columns', fetch_result=True) -%}\n    {{ fetch_non_null_constraint_columns_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_non_null_constraint_columns').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_non_null_constraint_columns_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6787682, "supported_languages": null}, "macro.dbt_databricks.fetch_non_null_constraint_columns_sql": {"name": "fetch_non_null_constraint_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_non_null_constraint_columns_sql", "macro_sql": "{% macro fetch_non_null_constraint_columns_sql(relation) -%}\n  SELECT column_name\n  FROM `{{ relation.database|lower }}`.`information_schema`.`columns`\n  WHERE table_catalog = '{{ relation.database|lower }}' \n    AND table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n    AND is_nullable = 'NO';\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6790624, "supported_languages": null}, "macro.dbt_databricks.fetch_primary_key_constraints": {"name": "fetch_primary_key_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_primary_key_constraints", "macro_sql": "{% macro fetch_primary_key_constraints(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_primary_key_constraints', fetch_result=True) -%}\n    {{ fetch_primary_key_constraints_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_primary_key_constraints').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_primary_key_constraints_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6795206, "supported_languages": null}, "macro.dbt_databricks.fetch_primary_key_constraints_sql": {"name": "fetch_primary_key_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_primary_key_constraints_sql", "macro_sql": "{% macro fetch_primary_key_constraints_sql(relation) -%}\n  SELECT kcu.constraint_name, kcu.column_name\n  FROM `{{ relation.database|lower }}`.information_schema.key_column_usage kcu\n  WHERE kcu.table_catalog = '{{ relation.database|lower }}' \n    AND kcu.table_schema = '{{ relation.schema|lower }}'\n    AND kcu.table_name = '{{ relation.identifier|lower }}' \n    AND kcu.constraint_name = (\n      SELECT constraint_name\n      FROM `{{ relation.database|lower }}`.information_schema.table_constraints\n      WHERE table_catalog = '{{ relation.database|lower }}'\n        AND table_schema = '{{ relation.schema|lower }}'\n        AND table_name = '{{ relation.identifier|lower }}' \n        AND constraint_type = 'PRIMARY KEY'\n    )\n  ORDER BY kcu.ordinal_position;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6800241, "supported_languages": null}, "macro.dbt_databricks.fetch_foreign_key_constraints": {"name": "fetch_foreign_key_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_foreign_key_constraints", "macro_sql": "{% macro fetch_foreign_key_constraints(relation) -%}\n  {% if relation.is_hive_metastore() %}\n    {{ exceptions.raise_compiler_error(\"Incremental application of constraints is not supported for Hive Metastore\") }}\n  {%- endif %}\n  {% call statement('list_foreign_key_constraints', fetch_result=True) -%}\n    {{ fetch_foreign_key_constraints_sql(relation) }}\n  {% endcall %}\n  {% do return(load_result('list_foreign_key_constraints').table) %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.fetch_foreign_key_constraints_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6805353, "supported_languages": null}, "macro.dbt_databricks.fetch_foreign_key_constraints_sql": {"name": "fetch_foreign_key_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.fetch_foreign_key_constraints_sql", "macro_sql": "{% macro fetch_foreign_key_constraints_sql(relation) -%}\n  SELECT\n    kcu.constraint_name,\n    kcu.column_name AS from_column,\n    ukcu.table_catalog AS to_catalog,\n    ukcu.table_schema AS to_schema,\n    ukcu.table_name AS to_table,\n    ukcu.column_name AS to_column\n  FROM `{{ relation.database|lower }}`.information_schema.key_column_usage kcu\n  JOIN `{{ relation.database|lower }}`.information_schema.referential_constraints rc\n    ON kcu.constraint_name = rc.constraint_name\n  JOIN `{{ relation.database|lower }}`.information_schema.key_column_usage ukcu\n    ON rc.unique_constraint_name = ukcu.constraint_name\n    AND kcu.ordinal_position = ukcu.ordinal_position\n  WHERE kcu.table_catalog = '{{ relation.database|lower }}'\n    AND kcu.table_schema = '{{ relation.schema|lower }}'\n    AND kcu.table_name = '{{ relation.identifier|lower }}'\n    AND kcu.constraint_name IN (\n      SELECT constraint_name\n      FROM `{{ relation.database|lower }}`.information_schema.table_constraints\n      WHERE table_catalog = '{{ relation.database|lower }}'\n        AND table_schema = '{{ relation.schema|lower }}'\n        AND table_name = '{{ relation.identifier|lower }}'\n        AND constraint_type = 'FOREIGN KEY'\n    )\n  ORDER BY kcu.ordinal_position;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6810985, "supported_languages": null}, "macro.dbt_databricks.apply_constraints": {"name": "apply_constraints", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.apply_constraints", "macro_sql": "{% macro apply_constraints(relation, constraints) -%}\n  {{ log(\"Applying constraints to relation \" ~ constraints) }}\n  {%- if constraints and relation.is_hive_metastore() -%}\n    {{ exceptions.raise_compiler_error(\"Constraints are only supported for Unity Catalog\") }}\n  {%- endif -%}\n  {# Order matters here because key constraints depend on non-null constraints #} \n  {%- if constraints.unset_constraints %}\n    {%- for constraint in constraints.unset_constraints -%}\n      {%- call statement('main') -%}\n        {{ alter_unset_constraint(relation, constraint) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.unset_non_nulls %}\n    {%- for column in constraints.unset_non_nulls -%}\n      {%- call statement('main') -%}\n        {{ alter_unset_non_null_constraint(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.set_non_nulls %}\n    {%- for column in constraints.set_non_nulls -%}\n      {%- call statement('main') -%}\n        {{ alter_set_non_null_constraint(relation, column) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n  {%- if constraints.set_constraints %}\n    {%- for constraint in constraints.set_constraints -%}\n      {%- call statement('main') -%}\n        {{ alter_set_constraint(relation, constraint) }}\n      {%- endcall -%}\n    {%- endfor -%}\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.alter_unset_constraint", "macro.dbt_databricks.alter_unset_non_null_constraint", "macro.dbt_databricks.alter_set_non_null_constraint", "macro.dbt_databricks.alter_set_constraint"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6825025, "supported_languages": null}, "macro.dbt_databricks.alter_set_non_null_constraint": {"name": "alter_set_non_null_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_set_non_null_constraint", "macro_sql": "{% macro alter_set_non_null_constraint(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ALTER COLUMN {{ column }} SET NOT NULL;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6827312, "supported_languages": null}, "macro.dbt_databricks.alter_unset_non_null_constraint": {"name": "alter_unset_non_null_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_unset_non_null_constraint", "macro_sql": "{% macro alter_unset_non_null_constraint(relation, column) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ALTER COLUMN {{ column }} DROP NOT NULL;\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6829517, "supported_languages": null}, "macro.dbt_databricks.alter_set_constraint": {"name": "alter_set_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_set_constraint", "macro_sql": "{% macro alter_set_constraint(relation, constraint) -%}\n  ALTER {{ relation.type }} {{ relation.render() }} ADD {{ constraint.render() }};\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6831813, "supported_languages": null}, "macro.dbt_databricks.alter_unset_constraint": {"name": "alter_unset_constraint", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/constraints.sql", "original_file_path": "macros/relations/components/constraints.sql", "unique_id": "macro.dbt_databricks.alter_unset_constraint", "macro_sql": "{% macro alter_unset_constraint(relation, constraint) -%}\n  {% set constraint_type = constraint.type %}\n  {% if constraint_type == 'primary_key' %}\n    {# Need to only add CASCADE to PK constraints because dropping check constraints break when adding CASCADE #}\n    ALTER {{ relation.type }} {{ relation.render() }} DROP CONSTRAINT {{ constraint.name }} CASCADE;\n  {% else %}\n    ALTER {{ relation.type }} {{ relation.render() }} DROP CONSTRAINT IF EXISTS {{ constraint.name }};\n  {% endif %}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6836746, "supported_languages": null}, "macro.dbt_databricks.get_create_sql_tblproperties": {"name": "get_create_sql_tblproperties", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/components/tblproperties.sql", "original_file_path": "macros/relations/components/tblproperties.sql", "unique_id": "macro.dbt_databricks.get_create_sql_tblproperties", "macro_sql": "{% macro get_create_sql_tblproperties(tblproperties) %}\n  {{ databricks__tblproperties_clause(tblproperties)}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6839204, "supported_languages": null}, "macro.dbt_databricks.apply_config_changeset": {"name": "apply_config_changeset", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/alter.sql", "original_file_path": "macros/relations/table/alter.sql", "unique_id": "macro.dbt_databricks.apply_config_changeset", "macro_sql": "{% macro apply_config_changeset(target_relation, model, configuration_changes) %}\n    {{ log(\"Applying configuration changes to relation \" ~ target_relation) }}\n    {% if configuration_changes %}\n      {% set comment = configuration_changes.changes.get(\"comment\") %}\n      {% set column_comments = configuration_changes.changes.get(\"column_comments\") %}\n      {% set column_tags = configuration_changes.changes.get(\"column_tags\") %}\n      {% set tags = configuration_changes.changes.get(\"tags\") %}\n      {% set tblproperties = configuration_changes.changes.get(\"tblproperties\") %}\n      {% set liquid_clustering = configuration_changes.changes.get(\"liquid_clustering\")%}\n      {% set constraints = configuration_changes.changes.get(\"constraints\") %}\n      {% set column_masks = configuration_changes.changes.get(\"column_masks\") %}\n      {% if tags is not none %}\n        {% do apply_tags(target_relation, tags.set_tags) %}\n      {%- endif -%}\n      {% if tblproperties is not none %}\n        {% do apply_tblproperties(target_relation, tblproperties.tblproperties) %}\n      {%- endif -%}\n      {% if liquid_clustering is not none %}\n        {% do apply_liquid_clustered_cols(target_relation, liquid_clustering) %}\n      {%- endif -%}\n      {% if comment %}\n        {{ run_query_as(alter_relation_comment_sql(target_relation, comment.comment), 'alter_relation_comment', fetch_result=False) }}\n      {% endif %}\n      {% if column_comments %}\n        {{ alter_column_comments(target_relation, column_comments.comments) }}\n      {% endif %}\n      {% if column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n      {% endif %}\n      {% if constraints %}\n        {{ apply_constraints(target_relation, constraints) }}\n      {% endif %}\n      {% if column_masks %}\n        {{ apply_column_masks(target_relation, column_masks) }}\n      {% endif %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.apply_liquid_clustered_cols", "macro.dbt_databricks.run_query_as", "macro.dbt_databricks.alter_relation_comment_sql", "macro.dbt_databricks.alter_column_comments", "macro.dbt_databricks.apply_column_tags", "macro.dbt_databricks.apply_constraints", "macro.dbt_databricks.apply_column_masks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.68636, "supported_languages": null}, "macro.dbt_databricks.databricks__get_rename_table_sql": {"name": "databricks__get_rename_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt_databricks.databricks__get_rename_table_sql", "macro_sql": "{% macro databricks__get_rename_table_sql(relation, new_name) %}\n  ALTER TABLE {{ relation.render() }} RENAME TO `{{ new_name }}`\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6866117, "supported_languages": null}, "macro.dbt_databricks.create_table_at": {"name": "create_table_at", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.create_table_at", "macro_sql": "{% macro create_table_at(relation, intermediate_relation, compiled_code) %}\n  {% set tags = config.get('databricks_tags') %}\n  {% set model_columns = model.get('columns', []) %}\n  {% set existing_columns = adapter.get_columns_in_relation(intermediate_relation) %}\n  {% set model_constraints = model.get('constraints', []) %}\n  {% set columns_and_constraints = adapter.parse_columns_and_constraints(existing_columns, model_columns, model_constraints) %}\n  {% set target_relation = relation.enrich(columns_and_constraints[1]) %}\n  \n  {% call statement('main') %}\n    {{ get_create_table_sql(target_relation, columns_and_constraints[0], compiled_code) }}\n  {% endcall %}\n\n  {{ apply_alter_constraints(target_relation) }}\n  {{ apply_tags(target_relation, tags) }}\n  {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n  {% if column_tags and column_tags.set_column_tags %}\n    {{ apply_column_tags(target_relation, column_tags) }}\n  {% endif %}\n\n  {% call statement('merge into target') %}\n    insert into {{ target_relation }} select * from {{ intermediate_relation }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_create_table_sql", "macro.dbt_databricks.apply_alter_constraints", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6888702, "supported_languages": null}, "macro.dbt_databricks.get_create_table_sql": {"name": "get_create_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.get_create_table_sql", "macro_sql": "{% macro get_create_table_sql(target_relation, columns, compiled_code) %}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- set contract = config.get('contract') -%}\n  {%- set contract_enforced = contract and contract.enforced -%}\n  {%- if contract_enforced -%}\n    {{ get_assert_columns_equivalent(compiled_code) }}\n  {%- endif -%}\n\n  {%- if catalog_relation.file_format == 'delta' %}\n  create or replace table {{ target_relation.render() }}\n  {% else %}\n  create table {{ target_relation.render() }}\n  {% endif -%}\n  {{ get_column_and_constraints_sql(target_relation, columns) }}\n  {{ file_format_clause(catalog_relation) }}\n  {{ databricks__options_clause(catalog_relation) }}\n  {{ partition_cols(label=\"partitioned by\") }}\n  {{ liquid_clustered_cols() }}\n  {{ clustered_cols(label=\"clustered by\") }}\n  {{ location_clause(catalog_relation) }}\n  {{ comment_clause() }}\n  {{ tblproperties_clause() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.file_format_clause", "macro.dbt_databricks.databricks__options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_databricks.liquid_clustered_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6899583, "supported_languages": null}, "macro.dbt_databricks.databricks__create_table_as": {"name": "databricks__create_table_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.databricks__create_table_as", "macro_sql": "{% macro databricks__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if catalog_relation.file_format == 'delta' %}\n        create or replace table {{ relation.render() }}\n      {% else %}\n        create table {{ relation.render() }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {% if contract_config and contract_config.enforced %}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause(catalog_relation) }}\n      {{ databricks__options_clause(catalog_relation) }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ liquid_clustered_cols() }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause(catalog_relation) }}\n      {{ comment_clause() }}\n      {{ tblproperties_clause() }}\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ databricks__py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_databricks.file_format_clause", "macro.dbt_databricks.databricks__options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_databricks.liquid_clustered_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt_databricks.databricks__py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6913438, "supported_languages": null}, "macro.dbt_databricks.databricks__options_clause": {"name": "databricks__options_clause", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.databricks__options_clause", "macro_sql": "{% macro databricks__options_clause(catalog_relation=none) -%}\n  {#-\n    Moving forward, this macro should require a `catalog_relation`, which is covered by the first condition.\n    However, there could be existing macros that is still passing no arguments, including user macros.\n    Hence, we need to support the old code still, which is covered by the second condition.\n    Additionally, since this rolls up to `options_clause` in `dbt-spark`, which does not have any arguments,\n    all calls to `options_clause` will take the second path. This macro needs to be called directly\n    via `databricks__options_clause`.\n  -#}\n  {%- if catalog_relation is not none -%}\n    {%- set file_format = catalog_relation.file_format -%}\n  {%- else -%}\n    {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- endif -%}\n\n  {%- set options = config.get('options') -%}\n  {%- if file_format == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6929214, "supported_languages": null}, "macro.dbt_databricks.get_create_intermediate_table": {"name": "get_create_intermediate_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt_databricks.get_create_intermediate_table", "macro_sql": "{% macro get_create_intermediate_table(relation, compiled_code, language) %}\n  {%- if language == 'sql' -%}\n    {{ create_temporary_view(relation, compiled_code) }}\n  {%- else -%}\n    {{ create_python_intermediate_table(relation, compiled_code) }}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.create_python_intermediate_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6932623, "supported_languages": null}, "macro.dbt_databricks.safe_relation_replace": {"name": "safe_relation_replace", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt_databricks.safe_relation_replace", "macro_sql": "{% macro safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) %}\n  \n  {{ create_table_at(staging_relation, intermediate_relation, compiled_code) }}\n\n  {{ create_backup(existing_relation) }}\n\n  {{ adapter.rename_relation(staging_relation, existing_relation) }}\n\n  {% call statement('main') %}\n    {{ get_drop_backup_sql(existing_relation) }}\n  {% endcall %}\n  \n  {{ adapter.cache_dropped(make_backup_relation(existing_relation, existing_relation.type)) }}\n\n  {{ drop_relation_if_exists(intermediate_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_table_at", "macro.dbt_databricks.create_backup", "macro.dbt.statement", "macro.dbt.get_drop_backup_sql", "macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.694009, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_table": {"name": "databricks__drop_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_table", "macro_sql": "{% macro databricks__drop_table(relation) -%}\n    drop table if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.694207, "supported_languages": null}, "macro.dbt_databricks.alter_view": {"name": "alter_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/alter.sql", "original_file_path": "macros/relations/view/alter.sql", "unique_id": "macro.dbt_databricks.alter_view", "macro_sql": "{% macro alter_view(target_relation, changes) %}\n  {{ log(\"Updating view via ALTER\") }}\n  {{ adapter.dispatch('alter_view', 'dbt')(target_relation, changes) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.694679, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_view": {"name": "databricks__alter_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/alter.sql", "original_file_path": "macros/relations/view/alter.sql", "unique_id": "macro.dbt_databricks.databricks__alter_view", "macro_sql": "{% macro databricks__alter_view(target_relation, changes) %}\n  {% set tags = changes.get(\"tags\") %}\n  {% set tblproperties = changes.get(\"tblproperties\") %}\n  {% set query = changes.get(\"query\") %}\n  {% set column_comments = changes.get(\"column_comments\") %}\n  {% if tags %}\n    {{ apply_tags(target_relation, tags.set_tags) }}\n  {% endif %}\n  {% if tblproperties %}\n    {{ apply_tblproperties(target_relation, tblproperties.tblproperties) }}\n  {% endif %}\n  {% if query %}\n    {{ alter_query(target_relation, query.query) }}\n  {% endif %}\n  {% if column_comments %}\n    {{ alter_column_comments(target_relation, column_comments.comments) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.alter_query", "macro.dbt_databricks.alter_column_comments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.695612, "supported_languages": null}, "macro.dbt_databricks.databricks__get_rename_view_sql": {"name": "databricks__get_rename_view_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt_databricks.databricks__get_rename_view_sql", "macro_sql": "{% macro databricks__get_rename_view_sql(relation, new_name) %}\n  ALTER VIEW {{ relation.render() }} RENAME TO {{ new_name }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.695878, "supported_languages": null}, "macro.dbt_databricks.databricks__create_view_as": {"name": "databricks__create_view_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.databricks__create_view_as", "macro_sql": "{% macro databricks__create_view_as(relation, sql) %}\n  {% if column_mask_exists() %}\n    {% do exceptions.raise_compiler_error(\"Column masks are not supported for views.\") %}\n  {% endif %}\n  {{ log(\"Creating view \" ~ relation) }}\n  create or replace view {{ relation.render() }}\n  {%- if config.persist_column_docs() -%}\n    {%- set model_columns = model.columns -%}\n    {%- set query_columns = get_columns_in_query(sql) -%}\n    {%- if query_columns %}\n  (\n    {{ get_persist_docs_column_list(model_columns, query_columns) }}\n  )\n    {%- endif -%}\n  {%- endif %}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {%- if contract_config and contract_config.enforced %}\n  {{ get_assert_columns_equivalent(sql) }}\n  {%- endif -%}\n  {{ tblproperties_clause() }}\n  as (\n    {{ sql }}\n  )\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.column_mask_exists", "macro.dbt.get_columns_in_query", "macro.dbt_databricks.get_persist_docs_column_list", "macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent", "macro.dbt_databricks.tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6971393, "supported_languages": null}, "macro.dbt_databricks.get_column_comment_sql": {"name": "get_column_comment_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.get_column_comment_sql", "macro_sql": "{% macro get_column_comment_sql(column_name, column_dict) -%}\n  {%- if column_name in column_dict and column_dict[column_name][\"description\"] -%}\n    {%- set escaped_description = column_dict[column_name][\"description\"] | replace(\"'\", \"\\\\'\") -%}\n    {%- set column_comment_clause = \"comment '\" ~ escaped_description ~ \"'\" -%}\n    {{ adapter.quote(column_name) }} {{ column_comment_clause }}\n  {%- else -%}\n    {{ adapter.quote(column_name) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6977801, "supported_languages": null}, "macro.dbt_databricks.get_persist_docs_column_list": {"name": "get_persist_docs_column_list", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt_databricks.get_persist_docs_column_list", "macro_sql": "{% macro get_persist_docs_column_list(model_columns, query_columns) -%}\n  {%- for column_name in query_columns -%}\n    {{ get_column_comment_sql(column_name, model_columns) }}{{\",\\n\\t\" if not loop.last else \"\" }}\n  {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_column_comment_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6980982, "supported_languages": null}, "macro.dbt_databricks.databricks__get_replace_view_sql": {"name": "databricks__get_replace_view_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt_databricks.databricks__get_replace_view_sql", "macro_sql": "{% macro databricks__get_replace_view_sql(target_relation, sql) %}\n  {{ create_view_as(target_relation, sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6983252, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_view": {"name": "databricks__drop_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_view", "macro_sql": "{% macro databricks__drop_view(relation) -%}\n  DROP VIEW IF EXISTS {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.698523, "supported_languages": null}, "macro.dbt_databricks.get_alter_materialized_view_as_sql": {"name": "get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_materialized_view_as_sql", "macro_sql": "{% macro get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {%- do return(adapter.dispatch('get_alter_materialized_view_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    )) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6991262, "supported_languages": null}, "macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql": {"name": "databricks__get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql", "macro_sql": "{% macro databricks__get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    -- apply a full refresh immediately if needed\n    {% if configuration_changes.requires_full_refresh %}\n        {% do return(get_replace_sql(existing_relation, relation,  sql)) %}\n\n    -- otherwise apply individual changes as needed\n    {% else %}\n        {% do return(get_alter_mv_internal(relation, configuration_changes)) %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_alter_mv_internal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.6995814, "supported_languages": null}, "macro.dbt_databricks.get_alter_mv_internal": {"name": "get_alter_mv_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_mv_internal", "macro_sql": "{% macro get_alter_mv_internal(relation, configuration_changes) %}\n    {%- set refresh = configuration_changes.changes[\"refresh\"] -%}\n    -- Currently only schedule can be altered\n    ALTER MATERIALIZED VIEW {{ relation.render() }}\n        {{ get_alter_sql_refresh_schedule(refresh.cron, refresh.time_zone_value, refresh.is_altered) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_alter_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.699953, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_materialized_view_as_sql": {"name": "databricks__get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_materialized_view_as_sql", "macro_sql": "{% macro databricks__get_create_materialized_view_as_sql(relation, sql) -%}\n  {# Column masks are supported in DBSQL, but not yet wired up to the adapter. Return a helpful error until supported. #}\n  {% if column_mask_exists() %}\n    {% do exceptions.raise_compiler_error(\"Column masks are not yet supported for materialized views.\") %}\n  {% endif %}\n  {%- set materialized_view = adapter.get_config_from_model(config.model) -%}\n  {%- set partition_by = materialized_view.config[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = materialized_view.config[\"tblproperties\"].tblproperties -%}\n  {%- set comment = materialized_view.config[\"comment\"].comment -%}\n  {%- set refresh = materialized_view.config[\"refresh\"] -%}\n\n  {#\n    TODO: When DESCRIBE QUERY EXTENDED is supported, this implementation should be simplified\n    to use that instead. For now, we work around this limitation by writing results to a\n    temporary view and using DESCRIBE TABLE EXTENDED on the temporary view.\n  #}\n  {%- set temp_relation = make_temp_relation(relation) -%}\n  {% call statement('create_temp_view') -%}\n    {%- set sql_with_limit = sql.rstrip('; \\n\\t') ~ ' LIMIT 10' -%}\n    {{ create_temporary_view(temp_relation, sql_with_limit) }}\n  {%- endcall %}\n\n  {%- set columns = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set model_columns = model.get('columns', {}) -%}\n  {%- set model_constraints = model.get('constraints', []) -%}\n  {%- set columns_and_constraints = adapter.parse_columns_and_constraints(columns, model_columns, model_constraints) -%}\n  {%- set target_relation = relation.enrich(columns_and_constraints[1]) -%}\n\n  create materialized view {{ target_relation.render() }}\n    {{ get_column_and_constraints_sql(target_relation, columns_and_constraints[0]) }}\n    {{ get_create_sql_partition_by(partition_by) }}\n    {{ get_create_sql_comment(comment) }}\n    {{ get_create_sql_tblproperties(tblproperties) }}\n    {{ get_create_sql_refresh_schedule(refresh.cron, refresh.time_zone_value) }}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.column_mask_exists", "macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties", "macro.dbt_databricks.get_create_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7020836, "supported_languages": null}, "macro.dbt_databricks.databricks__refresh_materialized_view": {"name": "databricks__refresh_materialized_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt_databricks.databricks__refresh_materialized_view", "macro_sql": "{% macro databricks__refresh_materialized_view(relation) -%}\n  refresh materialized view {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7023053, "supported_languages": null}, "macro.dbt_databricks.databricks__drop_materialized_view": {"name": "databricks__drop_materialized_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt_databricks.databricks__drop_materialized_view", "macro_sql": "{% macro databricks__drop_materialized_view(relation) -%}\n    drop materialized view if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7025146, "supported_languages": null}, "macro.dbt_databricks.get_alter_streaming_table_as_sql": {"name": "get_alter_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_streaming_table_as_sql", "macro_sql": "{% macro get_alter_streaming_table_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {%- do return(adapter.dispatch('get_alter_streaming_table_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    )) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7032814, "supported_languages": null}, "macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql": {"name": "databricks__get_alter_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.databricks__get_alter_streaming_table_as_sql", "macro_sql": "{% macro databricks__get_alter_streaming_table_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    -- apply a full refresh immediately if needed\n    {% if configuration_changes.requires_full_refresh %}\n        {% do return(get_replace_sql(existing_relation, relation,  sql)) %}\n\n    -- otherwise apply individual changes as needed\n    {% else %}\n        {%- set alter_statement = get_alter_st_internal(relation, configuration_changes) -%}\n        {%- set create_statement = get_create_st_internal(relation, configuration_changes, sql) -%}\n        {%- set return_statements = [] -%}\n        {%- if create_statement -%}\n            {{ return_statements.append(create_statement) }}\n        {%- endif -%}\n        {%- if alter_statement -%}\n            {{ return_statements.append(alter_statement) }}\n        {%- endif -%}\n        {% do return(return_statements) %}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_alter_st_internal", "macro.dbt_databricks.get_create_st_internal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.704142, "supported_languages": null}, "macro.dbt_databricks.get_create_st_internal": {"name": "get_create_st_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_create_st_internal", "macro_sql": "{% macro get_create_st_internal(relation, configuration_changes, sql) %}\n  {%- set partition_by = configuration_changes.changes[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = configuration_changes.changes[\"tblproperties\"].tblproperties -%}\n  {%- set comment = configuration_changes.changes[\"comment\"].comment -%}\n  CREATE OR REFRESH STREAMING TABLE {{ relation.render() }}\n    {% if partition_by -%}\n        {{ get_create_sql_partition_by(partition_by) }}\n    {%- endif %}\n    {% if comment -%}\n        {{ get_create_sql_comment(comment) }}\n    {%- endif %}\n    {% if tblproperties -%}\n        {{ get_create_sql_tblproperties(tblproperties) }}\n    {%- endif %}\n    AS {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7049036, "supported_languages": null}, "macro.dbt_databricks.get_alter_st_internal": {"name": "get_alter_st_internal", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/alter.sql", "original_file_path": "macros/relations/streaming_table/alter.sql", "unique_id": "macro.dbt_databricks.get_alter_st_internal", "macro_sql": "{% macro get_alter_st_internal(relation, configuration_changes) %}\n  {%- set refresh = configuration_changes.changes[\"refresh\"] -%}\n  {%- if refresh and refresh.cron -%}\n    ALTER STREAMING TABLE {{ relation.render() }}\n        {{ get_alter_sql_refresh_schedule(refresh.cron, refresh.time_zone_value, False) -}}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_alter_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7053547, "supported_languages": null}, "macro.dbt_databricks.get_create_streaming_table_as_sql": {"name": "get_create_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/create.sql", "original_file_path": "macros/relations/streaming_table/create.sql", "unique_id": "macro.dbt_databricks.get_create_streaming_table_as_sql", "macro_sql": "{% macro get_create_streaming_table_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_streaming_table_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7059023, "supported_languages": null}, "macro.dbt_databricks.databricks__get_create_streaming_table_as_sql": {"name": "databricks__get_create_streaming_table_as_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/create.sql", "original_file_path": "macros/relations/streaming_table/create.sql", "unique_id": "macro.dbt_databricks.databricks__get_create_streaming_table_as_sql", "macro_sql": "{% macro databricks__get_create_streaming_table_as_sql(relation, sql) -%}\n  {%- set streaming_table = adapter.get_config_from_model(config.model) -%}\n  {%- set partition_by = streaming_table.config[\"partition_by\"].partition_by -%}\n  {%- set tblproperties = streaming_table.config[\"tblproperties\"].tblproperties -%}\n  {%- set comment = streaming_table.config[\"comment\"].comment -%}\n  {%- set refresh = streaming_table.config[\"refresh\"] -%}\n\n  {%- set analysis_sql = sql | replace('STREAM ', '') | replace('stream ', '') -%}\n\n  {#\n    TODO: When DESCRIBE QUERY EXTENDED is supported, this implementation should be simplified\n    to use that instead. For now, we work around this limitation by writing results to a\n    temporary view and using DESCRIBE TABLE EXTENDED on the temporary view.\n  #}\n  {%- set temp_relation = make_temp_relation(relation) -%}\n  {% call statement('create_temp_view') -%}\n    {%- set sql_with_limit = analysis_sql.rstrip('; \\n\\t') ~ ' LIMIT 10' -%}\n    {{ create_temporary_view(temp_relation, sql_with_limit) }}\n  {%- endcall %}\n\n  {%- set columns = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set model_columns = model.get('columns', {}) -%}\n  {%- set columns_and_constraints = adapter.parse_columns_and_constraints(columns, model_columns, []) -%}\n\n  {#-- We don't enrich the relation with model constraints because they are not supported for streaming tables --#}\n  CREATE STREAMING TABLE {{ relation.render() }}\n    {{ get_column_and_constraints_sql(relation, columns_and_constraints[0]) }}\n    {{ get_create_sql_partition_by(partition_by) }}\n    {{ get_create_sql_comment(comment) }}\n    {{ get_create_sql_tblproperties(tblproperties) }}\n    {{ get_create_sql_refresh_schedule(refresh.cron, refresh.time_zone_value) }}\n    AS {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt_spark.create_temporary_view", "macro.dbt_databricks.get_column_and_constraints_sql", "macro.dbt_databricks.get_create_sql_partition_by", "macro.dbt_databricks.get_create_sql_comment", "macro.dbt_databricks.get_create_sql_tblproperties", "macro.dbt_databricks.get_create_sql_refresh_schedule"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7081466, "supported_languages": null}, "macro.dbt_databricks.refresh_streaming_table": {"name": "refresh_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/refresh.sql", "original_file_path": "macros/relations/streaming_table/refresh.sql", "unique_id": "macro.dbt_databricks.refresh_streaming_table", "macro_sql": "{% macro refresh_streaming_table(relation, sql) -%}\n  {{ adapter.dispatch('refresh_streaming_table', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__refresh_streaming_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7085268, "supported_languages": null}, "macro.dbt_databricks.databricks__refresh_streaming_table": {"name": "databricks__refresh_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/refresh.sql", "original_file_path": "macros/relations/streaming_table/refresh.sql", "unique_id": "macro.dbt_databricks.databricks__refresh_streaming_table", "macro_sql": "{% macro databricks__refresh_streaming_table(relation, sql) -%}\n  create or refresh streaming table {{ relation.render() }}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.708718, "supported_languages": null}, "macro.dbt_databricks.drop_streaming_table": {"name": "drop_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/drop.sql", "original_file_path": "macros/relations/streaming_table/drop.sql", "unique_id": "macro.dbt_databricks.drop_streaming_table", "macro_sql": "{% macro drop_streaming_table(relation) -%}\n    {{ return(adapter.dispatch('drop_streaming_table', 'dbt')(relation)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.default__drop_streaming_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7089899, "supported_languages": null}, "macro.dbt_databricks.default__drop_streaming_table": {"name": "default__drop_streaming_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/relations/streaming_table/drop.sql", "original_file_path": "macros/relations/streaming_table/drop.sql", "unique_id": "macro.dbt_databricks.default__drop_streaming_table", "macro_sql": "{% macro default__drop_streaming_table(relation) -%}\n    drop table if exists {{ relation.render() }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7091286, "supported_languages": null}, "macro.dbt_databricks.databricks__datediff": {"name": "databricks__datediff", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_databricks.databricks__datediff", "macro_sql": "{% macro databricks__datediff(first_date, second_date, datepart) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampdiff({{datepart}}, {{date_trunc(datepart, first_date)}}, {{date_trunc(datepart, second_date)}})\n  {%- else -%}\n    {{ spark__datediff(first_date, second_date, datepart) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.date_trunc", "macro.dbt_spark.spark__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7096288, "supported_languages": null}, "macro.dbt_databricks.databricks__dateadd": {"name": "databricks__dateadd", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_databricks.databricks__dateadd", "macro_sql": "{% macro databricks__dateadd(datepart, interval, from_date_or_timestamp) %}\n  {%- if adapter.compare_dbr_version(10, 4) >= 0 -%}\n    timestampadd({{datepart}}, {{interval}}, {{from_date_or_timestamp}})\n  {%- else -%}\n    {{ spark__dateadd(datepart, interval, from_date_or_timestamp) }}\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7100852, "supported_languages": null}, "macro.dbt_databricks.databricks__split_part": {"name": "databricks__split_part", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt_databricks.databricks__split_part", "macro_sql": "{% macro databricks__split_part(string_text, delimiter_text, part_number) %}\n\n    {% set delimiter_expr %}\n\n        -- escape if starts with a special character\n        case when regexp_extract({{ delimiter_text }}, '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', {{ delimiter_text }})\n            else {{ delimiter_text }} end\n\n    {% endset %}\n\n    {% if part_number >= 0 %}\n\n        {% set split_part_expr %}\n\n        get(split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            ), {{ part_number - 1 if part_number > 0 else part_number }})\n\n        {% endset %}\n\n    {% else %}\n\n        {% set split_part_expr %}\n\n        get(split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            ), \n                length({{ string_text }})\n                - length(\n                    replace({{ string_text }},  {{ delimiter_text }}, '')\n                ) + 1 + {{ part_number }}\n            )\n\n        {% endset %}\n\n    {% endif %}\n\n    {{ return(split_part_expr) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7110307, "supported_languages": null}, "macro.dbt_databricks.statement_with_staging_table": {"name": "statement_with_staging_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.statement_with_staging_table", "macro_sql": "{% macro statement_with_staging_table(name=None, staging_table=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set res, table = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result, staging_table=staging_table) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.712084, "supported_languages": null}, "macro.dbt_databricks.execute_multiple_statements": {"name": "execute_multiple_statements", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.execute_multiple_statements", "macro_sql": "{% macro execute_multiple_statements(statements) %}\n  {%- if statements is string %}\n    {% call statement(name=\"main\") %}\n      {{ statements }}\n    {% endcall %}\n  {%- else %}\n    {%- for sql in statements %}\n      {% call statement(name=\"main\") %}\n        {{ sql }}\n      {% endcall %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7125475, "supported_languages": null}, "macro.dbt_databricks.run_query_as": {"name": "run_query_as", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt_databricks.run_query_as", "macro_sql": "{% macro run_query_as(sql, name, fetch_result=True) %}\n  {% call statement(name, fetch_result, auto_begin=False) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% if fetch_result %}\n    {{ return(load_result(name).table) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7129755, "supported_languages": null}, "macro.dbt_databricks.databricks__generate_database_name": {"name": "databricks__generate_database_name", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt_databricks.databricks__generate_database_name", "macro_sql": "{% macro databricks__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n        {{ return(default_database) }}\n    {%- else -%}\n        {{ return(custom_database_name) }}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7134006, "supported_languages": null}, "macro.dbt_databricks.materialization_view_databricks": {"name": "materialization_view_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.materialization_view_databricks", "macro_sql": "{% materialization view, adapter='databricks' -%}\n  {{ log(\"MATERIALIZING VIEW\") }}\n  {%- set existing_relation = load_relation_with_metadata(this) -%}\n  {%- set target_relation = this.incorporate(type='view') -%}\n  {% set grant_config = config.get('grants') %}\n  {% set tags = config.get('databricks_tags') %}\n  {% set sql = adapter.clean_sql(sql) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ run_pre_hooks() }}\n    {% if existing_relation %}\n      {% if relation_should_be_altered(existing_relation) %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n        {% if configuration_changes and configuration_changes.changes %}\n          {% if configuration_changes.requires_full_refresh %}\n            {{ log('Using replace_with_view') }}\n            {{ replace_with_view(existing_relation, target_relation) }}\n          {% else %}\n            {{ log('Using alter_view') }}\n            {{ log(configuration_changes.changes) }}\n            {{ alter_view(target_relation, configuration_changes.changes) }}\n          {% endif %}\n        {% else %}\n          {{ execute_no_op(target_relation) }}\n        {% endif %}\n      {% else %}\n        {{ replace_with_view(existing_relation, target_relation) }}\n      {% endif %}\n    {% else %}\n      {% call statement('main') -%}\n        {{ get_create_view_as_sql(target_relation, sql) }}\n      {%- endcall %}\n      {{ apply_tags(target_relation, tags) }}\n      {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n      {% if column_tags and column_tags.set_column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n      {% endif %}\n    {% endif %}\n    {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=True) %}\n\n    {{ run_post_hooks() }}\n\n  {% else %}\n    {{ run_hooks(pre_hooks) }}\n\n    -- If there's a table with the same name and we weren't told to full refresh,\n    -- that's an error. If we were told to full refresh, drop it. This behavior differs\n    -- for Snowflake and BigQuery, so multiple dispatch is used.\n    {%- if existing_relation is not none and not existing_relation.is_view -%}\n      {{ handle_existing_table(should_full_refresh(), existing_relation) }}\n    {%- endif -%}\n\n    -- build model\n    {% call statement('main') -%}\n      {{ get_create_view_as_sql(target_relation, sql) }}\n    {%- endcall %}\n\n    {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=True) %}\n\n    {%- do apply_tags(target_relation, tags) -%}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags and column_tags.set_column_tags %}\n      {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.load_relation_with_metadata", "macro.dbt_databricks.run_pre_hooks", "macro.dbt_databricks.relation_should_be_altered", "macro.dbt_databricks.get_configuration_changes", "macro.dbt_databricks.replace_with_view", "macro.dbt_databricks.alter_view", "macro.dbt_databricks.execute_no_op", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.run_post_hooks", "macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.716875, "supported_languages": ["sql"]}, "macro.dbt_databricks.replace_with_view": {"name": "replace_with_view", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.replace_with_view", "macro_sql": "{% macro replace_with_view(existing_relation, target_relation) %}\n  {% set sql = adapter.clean_sql(sql) %}\n  {% set tags = config.get('databricks_tags') %}\n  {{ execute_multiple_statements(get_replace_sql(existing_relation, target_relation, sql)) }}\n  {%- do apply_tags(target_relation, tags) -%}\n  \n  {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n  {% if column_tags and column_tags.set_column_tags %}\n    {{ apply_column_tags(target_relation, column_tags) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.execute_multiple_statements", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7176085, "supported_languages": null}, "macro.dbt_databricks.relation_should_be_altered": {"name": "relation_should_be_altered", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_databricks.relation_should_be_altered", "macro_sql": "{% macro relation_should_be_altered(existing_relation) %}\n  {% set update_via_alter = config.get('view_update_via_alter', False) | as_bool %}\n  {% if existing_relation.is_view and update_via_alter %}\n    {% if existing_relation.is_hive_metastore() %}\n      {{ exceptions.raise_compiler_error(\"Cannot update a view in the Hive metastore via ALTER VIEW. Please set `view_update_via_alter: false` in your model configuration.\") }}\n    {% endif %}\n    {{ return(True) }}\n  {% endif %}\n  {{ return(False) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7181282, "supported_languages": null}, "macro.dbt_databricks.materialization_streaming_table_databricks": {"name": "materialization_streaming_table_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.materialization_streaming_table_databricks", "macro_sql": "{% materialization streaming_table, adapter='databricks' %}\n  {% set existing_relation = load_cached_relation(this) %}\n  {% set target_relation = this.incorporate(type=this.StreamingTable) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n{% set build_sql = streaming_table_get_build_sql(existing_relation, target_relation) %}\n\n    {% if build_sql == '' %}\n        {{ execute_no_op(target_relation) }}\n    {% else %}\n        {{ streaming_table_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.run_hooks", "macro.dbt_databricks.streaming_table_get_build_sql", "macro.dbt_databricks.execute_no_op", "macro.dbt_databricks.streaming_table_execute_build_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7193325, "supported_languages": ["sql"]}, "macro.dbt_databricks.streaming_table_get_build_sql": {"name": "streaming_table_get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.streaming_table_get_build_sql", "macro_sql": "{% macro streaming_table_get_build_sql(existing_relation, target_relation) %}\n    {% set sql = adapter.clean_sql(sql) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_streaming_table_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_streaming_table %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_streaming_table(target_relation, sql) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_streaming_table_as_sql(target_relation, configuration_changes, sql, existing_relation, None, None) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = \"\" %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt_databricks.get_create_streaming_table_as_sql", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_configuration_changes", "macro.dbt_databricks.refresh_streaming_table", "macro.dbt_databricks.get_alter_streaming_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7208235, "supported_languages": null}, "macro.dbt_databricks.streaming_table_execute_build_sql": {"name": "streaming_table_execute_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/streaming_table.sql", "original_file_path": "macros/materializations/streaming_table.sql", "unique_id": "macro.dbt_databricks.streaming_table_execute_build_sql", "macro_sql": "{% macro streaming_table_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {{ execute_multiple_statements(build_sql) }}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags and column_tags.set_column_tags %}\n        {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt_databricks.execute_multiple_statements", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.apply_column_tags"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7215858, "supported_languages": null}, "macro.dbt_databricks.materialization_table_databricks": {"name": "materialization_table_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_databricks.materialization_table_databricks", "macro_sql": "{% materialization table, adapter = 'databricks', supported_languages=['sql', 'python'] %}\n  {{ log(\"MATERIALIZING TABLE\") }}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- set tags = config.get('databricks_tags') -%}\n  {%- set safe_create = config.get('use_safer_relation_operations', False) %}\n  {% set existing_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) %}\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set compiled_code = adapter.clean_sql(compiled_code) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set staging_relation = make_staging_relation(target_relation) %}\n\n    {{ run_pre_hooks() }}\n    \n    {% call statement('main', language=language) %}\n      {{ get_create_intermediate_table(intermediate_relation, compiled_code, language) }}\n    {% endcall %}\n    {% if not existing_relation %}\n      {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n    {% else %}\n      {% if safe_create and existing_relation.can_be_renamed %}\n        {{ safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) }}\n      {% else %}\n        {% if existing_relation and (existing_relation.type != 'table' or not (existing_relation.can_be_replaced and config.get('file_format', default='delta') == 'delta')) -%}\n          {{ adapter.drop_relation(existing_relation) }}\n        {%- endif %}\n        {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n      {% endif %}\n    {% endif %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {{ apply_grants(target_relation, grant_config, should_revoke) }}\n\n    {% if language == 'python' %}\n      {{ drop_relation_if_exists(intermediate_relation) }}\n    {% endif %}\n    \n    {{ run_post_hooks() }}\n  {% else %}\n    {{ run_hooks(pre_hooks) }}\n    -- setup: if the target relation already exists, drop it\n    -- in case if the existing and future table is delta, we want to do a\n    -- create or replace table instead of dropping, so we don't have the table unavailable\n    {% if existing_relation and (existing_relation.type != 'table' or not (existing_relation.can_be_replaced and config.get('file_format', default='delta') == 'delta')) -%}\n      {{ adapter.drop_relation(existing_relation) }}\n    {%- endif %}\n\n    -- build model\n\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% if language==\"python\" %}\n      {% do apply_tblproperties(target_relation, tblproperties) %}\n    {% endif %}\n    {%- do apply_tags(target_relation, tags) -%}\n\n    {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n\n    {% do persist_constraints(target_relation, model) %}\n\n    {% do optimize(target_relation) %}\n\n    {{ run_hooks(post_hooks) }}\n\n  {% endif %}\n  {{ return({'relations': [target_relation]})}}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt_databricks.make_staging_relation", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.statement", "macro.dbt_databricks.get_create_intermediate_table", "macro.dbt_databricks.create_table_at", "macro.dbt_databricks.safe_relation_replace", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.drop_relation_if_exists", "macro.dbt_databricks.run_post_hooks", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_databricks.apply_tblproperties", "macro.dbt_databricks.apply_tags", "macro.dbt.persist_docs", "macro.dbt_databricks.persist_constraints", "macro.dbt_databricks.optimize"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7261631, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.materialization_materialized_view_databricks": {"name": "materialization_materialized_view_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialization_materialized_view_databricks", "macro_sql": "{% materialization materialized_view, adapter = 'databricks' %}\n    {% set existing_relation = load_cached_relation(this) %}\n    {% set target_relation = this.incorporate(type=this.MaterializedView) %}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    {% set build_sql = materialized_view_get_build_sql(existing_relation, target_relation) %}\n\n    {% if build_sql == '' %}\n        {{ execute_no_op(target_relation) }}\n    {% else %}\n        {{ materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.run_hooks", "macro.dbt_databricks.materialized_view_get_build_sql", "macro.dbt_databricks.execute_no_op", "macro.dbt_databricks.materialized_view_execute_build_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7274435, "supported_languages": ["sql"]}, "macro.dbt_databricks.materialized_view_get_build_sql": {"name": "materialized_view_get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialized_view_get_build_sql", "macro_sql": "{% macro materialized_view_get_build_sql(existing_relation, target_relation) %}\n    {% set sql = adapter.clean_sql(sql) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_materialized_view_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_materialized_view %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_configuration_changes(existing_relation) %}\n\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_materialized_view(target_relation) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_materialized_view_as_sql(target_relation, configuration_changes, sql, existing_relation, None, None) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = \"\" %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt_databricks.get_replace_sql", "macro.dbt_databricks.get_configuration_changes", "macro.dbt.refresh_materialized_view", "macro.dbt_databricks.get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7289996, "supported_languages": null}, "macro.dbt_databricks.materialized_view_execute_build_sql": {"name": "materialized_view_execute_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/materialized_view.sql", "original_file_path": "macros/materializations/materialized_view.sql", "unique_id": "macro.dbt_databricks.materialized_view_execute_build_sql", "macro_sql": "{% macro materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {{ execute_multiple_statements(build_sql) }}\n\n    {% set column_tags = adapter.get_column_tags_from_model(config.model) %}\n    {% if column_tags %}\n      {{ apply_column_tags(target_relation, column_tags) }}\n    {% endif %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt_databricks.execute_multiple_statements", "macro.dbt_databricks.apply_column_tags", "macro.dbt.should_revoke", "macro.dbt.apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7297385, "supported_languages": null}, "macro.dbt_databricks.run_pre_hooks": {"name": "run_pre_hooks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt_databricks.run_pre_hooks", "macro_sql": "{% macro run_pre_hooks() %}\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7300396, "supported_languages": null}, "macro.dbt_databricks.run_post_hooks": {"name": "run_post_hooks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt_databricks.run_post_hooks", "macro_sql": "{% macro run_post_hooks() %}\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.730252, "supported_languages": null}, "macro.dbt_databricks.materialization_snapshot_databricks": {"name": "materialization_snapshot_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_databricks.materialization_snapshot_databricks", "macro_sql": "{% materialization snapshot, adapter='databricks' %}\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n  {% set sql = adapter.clean_sql(sql) %}\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'delta') -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = databricks__get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table',\n          needs_information=True) -%}\n\n  {%- if file_format not in ['delta', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, adapter.clean_sql(model['compiled_code'])) %}\n      {% set build_or_select_sql = build_sql %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.assert_valid_snapshot_target_given_strategy(target_relation, columns, strategy) }}\n\n      {% set build_or_select_sql = snapshot_staging_table(strategy, sql, target_relation) %}\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set remove_columns = ['dbt_change_type', 'DBT_CHANGE_TYPE', 'dbt_unique_key', 'DBT_UNIQUE_KEY'] %}\n      {% if unique_key | is_list %}\n          {% for key in strategy.unique_key %}\n              {{ remove_columns.append('dbt_unique_key_' + loop.index|string) }}\n              {{ remove_columns.append('DBT_UNIQUE_KEY_' + loop.index|string) }}\n          {% endfor %}\n      {% endif %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n\n  {{ check_time_data_types(build_or_select_sql) }}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode=False) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_staging_table", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.check_time_data_types", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot", "macro.dbt_databricks.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7355745, "supported_languages": ["sql"]}, "macro.dbt_databricks.materialization_seed_databricks": {"name": "materialization_seed_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.materialization_seed_databricks", "macro_sql": "{% materialization seed, adapter='databricks' %}\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ create_seed_v2(target_relation) }}\n  {% else %}\n    {{ create_seed_v1(target_relation) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.create_seed_v2", "macro.dbt_databricks.create_seed_v1"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.736693, "supported_languages": ["sql"]}, "macro.dbt_databricks.create_seed_v2": {"name": "create_seed_v2", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.create_seed_v2", "macro_sql": "{% macro create_seed_v2(target_relation) %}\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and (old_relation.is_view or old_relation.is_materialized_view)) -%}\n  {%- set exists_as_streaming_table = (old_relation is not none and old_relation.is_streaming_table) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparision later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_pre_hooks() }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view or a materialized view\".format(old_relation)) }}\n  {% elif exists_as_streaming_table %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a streaming table\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {{ log_seed_operation(agate_table, full_refresh_mode, create_table_sql, sql) }}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n  -- No need to persist docs, already handled in seed create\n\n  {{ run_post_hooks() }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt_databricks.log_seed_operation", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.run_post_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7386525, "supported_languages": null}, "macro.dbt_databricks.create_seed_v1": {"name": "create_seed_v1", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/seeds.sql", "original_file_path": "macros/materializations/seeds/seeds.sql", "unique_id": "macro.dbt_databricks.create_seed_v1", "macro_sql": "{% macro create_seed_v1(target_relation) %}\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier, needs_information=True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and (old_relation.is_view or old_relation.is_materialized_view)) -%}\n  {%- set exists_as_streaming_table = (old_relation is not none and old_relation.is_streaming_table) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparision later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view or a materialized view\".format(old_relation)) }}\n  {% elif exists_as_streaming_table %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a streaming table\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n  -- No need to persist docs, already handled in seed create\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.get_csv_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7412124, "supported_languages": null}, "macro.dbt_databricks.databricks__get_binding_char": {"name": "databricks__get_binding_char", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__get_binding_char", "macro_sql": "{% macro databricks__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7422075, "supported_languages": null}, "macro.dbt_databricks.databricks__load_csv_rows": {"name": "databricks__load_csv_rows", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__load_csv_rows", "macro_sql": "{% macro databricks__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n  {% set must_cast = model['config'].get('file_format', 'delta') == 'parquet' %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert {% if loop.index0 == 0 -%} overwrite {% else -%} into {% endif -%} {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- if must_cast -%}\n                    {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                    {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- else -%}\n                    {{ get_binding_char() }}\n                  {%- endif -%}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True, close_cursor=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.74408, "supported_languages": null}, "macro.dbt_databricks.databricks__reset_csv_table": {"name": "databricks__reset_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__reset_csv_table", "macro_sql": "{% macro databricks__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n      {% if old_relation.is_delta and config.get('file_format', default='delta') == 'delta' %}\n        {% set sql = create_or_replace_csv_table(model, agate_table, True) %}\n      {% else %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n      {% endif %}\n    {% else %}\n      {% set sql = create_csv_table(model, agate_table) %}\n    {% endif %}\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_or_replace_csv_table", "macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7448409, "supported_languages": null}, "macro.dbt_databricks.create_or_replace_csv_table": {"name": "create_or_replace_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.create_or_replace_csv_table", "macro_sql": "{% macro create_or_replace_csv_table(model, agate_table, replace=False) %}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n  {%- set column_comment = config.persist_column_docs() and model.columns %}\n  {%- set identifier = model['alias'] -%}\n  {%- set relation = api.Relation.create(database=database, schema=schema, identifier=identifier, type='table') -%}\n  {%- set replace_clause = \"\" -%}\n  {%- if replace -%}\n    {%- set replace_clause = \"or replace\" -%}\n  {%- endif -%}\n\n  {% set sql %}\n    create {{replace_clause}} table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {%- set column_comment_clause = \"\" -%}\n            {%- if column_comment and col_name in model.columns.keys() -%}   \n              {%- set comment = model.columns[col_name]['description'] | replace(\"'\", \"\\\\'\") -%}\n              {%- if comment and comment != \"\" -%}\n                {%- set column_comment_clause = \"comment '\" ~ comment ~ \"'\" -%}\n              {%- endif -%}\n            {%- endif -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {{ column_comment_clause }}{%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause(catalog_relation) }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause(catalog_relation) }}\n    {{ comment_clause() }}\n    {{ tblproperties_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_databricks.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_databricks.tblproperties_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.747325, "supported_languages": null}, "macro.dbt_databricks.databricks__create_csv_table": {"name": "databricks__create_csv_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.databricks__create_csv_table", "macro_sql": "{% macro databricks__create_csv_table(model, agate_table) %}\n  {{ return(create_or_replace_csv_table(model, agate_table)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.create_or_replace_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7476633, "supported_languages": null}, "macro.dbt_databricks.log_seed_operation": {"name": "log_seed_operation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt_databricks.log_seed_operation", "macro_sql": "{% macro log_seed_operation(agate_table, full_refresh_mode, create_table_sql, sql) %}\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.noop_statement", "macro.dbt.get_csv_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.748579, "supported_languages": null}, "macro.dbt_databricks.dbt_databricks_validate_get_file_format": {"name": "dbt_databricks_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_file_format", "macro_sql": "{% macro dbt_databricks_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7499683, "supported_languages": null}, "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy": {"name": "dbt_databricks_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_delta_only_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via warehouse\n    Use the 'merge' or 'replace_where' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in adapter.valid_incremental_strategies() %}\n    {{ log(\"WARNING - You are using an unsupported incremental strategy: \" ~ raw_strategy) }}\n    {{ log(\"You can ignore this warning if you are using a custom incremental strategy\") }}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n    {% if raw_strategy in ('replace_where', 'microbatch') and file_format not in ['delta'] %}\n      {% do exceptions.raise_compiler_error(invalid_delta_only_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7513895, "supported_languages": null}, "macro.dbt_databricks.materialization_incremental_databricks": {"name": "materialization_incremental_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.materialization_incremental_databricks", "macro_sql": "{% materialization incremental, adapter='databricks', supported_languages=['sql', 'python'] -%}\n  {{ log(\"MATERIALIZING INCREMENTAL\") }}\n\n  {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n  {% set existing_relation = load_relation_with_metadata(this) %}\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set incremental_strategy = get_incremental_strategy(catalog_relation.file_format) %}\n  {% set grant_config = config.get('grants') %}\n  {% set full_refresh = should_full_refresh() %}\n  {% set partition_by = config.get('partition_by') %}\n  {% set language = model['language'] %}\n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n  {% set is_delta = (catalog_relation.file_format == 'delta' and existing_relation.is_delta) %}\n  {% set compiled_code = adapter.clean_sql(model['compiled_code']) %}\n\n  {% if adapter.behavior.use_materialization_v2 %}\n    {{ log(\"USING V2 MATERIALIZATION\") }}\n    {#-- Set vars --#}\n    {% set safe_create = config.get('use_safer_relation_operations', False) | as_bool  %}\n    {{ log(\"Safe create: \" ~ safe_create) }}\n    {% set should_replace = existing_relation.is_dlt or existing_relation.is_view or full_refresh %}\n    {% set is_replaceable = existing_relation.can_be_replaced and is_delta and config.get(\"location_root\") %}\n\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set staging_relation = make_staging_relation(target_relation) %}\n\n    {{ run_pre_hooks() }}\n\n    {% call statement('main', language=language) %}\n      {{ get_create_intermediate_table(intermediate_relation, compiled_code, language) }}\n    {% endcall %}\n\n    {#-- Incremental run logic --#}\n    {%- if existing_relation is none -%}\n      {{ log(\"No existing relation found\") }}\n      {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n    {%- elif should_replace -%}\n      {{ log(\"Existing relation found that requires replacement\") }}\n      {% if safe_create and existing_relation.can_be_renamed %}\n        {{ log(\"Safe create enabled and relation can be renamed\") }}\n        {{ safe_relation_replace(existing_relation, staging_relation, intermediate_relation, compiled_code) }}\n      {% else %}\n        {#-- Relation must be dropped & recreated --#}\n        {% if not is_replaceable %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n          {{ log(\"Dropping existing relation, as it is not replaceable\") }}\n          {% do adapter.drop_relation(existing_relation) %}\n        {% endif %}\n        {{ log(\"Replacing target relation\") }}\n        {{ create_table_at(target_relation, intermediate_relation, compiled_code) }}\n      {% endif %}\n    {%- else -%}\n      {{ log(\"Existing relation found, proceeding with incremental work\")}}\n      {#-- Set Overwrite Mode to DYNAMIC for subsequent incremental operations --#}\n      {%- if incremental_strategy == 'insert_overwrite' and partition_by -%}\n        {{ set_overwrite_mode('DYNAMIC') }}\n      {%- endif -%}\n      {#-- Relation must be merged --#}\n      {%- do process_schema_changes(on_schema_change, intermediate_relation, existing_relation) -%}\n      {{ process_config_changes(target_relation) }}\n      {% set build_sql = get_build_sql(incremental_strategy, target_relation, intermediate_relation) %}\n      {%- if language == 'sql' -%}\n        {%- call statement('main') -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- elif language == 'python' -%}\n        {%- call statement_with_staging_table('main', intermediate_relation) -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- endif -%}\n    {%- endif -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% do optimize(target_relation) %}\n\n    {% if language == 'python' %}\n      {{ drop_relation_if_exists(intermediate_relation) }}\n    {% endif %}\n\n    {{ run_post_hooks() }}\n\n  {% else %}\n    {%- set tblproperties = config.get('tblproperties') -%}\n    {%- set tags = config.get('databricks_tags') -%}\n    {% set temp_relation = make_temp_relation(target_relation) %}\n    {% set incremental_predicates = config.get('predicates') or config.get('incremental_predicates') %}\n    {%- set unique_key = config.get('unique_key') -%}\n\n    {#-- Run pre-hooks --#}\n    {{ run_hooks(pre_hooks) }}\n    {#-- Incremental run logic --#}\n    {%- if existing_relation is none -%}\n      {#-- Relation must be created --#}\n      {%- call statement('main', language=language) -%}\n        {{ create_table_as(False, target_relation, compiled_code, language) }}\n      {%- endcall -%}\n      {% do persist_constraints(target_relation, model) %}\n      {% do apply_tags(target_relation, tags) %}\n      {%- if language == 'python' -%}\n        {%- do apply_tblproperties(target_relation, tblproperties) %}\n      {%- endif -%}\n\n      {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n    {%- elif existing_relation.is_view or existing_relation.is_materialized_view or existing_relation.is_streaming_table or should_full_refresh() -%}\n      {#-- Relation must be dropped & recreated --#}\n      {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n        {% do adapter.drop_relation(existing_relation) %}\n      {% endif %}\n      {%- call statement('main', language=language) -%}\n        {{ create_table_as(False, target_relation, compiled_code, language) }}\n      {%- endcall -%}\n\n      {% if not existing_relation.is_view %}\n        {% do persist_constraints(target_relation, model) %}\n      {% endif %}\n      {% do apply_tags(target_relation, tags) %}\n      {% do persist_docs(target_relation, model, for_relation=language=='python') %}\n    {%- else -%}\n      {#-- Set Overwrite Mode to DYNAMIC for subsequent incremental operations --#}\n      {%- if incremental_strategy == 'insert_overwrite' and partition_by -%}\n        {{ set_overwrite_mode('DYNAMIC') }}\n      {%- endif -%}\n      {#-- Relation must be merged --#}\n      {%- set _existing_config = adapter.get_relation_config(existing_relation) -%}\n      {%- set model_config = adapter.get_config_from_model(config.model) -%}\n      {%- set _configuration_changes = model_config.get_changeset(_existing_config) -%}\n      {%- call statement('create_temp_relation', language=language) -%}\n        {{ create_table_as(True, temp_relation, compiled_code, language) }}\n      {%- endcall -%}\n      {%- do process_schema_changes(on_schema_change, temp_relation, existing_relation) -%}\n      {%- set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) -%}\n      {%- set strategy_arg_dict = ({\n              'target_relation': target_relation,\n              'temp_relation': temp_relation,\n              'unique_key': unique_key,\n              'dest_columns': none,\n              'incremental_predicates': incremental_predicates}) -%}\n      {%- set build_sql = strategy_sql_macro_func(strategy_arg_dict) -%}\n      {%- if language == 'sql' -%}\n        {%- call statement('main') -%}\n          {{ build_sql }}\n        {%- endcall -%}\n      {%- elif language == 'python' -%}\n        {%- call statement_with_staging_table('main', temp_relation) -%}\n          {{ build_sql }}\n        {%- endcall -%}\n        {#--\n        This is yucky.\n        See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n        re: python models and temporary views.\n\n        Also, why does not either drop_relation or adapter.drop_relation work here?!\n        --#}\n      {%- endif -%}\n      {% if _configuration_changes is not none %}\n        {% set tags = _configuration_changes.changes.get(\"tags\", None) %}\n        {% set tblproperties = _configuration_changes.changes.get(\"tblproperties\", None) %}\n        {% set liquid_clustering = _configuration_changes.changes.get(\"liquid_clustering\") %}\n        {% if tags is not none %}\n          {% do apply_tags(target_relation, tags.set_tags) %}\n        {%- endif -%}\n        {% if tblproperties is not none %}\n          {% do apply_tblproperties(target_relation, tblproperties.tblproperties) %}\n        {%- endif -%}\n        {% if liquid_clustering is not none %}\n          {% do apply_liquid_clustered_cols(target_relation, liquid_clustering) %}\n        {% endif %}\n      {%- endif -%}\n      {% do persist_docs(target_relation, model, for_relation=True) %}\n    {%- endif -%}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke) %}\n    {% do optimize(target_relation) %}\n\n    {{ run_hooks(post_hooks) }}\n  {%- endif -%}\n\n  {%- if incremental_strategy == 'insert_overwrite' and not full_refresh -%}\n    {{ set_overwrite_mode('STATIC') }}\n  {%- endif -%}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_databricks.load_relation_with_metadata", "macro.dbt_databricks.get_incremental_strategy", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.make_intermediate_relation", "macro.dbt_databricks.make_staging_relation", "macro.dbt_databricks.run_pre_hooks", "macro.dbt.statement", "macro.dbt_databricks.get_create_intermediate_table", "macro.dbt_databricks.create_table_at", "macro.dbt_databricks.safe_relation_replace", "macro.dbt_databricks.set_overwrite_mode", "macro.dbt.process_schema_changes", "macro.dbt_databricks.process_config_changes", "macro.dbt_databricks.get_build_sql", "macro.dbt_databricks.statement_with_staging_table", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt_databricks.optimize", "macro.dbt.drop_relation_if_exists", "macro.dbt_databricks.run_post_hooks", "macro.dbt.make_temp_relation", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_databricks.persist_constraints", "macro.dbt_databricks.apply_tags", "macro.dbt_databricks.apply_tblproperties", "macro.dbt.persist_docs", "macro.dbt_databricks.apply_liquid_clustered_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7614837, "supported_languages": ["sql", "python"]}, "macro.dbt_databricks.set_overwrite_mode": {"name": "set_overwrite_mode", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.set_overwrite_mode", "macro_sql": "{% macro set_overwrite_mode(value) %}\n  {% if adapter.is_cluster() %}\n    {%- call statement('Setting partitionOverwriteMode: ' ~ value) -%}\n      set spark.sql.sources.partitionOverwriteMode = {{ value }}\n    {%- endcall -%}\n  {% else %}\n    {{ exceptions.warn(\"INSERT OVERWRITE is only properly supported on all-purpose clusters.  On SQL Warehouses, this strategy would be equivalent to using the table materialization.\") }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.761908, "supported_languages": null}, "macro.dbt_databricks.get_build_sql": {"name": "get_build_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.get_build_sql", "macro_sql": "{% macro get_build_sql(incremental_strategy, target_relation, intermediate_relation) %}\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set incremental_predicates = config.get('predicates') or config.get('incremental_predicates') -%}\n  {%- set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) -%}\n  {%- set strategy_arg_dict = ({\n          'target_relation': target_relation,\n          'temp_relation': intermediate_relation,\n          'unique_key': unique_key,\n          'dest_columns': none,\n          'incremental_predicates': incremental_predicates}) -%}\n  {{ strategy_sql_macro_func(strategy_arg_dict) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7625682, "supported_languages": null}, "macro.dbt_databricks.process_config_changes": {"name": "process_config_changes", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_databricks.process_config_changes", "macro_sql": "{% macro process_config_changes(target_relation) %}\n  {% set apply_config_changes = config.get('incremental_apply_config_changes', True) | as_bool %}\n  {% if apply_config_changes %}\n    {%- set existing_config = adapter.get_relation_config(target_relation) -%}\n    {%- set model_config = adapter.get_config_from_model(config.model) -%}\n    {%- set configuration_changes = model_config.get_changeset(existing_config) -%}\n    {{ apply_config_changeset(target_relation, model, configuration_changes) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.apply_config_changeset"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7630954, "supported_languages": null}, "macro.dbt_databricks.get_incremental_strategy": {"name": "get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_incremental_strategy", "macro_sql": "{% macro get_incremental_strategy(file_format) %}\n  {% set raw_strategy = config.get('incremental_strategy') or 'merge' %}\n  {% do return(dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7647734, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_default_sql": {"name": "databricks__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_default_sql", "macro_sql": "{% macro databricks__get_incremental_default_sql(arg_dict) %}\n  {{ return(get_incremental_merge_sql(arg_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7649343, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_append_sql": {"name": "databricks__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_append_sql", "macro_sql": "{% macro databricks__get_incremental_append_sql(arg_dict) %}\n  {% do return(get_insert_into_sql(arg_dict[\"temp_relation\"], arg_dict[\"target_relation\"])) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.765153, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_replace_where_sql": {"name": "databricks__get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_replace_where_sql", "macro_sql": "{% macro databricks__get_incremental_replace_where_sql(arg_dict) %}\n  {% do return(get_replace_where_sql(arg_dict)) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7653139, "supported_languages": null}, "macro.dbt_databricks.get_incremental_replace_where_sql": {"name": "get_incremental_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_incremental_replace_where_sql", "macro_sql": "{% macro get_incremental_replace_where_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_replace_where_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7655091, "supported_languages": null}, "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql": {"name": "databricks__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql", "macro_sql": "{% macro databricks__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) %}\n    {{ return(get_insert_overwrite_sql(source, target)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7657142, "supported_languages": null}, "macro.dbt_databricks.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation) %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) | map(attribute='quoted') | list -%}\n    {%- set source_columns = adapter.get_columns_in_relation(source_relation) | map(attribute='quoted') | list -%}\n    {%- set common_columns = [] -%}\n    {%- for dest_col in dest_columns -%}\n      {%- if dest_col in source_columns -%}\n        {%- do common_columns.append(dest_col) -%}\n      {%- else -%}\n        {%- do common_columns.append('DEFAULT') -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- set dest_cols_csv = dest_columns | join(', ') -%}\n    {%- set source_cols_csv = common_columns | join(', ') -%}\n    insert overwrite table {{ target_relation }}\n    {{ partition_cols(label=\"partition\") }}\n    select {{source_cols_csv}} from {{ source_relation }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7666106, "supported_languages": null}, "macro.dbt_databricks.get_replace_where_sql": {"name": "get_replace_where_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_replace_where_sql", "macro_sql": "{% macro get_replace_where_sql(args_dict) -%}\n  {%- set predicates = args_dict['incremental_predicates'] -%}\n  {%- set target_relation = args_dict['target_relation'] -%}\n  {%- set temp_relation = args_dict['temp_relation'] -%}\nINSERT INTO {{ target_relation.render() }}\n{% if predicates %}\n  {% if predicates is sequence and predicates is not string %}\nREPLACE WHERE {{ predicates | join(' and ') }}\n  {% else %}\nREPLACE WHERE {{ predicates }}\n  {% endif %}\n{% endif %}\nTABLE {{ temp_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7672043, "supported_languages": null}, "macro.dbt_databricks.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n    {%- set source_columns = adapter.get_columns_in_relation(source_relation) | map(attribute=\"quoted\") | list -%}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) | map(attribute=\"quoted\") | list -%}\n    {{ insert_into_sql_impl(target_relation, dest_columns, source_relation, source_columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.insert_into_sql_impl"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.767613, "supported_languages": null}, "macro.dbt_databricks.insert_into_sql_impl": {"name": "insert_into_sql_impl", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.insert_into_sql_impl", "macro_sql": "{% macro insert_into_sql_impl(target_relation, dest_columns, source_relation, source_columns) %}\n    {%- set common_columns = [] -%}\n    {%- for dest_col in dest_columns -%}\n      {%- if dest_col in source_columns -%}\n        {%- do common_columns.append(dest_col) -%}\n      {%- else -%}\n        {%- do common_columns.append('DEFAULT') -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- set dest_cols_csv = dest_columns | join(', ') -%}\n    {%- set source_cols_csv = common_columns | join(', ') -%}\ninsert into table {{ target_relation }} ({{ dest_cols_csv }})\nselect {{source_cols_csv}} from {{ source_relation }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.768269, "supported_languages": null}, "macro.dbt_databricks.databricks__get_merge_sql": {"name": "databricks__get_merge_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_merge_sql", "macro_sql": "{% macro databricks__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n\n  {%- set target_alias = config.get('target_alias', 'DBT_INTERNAL_DEST') -%}\n  {%- set source_alias = config.get('source_alias', 'DBT_INTERNAL_SOURCE') -%}\n\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set source_columns = (adapter.get_columns_in_relation(source) | map(attribute='quoted') | list)-%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set merge_with_schema_evolution = (config.get('merge_with_schema_evolution') | lower == 'true') -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n  {%- set skip_matched_step = (config.get('skip_matched_step') | lower == 'true') -%}\n  {%- set skip_not_matched_step = (config.get('skip_not_matched_step') | lower == 'true') -%}\n\n  {%- set matched_condition = config.get('matched_condition') -%}\n  {%- set not_matched_condition = config.get('not_matched_condition') -%}\n\n  {%- set not_matched_by_source_action = config.get('not_matched_by_source_action') -%}\n  {%- set not_matched_by_source_condition = config.get('not_matched_by_source_condition') -%}\n\n  {%- set not_matched_by_source_action_trimmed = not_matched_by_source_action | lower | trim(' \\n\\t') %}\n  {%- set not_matched_by_source_action_is_set = (\n      not_matched_by_source_action_trimmed == 'delete'\n      or not_matched_by_source_action_trimmed.startswith('update')\n    )\n  %}\n  \n  \n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  {{ source_alias }}.{{ key }} <=> {{ target_alias }}.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              {{ source_alias }}.{{ unique_key }} <=> {{ target_alias }}.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n    merge\n        {%- if merge_with_schema_evolution %}\n        with schema evolution\n        {%- endif %}\n    into\n        {{ target }} as {{ target_alias }}\n    using\n        {{ source }} as {{ source_alias }}\n    on\n        {{ predicates | join('\\n    and ') }}\n    {%- if not skip_matched_step %}\n    when matched\n        {%- if matched_condition %}\n        and ({{ matched_condition }})\n        {%- endif %}\n        then update set\n            {{ get_merge_update_set(update_columns, on_schema_change, source_columns, source_alias) }}\n    {%- endif %}\n    {%- if not skip_not_matched_step %}\n    when not matched\n        {%- if not_matched_condition %}\n        and ({{ not_matched_condition }})\n        {%- endif %}\n        then insert\n            {{ get_merge_insert(on_schema_change, source_columns, source_alias) }}\n    {%- endif %}\n    {%- if not_matched_by_source_action_is_set %}\n    when not matched by source\n        {%- if not_matched_by_source_condition %}\n        and ({{ not_matched_by_source_condition }})\n        {%- endif %}\n        then {{ not_matched_by_source_action }}\n    {%- endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.incremental_validate_on_schema_change", "macro.dbt.get_merge_update_columns", "macro.dbt_databricks.get_merge_update_set", "macro.dbt_databricks.get_merge_insert"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.771868, "supported_languages": null}, "macro.dbt_databricks.get_merge_update_set": {"name": "get_merge_update_set", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_merge_update_set", "macro_sql": "{% macro get_merge_update_set(update_columns, on_schema_change, source_columns, source_alias='DBT_INTERNAL_SOURCE') %}\n  {%- if update_columns -%}\n    {%- for column_name in update_columns -%}\n      {{ column_name }} = {{ source_alias }}.{{ column_name }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  {%- elif on_schema_change == 'ignore' -%}\n    *\n  {%- else -%}\n    {%- for column in source_columns -%}\n      {{ column }} = {{ source_alias }}.{{ column }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7726822, "supported_languages": null}, "macro.dbt_databricks.get_merge_insert": {"name": "get_merge_insert", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.get_merge_insert", "macro_sql": "{% macro get_merge_insert(on_schema_change, source_columns, source_alias='DBT_INTERNAL_SOURCE') %}\n  {%- if on_schema_change == 'ignore' -%}\n    *\n  {%- else -%}\n    ({{ source_columns | join(\", \") }}) VALUES (\n    {%- for column in source_columns -%}\n      {{ source_alias }}.{{ column }}{%- if not loop.last %}, {% endif -%}\n    {%- endfor %})\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.773131, "supported_languages": null}, "macro.dbt_databricks.databricks__get_incremental_microbatch_sql": {"name": "databricks__get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__get_incremental_microbatch_sql", "macro_sql": "{% macro databricks__get_incremental_microbatch_sql(arg_dict) %}\n  {%- set incremental_predicates = [] if arg_dict.get('incremental_predicates') is none else arg_dict.get('incremental_predicates') -%}\n  {%- set event_time = model.config.event_time -%}\n  {%- set start_time = config.get(\"__dbt_internal_microbatch_event_time_start\") -%}\n  {%- set end_time = config.get(\"__dbt_internal_microbatch_event_time_end\") -%}\n  {%- if start_time -%}\n    {%- do incremental_predicates.append(\"cast(\" ~ event_time ~ \" as TIMESTAMP) >= '\" ~ start_time ~ \"'\") -%}\n  {%- endif -%}\n  {%- if end_time -%}\n    {%- do incremental_predicates.append(\"cast(\" ~ event_time ~ \" as TIMESTAMP) < '\" ~ end_time ~ \"'\") -%}\n  {%- endif -%}\n  {%- do arg_dict.update({'incremental_predicates': incremental_predicates}) -%}\n  {{ return(get_replace_where_sql(arg_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.get_replace_where_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7740595, "supported_languages": null}, "macro.dbt_databricks.databricks__can_clone_table": {"name": "databricks__can_clone_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/clone.sql", "original_file_path": "macros/materializations/clone/clone.sql", "unique_id": "macro.dbt_databricks.databricks__can_clone_table", "macro_sql": "{% macro databricks__can_clone_table() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7746632, "supported_languages": null}, "macro.dbt_databricks.materialization_clone_databricks": {"name": "materialization_clone_databricks", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/clone.sql", "original_file_path": "macros/materializations/clone/clone.sql", "unique_id": "macro.dbt_databricks.materialization_clone_databricks", "macro_sql": "\n\n\n{%- materialization clone, adapter='databricks' -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% if other_existing_relation.is_external_table %}\n          {% call statement('main') %}\n              {{ create_or_replace_clone_external(target_relation, defer_relation) }}\n          {% endcall %}\n      {% else %}\n          {% call statement('main') %}\n              {{ create_or_replace_clone(target_relation, defer_relation) }}\n          {% endcall %}\n      {% endif %}\n\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n  {% endif %}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt_databricks.create_or_replace_clone_external", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7772741, "supported_languages": ["sql"]}, "macro.dbt_databricks.databricks__create_or_replace_clone": {"name": "databricks__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/strategies.sql", "original_file_path": "macros/materializations/clone/strategies.sql", "unique_id": "macro.dbt_databricks.databricks__create_or_replace_clone", "macro_sql": "{% macro databricks__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace\n    table {{ this_relation.render() }}\n    shallow clone {{ defer_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7776423, "supported_languages": null}, "macro.dbt_databricks.create_or_replace_clone_external": {"name": "create_or_replace_clone_external", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/materializations/clone/strategies.sql", "original_file_path": "macros/materializations/clone/strategies.sql", "unique_id": "macro.dbt_databricks.create_or_replace_clone_external", "macro_sql": "{% macro create_or_replace_clone_external(this_relation, defer_relation) %}\n\n    {%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}\n\n    create or replace\n    table {{ this_relation.render() }}\n    shallow clone {{ defer_relation.render() }}\n    {{ location_clause(catalog_relation) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.location_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.777975, "supported_languages": null}, "macro.dbt_databricks.databricks__list_relations_without_caching": {"name": "databricks__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__list_relations_without_caching", "macro_sql": "{% macro databricks__list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.get_relations_without_caching(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7787232, "supported_languages": null}, "macro.dbt_databricks.show_table_extended": {"name": "show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_table_extended", "macro_sql": "{% macro show_table_extended(schema_relation) %}\n  {{ return(adapter.dispatch('show_table_extended', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_table_extended"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7789254, "supported_languages": null}, "macro.dbt_databricks.databricks__show_table_extended": {"name": "databricks__show_table_extended", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_table_extended", "macro_sql": "{% macro databricks__show_table_extended(schema_relation) %}\n  {{ return(run_query_as(show_table_extended_sql(schema_relation), 'show_table_extended')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_table_extended_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7791138, "supported_languages": null}, "macro.dbt_databricks.show_table_extended_sql": {"name": "show_table_extended_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_table_extended_sql", "macro_sql": "{% macro show_table_extended_sql(schema_relation) %}\nSHOW TABLE EXTENDED IN {{ schema_relation.without_identifier()|lower }} LIKE '{{ schema_relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7792978, "supported_languages": null}, "macro.dbt_databricks.show_tables": {"name": "show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_tables", "macro_sql": "{% macro show_tables(relation) %}\n  {{ return(adapter.dispatch('show_tables', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_tables"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7794914, "supported_languages": null}, "macro.dbt_databricks.databricks__show_tables": {"name": "databricks__show_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_tables", "macro_sql": "{% macro databricks__show_tables(relation) %}\n  {{ return(run_query_as(show_tables_sql(relation), 'show_tables')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_tables_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.779677, "supported_languages": null}, "macro.dbt_databricks.show_tables_sql": {"name": "show_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_tables_sql", "macro_sql": "{% macro show_tables_sql(relation) %}\nSHOW TABLES IN {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7798133, "supported_languages": null}, "macro.dbt_databricks.show_views": {"name": "show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_views", "macro_sql": "{% macro show_views(relation) %}\n  {{ return(adapter.dispatch('show_views', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__show_views"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7800252, "supported_languages": null}, "macro.dbt_databricks.databricks__show_views": {"name": "databricks__show_views", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__show_views", "macro_sql": "{% macro databricks__show_views(relation) %}\n  {{ return(run_query_as(show_views_sql(relation), 'show_views')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.show_views_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7802162, "supported_languages": null}, "macro.dbt_databricks.show_views_sql": {"name": "show_views_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.show_views_sql", "macro_sql": "{% macro show_views_sql(relation) %}\nSHOW VIEWS IN {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.780355, "supported_languages": null}, "macro.dbt_databricks.databricks__get_relation_last_modified": {"name": "databricks__get_relation_last_modified", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.databricks__get_relation_last_modified", "macro_sql": "{% macro databricks__get_relation_last_modified(information_schema, relations) -%}\n  {% call statement('last_modified', fetch_result=True) %}\n    {{ get_relation_last_modified_sql(information_schema, relations) }}\n  {% endcall %}\n  {{ return(load_result('last_modified')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_databricks.get_relation_last_modified_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.780673, "supported_languages": null}, "macro.dbt_databricks.get_relation_last_modified_sql": {"name": "get_relation_last_modified_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_relation_last_modified_sql", "macro_sql": "{% macro get_relation_last_modified_sql(information_schema, relations) %}\n  {% if information_schema.is_hive_metastore() %}\n    {%- for relation in relations -%}\nSELECT\n  '{{ relation.schema }}' AS schema,\n  '{{ relation.identifier }}' AS identifier,\n  max(timestamp) AS last_modified,\n  {{ current_timestamp() }} AS snapshotted_at\n  FROM (DESCRIBE HISTORY {{ relation.schema|lower }}.{{ relation.identifier|lower }})\n      {% if not loop.last %}\nUNION ALL\n      {% endif %}\n    {%- endfor -%}\n  {% else %}\nSELECT\n  table_schema AS schema,\n  table_name AS identifier,\n  last_altered AS last_modified,\n  {{ current_timestamp() }} AS snapshotted_at\nFROM `system`.`information_schema`.`tables`\nWHERE table_catalog = '{{ information_schema.database|lower }}'\n  AND (\n    {%- for relation in relations -%}\n    (table_schema = '{{ relation.schema|lower }}' AND\n    table_name = '{{ relation.identifier|lower }}'){%- if not loop.last %} OR {% endif -%}\n    {%- endfor -%}\n  )\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7814834, "supported_languages": null}, "macro.dbt_databricks.get_view_description": {"name": "get_view_description", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_view_description", "macro_sql": "{% macro get_view_description(relation) %}\n  {{ return(run_query_as(get_view_description_sql(relation), 'get_view_description')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_view_description_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7816758, "supported_languages": null}, "macro.dbt_databricks.get_view_description_sql": {"name": "get_view_description_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_view_description_sql", "macro_sql": "{% macro get_view_description_sql(relation) %}\nSELECT *\nFROM `system`.`information_schema`.`views`\nWHERE table_catalog = '{{ relation.database|lower }}'\n  AND table_schema = '{{ relation.schema|lower }}'\n  AND table_name = '{{ relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7818894, "supported_languages": null}, "macro.dbt_databricks.get_uc_tables": {"name": "get_uc_tables", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_uc_tables", "macro_sql": "{% macro get_uc_tables(relation) %}\n  {{ return(run_query_as(get_uc_tables_sql(relation), 'get_uc_tables')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_uc_tables_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7820973, "supported_languages": null}, "macro.dbt_databricks.get_uc_tables_sql": {"name": "get_uc_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt_databricks.get_uc_tables_sql", "macro_sql": "{% macro get_uc_tables_sql(relation) %}\nSELECT\n  table_name,\n  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,\n  lower(data_source_format) AS file_format,\n  table_owner,\n  if(\n    table_type IN (\n      'EXTERNAL',\n      'MANAGED',\n      'MANAGED_SHALLOW_CLONE',\n      'EXTERNAL_SHALLOW_CLONE'\n    ),\n    lower(table_type),\n    NULL\n  ) AS databricks_table_type\nFROM `system`.`information_schema`.`tables`\nWHERE table_catalog = '{{ relation.database|lower }}' \n  AND table_schema = '{{ relation.schema|lower }}'\n  {%- if relation.identifier %}\n  AND table_name = '{{ relation.identifier|lower }}'\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7824097, "supported_languages": null}, "macro.dbt_databricks.make_staging_relation": {"name": "make_staging_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.make_staging_relation", "macro_sql": "{% macro make_staging_relation(base_relation, suffix='__dbt_stg', type='table') %}\n  {% set unique_tmp_table_suffix = config.get('unique_tmp_table_suffix', False) | as_bool %}\n  {% if unique_tmp_table_suffix %}\n    {% set suffix = adapter.generate_unique_temporary_table_suffix(suffix) %}\n  {% endif %}\n  {% set stg_identifier = base_relation.identifier ~ suffix %}\n  {% set stg_relation = api.Relation.create(database=base_relation.database, schema=base_relation.schema, identifier=stg_identifier, type=type) %}\n  {% do return(stg_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7834668, "supported_languages": null}, "macro.dbt_databricks.databricks__make_intermediate_relation": {"name": "databricks__make_intermediate_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__make_intermediate_relation", "macro_sql": "{% macro databricks__make_intermediate_relation(base_relation, suffix) %}\n    {{ return(databricks__make_temp_relation(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7836595, "supported_languages": null}, "macro.dbt_databricks.databricks__make_temp_relation": {"name": "databricks__make_temp_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__make_temp_relation", "macro_sql": "{% macro databricks__make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {% set unique_tmp_table_suffix = config.get('unique_tmp_table_suffix', False) | as_bool %}\n\n  {% if unique_tmp_table_suffix %}\n    {% set suffix = adapter.generate_unique_temporary_table_suffix() %}\n  {% endif %}\n  \n  {% if suffix == '__dbt_tmp' and model.batch %}\n    {% set suffix = suffix ~ '_' ~ model.batch.id %}\n  {% endif %}\n\n  {% set tmp_identifier = base_relation.identifier ~ suffix %}\n  {% set language = model['language'] %}\n  {%- if language == 'sql' -%}\n    {% set temporary = not base_relation.is_hive_metastore() %}\n    {% set tmp_relation = api.Relation.create(identifier=tmp_identifier, type='view', temporary=temporary) %}\n  {%- else -%}\n    {% set tmp_relation = api.Relation.create(database=base_relation.database, schema=base_relation.schema, identifier=tmp_identifier, type='table') %}\n  {%- endif -%}\n  {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7848215, "supported_languages": null}, "macro.dbt_databricks.databricks__get_or_create_relation": {"name": "databricks__get_or_create_relation", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.databricks__get_or_create_relation", "macro_sql": "{% macro databricks__get_or_create_relation(database, schema, identifier, type, needs_information=False) %}\n  {%- set target_relation = adapter.get_relation(\n            database=database,\n            schema=schema,\n            identifier=identifier,\n            needs_information=needs_information) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type,\n      temporary=False\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7857127, "supported_languages": null}, "macro.dbt_databricks.get_column_and_constraints_sql": {"name": "get_column_and_constraints_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.get_column_and_constraints_sql", "macro_sql": "{% macro get_column_and_constraints_sql(relation, columns) %}\n  (\n    {% for column in columns %}\n      {{ column.render_for_create() }}{% if not loop.last or relation.create_constraints %},{% endif %}\n    {% endfor %}\n    {% if relation.create_constraints %}\n      {{ relation.render_constraints_for_create() }}\n    {% endif %}\n  )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7861714, "supported_languages": null}, "macro.dbt_databricks.load_relation_with_metadata": {"name": "load_relation_with_metadata", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt_databricks.load_relation_with_metadata", "macro_sql": "{% macro load_relation_with_metadata(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier,\n    needs_information=True\n  )) -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7864733, "supported_languages": null}, "macro.dbt_databricks.current_catalog": {"name": "current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.current_catalog", "macro_sql": "{% macro current_catalog() -%}\n  {{ return(adapter.dispatch('current_catalog', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__current_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.786884, "supported_languages": null}, "macro.dbt_databricks.databricks__current_catalog": {"name": "databricks__current_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.databricks__current_catalog", "macro_sql": "{% macro databricks__current_catalog() -%}\n  {{ return(run_query_as(current_catalog_sql(), 'current_catalog')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.current_catalog_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7870557, "supported_languages": null}, "macro.dbt_databricks.current_catalog_sql": {"name": "current_catalog_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.current_catalog_sql", "macro_sql": "{% macro current_catalog_sql() %}\nSELECT current_catalog()\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7871742, "supported_languages": null}, "macro.dbt_databricks.use_catalog": {"name": "use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.use_catalog", "macro_sql": "{% macro use_catalog(catalog) -%}\n  {{ adapter.dispatch('use_catalog', 'dbt')(catalog) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__use_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7873514, "supported_languages": null}, "macro.dbt_databricks.databricks__use_catalog": {"name": "databricks__use_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.databricks__use_catalog", "macro_sql": "{% macro databricks__use_catalog(catalog) -%}\n  {{ run_query_as(use_catalog_sql(catalog), 'use_catalog', fetch_result=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.use_catalog_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7875376, "supported_languages": null}, "macro.dbt_databricks.use_catalog_sql": {"name": "use_catalog_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/databricks_catalog.sql", "original_file_path": "macros/adapters/databricks_catalog.sql", "unique_id": "macro.dbt_databricks.use_catalog_sql", "macro_sql": "{% macro use_catalog_sql(catalog) %}\nUSE CATALOG {{ adapter.quote(catalog)|lower }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7877035, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog": {"name": "databricks__get_catalog", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog", "macro_sql": "{% macro databricks__get_catalog(information_schema, schemas) -%}\n  {% set query %}\nWITH tables AS (\n  {{ databricks__get_catalog_tables_sql(information_schema) }}\n  {{ databricks__get_catalog_schemas_where_clause_sql(information_schema.database, schemas) }}\n),\ncolumns AS (\n  {{ databricks__get_catalog_columns_sql(information_schema) }}\n  {{ databricks__get_catalog_schemas_where_clause_sql(information_schema.database, schemas) }}\n)\n{{ databricks__get_catalog_results_sql() }}\n  {%- endset -%}\n\n  {{ return(run_query_as(query, 'get_catalog')) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql", "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7885818, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_relations": {"name": "databricks__get_catalog_relations", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_relations", "macro_sql": "{% macro databricks__get_catalog_relations(information_schema, relations) -%}\n  {% set query %}\nWITH tables AS (\n  {{ databricks__get_catalog_tables_sql(information_schema) }}\n  {{ databricks__get_catalog_relations_where_clause_sql(information_schema.database, relations) }}\n),\ncolumns AS (\n  {{ databricks__get_catalog_columns_sql(information_schema) }}\n  {{ databricks__get_catalog_relations_where_clause_sql(information_schema.database, relations) }}\n)\n{{ databricks__get_catalog_results_sql() }}\n  {%- endset -%}\n\n  {{ return(run_query_as(query, 'get_catalog_relations')) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql", "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.789052, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_tables_sql": {"name": "databricks__get_catalog_tables_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_tables_sql", "macro_sql": "{% macro databricks__get_catalog_tables_sql(information_schema) -%}\nSELECT\n  table_catalog AS table_database,\n  table_schema,\n  table_name,\n  lower(table_type) AS table_type,\n  comment AS table_comment,\n  table_owner,\n  'Last Modified' AS `stats:last_modified:label`,\n  last_altered AS `stats:last_modified:value`,\n  'The timestamp for last update/change' AS `stats:last_modified:description`,\n  (last_altered IS NOT NULL AND table_type NOT ILIKE '%VIEW%') AS `stats:last_modified:include`\nFROM `system`.`information_schema`.`tables`\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7891989, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_columns_sql": {"name": "databricks__get_catalog_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_columns_sql", "macro_sql": "{% macro databricks__get_catalog_columns_sql(information_schema) -%}\nSELECT\n  table_catalog AS table_database,\n  table_schema,\n  table_name,\n  column_name,\n  ordinal_position AS column_index,\n  lower(full_data_type) AS column_type,\n  comment AS column_comment\nFROM `system`.`information_schema`.`columns`\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7893124, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_results_sql": {"name": "databricks__get_catalog_results_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_results_sql", "macro_sql": "{% macro databricks__get_catalog_results_sql() -%}\nSELECT *\nFROM tables\nJOIN columns USING (table_database, table_schema, table_name)\nORDER BY column_index\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.789403, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql": {"name": "databricks__get_catalog_schemas_where_clause_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_schemas_where_clause_sql", "macro_sql": "{% macro databricks__get_catalog_schemas_where_clause_sql(catalog, schemas) -%}\nWHERE table_catalog = '{{ catalog|lower }}' AND (\n  {%- for relation in schemas -%}\n  table_schema = '{{ relation[1]|lower }}'{%- if not loop.last %} OR {% endif -%}\n  {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7897358, "supported_languages": null}, "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql": {"name": "databricks__get_catalog_relations_where_clause_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/catalog.sql", "original_file_path": "macros/adapters/catalog.sql", "unique_id": "macro.dbt_databricks.databricks__get_catalog_relations_where_clause_sql", "macro_sql": "{% macro databricks__get_catalog_relations_where_clause_sql(catalog, relations) -%}\nWHERE table_catalog = '{{ catalog|lower }}' AND (\n  {%- for relation in relations -%}\n    {%- if relation.schema and relation.identifier %}\n  (\n    table_schema = '{{ relation.schema|lower }}'\n    AND table_name = '{{ relation.identifier|lower }}'\n  )\n    {%- elif relation.schema %}\n  (\n    table_schema = '{{ relation.schema|lower }}'\n  )\n    {% else %}\n      {% do exceptions.raise_compiler_error(\n        '`get_catalog_relations` requires a list of relations, each with a schema'\n      ) %}\n    {% endif %}\n    {%- if not loop.last %} OR {% endif -%}\n  {%- endfor -%}\n)\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7903595, "supported_languages": null}, "macro.dbt_databricks.databricks_copy_into": {"name": "databricks_copy_into", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/copy_into.sql", "original_file_path": "macros/adapters/copy_into.sql", "unique_id": "macro.dbt_databricks.databricks_copy_into", "macro_sql": "{% macro databricks_copy_into(\n  target_table,\n  source,\n  file_format,\n  expression_list=none,\n  source_credential=none,\n  source_encryption=none,\n  validate=none,\n  files=none,\n  pattern=none,\n  format_options=none,\n  copy_options=none) -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n        database=target.database,\n        schema=target.schema,\n        identifier=target_table,\n        type='table') -%}\n\n  {%- set source_clause -%}\n    {%- if expression_list -%}\n      ( select {{ expression_list }} from '{{ source }}' )\n    {%- else -%}\n      '{{ source }}'\n    {%- endif -%}\n    {%- if source_credential or source_encryption %}\n      WITH (\n      {%- if source_credential %}\n        credential (\n          {%- for name in source_credential -%}\n            '{{ name }}' = '{{ source_credential[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      {%- if source_encryption %}\n        encryption (\n          {%- for name in source_encryption -%}\n            '{{ name }}' = '{{ source_encryption[name] }}' {%- if not loop.last %}, {% endif -%}\n          {%- endfor -%}\n        )\n      {%- endif %}\n      )\n    {%- endif -%}\n  {%- endset -%}\n\n  {% set query %}\n    copy into {{ target_relation }}\n    from {{ source_clause }}\n    fileformat = {{ file_format }}\n    {% if validate -%} validate {{ validate }} {%- endif %}\n    {% if files and pattern %}\n        {{ exceptions.raise_compiler_error(\"You can only specify one of 'files' or 'pattern'\") }}\n    {% endif %}\n    {% if files -%}\n      files = (\n        {%- for file in files -%}\n          '{{ file }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if pattern -%}\n        pattern = '{{ pattern }}'\n    {%- endif %}\n    {% if format_options -%}\n      format_options (\n        {%- for key in format_options -%}\n          '{{ key }}' = '{{ format_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n    {% if copy_options -%}\n      copy_options (\n        {%- for key in copy_options -%}\n          '{{ key }}' = '{{ copy_options[key] }}' {%- if not loop.last %}, {% endif -%}\n        {%- endfor -%}\n      )\n    {%- endif %}\n  {% endset %}\n\n  {{ run_query_as(query, 'copy_into', fetch_result=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt_databricks.run_query_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7931833, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_column_comment": {"name": "databricks__alter_column_comment", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.databricks__alter_column_comment", "macro_sql": "{% macro databricks__alter_column_comment(relation, column_dict) %}\n  {% set file_format = config.get('file_format', default='delta') %}\n  {% if file_format in ['delta', 'hudi'] %}\n    {% for column in column_dict.values() %}\n      {% set comment = column['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set column_path = relation.render() ~ '.' ~ api.Column.get_name(column) %}\n      {{ run_query_as(comment_on_column_sql(column_path, escaped_comment), 'alter_column_comment', fetch_result=False) }}\n    {% endfor %}\n  {% else %}\n    {{ log('WARNING - requested to update column comments, but file format ' ~ file_format ~ ' does not support that.') }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.comment_on_column_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7944849, "supported_languages": null}, "macro.dbt_databricks.comment_on_column_sql": {"name": "comment_on_column_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.comment_on_column_sql", "macro_sql": "{% macro comment_on_column_sql(column_path, escaped_comment) %}\nCOMMENT ON COLUMN {{ column_path }} IS '{{ escaped_comment }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7947228, "supported_languages": null}, "macro.dbt_databricks.databricks__persist_docs": {"name": "databricks__persist_docs", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.databricks__persist_docs", "macro_sql": "{% macro databricks__persist_docs(relation, model, for_relation, for_columns) -%}\n  {%- if for_relation and config.persist_relation_docs() and model.description %}\n    {{ run_query_as(alter_relation_comment_sql(relation, model.description), 'alter_relation_comment', fetch_result=False) }}\n  {% endif %}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {%- set existing_columns = adapter.get_columns_in_relation(relation) -%}\n    {%- set columns_to_persist_docs = adapter.get_persist_doc_columns(existing_columns, model.columns) -%}\n    {{ alter_column_comment(relation, columns_to_persist_docs) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.alter_relation_comment_sql", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7954144, "supported_languages": null}, "macro.dbt_databricks.alter_relation_comment_sql": {"name": "alter_relation_comment_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.alter_relation_comment_sql", "macro_sql": "{% macro alter_relation_comment_sql(relation, description) %}\nCOMMENT ON {{ relation.type.upper() }} {{ relation.render() }} IS '{{ description | replace(\"'\", \"\\\\'\") }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7956805, "supported_languages": null}, "macro.dbt_databricks.alter_column_comments": {"name": "alter_column_comments", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt_databricks.alter_column_comments", "macro_sql": "{% macro alter_column_comments(relation, column_dict) %}\n  {% for column, comment in column_dict.items() %}\n    {{ log('Updating comment for column ' ~ column ~ ' with comment ' ~ comment) }}\n    {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n    {% set column_path = relation.render() ~ '.' ~ column %}\n    {{ run_query_as(comment_on_column_sql(column_path, escaped_comment), 'main', fetch_result=False) }}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.comment_on_column_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.796253, "supported_languages": null}, "macro.dbt_databricks.databricks__py_write_table": {"name": "databricks__py_write_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.databricks__py_write_table", "macro_sql": "{% macro databricks__py_write_table(compiled_code, target_relation) %}\n{{ compiled_code }}\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\nimport pyspark\n\n{{ py_try_import('pyspark.sql.connect.dataframe', 'newer_pyspark_available') }}\n{{ py_try_import('pandas', 'pandas_available') }}\n{{ py_try_import('pyspark.pandas', 'pyspark_pandas_api_available') }}\n{{ py_try_import('databricks.koalas', 'koalas_available') }}\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\n\nif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    if pyspark_pandas_api_available:\n        df = pyspark.pandas.frame.DataFrame(df)\n    elif koalas_available:\n        df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif newer_pyspark_available and isinstance(df, pyspark.sql.connect.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n    df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n    df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    df = spark.createDataFrame(df)\nelse:\n    msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n    raise Exception(msg)\n\nwriter = (\n    df.write\n        .mode(\"overwrite\")\n        .option(\"overwriteSchema\", \"true\")\n{{ py_get_writer_options()|indent(8, True) }}\n)\n\nwriter.saveAsTable(\"{{ target_relation }}\")\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.py_try_import", "macro.dbt_databricks.py_get_writer_options"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7974644, "supported_languages": null}, "macro.dbt_databricks.py_get_writer_options": {"name": "py_get_writer_options", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.py_get_writer_options", "macro_sql": "\n\n{%- macro py_get_writer_options() -%}\n{%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n{%- set file_format = config.get('file_format', validator=validation.any[basestring])|default('delta', true) -%}\n{%- set partition_by = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n{%- set liquid_clustered_by = config.get('liquid_clustered_by', validator=validation.any[list, basestring]) -%}\n{%- set clustered_by = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n{%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n.format(\"{{ file_format }}\")\n{%- if location_root is not none %}\n{%- set model_path = adapter.compute_external_path(config, model, is_incremental()) %}\n.option(\"path\", \"{{ model_path }}\")\n{%- endif -%}\n{%- if partition_by is not none -%}\n    {%- if partition_by is string -%}\n        {%- set partition_by = [partition_by] -%}\n    {%- endif %}\n.partitionBy({{ partition_by }})\n{%- endif -%}\n{%- if liquid_clustered_by and not is_incremental() -%}\n    {%- if liquid_clustered_by is string -%}\n        {%- set liquid_clustered_by = [liquid_clustered_by] -%}\n    {%- endif %}\n.clusterBy({{ liquid_clustered_by }})\n{%- endif -%}\n{%- if (clustered_by is not none) and (buckets is not none) -%}\n    {%- if clustered_by is string -%}\n        {%- set clustered_by = [clustered_by] -%}\n    {%- endif %}\n.bucketBy({{ buckets }}, {{ clustered_by }})\n{%- endif -%}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7992346, "supported_languages": null}, "macro.dbt_databricks.py_try_import": {"name": "py_try_import", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.py_try_import", "macro_sql": "{% macro py_try_import(library, var_name) -%}\n# make sure {{ library }} exists before using it\ntry:\n    import {{ library }}\n    {{ var_name }} = True\nexcept ImportError:\n    {{ var_name }} = False\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.7994578, "supported_languages": null}, "macro.dbt_databricks.create_python_intermediate_table": {"name": "create_python_intermediate_table", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/python.sql", "original_file_path": "macros/adapters/python.sql", "unique_id": "macro.dbt_databricks.create_python_intermediate_table", "macro_sql": "{% macro create_python_intermediate_table(relation, compiled_code) %}\n{{ compiled_code }}\n\n{%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n{%- set file_format = config.get('file_format', validator=validation.any[basestring])|default('delta', true) -%}\n\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\nimport pyspark\n\n{{ py_try_import('pyspark.sql.connect.dataframe', 'newer_pyspark_available') }}\n{{ py_try_import('pandas', 'pandas_available') }}\n{{ py_try_import('pyspark.pandas', 'pyspark_pandas_api_available') }}\n{{ py_try_import('databricks.koalas', 'koalas_available') }}\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\n\nif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    if pyspark_pandas_api_available:\n        df = pyspark.pandas.frame.DataFrame(df)\n    elif koalas_available:\n        df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif newer_pyspark_available and isinstance(df, pyspark.sql.connect.dataframe.DataFrame):\n    pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n    df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n    df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n    df = spark.createDataFrame(df)\nelse:\n    msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n    raise Exception(msg)\n\nwriter = (\n    df.write\n        .mode(\"overwrite\")\n        .option(\"overwriteSchema\", \"true\")\n        .format(\"{{ file_format }}\")\n{%- if location_root is not none -%}\n{%- set model_path = adapter.compute_external_path(config, model, True) %}\n        .option(\"path\", \"{{ model_path }}\")\n{%- endif -%}\n)\n\nwriter.saveAsTable(\"{{ relation.render() }}\")\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.py_try_import"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8004344, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments": {"name": "get_columns_comments", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments", "macro_sql": "{% macro get_columns_comments(relation) -%}\n  {{ return(run_query_as(get_columns_comments_sql(relation), 'get_columns_comments')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_columns_comments_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8009727, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_sql": {"name": "get_columns_comments_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_sql", "macro_sql": "{% macro get_columns_comments_sql(relation) %}\nDESCRIBE TABLE {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8011334, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_as_json": {"name": "get_columns_comments_as_json", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_as_json", "macro_sql": "{% macro get_columns_comments_as_json(relation) -%}\n  {{ return(run_query_as(get_columns_comments_as_json_sql(relation), 'get_columns_comments_as_json')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.get_columns_comments_as_json_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8013191, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_as_json_sql": {"name": "get_columns_comments_as_json_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_as_json_sql", "macro_sql": "{% macro get_columns_comments_as_json_sql(relation) %}\n  DESCRIBE TABLE EXTENDED {{ relation.render() }} AS JSON\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8014565, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_via_information_schema": {"name": "get_columns_comments_via_information_schema", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_via_information_schema", "macro_sql": "{% macro get_columns_comments_via_information_schema(relation) -%}\n  {{ run_query_as(repair_table_sql(relation), 'repair_table', fetch_result=False) }}\n  {{ return(run_query_as(get_columns_comments_via_information_schema_sql(relation), 'get_columns_comments_via_information_schema')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.repair_table_sql", "macro.dbt_databricks.get_columns_comments_via_information_schema_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8017433, "supported_languages": null}, "macro.dbt_databricks.repair_table_sql": {"name": "repair_table_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.repair_table_sql", "macro_sql": "{% macro repair_table_sql(relation) %}\nREPAIR TABLE {{ relation.render() }} SYNC METADATA\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8019328, "supported_languages": null}, "macro.dbt_databricks.get_columns_comments_via_information_schema_sql": {"name": "get_columns_comments_via_information_schema_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.get_columns_comments_via_information_schema_sql", "macro_sql": "{% macro get_columns_comments_via_information_schema_sql(relation) %}\nSELECT\n  column_name,\n  full_data_type,\n  comment\nFROM `system`.`information_schema`.`columns`\nWHERE\n  table_catalog = '{{ relation.database|lower }}' and\n  table_schema = '{{ relation.schema|lower }}' and \n  table_name = '{{ relation.identifier|lower }}'\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8023348, "supported_languages": null}, "macro.dbt_databricks.databricks__alter_relation_add_remove_columns": {"name": "databricks__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.databricks__alter_relation_add_remove_columns", "macro_sql": "{% macro databricks__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n  {% if remove_columns %}\n    {{ run_query_as(drop_columns_sql(relation, remove_columns), 'alter_relation_remove_columns', fetch_result=False) }}\n  {% endif %}\n\n  {% if add_columns %}\n    {{ run_query_as(add_columns_sql(relation, add_columns), 'alter_relation_add_columns', fetch_result=False) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.run_query_as", "macro.dbt_databricks.drop_columns_sql", "macro.dbt_databricks.add_columns_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8031325, "supported_languages": null}, "macro.dbt_databricks.drop_columns_sql": {"name": "drop_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.drop_columns_sql", "macro_sql": "{% macro drop_columns_sql(relation, remove_columns) %}\nALTER TABLE {{ relation.render() }} DROP COLUMNS ({{ api.Column.format_remove_column_list(remove_columns) }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.80335, "supported_languages": null}, "macro.dbt_databricks.add_columns_sql": {"name": "add_columns_sql", "resource_type": "macro", "package_name": "dbt_databricks", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt_databricks.add_columns_sql", "macro_sql": "{% macro add_columns_sql(relation, add_columns) %}\nALTER TABLE {{ relation.render() }} ADD COLUMNS ({{ api.Column.format_add_column_list(add_columns) }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.80355, "supported_languages": null}, "macro.dbt_spark.spark__copy_grants": {"name": "spark__copy_grants", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__copy_grants", "macro_sql": "{% macro spark__copy_grants() %}\n\n    {% if config.materialized == 'view' %}\n        {#-- Spark views don't copy grants when they're replaced --#}\n        {{ return(False) }}\n\n    {% else %}\n      {#-- This depends on how we're replacing the table, which depends on its file format\n        -- Just play it safe by assuming that grants have been copied over, and need to be checked / possibly revoked\n        -- We can make this more efficient in the future\n      #}\n        {{ return(True) }}\n\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.804072, "supported_languages": null}, "macro.dbt_spark.spark__get_grant_sql": {"name": "spark__get_grant_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_grant_sql", "macro_sql": "\n\n\n{%- macro spark__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation }} to {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8042996, "supported_languages": null}, "macro.dbt_spark.spark__get_revoke_sql": {"name": "spark__get_revoke_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__get_revoke_sql", "macro_sql": "\n\n\n{%- macro spark__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation }} from {{ adapter.quote(grantees[0]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8045475, "supported_languages": null}, "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement": {"name": "spark__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n\n{%- macro spark__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(False) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.804676, "supported_languages": null}, "macro.dbt_spark.spark__call_dcl_statements": {"name": "spark__call_dcl_statements", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/apply_grants.sql", "original_file_path": "macros/apply_grants.sql", "unique_id": "macro.dbt_spark.spark__call_dcl_statements", "macro_sql": "{% macro spark__call_dcl_statements(dcl_statement_list) %}\n    {% for dcl_statement in dcl_statement_list %}\n        {% call statement('grant_or_revoke') %}\n            {{ dcl_statement }}\n        {% endcall %}\n    {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8049366, "supported_languages": null}, "macro.dbt_spark.tblproperties_clause": {"name": "tblproperties_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.tblproperties_clause", "macro_sql": "{% macro tblproperties_clause() %}\n  {{ return(adapter.dispatch('tblproperties_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__tblproperties_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8077545, "supported_languages": null}, "macro.dbt_spark.spark__tblproperties_clause": {"name": "spark__tblproperties_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__tblproperties_clause", "macro_sql": "{% macro spark__tblproperties_clause() -%}\n  {%- set tblproperties = config.get('tblproperties') -%}\n  {%- if tblproperties is not none %}\n    tblproperties (\n      {%- for prop in tblproperties -%}\n      '{{ prop }}' = '{{ tblproperties[prop] }}' {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8081944, "supported_languages": null}, "macro.dbt_spark.file_format_clause": {"name": "file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.file_format_clause", "macro_sql": "{% macro file_format_clause() %}\n  {{ return(adapter.dispatch('file_format_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__file_format_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.808443, "supported_languages": null}, "macro.dbt_spark.spark__file_format_clause": {"name": "spark__file_format_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__file_format_clause", "macro_sql": "{% macro spark__file_format_clause() %}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8087583, "supported_languages": null}, "macro.dbt_spark.location_clause": {"name": "location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.location_clause", "macro_sql": "{% macro location_clause() %}\n  {{ return(adapter.dispatch('location_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__location_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8089375, "supported_languages": null}, "macro.dbt_spark.spark__location_clause": {"name": "spark__location_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__location_clause", "macro_sql": "{% macro spark__location_clause() %}\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n    location '{{ location_root }}/{{ identifier }}'\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8093286, "supported_languages": null}, "macro.dbt_spark.options_clause": {"name": "options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.options_clause", "macro_sql": "{% macro options_clause() -%}\n  {{ return(adapter.dispatch('options_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__options_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.809505, "supported_languages": null}, "macro.dbt_spark.spark__options_clause": {"name": "spark__options_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__options_clause", "macro_sql": "{% macro spark__options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8106534, "supported_languages": null}, "macro.dbt_spark.comment_clause": {"name": "comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.comment_clause", "macro_sql": "{% macro comment_clause() %}\n  {{ return(adapter.dispatch('comment_clause', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.810847, "supported_languages": null}, "macro.dbt_spark.spark__comment_clause": {"name": "spark__comment_clause", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__comment_clause", "macro_sql": "{% macro spark__comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {% endif %}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.811401, "supported_languages": null}, "macro.dbt_spark.partition_cols": {"name": "partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.partition_cols", "macro_sql": "{% macro partition_cols(label, required=false) %}\n  {{ return(adapter.dispatch('partition_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8116322, "supported_languages": null}, "macro.dbt_spark.spark__partition_cols": {"name": "spark__partition_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__partition_cols", "macro_sql": "{% macro spark__partition_cols(label, required=false) %}\n  {%- set cols = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8122127, "supported_languages": null}, "macro.dbt_spark.clustered_cols": {"name": "clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.clustered_cols", "macro_sql": "{% macro clustered_cols(label, required=false) %}\n  {{ return(adapter.dispatch('clustered_cols', 'dbt')(label, required)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__clustered_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8124523, "supported_languages": null}, "macro.dbt_spark.spark__clustered_cols": {"name": "spark__clustered_cols", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__clustered_cols", "macro_sql": "{% macro spark__clustered_cols(label, required=false) %}\n  {%- set cols = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n  {%- if (cols is not none) and (buckets is not none) %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    ) into {{ buckets }} buckets\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8132308, "supported_languages": null}, "macro.dbt_spark.fetch_tbl_properties": {"name": "fetch_tbl_properties", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.fetch_tbl_properties", "macro_sql": "{% macro fetch_tbl_properties(relation) -%}\n  {% call statement('list_properties', fetch_result=True) -%}\n    SHOW TBLPROPERTIES {{ relation }}\n  {% endcall %}\n  {% do return(load_result('list_properties').table) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8135152, "supported_languages": null}, "macro.dbt_spark.create_temporary_view": {"name": "create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.create_temporary_view", "macro_sql": "{% macro create_temporary_view(relation, compiled_code) -%}\n  {{ return(adapter.dispatch('create_temporary_view', 'dbt')(relation, compiled_code)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__create_temporary_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.813733, "supported_languages": null}, "macro.dbt_spark.spark__create_temporary_view": {"name": "spark__create_temporary_view", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_temporary_view", "macro_sql": "{% macro spark__create_temporary_view(relation, compiled_code) -%}\n    create or replace temporary view {{ relation }} as\n      {{ compiled_code }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.813882, "supported_languages": null}, "macro.dbt_spark.spark__create_table_as": {"name": "spark__create_table_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_table_as", "macro_sql": "{%- macro spark__create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {%- if language == 'sql' -%}\n    {%- if temporary -%}\n      {{ create_temporary_view(relation, compiled_code) }}\n    {%- else -%}\n      {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'iceberg'] %}\n        create or replace table {{ relation }}\n      {% else %}\n        create table {{ relation }}\n      {% endif %}\n      {%- set contract_config = config.get('contract') -%}\n      {%- if contract_config.enforced -%}\n        {{ get_assert_columns_equivalent(compiled_code) }}\n        {%- set compiled_code = get_select_subquery(compiled_code) %}\n      {% endif %}\n      {{ file_format_clause() }}\n      {{ options_clause() }}\n      {{ tblproperties_clause() }}\n      {{ partition_cols(label=\"partitioned by\") }}\n      {{ clustered_cols(label=\"clustered by\") }}\n      {{ location_clause() }}\n      {{ comment_clause() }}\n\n      as\n      {{ compiled_code }}\n    {%- endif -%}\n  {%- elif language == 'python' -%}\n    {#--\n    N.B. Python models _can_ write to temp views HOWEVER they use a different session\n    and have already expired by the time they need to be used (I.E. in merges for incremental models)\n\n    TODO: Deep dive into spark sessions to see if we can reuse a single session for an entire\n    dbt invocation.\n     --#}\n    {{ py_write_table(compiled_code=compiled_code, target_relation=relation) }}\n  {%- endif -%}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_select_subquery", "macro.dbt_spark.file_format_clause", "macro.dbt_spark.options_clause", "macro.dbt_spark.tblproperties_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt_spark.py_write_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8157096, "supported_languages": null}, "macro.dbt_spark.persist_constraints": {"name": "persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.persist_constraints", "macro_sql": "{% macro persist_constraints(relation, model) %}\n  {{ return(adapter.dispatch('persist_constraints', 'dbt')(relation, model)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8159811, "supported_languages": null}, "macro.dbt_spark.spark__persist_constraints": {"name": "spark__persist_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_constraints", "macro_sql": "{% macro spark__persist_constraints(relation, model) %}\n  {%- set contract_config = config.get('contract') -%}\n  {% if contract_config.enforced and config.get('file_format', 'delta') == 'delta' %}\n    {% do alter_table_add_constraints(relation, model.constraints) %}\n    {% do alter_column_set_constraints(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.alter_table_add_constraints", "macro.dbt_spark.alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8165126, "supported_languages": null}, "macro.dbt_spark.alter_table_add_constraints": {"name": "alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_table_add_constraints", "macro_sql": "{% macro alter_table_add_constraints(relation, constraints) %}\n  {{ return(adapter.dispatch('alter_table_add_constraints', 'dbt')(relation, constraints)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_table_add_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8167567, "supported_languages": null}, "macro.dbt_spark.spark__alter_table_add_constraints": {"name": "spark__alter_table_add_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_table_add_constraints", "macro_sql": "{% macro spark__alter_table_add_constraints(relation, constraints) %}\n  {% for constraint in constraints %}\n    {% if constraint.type == 'check' and not is_incremental() %}\n      {%- set constraint_hash = local_md5(column_name ~ \";\" ~ constraint.expression ~ \";\" ~ loop.index) -%}\n      {% call statement() %}\n        alter table {{ relation }} add constraint {{ constraint.name if constraint.name else constraint_hash }} check ({{ constraint.expression }});\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.is_incremental", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8173585, "supported_languages": null}, "macro.dbt_spark.alter_column_set_constraints": {"name": "alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.alter_column_set_constraints", "macro_sql": "{% macro alter_column_set_constraints(relation, column_dict) %}\n  {{ return(adapter.dispatch('alter_column_set_constraints', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_set_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8175838, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_set_constraints": {"name": "spark__alter_column_set_constraints", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_set_constraints", "macro_sql": "{% macro spark__alter_column_set_constraints(relation, column_dict) %}\n  {% for column_name in column_dict %}\n    {% set constraints = column_dict[column_name]['constraints'] %}\n    {% for constraint in constraints %}\n      {% if constraint.type != 'not_null' %}\n        {{ exceptions.warn('Invalid constraint for column ' ~ column_name ~ '. Only `not_null` is supported.') }}\n      {% else %}\n        {% set quoted_name = adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name %}\n        {% call statement() %}\n          alter table {{ relation }} change column {{ quoted_name }} set not null {{ constraint.expression or \"\" }};\n        {% endcall %}\n      {% endif %}\n    {% endfor %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8183668, "supported_languages": null}, "macro.dbt_spark.get_column_comment_sql": {"name": "get_column_comment_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_column_comment_sql", "macro_sql": "{% macro get_column_comment_sql(column_name, column_dict) -%}\n  {% if column_name in column_dict and column_dict[column_name][\"description\"] -%}\n    {% set escaped_description = column_dict[column_name][\"description\"] | replace(\"'\", \"\\\\'\") %}\n    {% set column_comment_clause = \"comment '\" ~ escaped_description ~ \"'\" %}\n  {%- endif -%}\n  {{ adapter.quote(column_name) }} {{ column_comment_clause }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.818854, "supported_languages": null}, "macro.dbt_spark.get_persist_docs_column_list": {"name": "get_persist_docs_column_list", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_persist_docs_column_list", "macro_sql": "{% macro get_persist_docs_column_list(model_columns, query_columns) %}\n  {% for column_name in query_columns %}\n    {{ get_column_comment_sql(column_name, model_columns) }}\n    {{- \", \" if not loop.last else \"\" }}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.get_column_comment_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.819174, "supported_languages": null}, "macro.dbt_spark.spark__create_view_as": {"name": "spark__create_view_as", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_view_as", "macro_sql": "{% macro spark__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {% if config.persist_column_docs() -%}\n    {% set model_columns = model.columns %}\n    {% set query_columns = get_columns_in_query(sql) %}\n    (\n    {{ get_persist_docs_column_list(model_columns, query_columns) }}\n    )\n  {% endif %}\n  {{ comment_clause() }}\n  {%- set contract_config = config.get('contract') -%}\n  {%- if contract_config.enforced -%}\n    {{ get_assert_columns_equivalent(sql) }}\n  {%- endif %}\n  as\n    {{ sql }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query", "macro.dbt_spark.get_persist_docs_column_list", "macro.dbt_spark.comment_clause", "macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8197663, "supported_languages": null}, "macro.dbt_spark.spark__create_schema": {"name": "spark__create_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__create_schema", "macro_sql": "{% macro spark__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{relation}}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8199525, "supported_languages": null}, "macro.dbt_spark.spark__drop_schema": {"name": "spark__drop_schema", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_schema", "macro_sql": "{% macro spark__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation }} cascade\n  {%- endcall -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.820131, "supported_languages": null}, "macro.dbt_spark.get_columns_in_relation_raw": {"name": "get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.get_columns_in_relation_raw", "macro_sql": "{% macro get_columns_in_relation_raw(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation_raw', 'dbt')(relation)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation_raw"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.820325, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation_raw": {"name": "spark__get_columns_in_relation_raw", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation_raw", "macro_sql": "{% macro spark__get_columns_in_relation_raw(relation) -%}\n  {% call statement('get_columns_in_relation_raw', fetch_result=True) %}\n      describe extended {{ relation }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation_raw').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.820705, "supported_languages": null}, "macro.dbt_spark.spark__get_columns_in_relation": {"name": "spark__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__get_columns_in_relation", "macro_sql": "{% macro spark__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      describe extended {{ relation.include(schema=(schema is not none)) }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8210862, "supported_languages": null}, "macro.dbt_spark.spark__list_relations_without_caching": {"name": "spark__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_relations_without_caching", "macro_sql": "{% macro spark__list_relations_without_caching(relation) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    show table extended in {{ relation.schema }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8213906, "supported_languages": null}, "macro.dbt_spark.list_relations_show_tables_without_caching": {"name": "list_relations_show_tables_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.list_relations_show_tables_without_caching", "macro_sql": "{% macro list_relations_show_tables_without_caching(schema_relation) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('list_relations_without_caching_show_tables', fetch_result=True) -%}\n    show tables in {{ schema_relation.schema }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching_show_tables').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8217075, "supported_languages": null}, "macro.dbt_spark.describe_table_extended_without_caching": {"name": "describe_table_extended_without_caching", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.describe_table_extended_without_caching", "macro_sql": "{% macro describe_table_extended_without_caching(table_name) %}\n  {#-- Spark with iceberg tables don't work with show table extended for #}\n  {#-- V2 iceberg tables #}\n  {#-- https://issues.apache.org/jira/browse/SPARK-33393 #}\n  {% call statement('describe_table_extended_without_caching', fetch_result=True) -%}\n    describe extended {{ table_name }}\n  {% endcall %}\n  {% do return(load_result('describe_table_extended_without_caching').table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.822011, "supported_languages": null}, "macro.dbt_spark.spark__list_schemas": {"name": "spark__list_schemas", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__list_schemas", "macro_sql": "{% macro spark__list_schemas(database) -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    show databases\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8222892, "supported_languages": null}, "macro.dbt_spark.spark__rename_relation": {"name": "spark__rename_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__rename_relation", "macro_sql": "{% macro spark__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    {% if not from_relation.type %}\n      {% do exceptions.raise_database_error(\"Cannot rename a relation with a blank type: \" ~ from_relation.identifier) %}\n    {% elif from_relation.type in ('table') %}\n        alter table {{ from_relation }} rename to {{ to_relation }}\n    {% elif from_relation.type == 'view' %}\n        alter view {{ from_relation }} rename to {{ to_relation }}\n    {% else %}\n      {% do exceptions.raise_database_error(\"Unknown type '\" ~ from_relation.type ~ \"' for relation: \" ~ from_relation.identifier) %}\n    {% endif %}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8230007, "supported_languages": null}, "macro.dbt_spark.spark__drop_relation": {"name": "spark__drop_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__drop_relation", "macro_sql": "{% macro spark__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8232632, "supported_languages": null}, "macro.dbt_spark.spark__generate_database_name": {"name": "spark__generate_database_name", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__generate_database_name", "macro_sql": "{% macro spark__generate_database_name(custom_database_name=none, node=none) -%}\n  {% do return(None) %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8234348, "supported_languages": null}, "macro.dbt_spark.spark__persist_docs": {"name": "spark__persist_docs", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__persist_docs", "macro_sql": "{% macro spark__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do alter_column_comment(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8237426, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_comment": {"name": "spark__alter_column_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_comment", "macro_sql": "{% macro spark__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'hudi', 'iceberg'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        {% if relation.is_iceberg %}\n          alter table {{ relation }} alter column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% else %}\n          alter table {{ relation }} change column\n              {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n              comment '{{ escaped_comment }}';\n        {% endif %}\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.824915, "supported_languages": null}, "macro.dbt_spark.spark__make_temp_relation": {"name": "spark__make_temp_relation", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__make_temp_relation", "macro_sql": "{% macro spark__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(path = {\n        \"identifier\": tmp_identifier\n    }) -%}\n\n    {%- set tmp_relation = tmp_relation.include(database=false, schema=false) -%}\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8253727, "supported_languages": null}, "macro.dbt_spark.spark__alter_column_type": {"name": "spark__alter_column_type", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_column_type", "macro_sql": "{% macro spark__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter column {{ column_name }} type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.825624, "supported_languages": null}, "macro.dbt_spark.spark__alter_relation_add_remove_columns": {"name": "spark__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "unique_id": "macro.dbt_spark.spark__alter_relation_add_remove_columns", "macro_sql": "{% macro spark__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if remove_columns %}\n    {% if relation.is_delta %}\n      {% set platform_name = 'Delta Lake' %}\n    {% elif relation.is_iceberg %}\n      {% set platform_name = 'Iceberg' %}\n    {% else %}\n      {% set platform_name = 'Apache Spark' %}\n    {% endif %}\n    {{ exceptions.raise_compiler_error(platform_name + ' does not support dropping columns from tables') }}\n  {% endif %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation }}\n\n       {% if add_columns %} add columns {% endif %}\n            {% for column in add_columns %}\n               {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8266616, "supported_languages": null}, "macro.dbt_spark.spark__datediff": {"name": "spark__datediff", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt_spark.spark__datediff", "macro_sql": "{% macro spark__datediff(first_date, second_date, datepart) %}\n\n    {%- if datepart in ['day', 'week', 'month', 'quarter', 'year'] -%}\n\n        {# make sure the dates are real, otherwise raise an error asap #}\n        {% set first_date = assert_not_null('date', first_date) %}\n        {% set second_date = assert_not_null('date', second_date) %}\n\n    {%- endif -%}\n\n    {%- if datepart == 'day' -%}\n\n        datediff({{second_date}}, {{first_date}})\n\n    {%- elif datepart == 'week' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(datediff({{second_date}}, {{first_date}})/7)\n            else ceil(datediff({{second_date}}, {{first_date}})/7)\n            end\n\n        -- did we cross a week boundary (Sunday)?\n        + case\n            when {{first_date}} < {{second_date}} and dayofweek({{second_date}}) < dayofweek({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofweek({{second_date}}) > dayofweek({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'month' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}})))\n            else ceil(months_between(date({{second_date}}), date({{first_date}})))\n            end\n\n        -- did we cross a month boundary?\n        + case\n            when {{first_date}} < {{second_date}} and dayofmonth({{second_date}}) < dayofmonth({{first_date}}) then 1\n            when {{first_date}} > {{second_date}} and dayofmonth({{second_date}}) > dayofmonth({{first_date}}) then -1\n            else 0 end\n\n    {%- elif datepart == 'quarter' -%}\n\n        case when {{first_date}} < {{second_date}}\n            then floor(months_between(date({{second_date}}), date({{first_date}}))/3)\n            else ceil(months_between(date({{second_date}}), date({{first_date}}))/3)\n            end\n\n        -- did we cross a quarter boundary?\n        + case\n            when {{first_date}} < {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                < (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then 1\n            when {{first_date}} > {{second_date}} and (\n                (dayofyear({{second_date}}) - (quarter({{second_date}}) * 365/4))\n                > (dayofyear({{first_date}}) - (quarter({{first_date}}) * 365/4))\n            ) then -1\n            else 0 end\n\n    {%- elif datepart == 'year' -%}\n\n        year({{second_date}}) - year({{first_date}})\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set divisor -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        case when {{first_date}} < {{second_date}}\n            then ceil((\n                {# make sure the timestamps are real, otherwise raise an error asap #}\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            else floor((\n                {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', second_date)) }}\n                - {{ assert_not_null('to_unix_timestamp', assert_not_null('to_timestamp', first_date)) }}\n            ) / {{divisor}})\n            end\n\n            {% if datepart == 'millisecond' %}\n                + cast(date_format({{second_date}}, 'SSS') as int)\n                - cast(date_format({{first_date}}, 'SSS') as int)\n            {% endif %}\n\n            {% if datepart == 'microsecond' %}\n                {% set capture_str = '[0-9]{4}-[0-9]{2}-[0-9]{2}.[0-9]{2}:[0-9]{2}:[0-9]{2}.([0-9]{6})' %}\n                -- Spark doesn't really support microseconds, so this is a massive hack!\n                -- It will only work if the timestamp-string is of the format\n                -- 'yyyy-MM-dd-HH mm.ss.SSSSSS'\n                + cast(regexp_extract({{second_date}}, '{{capture_str}}', 1) as int)\n                - cast(regexp_extract({{first_date}}, '{{capture_str}}', 1) as int)\n            {% endif %}\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro datediff not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8305845, "supported_languages": null}, "macro.dbt_spark.spark__dateadd": {"name": "spark__dateadd", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt_spark.spark__dateadd", "macro_sql": "{% macro spark__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {%- set clock_component -%}\n        {# make sure the dates + timestamps are real, otherwise raise an error asap #}\n        to_unix_timestamp({{ assert_not_null('to_timestamp', from_date_or_timestamp) }})\n        - to_unix_timestamp({{ assert_not_null('date', from_date_or_timestamp) }})\n    {%- endset -%}\n\n    {%- if datepart in ['day', 'week'] -%}\n\n        {%- set multiplier = 7 if datepart == 'week' else 1 -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                date_add(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ['month', 'quarter', 'year'] -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'month' -%} 1\n            {%- elif datepart == 'quarter' -%} 3\n            {%- elif datepart == 'year' -%} 12\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            to_unix_timestamp(\n                add_months(\n                    {{ assert_not_null('date', from_date_or_timestamp) }},\n                    cast({{interval}} * {{multiplier}} as int)\n                )\n            ) + {{clock_component}}\n        )\n\n    {%- elif datepart in ('hour', 'minute', 'second', 'millisecond', 'microsecond') -%}\n\n        {%- set multiplier -%}\n            {%- if datepart == 'hour' -%} 3600\n            {%- elif datepart == 'minute' -%} 60\n            {%- elif datepart == 'second' -%} 1\n            {%- elif datepart == 'millisecond' -%} (1/1000000)\n            {%- elif datepart == 'microsecond' -%} (1/1000000)\n            {%- endif -%}\n        {%- endset -%}\n\n        to_timestamp(\n            {{ assert_not_null('to_unix_timestamp', from_date_or_timestamp) }}\n            + cast({{interval}} * {{multiplier}} as int)\n        )\n\n    {%- else -%}\n\n        {{ exceptions.raise_compiler_error(\"macro dateadd not implemented for datepart ~ '\" ~ datepart ~ \"' ~ on Spark\") }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8327603, "supported_languages": null}, "macro.dbt_spark.spark__concat": {"name": "spark__concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt_spark.spark__concat", "macro_sql": "{% macro spark__concat(fields) -%}\n    concat({{ fields|join(', ') }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8330073, "supported_languages": null}, "macro.dbt_spark.spark__date": {"name": "spark__date", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt_spark.spark__date", "macro_sql": "{% macro spark__date(year, month, day) -%}\n    {%- set dt = modules.datetime.date(year, month, day) -%}\n    {%- set iso_8601_formatted_date = dt.strftime('%Y-%m-%d') -%}\n    to_date('{{ iso_8601_formatted_date }}', 'yyyy-MM-dd')\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.83339, "supported_languages": null}, "macro.dbt_spark.spark__bool_or": {"name": "spark__bool_or", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt_spark.spark__bool_or", "macro_sql": "{% macro spark__bool_or(expression) -%}\n\n    max({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8335636, "supported_languages": null}, "macro.dbt_spark.spark__array_construct": {"name": "spark__array_construct", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt_spark.spark__array_construct", "macro_sql": "{% macro spark__array_construct(inputs, data_type) -%}\n    array( {{ inputs|join(' , ') }} )\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.833759, "supported_languages": null}, "macro.dbt_spark.assert_not_null": {"name": "assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.assert_not_null", "macro_sql": "{% macro assert_not_null(function, arg) -%}\n  {{ return(adapter.dispatch('assert_not_null', 'dbt')(function, arg)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__assert_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8340554, "supported_languages": null}, "macro.dbt_spark.spark__assert_not_null": {"name": "spark__assert_not_null", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/assert_not_null.sql", "original_file_path": "macros/utils/assert_not_null.sql", "unique_id": "macro.dbt_spark.spark__assert_not_null", "macro_sql": "{% macro spark__assert_not_null(function, arg) %}\n\n    coalesce({{function}}({{arg}}), nvl2({{function}}({{arg}}), assert_true({{function}}({{arg}}) is not null), null))\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.834275, "supported_languages": null}, "macro.dbt_spark.spark__split_part": {"name": "spark__split_part", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt_spark.spark__split_part", "macro_sql": "{% macro spark__split_part(string_text, delimiter_text, part_number) %}\n\n    {% set delimiter_expr %}\n\n        -- escape if starts with a special character\n        case when regexp_extract({{ delimiter_text }}, '([^A-Za-z0-9])(.*)', 1) != '_'\n            then concat('\\\\', {{ delimiter_text }})\n            else {{ delimiter_text }} end\n\n    {% endset %}\n\n    {% if part_number >= 0 %}\n\n        {% set split_part_expr %}\n\n        split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            )[({{ part_number - 1 if part_number > 0 else part_number }})]\n\n        {% endset %}\n\n    {% else %}\n\n        {% set split_part_expr %}\n\n        split(\n            {{ string_text }},\n            {{ delimiter_expr }}\n            )[(\n                length({{ string_text }})\n                - length(\n                    replace({{ string_text }},  {{ delimiter_text }}, '')\n                ) + 1 + {{ part_number }}\n            )]\n\n        {% endset %}\n\n    {% endif %}\n\n    {{ return(split_part_expr) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8352277, "supported_languages": null}, "macro.dbt_spark.spark__escape_single_quotes": {"name": "spark__escape_single_quotes", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt_spark.spark__escape_single_quotes", "macro_sql": "{% macro spark__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"\\\\'\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8354511, "supported_languages": null}, "macro.dbt_spark.spark__array_append": {"name": "spark__array_append", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt_spark.spark__array_append", "macro_sql": "{% macro spark__array_append(array, new_element) -%}\n    {{ array_concat(array, array_construct([new_element])) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.array_concat", "macro.dbt.array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8356738, "supported_languages": null}, "macro.dbt_spark.spark__current_timestamp": {"name": "spark__current_timestamp", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/timestamps.sql", "original_file_path": "macros/utils/timestamps.sql", "unique_id": "macro.dbt_spark.spark__current_timestamp", "macro_sql": "{% macro spark__current_timestamp() -%}\n    current_timestamp()\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8357906, "supported_languages": null}, "macro.dbt_spark.spark__safe_cast": {"name": "spark__safe_cast", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt_spark.spark__safe_cast", "macro_sql": "{% macro spark__safe_cast(field, type) %}\n{%- set field_clean = field.strip('\"').strip(\"'\") if (cast_from_string_unsupported_for(type) and field is string) else field -%}\ncast({{field_clean}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.cast_from_string_unsupported_for"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8362086, "supported_languages": null}, "macro.dbt_spark.cast_from_string_unsupported_for": {"name": "cast_from_string_unsupported_for", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt_spark.cast_from_string_unsupported_for", "macro_sql": "{% macro cast_from_string_unsupported_for(type) %}\n    {{ return(type.lower().startswith('struct') or type.lower().startswith('array') or type.lower().startswith('map')) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8365273, "supported_languages": null}, "macro.dbt_spark.spark__listagg": {"name": "spark__listagg", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt_spark.spark__listagg", "macro_sql": "{% macro spark__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n  {% if order_by_clause %}\n    {{ exceptions.warn(\"order_by_clause is not supported for listagg on Spark/Databricks\") }}\n  {% endif %}\n\n  {% set collect_list %} collect_list({{ measure }}) {% endset %}\n\n  {% set limited %} slice({{ collect_list }}, 1, {{ limit_num }}) {% endset %}\n\n  {% set collected = limited if limit_num else collect_list %}\n\n  {% set final %} array_join({{ collected }}, {{ delimiter_text }}) {% endset %}\n\n  {% do return(final) %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.837282, "supported_languages": null}, "macro.dbt_spark.spark__array_concat": {"name": "spark__array_concat", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt_spark.spark__array_concat", "macro_sql": "{% macro spark__array_concat(array_1, array_2) -%}\n    concat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.837499, "supported_languages": null}, "macro.dbt_spark.spark__any_value": {"name": "spark__any_value", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt_spark.spark__any_value", "macro_sql": "{% macro spark__any_value(expression) -%}\n    {#-- return any value (non-deterministic)  --#}\n    first({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8376684, "supported_languages": null}, "macro.dbt_spark.spark__can_clone_table": {"name": "spark__can_clone_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.spark__can_clone_table", "macro_sql": "{% macro spark__can_clone_table() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.838212, "supported_languages": null}, "macro.dbt_spark.spark__create_or_replace_clone": {"name": "spark__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.spark__create_or_replace_clone", "macro_sql": "{% macro spark__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace table {{ this_relation }} shallow clone {{ defer_relation }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.838367, "supported_languages": null}, "macro.dbt_spark.materialization_clone_spark": {"name": "materialization_clone_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/clone.sql", "original_file_path": "macros/materializations/clone.sql", "unique_id": "macro.dbt_spark.materialization_clone_spark", "macro_sql": "\n\n{%- materialization clone, adapter='spark' -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if file_format != 'delta' -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      shallow clone requires file_format be set to 'delta'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {%- elif other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% call statement('main') %}\n          {{ create_or_replace_clone(target_relation, defer_relation) }}\n      {% endcall %}\n\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n  {% endif %}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8411617, "supported_languages": ["sql"]}, "macro.dbt_spark.materialization_view_spark": {"name": "materialization_view_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "unique_id": "macro.dbt_spark.materialization_view_spark", "macro_sql": "{% materialization view, adapter='spark' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.841406, "supported_languages": ["sql"]}, "macro.dbt_spark.materialization_table_spark": {"name": "materialization_table_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.materialization_table_spark", "macro_sql": "{% materialization table, adapter = 'spark', supported_languages=['sql', 'python'] %}\n  {%- set language = model['language'] -%}\n  {%- set identifier = model['alias'] -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta or iceberg, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation is not none %}\n    {% set is_delta = (old_relation.is_delta and config.get('file_format', validator=validation.any[basestring]) == 'delta') %}\n    {% set is_iceberg = (old_relation.is_iceberg and config.get('file_format', validator=validation.any[basestring]) == 'iceberg') %}\n    {% set old_relation_type = old_relation.type %}\n  {% else %}\n    {% set is_delta = false %}\n    {% set is_iceberg = false %}\n    {% set old_relation_type = target_relation.type %}\n  {% endif %}\n\n  {% if not is_delta and not is_iceberg %}\n    {% set existing_relation = target_relation %}\n    {{ adapter.drop_relation(existing_relation.incorporate(type=old_relation_type)) }}\n  {% endif %}\n\n  -- build model\n  {%- call statement('main', language=language) -%}\n    {{ create_table_as(False, target_relation, compiled_code, language) }}\n  {%- endcall -%}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do persist_constraints(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt_spark.persist_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.843985, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.py_write_table": {"name": "py_write_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_write_table", "macro_sql": "{% macro py_write_table(compiled_code, target_relation) %}\n{{ compiled_code }}\n# --- Autogenerated dbt materialization code. --- #\ndbt = dbtObj(spark.table)\ndf = model(dbt, spark)\n\n# make sure pyspark exists in the namepace, for 7.3.x-scala2.12 it does not exist\nimport pyspark\n# make sure pandas exists before using it\ntry:\n  import pandas\n  pandas_available = True\nexcept ImportError:\n  pandas_available = False\n\n# make sure pyspark.pandas exists before using it\ntry:\n  import pyspark.pandas\n  pyspark_pandas_api_available = True\nexcept ImportError:\n  pyspark_pandas_api_available = False\n\n# make sure databricks.koalas exists before using it\ntry:\n  import databricks.koalas\n  koalas_available = True\nexcept ImportError:\n  koalas_available = False\n\n# preferentially convert pandas DataFrames to pandas-on-Spark or Koalas DataFrames first\n# since they know how to convert pandas DataFrames better than `spark.createDataFrame(df)`\n# and converting from pandas-on-Spark to Spark DataFrame has no overhead\nif pyspark_pandas_api_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = pyspark.pandas.frame.DataFrame(df)\nelif koalas_available and pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = databricks.koalas.frame.DataFrame(df)\n\n# convert to pyspark.sql.dataframe.DataFrame\nif isinstance(df, pyspark.sql.dataframe.DataFrame):\n  pass  # since it is already a Spark DataFrame\nelif pyspark_pandas_api_available and isinstance(df, pyspark.pandas.frame.DataFrame):\n  df = df.to_spark()\nelif koalas_available and isinstance(df, databricks.koalas.frame.DataFrame):\n  df = df.to_spark()\nelif pandas_available and isinstance(df, pandas.core.frame.DataFrame):\n  df = spark.createDataFrame(df)\nelse:\n  msg = f\"{type(df)} is not a supported type for dbt Python materialization\"\n  raise Exception(msg)\n\ndf.write.mode(\"overwrite\").format(\"{{ config.get('file_format', 'delta') }}\").option(\"overwriteSchema\", \"true\").saveAsTable(\"{{ target_relation }}\")\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.844338, "supported_languages": null}, "macro.dbt_spark.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "unique_id": "macro.dbt_spark.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n# how to execute python model in notebook\n# dbt = dbtObj(spark.table)\n# df = model(dbt, spark)\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.844446, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_hash_arguments": {"name": "spark__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_hash_arguments", "macro_sql": "{% macro spark__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as string ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8459032, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_string_as_time": {"name": "spark__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_string_as_time", "macro_sql": "{% macro spark__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.846204, "supported_languages": null}, "macro.dbt_spark.spark__snapshot_merge_sql": {"name": "spark__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__snapshot_merge_sql", "macro_sql": "{% macro spark__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    {% if target.is_iceberg %}\n      {# create view only supports a name (no catalog, or schema) #}\n      using {{ source.identifier }} as DBT_INTERNAL_SOURCE\n    {% else %}\n      using {{ source }} as DBT_INTERNAL_SOURCE\n    {% endif %}\n    on DBT_INTERNAL_SOURCE.{{ columns.dbt_scd_id }} = DBT_INTERNAL_DEST.{{ columns.dbt_scd_id }}\n    when matched\n     {% if config.get(\"dbt_valid_to_current\") %}\n       and ( DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} = {{ config.get('dbt_valid_to_current') }} or\n             DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null )\n     {% else %}\n       and DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null\n     {% endif %}\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set {{ columns.dbt_valid_to }} = DBT_INTERNAL_SOURCE.{{ columns.dbt_valid_to }}\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert *\n    ;\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8471231, "supported_languages": null}, "macro.dbt_spark.spark_build_snapshot_staging_table": {"name": "spark_build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark_build_snapshot_staging_table", "macro_sql": "{% macro spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n\n    {% if target_relation.is_iceberg %}\n      {# iceberg catalog does not support create view, but regular spark does. We removed the catalog and schema #}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=none,\n                                                    database=none,\n                                                    type='view') -%}\n    {% else %}\n      {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                    schema=target_relation.schema,\n                                                    database=none,\n                                                    type='view') -%}\n    {% endif %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8481402, "supported_languages": null}, "macro.dbt_spark.spark__post_snapshot": {"name": "spark__post_snapshot", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__post_snapshot", "macro_sql": "{% macro spark__post_snapshot(staging_relation) %}\n    {% do adapter.drop_relation(staging_relation) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.848314, "supported_languages": null}, "macro.dbt_spark.spark__create_columns": {"name": "spark__create_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.spark__create_columns", "macro_sql": "{% macro spark__create_columns(relation, columns) %}\n    {% if columns|length > 0 %}\n    {% call statement() %}\n      alter table {{ relation }} add columns (\n        {% for column in columns %}\n          `{{ column.name }}` {{ column.data_type }} {{- ',' if not loop.last -}}\n        {% endfor %}\n      );\n    {% endcall %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8488274, "supported_languages": null}, "macro.dbt_spark.materialization_snapshot_spark": {"name": "materialization_snapshot_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "unique_id": "macro.dbt_spark.materialization_snapshot_spark", "macro_sql": "{% materialization snapshot, adapter='spark' %}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format') or 'parquet' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=none,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if file_format not in ['delta', 'iceberg', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'iceberg' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_iceberg and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'iceberg' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.schema) %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.valid_snapshot_target(target_relation, columns) }}\n\n      {% set staging_table = spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.create_schema", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt_spark.spark_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8532279, "supported_languages": ["sql"]}, "macro.dbt_spark.spark__get_binding_char": {"name": "spark__get_binding_char", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__get_binding_char", "macro_sql": "{% macro spark__get_binding_char() %}\n  {{ return('?' if target.method == 'odbc' else '%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8539972, "supported_languages": null}, "macro.dbt_spark.spark__reset_csv_table": {"name": "spark__reset_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__reset_csv_table", "macro_sql": "{% macro spark__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n        {{ adapter.drop_relation(old_relation) }}\n    {% endif %}\n    {% set sql = create_csv_table(model, agate_table) %}\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8543632, "supported_languages": null}, "macro.dbt_spark.spark__load_csv_rows": {"name": "spark__load_csv_rows", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__load_csv_rows", "macro_sql": "{% macro spark__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                  {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8559, "supported_languages": null}, "macro.dbt_spark.spark__create_csv_table": {"name": "spark__create_csv_table", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "unique_id": "macro.dbt_spark.spark__create_csv_table", "macro_sql": "{% macro spark__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8572445, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_file_format": {"name": "dbt_spark_validate_get_file_format", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_file_format", "macro_sql": "{% macro dbt_spark_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'iceberg', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8582313, "supported_languages": null}, "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy": {"name": "dbt_spark_validate_get_incremental_strategy", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "unique_id": "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'append', 'merge', 'insert_overwrite', 'microbatch'\n  {%- endset %}\n\n  {% set invalid_merge_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta' or 'iceberg' or 'hudi'\n  {%- endset %}\n\n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via endpoint\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite', 'microbatch'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'iceberg', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_merge_msg) %}\n    {% endif %}\n    {% if raw_strategy in ['insert_overwrite', 'microbatch'] and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8592727, "supported_languages": null}, "macro.dbt_spark.materialization_incremental_spark": {"name": "materialization_incremental_spark", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "unique_id": "macro.dbt_spark.materialization_incremental_spark", "macro_sql": "{% materialization incremental, adapter='spark', supported_languages=['sql', 'python'] -%}\n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='parquet') -%}\n  {%- set raw_strategy = config.get('incremental_strategy') or 'append' -%}\n  {%- set grant_config = config.get('grants') -%}\n\n  {%- set file_format = dbt_spark_validate_get_file_format(raw_file_format) -%}\n  {%- set strategy = dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n\n  {#-- Set vars --#}\n\n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n  {%- set language = model['language'] -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n  {%- set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) -%}\n  {%- set target_relation = this -%}\n  {%- set existing_relation = load_relation(this) -%}\n  {% set tmp_relation = this.incorporate(path = {\"identifier\": this.identifier ~ '__dbt_tmp'}) -%}\n\n  {#-- for SQL model we will create temp view that doesn't have database and schema --#}\n  {%- if language == 'sql'-%}\n    {%- set tmp_relation = tmp_relation.include(database=false, schema=false) -%}\n  {%- endif -%}\n\n  {#-- Set Overwrite Mode --#}\n  {%- if strategy in ['insert_overwrite', 'microbatch'] and partition_by -%}\n    {%- call statement() -%}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {%- endcall -%}\n  {%- endif -%}\n\n  {#-- Run pre-hooks --#}\n  {{ run_hooks(pre_hooks) }}\n\n  {#-- Incremental run logic --#}\n  {%- if existing_relation is none -%}\n    {#-- Relation must be created --#}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- elif existing_relation.is_view or should_full_refresh() -%}\n    {#-- Relation must be dropped & recreated --#}\n    {% set is_delta = (file_format == 'delta' and existing_relation.is_delta) %}\n    {% if not is_delta %} {#-- If Delta, we will `create or replace` below, so no need to drop --#}\n      {% do adapter.drop_relation(existing_relation) %}\n    {% endif %}\n    {%- call statement('main', language=language) -%}\n      {{ create_table_as(False, target_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {% do persist_constraints(target_relation, model) %}\n  {%- else -%}\n    {#-- Relation must be merged --#}\n    {%- call statement('create_tmp_relation', language=language) -%}\n      {{ create_table_as(True, tmp_relation, compiled_code, language) }}\n    {%- endcall -%}\n    {%- do process_schema_changes(on_schema_change, tmp_relation, existing_relation) -%}\n    {%- call statement('main') -%}\n      {{ dbt_spark_get_incremental_sql(strategy, tmp_relation, target_relation, existing_relation, unique_key, incremental_predicates) }}\n    {%- endcall -%}\n    {%- if language == 'python' -%}\n      {#--\n      This is yucky.\n      See note in dbt-spark/dbt/include/spark/macros/adapters.sql\n      re: python models and temporary views.\n\n      Also, why do neither drop_relation or adapter.drop_relation work here?!\n      --#}\n      {% call statement('drop_relation') -%}\n        drop table if exists {{ tmp_relation }}\n      {%- endcall %}\n    {%- endif -%}\n  {%- endif -%}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt_spark.persist_constraints", "macro.dbt.should_full_refresh", "macro.dbt.process_schema_changes", "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8634257, "supported_languages": ["sql", "python"]}, "macro.dbt_spark.spark__get_merge_update_columns": {"name": "spark__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/column_helpers.sql", "original_file_path": "macros/materializations/incremental/column_helpers.sql", "unique_id": "macro.dbt_spark.spark__get_merge_update_columns", "macro_sql": "{% macro spark__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = None -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8643956, "supported_languages": null}, "macro.dbt_spark.get_insert_overwrite_sql": {"name": "get_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation, existing_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    {% if existing_relation.is_iceberg %}\n      {# removed table from statement for iceberg #}\n      insert overwrite {{ target_relation }}\n      {# removed partition_cols for iceberg as well #}\n    {% else %}\n      insert overwrite table {{ target_relation }}\n      {{ partition_cols(label=\"partition\") }}\n    {% endif %}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.865592, "supported_languages": null}, "macro.dbt_spark.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8659518, "supported_languages": null}, "macro.dbt_spark.spark__get_merge_sql": {"name": "spark__get_merge_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.spark__get_merge_sql", "macro_sql": "{% macro spark__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}\n  {# need dest_columns for merge_exclude_columns, default to use \"*\" #}\n  {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n  {%- set dest_columns = adapter.get_columns_in_relation(target) -%}\n  {%- set merge_update_columns = config.get('merge_update_columns') -%}\n  {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n  {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n\n  {% if unique_key %}\n      {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n          {% for key in unique_key %}\n              {% set this_key_match %}\n                  DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n              {% endset %}\n              {% do predicates.append(this_key_match) %}\n          {% endfor %}\n      {% else %}\n          {% set unique_key_match %}\n              DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n          {% endset %}\n          {% do predicates.append(unique_key_match) %}\n      {% endif %}\n  {% else %}\n      {% do predicates.append('FALSE') %}\n  {% endif %}\n\n  {{ sql_header if sql_header is not none }}\n\n  merge into {{ target }} as DBT_INTERNAL_DEST\n      using {{ source }} as DBT_INTERNAL_SOURCE\n      on {{ predicates | join(' and ') }}\n\n      when matched then update set\n        {% if update_columns -%}{%- for column_name in update_columns %}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n        {%- else %} * {% endif %}\n\n      when not matched then insert *\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.867574, "supported_languages": null}, "macro.dbt_spark.dbt_spark_get_incremental_sql": {"name": "dbt_spark_get_incremental_sql", "resource_type": "macro", "package_name": "dbt_spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "unique_id": "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro_sql": "{% macro dbt_spark_get_incremental_sql(strategy, source, target, existing, unique_key, incremental_predicates) %}\n  {%- if strategy == 'append' -%}\n    {#-- insert new records into existing table, without updating or overwriting #}\n    {{ get_insert_into_sql(source, target) }}\n  {%- elif strategy == 'insert_overwrite' -%}\n    {#-- insert statements don't like CTEs, so support them via a temp view #}\n    {{ get_insert_overwrite_sql(source, target, existing) }}\n  {%- elif strategy == 'microbatch' -%}\n    {#-- microbatch wraps insert_overwrite, and requires a partition_by config #}\n    {% set missing_partition_key_microbatch_msg -%}\n      dbt-spark 'microbatch' incremental strategy requires a `partition_by` config.\n      Ensure you are using a `partition_by` column that is of grain {{ config.get('batch_size') }}.\n    {%- endset %}\n\n    {%- if not config.get('partition_by') -%}\n      {{ exceptions.raise_compiler_error(missing_partition_key_microbatch_msg) }}\n    {%- endif -%}\n    {{ get_insert_overwrite_sql(source, target, existing) }}\n  {%- elif strategy == 'merge' -%}\n  {#-- merge all columns for datasources which implement MERGE INTO (e.g. databricks, iceberg) - schema changes are handled for us #}\n    {{ get_merge_sql(target, source, unique_key, dest_columns=none, incremental_predicates=incremental_predicates) }}\n  {%- else -%}\n    {% set no_sql_for_strategy_msg -%}\n      No known SQL for the incremental strategy provided: {{ strategy }}\n    {%- endset %}\n    {%- do exceptions.raise_compiler_error(no_sql_for_strategy_msg) -%}\n  {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.get_insert_into_sql", "macro.dbt_spark.get_insert_overwrite_sql", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8686917, "supported_languages": null}, "macro.dbt.get_fixture_sql": {"name": "get_fixture_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.get_fixture_sql", "macro_sql": "{% macro get_fixture_sql(rows, column_name_to_data_types) %}\n-- Fixture for {{ model.name }}\n{% set default_row = {} %}\n\n{%- if not column_name_to_data_types -%}\n{#-- Use defer_relation IFF it is available in the manifest and 'this' is missing from the database --#}\n{%-   set this_or_defer_relation = defer_relation if (defer_relation and not load_relation(this)) else this -%}\n{%-   set columns_in_relation = adapter.get_columns_in_relation(this_or_defer_relation) -%}\n\n{%-   set column_name_to_data_types = {} -%}\n{%-   for column in columns_in_relation -%}\n{#-- This needs to be a case-insensitive comparison --#}\n{%-     do column_name_to_data_types.update({column.name|lower: column.data_type}) -%}\n{%-   endfor -%}\n{%- endif -%}\n\n{%- if not column_name_to_data_types -%}\n    {{ exceptions.raise_compiler_error(\"Not able to get columns for unit test '\" ~ model.name ~ \"' from relation \" ~ this ~ \" because the relation doesn't exist\") }}\n{%- endif -%}\n\n{%- for column_name, column_type in column_name_to_data_types.items() -%}\n    {%- do default_row.update({column_name: (safe_cast(\"null\", column_type) | trim )}) -%}\n{%- endfor -%}\n\n{{ validate_fixture_rows(rows, row_number) }}\n\n{%- for row in rows -%}\n{%-   set formatted_row = format_row(row, column_name_to_data_types) -%}\n{%-   set default_row_copy = default_row.copy() -%}\n{%-   do default_row_copy.update(formatted_row) -%}\nselect\n{%-   for column_name, column_value in default_row_copy.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%}, {%- endif %}\n{%-   endfor %}\n{%-   if not loop.last %}\nunion all\n{%    endif %}\n{%- endfor -%}\n\n{%- if (rows | length) == 0 -%}\n    select\n    {%- for column_name, column_value in default_row.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%},{%- endif %}\n    {%- endfor %}\n    limit 0\n{%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.safe_cast", "macro.dbt.validate_fixture_rows", "macro.dbt.format_row"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8713336, "supported_languages": null}, "macro.dbt.get_expected_sql": {"name": "get_expected_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.get_expected_sql", "macro_sql": "{% macro get_expected_sql(rows, column_name_to_data_types) %}\n\n{%- if (rows | length) == 0 -%}\n    select * from dbt_internal_unit_test_actual\n    limit 0\n{%- else -%}\n{%- for row in rows -%}\n{%- set formatted_row = format_row(row, column_name_to_data_types) -%}\nselect\n{%- for column_name, column_value in formatted_row.items() %} {{ column_value }} as {{ column_name }}{% if not loop.last -%}, {%- endif %}\n{%- endfor %}\n{%- if not loop.last %}\nunion all\n{% endif %}\n{%- endfor -%}\n{%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.format_row"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8719726, "supported_languages": null}, "macro.dbt.format_row": {"name": "format_row", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.format_row", "macro_sql": "\n\n{%- macro format_row(row, column_name_to_data_types) -%}\n    {#-- generate case-insensitive formatted row --#}\n    {% set formatted_row = {} %}\n    {%- for column_name, column_value in row.items() -%}\n        {% set column_name = column_name|lower %}\n\n        {%- if column_name not in column_name_to_data_types %}\n            {#-- if user-provided row contains column name that relation does not contain, raise an error --#}\n            {% set fixture_name = \"expected output\" if model.resource_type == 'unit_test' else (\"'\" ~ model.name ~ \"'\") %}\n            {{ exceptions.raise_compiler_error(\n                \"Invalid column name: '\" ~ column_name ~ \"' in unit test fixture for \" ~ fixture_name ~ \".\"\n                \"\\nAccepted columns for \" ~ fixture_name ~ \" are: \" ~ (column_name_to_data_types.keys()|list)\n            ) }}\n        {%- endif -%}\n\n        {%- set column_type = column_name_to_data_types[column_name] %}\n\n        {#-- sanitize column_value: wrap yaml strings in quotes, apply cast --#}\n        {%- set column_value_clean = column_value -%}\n        {%- if column_value is string -%}\n            {%- set column_value_clean = dbt.string_literal(dbt.escape_single_quotes(column_value)) -%}\n        {%- elif column_value is none -%}\n            {%- set column_value_clean = 'null' -%}\n        {%- endif -%}\n\n        {%- set row_update = {column_name: safe_cast(column_value_clean, column_type) } -%}\n        {%- do formatted_row.update(row_update) -%}\n    {%- endfor -%}\n    {{ return(formatted_row) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.string_literal", "macro.dbt.escape_single_quotes", "macro.dbt.safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8733413, "supported_languages": null}, "macro.dbt.validate_fixture_rows": {"name": "validate_fixture_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.validate_fixture_rows", "macro_sql": "{%- macro validate_fixture_rows(rows, row_number) -%}\n  {{ return(adapter.dispatch('validate_fixture_rows', 'dbt')(rows, row_number)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__validate_fixture_rows"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.873576, "supported_languages": null}, "macro.dbt.default__validate_fixture_rows": {"name": "default__validate_fixture_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/unit_test_sql/get_fixture_sql.sql", "original_file_path": "macros/unit_test_sql/get_fixture_sql.sql", "unique_id": "macro.dbt.default__validate_fixture_rows", "macro_sql": "{%- macro default__validate_fixture_rows(rows, row_number) -%}\n  {# This is an abstract method for adapter overrides as needed #}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8736877, "supported_languages": null}, "macro.dbt.get_rename_intermediate_sql": {"name": "get_rename_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename_intermediate.sql", "original_file_path": "macros/relations/rename_intermediate.sql", "unique_id": "macro.dbt.get_rename_intermediate_sql", "macro_sql": "{%- macro get_rename_intermediate_sql(relation) -%}\n    {{- log('Applying RENAME INTERMEDIATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_rename_intermediate_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_rename_intermediate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8740258, "supported_languages": null}, "macro.dbt.default__get_rename_intermediate_sql": {"name": "default__get_rename_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename_intermediate.sql", "original_file_path": "macros/relations/rename_intermediate.sql", "unique_id": "macro.dbt.default__get_rename_intermediate_sql", "macro_sql": "{%- macro default__get_rename_intermediate_sql(relation) -%}\n\n    -- get the standard intermediate name\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    {{ get_rename_sql(intermediate_relation, relation.identifier) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.874255, "supported_languages": null}, "macro.dbt.get_create_intermediate_sql": {"name": "get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt.get_create_intermediate_sql", "macro_sql": "{%- macro get_create_intermediate_sql(relation, sql) -%}\n    {{- log('Applying CREATE INTERMEDIATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_intermediate_sql', 'dbt')(relation, sql) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_intermediate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8746316, "supported_languages": null}, "macro.dbt.default__get_create_intermediate_sql": {"name": "default__get_create_intermediate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_intermediate.sql", "original_file_path": "macros/relations/create_intermediate.sql", "unique_id": "macro.dbt.default__get_create_intermediate_sql", "macro_sql": "{%- macro default__get_create_intermediate_sql(relation, sql) -%}\n\n    -- get the standard intermediate name\n    {% set intermediate_relation = make_intermediate_relation(relation) %}\n\n    -- drop any pre-existing intermediate\n    {{ get_drop_sql(intermediate_relation) }};\n\n    {{ get_create_sql(intermediate_relation, sql) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_intermediate_relation", "macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.874908, "supported_languages": null}, "macro.dbt.get_rename_sql": {"name": "get_rename_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.get_rename_sql", "macro_sql": "{%- macro get_rename_sql(relation, new_name) -%}\n    {{- log('Applying RENAME to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_rename_sql', 'dbt')(relation, new_name) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8753812, "supported_languages": null}, "macro.dbt.default__get_rename_sql": {"name": "default__get_rename_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.default__get_rename_sql", "macro_sql": "{%- macro default__get_rename_sql(relation, new_name) -%}\n\n    {%- if relation.is_view -%}\n        {{ get_rename_view_sql(relation, new_name) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_rename_table_sql(relation, new_name) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_rename_materialized_view_sql(relation, new_name) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_rename_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.get_rename_view_sql", "macro.dbt.get_rename_table_sql", "macro.dbt.get_rename_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.875857, "supported_languages": null}, "macro.dbt.rename_relation": {"name": "rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation', 'dbt')(from_relation, to_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__rename_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.876079, "supported_languages": null}, "macro.dbt.default__rename_relation": {"name": "default__rename_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/rename.sql", "original_file_path": "macros/relations/rename.sql", "unique_id": "macro.dbt.default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation.render() }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8764386, "supported_languages": null}, "macro.dbt.get_create_backup_sql": {"name": "get_create_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt.get_create_backup_sql", "macro_sql": "{%- macro get_create_backup_sql(relation) -%}\n    {{- log('Applying CREATE BACKUP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_backup_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_create_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8767998, "supported_languages": null}, "macro.dbt.default__get_create_backup_sql": {"name": "default__get_create_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create_backup.sql", "original_file_path": "macros/relations/create_backup.sql", "unique_id": "macro.dbt.default__get_create_backup_sql", "macro_sql": "{%- macro default__get_create_backup_sql(relation) -%}\n\n    -- get the standard backup name\n    {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n    -- drop any pre-existing backup\n    {{ get_drop_sql(backup_relation) }};\n\n    {{ get_rename_sql(relation, backup_relation.identifier) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.get_drop_sql", "macro.dbt.get_rename_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8773305, "supported_languages": null}, "macro.dbt.get_drop_backup_sql": {"name": "get_drop_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop_backup.sql", "original_file_path": "macros/relations/drop_backup.sql", "unique_id": "macro.dbt.get_drop_backup_sql", "macro_sql": "{%- macro get_drop_backup_sql(relation) -%}\n    {{- log('Applying DROP BACKUP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_drop_backup_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.default__get_drop_backup_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8777149, "supported_languages": null}, "macro.dbt.default__get_drop_backup_sql": {"name": "default__get_drop_backup_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop_backup.sql", "original_file_path": "macros/relations/drop_backup.sql", "unique_id": "macro.dbt.default__get_drop_backup_sql", "macro_sql": "{%- macro default__get_drop_backup_sql(relation) -%}\n\n    -- get the standard backup name\n    {% set backup_relation = make_backup_relation(relation, relation.type) %}\n\n    {{ get_drop_sql(backup_relation) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.make_backup_relation", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8780677, "supported_languages": null}, "macro.dbt.get_create_sql": {"name": "get_create_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt.get_create_sql", "macro_sql": "{%- macro get_create_sql(relation, sql) -%}\n    {{- log('Applying CREATE to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_create_sql', 'dbt')(relation, sql) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8790843, "supported_languages": null}, "macro.dbt.default__get_create_sql": {"name": "default__get_create_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/create.sql", "original_file_path": "macros/relations/create.sql", "unique_id": "macro.dbt.default__get_create_sql", "macro_sql": "{%- macro default__get_create_sql(relation, sql) -%}\n\n    {%- if relation.is_view -%}\n        {{ get_create_view_as_sql(relation, sql) }}\n\n    {%- elif relation.is_table -%}\n        {{ get_create_table_as_sql(False, relation, sql) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ get_create_materialized_view_as_sql(relation, sql) }}\n\n    {%- else -%}\n        {{- exceptions.raise_compiler_error(\"`get_create_sql` has not been implemented for: \" ~ relation.type ) -}}\n\n    {%- endif -%}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.get_create_view_as_sql", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_create_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8800159, "supported_languages": null}, "macro.dbt.get_replace_sql": {"name": "get_replace_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt.get_replace_sql", "macro_sql": "{% macro get_replace_sql(existing_relation, target_relation, sql) %}\n    {{- log('Applying REPLACE to: ' ~ existing_relation) -}}\n    {{- adapter.dispatch('get_replace_sql', 'dbt')(existing_relation, target_relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8811154, "supported_languages": null}, "macro.dbt.default__get_replace_sql": {"name": "default__get_replace_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/replace.sql", "original_file_path": "macros/relations/replace.sql", "unique_id": "macro.dbt.default__get_replace_sql", "macro_sql": "{% macro default__get_replace_sql(existing_relation, target_relation, sql) %}\n\n    {# /* use a create or replace statement if possible */ #}\n\n    {% set is_replaceable = existing_relation.type == target_relation.type and existing_relation.can_be_replaced %}\n\n    {% if is_replaceable and existing_relation.is_view %}\n        {{ get_replace_view_sql(target_relation, sql) }}\n\n    {% elif is_replaceable and existing_relation.is_table %}\n        {{ get_replace_table_sql(target_relation, sql) }}\n\n    {% elif is_replaceable and existing_relation.is_materialized_view %}\n        {{ get_replace_materialized_view_sql(target_relation, sql) }}\n\n    {# /* a create or replace statement is not possible, so try to stage and/or backup to be safe */ #}\n\n    {# /* create target_relation as an intermediate relation, then swap it out with the existing one using a backup */ #}\n    {%- elif target_relation.can_be_renamed and existing_relation.can_be_renamed -%}\n        {{ get_create_intermediate_sql(target_relation, sql) }};\n        {{ get_create_backup_sql(existing_relation) }};\n        {{ get_rename_intermediate_sql(target_relation) }};\n        {{ get_drop_backup_sql(existing_relation) }}\n\n    {# /* create target_relation as an intermediate relation, then swap it out with the existing one without using a backup */ #}\n    {%- elif target_relation.can_be_renamed -%}\n        {{ get_create_intermediate_sql(target_relation, sql) }};\n        {{ get_drop_sql(existing_relation) }};\n        {{ get_rename_intermediate_sql(target_relation) }}\n\n    {# /* create target_relation in place by first backing up the existing relation */ #}\n    {%- elif existing_relation.can_be_renamed -%}\n        {{ get_create_backup_sql(existing_relation) }};\n        {{ get_create_sql(target_relation, sql) }};\n        {{ get_drop_backup_sql(existing_relation) }}\n\n    {# /* no renaming is allowed, so just drop and create */ #}\n    {%- else -%}\n        {{ get_drop_sql(existing_relation) }};\n        {{ get_create_sql(target_relation, sql) }}\n\n    {%- endif -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_replace_view_sql", "macro.dbt.get_replace_table_sql", "macro.dbt.get_replace_materialized_view_sql", "macro.dbt.get_create_intermediate_sql", "macro.dbt.get_create_backup_sql", "macro.dbt.get_rename_intermediate_sql", "macro.dbt.get_drop_backup_sql", "macro.dbt.get_drop_sql", "macro.dbt.get_create_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8824337, "supported_languages": null}, "macro.dbt.get_drop_sql": {"name": "get_drop_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.get_drop_sql", "macro_sql": "{%- macro get_drop_sql(relation) -%}\n    {{- log('Applying DROP to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_drop_sql', 'dbt')(relation) -}}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8829114, "supported_languages": null}, "macro.dbt.default__get_drop_sql": {"name": "default__get_drop_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.default__get_drop_sql", "macro_sql": "{%- macro default__get_drop_sql(relation) -%}\n\n    {%- if relation.is_view -%}\n        {{ drop_view(relation) }}\n\n    {%- elif relation.is_table -%}\n        {{ drop_table(relation) }}\n\n    {%- elif relation.is_materialized_view -%}\n        {{ drop_materialized_view(relation) }}\n\n    {%- else -%}\n        drop {{ relation.type }} if exists {{ relation.render() }} cascade\n\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt.drop_view", "macro.dbt.drop_table", "macro.dbt.drop_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8833425, "supported_languages": null}, "macro.dbt.drop_relation": {"name": "drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n    {{ return(adapter.dispatch('drop_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8835642, "supported_languages": null}, "macro.dbt.default__drop_relation": {"name": "default__drop_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n    {% call statement('drop_relation', auto_begin=False) -%}\n        {{ get_drop_sql(relation) }}\n    {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_drop_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8837867, "supported_languages": null}, "macro.dbt.drop_relation_if_exists": {"name": "drop_relation_if_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/drop.sql", "original_file_path": "macros/relations/drop.sql", "unique_id": "macro.dbt.drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8840086, "supported_languages": null}, "macro.dbt.drop_schema_named": {"name": "drop_schema_named", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/schema.sql", "original_file_path": "macros/relations/schema.sql", "unique_id": "macro.dbt.drop_schema_named", "macro_sql": "{% macro drop_schema_named(schema_name) %}\n    {{ return(adapter.dispatch('drop_schema_named', 'dbt') (schema_name)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__drop_schema_named"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8842952, "supported_languages": null}, "macro.dbt.default__drop_schema_named": {"name": "default__drop_schema_named", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/schema.sql", "original_file_path": "macros/relations/schema.sql", "unique_id": "macro.dbt.default__drop_schema_named", "macro_sql": "{% macro default__drop_schema_named(schema_name) %}\n  {% set schema_relation = api.Relation.create(schema=schema_name) %}\n  {{ adapter.drop_schema(schema_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8845713, "supported_languages": null}, "macro.dbt.get_rename_table_sql": {"name": "get_rename_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt.get_rename_table_sql", "macro_sql": "{% macro get_rename_table_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_table_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_rename_table_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8848495, "supported_languages": null}, "macro.dbt.default__get_rename_table_sql": {"name": "default__get_rename_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/rename.sql", "original_file_path": "macros/relations/table/rename.sql", "unique_id": "macro.dbt.default__get_rename_table_sql", "macro_sql": "{% macro default__get_rename_table_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_table_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.885031, "supported_languages": null}, "macro.dbt.get_create_table_as_sql": {"name": "get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.get_create_table_as_sql", "macro_sql": "{% macro get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ adapter.dispatch('get_create_table_as_sql', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8856537, "supported_languages": null}, "macro.dbt.default__get_create_table_as_sql": {"name": "default__get_create_table_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_create_table_as_sql", "macro_sql": "{% macro default__get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ return(create_table_as(temporary, relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8858519, "supported_languages": null}, "macro.dbt.create_table_as": {"name": "create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, compiled_code, language='sql') -%}\n  {# backward compatibility for create_table_as that does not support language #}\n  {% if language == \"sql\" %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code)}}\n  {% else %}\n    {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, compiled_code, language) }}\n  {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8863206, "supported_languages": null}, "macro.dbt.default__create_table_as": {"name": "default__create_table_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  {% set contract_config = config.get('contract') %}\n  {% if contract_config.enforced and (not temporary) %}\n    {{ get_assert_columns_equivalent(sql) }}\n    {{ get_table_columns_and_constraints() }}\n    {%- set sql = get_select_subquery(sql) %}\n  {% endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent", "macro.dbt.get_table_columns_and_constraints", "macro.dbt.get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8871102, "supported_languages": null}, "macro.dbt.default__get_column_names": {"name": "default__get_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_column_names", "macro_sql": "{% macro default__get_column_names() %}\n  {#- loop through user_provided_columns to get column names -#}\n    {%- set user_provided_columns = model['columns'] -%}\n    {%- for i in user_provided_columns %}\n      {%- set col = user_provided_columns[i] -%}\n      {%- set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] -%}\n      {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8876283, "supported_languages": null}, "macro.dbt.get_select_subquery": {"name": "get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.get_select_subquery", "macro_sql": "{% macro get_select_subquery(sql) %}\n  {{ return(adapter.dispatch('get_select_subquery', 'dbt')(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_select_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.88783, "supported_languages": null}, "macro.dbt.default__get_select_subquery": {"name": "default__get_select_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/create.sql", "original_file_path": "macros/relations/table/create.sql", "unique_id": "macro.dbt.default__get_select_subquery", "macro_sql": "{% macro default__get_select_subquery(sql) %}\n    select {{ adapter.dispatch('get_column_names', 'dbt')() }}\n    from (\n        {{ sql }}\n    ) as model_subq\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_column_names"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8880258, "supported_languages": null}, "macro.dbt.get_replace_table_sql": {"name": "get_replace_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt.get_replace_table_sql", "macro_sql": "{% macro get_replace_table_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_table_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_replace_table_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.888323, "supported_languages": null}, "macro.dbt.default__get_replace_table_sql": {"name": "default__get_replace_table_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/replace.sql", "original_file_path": "macros/relations/table/replace.sql", "unique_id": "macro.dbt.default__get_replace_table_sql", "macro_sql": "{% macro default__get_replace_table_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_table_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8885849, "supported_languages": null}, "macro.dbt.drop_table": {"name": "drop_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt.drop_table", "macro_sql": "{% macro drop_table(relation) -%}\n    {{- adapter.dispatch('drop_table', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8888786, "supported_languages": null}, "macro.dbt.default__drop_table": {"name": "default__drop_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/table/drop.sql", "original_file_path": "macros/relations/table/drop.sql", "unique_id": "macro.dbt.default__drop_table", "macro_sql": "{% macro default__drop_table(relation) -%}\n    drop table if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8891065, "supported_languages": null}, "macro.dbt.get_rename_view_sql": {"name": "get_rename_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt.get_rename_view_sql", "macro_sql": "{% macro get_rename_view_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_view_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_rename_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8894012, "supported_languages": null}, "macro.dbt.default__get_rename_view_sql": {"name": "default__get_rename_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/rename.sql", "original_file_path": "macros/relations/view/rename.sql", "unique_id": "macro.dbt.default__get_rename_view_sql", "macro_sql": "{% macro default__get_rename_view_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8895686, "supported_languages": null}, "macro.dbt.get_create_view_as_sql": {"name": "get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.get_create_view_as_sql", "macro_sql": "{% macro get_create_view_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_view_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8899474, "supported_languages": null}, "macro.dbt.default__get_create_view_as_sql": {"name": "default__get_create_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.default__get_create_view_as_sql", "macro_sql": "{% macro default__get_create_view_as_sql(relation, sql) -%}\n  {{ return(create_view_as(relation, sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8901339, "supported_languages": null}, "macro.dbt.create_view_as": {"name": "create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as', 'dbt')(relation, sql) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8903427, "supported_languages": null}, "macro.dbt.default__create_view_as": {"name": "default__create_view_as", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/create.sql", "original_file_path": "macros/relations/view/create.sql", "unique_id": "macro.dbt.default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation.render() }}\n    {% set contract_config = config.get('contract') %}\n    {% if contract_config.enforced %}\n      {{ get_assert_columns_equivalent(sql) }}\n    {%- endif %}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8908162, "supported_languages": null}, "macro.dbt.get_replace_view_sql": {"name": "get_replace_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.get_replace_view_sql", "macro_sql": "{% macro get_replace_view_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_view_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_replace_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8913498, "supported_languages": null}, "macro.dbt.default__get_replace_view_sql": {"name": "default__get_replace_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.default__get_replace_view_sql", "macro_sql": "{% macro default__get_replace_view_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8917978, "supported_languages": null}, "macro.dbt.create_or_replace_view": {"name": "create_or_replace_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.create_or_replace_view", "macro_sql": "{% macro create_or_replace_view() %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(target_relation, sql) }}\n  {%- endcall %}\n\n  {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8932862, "supported_languages": null}, "macro.dbt.handle_existing_table": {"name": "handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch('handle_existing_table', 'dbt')(full_refresh, old_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__handle_existing_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8935187, "supported_languages": null}, "macro.dbt.default__handle_existing_table": {"name": "default__handle_existing_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/replace.sql", "original_file_path": "macros/relations/view/replace.sql", "unique_id": "macro.dbt.default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ log(\"Dropping relation \" ~ old_relation.render() ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8937764, "supported_languages": null}, "macro.dbt.drop_view": {"name": "drop_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt.drop_view", "macro_sql": "{% macro drop_view(relation) -%}\n    {{- adapter.dispatch('drop_view', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8940926, "supported_languages": null}, "macro.dbt.default__drop_view": {"name": "default__drop_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/view/drop.sql", "original_file_path": "macros/relations/view/drop.sql", "unique_id": "macro.dbt.default__drop_view", "macro_sql": "{% macro default__drop_view(relation) -%}\n    drop view if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8942313, "supported_languages": null}, "macro.dbt.get_table_columns_and_constraints": {"name": "get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_table_columns_and_constraints", "macro_sql": "{%- macro get_table_columns_and_constraints() -%}\n  {{ adapter.dispatch('get_table_columns_and_constraints', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8949397, "supported_languages": null}, "macro.dbt.default__get_table_columns_and_constraints": {"name": "default__get_table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_table_columns_and_constraints", "macro_sql": "{% macro default__get_table_columns_and_constraints() -%}\n  {{ return(table_columns_and_constraints()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.table_columns_and_constraints"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8950882, "supported_languages": null}, "macro.dbt.table_columns_and_constraints": {"name": "table_columns_and_constraints", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.table_columns_and_constraints", "macro_sql": "{% macro table_columns_and_constraints() %}\n  {# loop through user_provided_columns to create DDL with data types and constraints #}\n    {%- set raw_column_constraints = adapter.render_raw_columns_constraints(raw_columns=model['columns']) -%}\n    {%- set raw_model_constraints = adapter.render_raw_model_constraints(raw_constraints=model['constraints']) -%}\n    (\n    {% for c in raw_column_constraints -%}\n      {{ c }}{{ \",\" if not loop.last or raw_model_constraints }}\n    {% endfor %}\n    {% for c in raw_model_constraints -%}\n        {{ c }}{{ \",\" if not loop.last }}\n    {% endfor -%}\n    )\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.895673, "supported_languages": null}, "macro.dbt.get_assert_columns_equivalent": {"name": "get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.get_assert_columns_equivalent", "macro_sql": "\n\n{%- macro get_assert_columns_equivalent(sql) -%}\n  {{ adapter.dispatch('get_assert_columns_equivalent', 'dbt')(sql) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8958778, "supported_languages": null}, "macro.dbt.default__get_assert_columns_equivalent": {"name": "default__get_assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__get_assert_columns_equivalent", "macro_sql": "{% macro default__get_assert_columns_equivalent(sql) -%}\n  {{ return(assert_columns_equivalent(sql)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.assert_columns_equivalent"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8960404, "supported_languages": null}, "macro.dbt.assert_columns_equivalent": {"name": "assert_columns_equivalent", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.assert_columns_equivalent", "macro_sql": "{% macro assert_columns_equivalent(sql) %}\n\n  {#-- First ensure the user has defined 'columns' in yaml specification --#}\n  {%- set user_defined_columns = model['columns'] -%}\n  {%- if not user_defined_columns -%}\n      {{ exceptions.raise_contract_error([], []) }}\n  {%- endif -%}\n\n  {#-- Obtain the column schema provided by sql file. #}\n  {%- set sql_file_provided_columns = get_column_schema_from_query(sql, config.get('sql_header', none)) -%}\n  {#--Obtain the column schema provided by the schema file by generating an 'empty schema' query from the model's columns. #}\n  {%- set schema_file_provided_columns = get_column_schema_from_query(get_empty_schema_sql(user_defined_columns)) -%}\n\n  {#-- create dictionaries with name and formatted data type and strings for exception #}\n  {%- set sql_columns = format_columns(sql_file_provided_columns) -%}\n  {%- set yaml_columns = format_columns(schema_file_provided_columns)  -%}\n\n  {%- if sql_columns|length != yaml_columns|length -%}\n    {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n  {%- endif -%}\n\n  {%- for sql_col in sql_columns -%}\n    {%- set yaml_col = [] -%}\n    {%- for this_col in yaml_columns -%}\n      {%- if this_col['name'] == sql_col['name'] -%}\n        {%- do yaml_col.append(this_col) -%}\n        {%- break -%}\n      {%- endif -%}\n    {%- endfor -%}\n    {%- if not yaml_col -%}\n      {#-- Column with name not found in yaml #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n    {%- if sql_col['formatted'] != yaml_col[0]['formatted'] -%}\n      {#-- Column data types don't match #}\n      {%- do exceptions.raise_contract_error(yaml_columns, sql_columns) -%}\n    {%- endif -%}\n  {%- endfor -%}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_column_schema_from_query", "macro.dbt.get_empty_schema_sql", "macro.dbt.format_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8974695, "supported_languages": null}, "macro.dbt.format_columns": {"name": "format_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.format_columns", "macro_sql": "{% macro format_columns(columns) %}\n  {% set formatted_columns = [] %}\n  {% for column in columns %}\n    {%- set formatted_column = adapter.dispatch('format_column', 'dbt')(column) -%}\n    {%- do formatted_columns.append(formatted_column) -%}\n  {% endfor %}\n  {{ return(formatted_columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__format_column"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8979318, "supported_languages": null}, "macro.dbt.default__format_column": {"name": "default__format_column", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/column/columns_spec_ddl.sql", "original_file_path": "macros/relations/column/columns_spec_ddl.sql", "unique_id": "macro.dbt.default__format_column", "macro_sql": "{% macro default__format_column(column) -%}\n  {% set data_type = column.dtype %}\n  {% set formatted = column.column.lower() ~ \" \" ~ data_type %}\n  {{ return({'name': column.name, 'data_type': data_type, 'formatted': formatted}) }}\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8983004, "supported_languages": null}, "macro.dbt.get_alter_materialized_view_as_sql": {"name": "get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.get_alter_materialized_view_as_sql", "macro_sql": "{% macro get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{- log('Applying ALTER to: ' ~ relation) -}}\n    {{- adapter.dispatch('get_alter_materialized_view_as_sql', 'dbt')(\n        relation,\n        configuration_changes,\n        sql,\n        existing_relation,\n        backup_relation,\n        intermediate_relation\n    ) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8988776, "supported_languages": null}, "macro.dbt.default__get_alter_materialized_view_as_sql": {"name": "default__get_alter_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.default__get_alter_materialized_view_as_sql", "macro_sql": "{% macro default__get_alter_materialized_view_as_sql(\n    relation,\n    configuration_changes,\n    sql,\n    existing_relation,\n    backup_relation,\n    intermediate_relation\n) %}\n    {{ exceptions.raise_compiler_error(\"Materialized views have not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8990903, "supported_languages": null}, "macro.dbt.get_materialized_view_configuration_changes": {"name": "get_materialized_view_configuration_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.get_materialized_view_configuration_changes", "macro_sql": "{% macro get_materialized_view_configuration_changes(existing_relation, new_config) %}\n    /* {#\n    It's recommended that configuration changes be formatted as follows:\n    {\"<change_category>\": [{\"action\": \"<name>\", \"context\": ...}]}\n\n    For example:\n    {\n        \"indexes\": [\n            {\"action\": \"drop\", \"context\": \"index_abc\"},\n            {\"action\": \"create\", \"context\": {\"columns\": [\"column_1\", \"column_2\"], \"type\": \"hash\", \"unique\": True}},\n        ],\n    }\n\n    Either way, `get_materialized_view_configuration_changes` needs to align with `get_alter_materialized_view_as_sql`.\n    #} */\n    {{- log('Determining configuration changes on: ' ~ existing_relation) -}}\n    {%- do return(adapter.dispatch('get_materialized_view_configuration_changes', 'dbt')(existing_relation, new_config)) -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_materialized_view_configuration_changes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8993952, "supported_languages": null}, "macro.dbt.default__get_materialized_view_configuration_changes": {"name": "default__get_materialized_view_configuration_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/alter.sql", "original_file_path": "macros/relations/materialized_view/alter.sql", "unique_id": "macro.dbt.default__get_materialized_view_configuration_changes", "macro_sql": "{% macro default__get_materialized_view_configuration_changes(existing_relation, new_config) %}\n    {{ exceptions.raise_compiler_error(\"Materialized views have not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8995545, "supported_languages": null}, "macro.dbt.get_rename_materialized_view_sql": {"name": "get_rename_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/rename.sql", "original_file_path": "macros/relations/materialized_view/rename.sql", "unique_id": "macro.dbt.get_rename_materialized_view_sql", "macro_sql": "{% macro get_rename_materialized_view_sql(relation, new_name) %}\n    {{- adapter.dispatch('get_rename_materialized_view_sql', 'dbt')(relation, new_name) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_rename_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.8998857, "supported_languages": null}, "macro.dbt.default__get_rename_materialized_view_sql": {"name": "default__get_rename_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/rename.sql", "original_file_path": "macros/relations/materialized_view/rename.sql", "unique_id": "macro.dbt.default__get_rename_materialized_view_sql", "macro_sql": "{% macro default__get_rename_materialized_view_sql(relation, new_name) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_rename_materialized_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9000492, "supported_languages": null}, "macro.dbt.get_create_materialized_view_as_sql": {"name": "get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt.get_create_materialized_view_as_sql", "macro_sql": "{% macro get_create_materialized_view_as_sql(relation, sql) -%}\n    {{- adapter.dispatch('get_create_materialized_view_as_sql', 'dbt')(relation, sql) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_create_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9003336, "supported_languages": null}, "macro.dbt.default__get_create_materialized_view_as_sql": {"name": "default__get_create_materialized_view_as_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/create.sql", "original_file_path": "macros/relations/materialized_view/create.sql", "unique_id": "macro.dbt.default__get_create_materialized_view_as_sql", "macro_sql": "{% macro default__get_create_materialized_view_as_sql(relation, sql) -%}\n    {{ exceptions.raise_compiler_error(\n        \"`get_create_materialized_view_as_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.900512, "supported_languages": null}, "macro.dbt.refresh_materialized_view": {"name": "refresh_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt.refresh_materialized_view", "macro_sql": "{% macro refresh_materialized_view(relation) %}\n    {{- log('Applying REFRESH to: ' ~ relation) -}}\n    {{- adapter.dispatch('refresh_materialized_view', 'dbt')(relation) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__refresh_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.900836, "supported_languages": null}, "macro.dbt.default__refresh_materialized_view": {"name": "default__refresh_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/refresh.sql", "original_file_path": "macros/relations/materialized_view/refresh.sql", "unique_id": "macro.dbt.default__refresh_materialized_view", "macro_sql": "{% macro default__refresh_materialized_view(relation) %}\n    {{ exceptions.raise_compiler_error(\"`refresh_materialized_view` has not been implemented for this adapter.\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9009883, "supported_languages": null}, "macro.dbt.get_replace_materialized_view_sql": {"name": "get_replace_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/replace.sql", "original_file_path": "macros/relations/materialized_view/replace.sql", "unique_id": "macro.dbt.get_replace_materialized_view_sql", "macro_sql": "{% macro get_replace_materialized_view_sql(relation, sql) %}\n    {{- adapter.dispatch('get_replace_materialized_view_sql', 'dbt')(relation, sql) -}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_replace_materialized_view_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9012587, "supported_languages": null}, "macro.dbt.default__get_replace_materialized_view_sql": {"name": "default__get_replace_materialized_view_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/replace.sql", "original_file_path": "macros/relations/materialized_view/replace.sql", "unique_id": "macro.dbt.default__get_replace_materialized_view_sql", "macro_sql": "{% macro default__get_replace_materialized_view_sql(relation, sql) %}\n    {{ exceptions.raise_compiler_error(\n        \"`get_replace_materialized_view_sql` has not been implemented for this adapter.\"\n    ) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9014254, "supported_languages": null}, "macro.dbt.drop_materialized_view": {"name": "drop_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt.drop_materialized_view", "macro_sql": "{% macro drop_materialized_view(relation) -%}\n    {{- adapter.dispatch('drop_materialized_view', 'dbt')(relation) -}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__drop_materialized_view"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9016914, "supported_languages": null}, "macro.dbt.default__drop_materialized_view": {"name": "default__drop_materialized_view", "resource_type": "macro", "package_name": "dbt", "path": "macros/relations/materialized_view/drop.sql", "original_file_path": "macros/relations/materialized_view/drop.sql", "unique_id": "macro.dbt.default__drop_materialized_view", "macro_sql": "{% macro default__drop_materialized_view(relation) -%}\n    drop materialized view if exists {{ relation.render() }} cascade\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.901867, "supported_languages": null}, "macro.dbt.default__test_relationships": {"name": "default__test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/relationships.sql", "original_file_path": "macros/generic_test_sql/relationships.sql", "unique_id": "macro.dbt.default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, column_name, to, field) %}\n\nwith child as (\n    select {{ column_name }} as from_field\n    from {{ model }}\n    where {{ column_name }} is not null\n),\n\nparent as (\n    select {{ field }} as to_field\n    from {{ to }}\n)\n\nselect\n    from_field\n\nfrom child\nleft join parent\n    on child.from_field = parent.to_field\n\nwhere parent.to_field is null\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9021828, "supported_languages": null}, "macro.dbt.default__test_accepted_values": {"name": "default__test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/accepted_values.sql", "original_file_path": "macros/generic_test_sql/accepted_values.sql", "unique_id": "macro.dbt.default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, column_name, values, quote=True) %}\n\nwith all_values as (\n\n    select\n        {{ column_name }} as value_field,\n        count(*) as n_records\n\n    from {{ model }}\n    group by {{ column_name }}\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    {% for value in values -%}\n        {% if quote -%}\n        '{{ value }}'\n        {%- else -%}\n        {{ value }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n    {%- endfor %}\n)\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9027567, "supported_languages": null}, "macro.dbt.default__test_not_null": {"name": "default__test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/not_null.sql", "original_file_path": "macros/generic_test_sql/not_null.sql", "unique_id": "macro.dbt.default__test_not_null", "macro_sql": "{% macro default__test_not_null(model, column_name) %}\n\n{% set column_list = '*' if should_store_failures() else column_name %}\n\nselect {{ column_list }}\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_store_failures"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9030757, "supported_languages": null}, "macro.dbt.default__test_unique": {"name": "default__test_unique", "resource_type": "macro", "package_name": "dbt", "path": "macros/generic_test_sql/unique.sql", "original_file_path": "macros/generic_test_sql/unique.sql", "unique_id": "macro.dbt.default__test_unique", "macro_sql": "{% macro default__test_unique(model, column_name) %}\n\nselect\n    {{ column_name }} as unique_field,\n    count(*) as n_records\n\nfrom {{ model }}\nwhere {{ column_name }} is not null\ngroup by {{ column_name }}\nhaving count(*) > 1\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9033227, "supported_languages": null}, "macro.dbt.datediff": {"name": "datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', 'dbt')(first_date, second_date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.903652, "supported_languages": null}, "macro.dbt.default__datediff": {"name": "default__datediff", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/datediff.sql", "original_file_path": "macros/utils/datediff.sql", "unique_id": "macro.dbt.default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) -%}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9038706, "supported_languages": null}, "macro.dbt.dateadd": {"name": "dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', 'dbt')(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9041996, "supported_languages": null}, "macro.dbt.default__dateadd": {"name": "default__dateadd", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/dateadd.sql", "original_file_path": "macros/utils/dateadd.sql", "unique_id": "macro.dbt.default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9043958, "supported_languages": null}, "macro.dbt.concat": {"name": "concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', 'dbt')(fields)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9046578, "supported_languages": null}, "macro.dbt.default__concat": {"name": "default__concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/concat.sql", "original_file_path": "macros/utils/concat.sql", "unique_id": "macro.dbt.default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    {{ fields|join(' || ') }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9048605, "supported_languages": null}, "macro.dbt.except": {"name": "except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__except"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9050984, "supported_languages": null}, "macro.dbt.default__except": {"name": "default__except", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/except.sql", "original_file_path": "macros/utils/except.sql", "unique_id": "macro.dbt.default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9051855, "supported_languages": null}, "macro.dbt.cast_bool_to_text": {"name": "cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.cast_bool_to_text", "macro_sql": "{% macro cast_bool_to_text(field) %}\n  {{ adapter.dispatch('cast_bool_to_text', 'dbt') (field) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9054341, "supported_languages": null}, "macro.dbt.default__cast_bool_to_text": {"name": "default__cast_bool_to_text", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast_bool_to_text.sql", "original_file_path": "macros/utils/cast_bool_to_text.sql", "unique_id": "macro.dbt.default__cast_bool_to_text", "macro_sql": "{% macro default__cast_bool_to_text(field) %}\n    cast({{ field }} as {{ api.Column.translate_type('string') }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.905619, "supported_languages": null}, "macro.dbt.date": {"name": "date", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt.date", "macro_sql": "{% macro date(year, month, day) %}\n  {{ return(adapter.dispatch('date', 'dbt') (year, month, day)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__date"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9059942, "supported_languages": null}, "macro.dbt.default__date": {"name": "default__date", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date.sql", "original_file_path": "macros/utils/date.sql", "unique_id": "macro.dbt.default__date", "macro_sql": "{% macro default__date(year, month, day) -%}\n    {%- set dt = modules.datetime.date(year, month, day) -%}\n    {%- set iso_8601_formatted_date = dt.strftime('%Y-%m-%d') -%}\n    to_date('{{ iso_8601_formatted_date }}', 'YYYY-MM-DD')\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9063125, "supported_languages": null}, "macro.dbt.get_intervals_between": {"name": "get_intervals_between", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', 'dbt')(start_date, end_date, datepart)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_intervals_between"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9068222, "supported_languages": null}, "macro.dbt.default__get_intervals_between": {"name": "default__get_intervals_between", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.default__get_intervals_between", "macro_sql": "{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{ dbt.datediff(start_date, end_date, datepart) }}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.datediff"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9074838, "supported_languages": null}, "macro.dbt.date_spine": {"name": "date_spine", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', 'dbt')(datepart, start_date, end_date)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__date_spine"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9078624, "supported_languages": null}, "macro.dbt.default__date_spine": {"name": "default__date_spine", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_spine.sql", "original_file_path": "macros/utils/date_spine.sql", "unique_id": "macro.dbt.default__date_spine", "macro_sql": "{% macro default__date_spine(datepart, start_date, end_date) %}\n\n\n    {# call as follows:\n\n    date_spine(\n        \"day\",\n        \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n        \"dbt.dateadd(week, 1, current_date)\"\n    ) #}\n\n\n    with rawdata as (\n\n        {{dbt.generate_series(\n            dbt.get_intervals_between(start_date, end_date, datepart)\n        )}}\n\n    ),\n\n    all_periods as (\n\n        select (\n            {{\n                dbt.dateadd(\n                    datepart,\n                    \"row_number() over (order by 1) - 1\",\n                    start_date\n                )\n            }}\n        ) as date_{{datepart}}\n        from rawdata\n\n    ),\n\n    filtered as (\n\n        select *\n        from all_periods\n        where date_{{datepart}} <= {{ end_date }}\n\n    )\n\n    select * from filtered\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.generate_series", "macro.dbt.get_intervals_between", "macro.dbt.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9082816, "supported_languages": null}, "macro.dbt.cast": {"name": "cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast.sql", "original_file_path": "macros/utils/cast.sql", "unique_id": "macro.dbt.cast", "macro_sql": "{% macro cast(field, type) %}\n  {{ return(adapter.dispatch('cast', 'dbt') (field, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.908596, "supported_languages": null}, "macro.dbt.default__cast": {"name": "default__cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/cast.sql", "original_file_path": "macros/utils/cast.sql", "unique_id": "macro.dbt.default__cast", "macro_sql": "{% macro default__cast(field, type) %}\n    cast({{field}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9087431, "supported_languages": null}, "macro.dbt.bool_or": {"name": "bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.bool_or", "macro_sql": "{% macro bool_or(expression) -%}\n    {{ return(adapter.dispatch('bool_or', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__bool_or"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9090617, "supported_languages": null}, "macro.dbt.default__bool_or": {"name": "default__bool_or", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/bool_or.sql", "original_file_path": "macros/utils/bool_or.sql", "unique_id": "macro.dbt.default__bool_or", "macro_sql": "{% macro default__bool_or(expression) -%}\n\n    bool_or({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9091907, "supported_languages": null}, "macro.dbt.date_trunc": {"name": "date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', 'dbt') (datepart, date)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9095204, "supported_languages": null}, "macro.dbt.default__date_trunc": {"name": "default__date_trunc", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/date_trunc.sql", "original_file_path": "macros/utils/date_trunc.sql", "unique_id": "macro.dbt.default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) -%}\n    date_trunc('{{datepart}}', {{date}})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9096751, "supported_languages": null}, "macro.dbt.array_construct": {"name": "array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.array_construct", "macro_sql": "{% macro array_construct(inputs=[], data_type=api.Column.translate_type('integer')) -%}\n  {{ return(adapter.dispatch('array_construct', 'dbt')(inputs, data_type)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_construct"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.91009, "supported_languages": null}, "macro.dbt.default__array_construct": {"name": "default__array_construct", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_construct.sql", "original_file_path": "macros/utils/array_construct.sql", "unique_id": "macro.dbt.default__array_construct", "macro_sql": "{% macro default__array_construct(inputs, data_type) -%}\n    {% if inputs|length > 0 %}\n    array[ {{ inputs|join(' , ') }} ]\n    {% else %}\n    array[]::{{data_type}}[]\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9103677, "supported_languages": null}, "macro.dbt.position": {"name": "position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', 'dbt') (substring_text, string_text)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__position"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9106567, "supported_languages": null}, "macro.dbt.default__position": {"name": "default__position", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/position.sql", "original_file_path": "macros/utils/position.sql", "unique_id": "macro.dbt.default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9108138, "supported_languages": null}, "macro.dbt.get_powers_of_two": {"name": "get_powers_of_two", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', 'dbt')(upper_bound)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.911252, "supported_languages": null}, "macro.dbt.default__get_powers_of_two": {"name": "default__get_powers_of_two", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.default__get_powers_of_two", "macro_sql": "{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9117506, "supported_languages": null}, "macro.dbt.generate_series": {"name": "generate_series", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', 'dbt')(upper_bound)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_series"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9119668, "supported_languages": null}, "macro.dbt.default__generate_series": {"name": "default__generate_series", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/generate_series.sql", "original_file_path": "macros/utils/generate_series.sql", "unique_id": "macro.dbt.default__generate_series", "macro_sql": "{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9125626, "supported_languages": null}, "macro.dbt.split_part": {"name": "split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', 'dbt') (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__split_part"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9129539, "supported_languages": null}, "macro.dbt.default__split_part": {"name": "default__split_part", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt.default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9131474, "supported_languages": null}, "macro.dbt._split_part_negative": {"name": "_split_part_negative", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/split_part.sql", "original_file_path": "macros/utils/split_part.sql", "unique_id": "macro.dbt._split_part_negative", "macro_sql": "{% macro _split_part_negative(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n          length({{ string_text }})\n          - length(\n              replace({{ string_text }},  {{ delimiter_text }}, '')\n          ) + 2 + {{ part_number }}\n        )\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9133966, "supported_languages": null}, "macro.dbt.type_string": {"name": "type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_string"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9141197, "supported_languages": null}, "macro.dbt.default__type_string": {"name": "default__type_string", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_string", "macro_sql": "{% macro default__type_string() %}\n    {{ return(api.Column.translate_type(\"string\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9142919, "supported_languages": null}, "macro.dbt.type_timestamp": {"name": "type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9144676, "supported_languages": null}, "macro.dbt.default__type_timestamp": {"name": "default__type_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    {{ return(api.Column.translate_type(\"timestamp\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.91463, "supported_languages": null}, "macro.dbt.type_float": {"name": "type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_float"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.914801, "supported_languages": null}, "macro.dbt.default__type_float": {"name": "default__type_float", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_float", "macro_sql": "{% macro default__type_float() %}\n    {{ return(api.Column.translate_type(\"float\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9149618, "supported_languages": null}, "macro.dbt.type_numeric": {"name": "type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9151325, "supported_languages": null}, "macro.dbt.default__type_numeric": {"name": "default__type_numeric", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    {{ return(api.Column.numeric_type(\"numeric\", 28, 6)) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9153702, "supported_languages": null}, "macro.dbt.type_bigint": {"name": "type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9172165, "supported_languages": null}, "macro.dbt.default__type_bigint": {"name": "default__type_bigint", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    {{ return(api.Column.translate_type(\"bigint\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9174352, "supported_languages": null}, "macro.dbt.type_int": {"name": "type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_int"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9176378, "supported_languages": null}, "macro.dbt.default__type_int": {"name": "default__type_int", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_int", "macro_sql": "{%- macro default__type_int() -%}\n  {{ return(api.Column.translate_type(\"integer\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9178383, "supported_languages": null}, "macro.dbt.type_boolean": {"name": "type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.type_boolean", "macro_sql": "\n\n{%- macro type_boolean() -%}\n  {{ return(adapter.dispatch('type_boolean', 'dbt')()) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__type_boolean"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9180198, "supported_languages": null}, "macro.dbt.default__type_boolean": {"name": "default__type_boolean", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/data_types.sql", "original_file_path": "macros/utils/data_types.sql", "unique_id": "macro.dbt.default__type_boolean", "macro_sql": "{%- macro default__type_boolean() -%}\n  {{ return(api.Column.translate_type(\"boolean\")) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.918193, "supported_languages": null}, "macro.dbt.replace": {"name": "replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', 'dbt') (field, old_chars, new_chars)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__replace"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.918763, "supported_languages": null}, "macro.dbt.default__replace": {"name": "default__replace", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/replace.sql", "original_file_path": "macros/utils/replace.sql", "unique_id": "macro.dbt.default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9190416, "supported_languages": null}, "macro.dbt.escape_single_quotes": {"name": "escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.escape_single_quotes", "macro_sql": "{% macro escape_single_quotes(expression) %}\n      {{ return(adapter.dispatch('escape_single_quotes', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__escape_single_quotes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9195042, "supported_languages": null}, "macro.dbt.default__escape_single_quotes": {"name": "default__escape_single_quotes", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/escape_single_quotes.sql", "original_file_path": "macros/utils/escape_single_quotes.sql", "unique_id": "macro.dbt.default__escape_single_quotes", "macro_sql": "{% macro default__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"''\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9197543, "supported_languages": null}, "macro.dbt.array_append": {"name": "array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.array_append", "macro_sql": "{% macro array_append(array, new_element) -%}\n  {{ return(adapter.dispatch('array_append', 'dbt')(array, new_element)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_append"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.920092, "supported_languages": null}, "macro.dbt.default__array_append": {"name": "default__array_append", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_append.sql", "original_file_path": "macros/utils/array_append.sql", "unique_id": "macro.dbt.default__array_append", "macro_sql": "{% macro default__array_append(array, new_element) -%}\n    array_append({{ array }}, {{ new_element }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.92025, "supported_languages": null}, "macro.dbt.length": {"name": "length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__length"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9205384, "supported_languages": null}, "macro.dbt.default__length": {"name": "default__length", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/length.sql", "original_file_path": "macros/utils/length.sql", "unique_id": "macro.dbt.default__length", "macro_sql": "{% macro default__length(expression) %}\n\n    length(\n        {{ expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9206622, "supported_languages": null}, "macro.dbt.right": {"name": "right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', 'dbt') (string_text, length_expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__right"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9209518, "supported_languages": null}, "macro.dbt.default__right": {"name": "default__right", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/right.sql", "original_file_path": "macros/utils/right.sql", "unique_id": "macro.dbt.default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n\n{%- endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9211075, "supported_languages": null}, "macro.dbt.last_day": {"name": "last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', 'dbt') (date, datepart)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.921427, "supported_languages": null}, "macro.dbt.default_last_day": {"name": "default_last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default_last_day", "macro_sql": "\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt.dateadd('day', '-1',\n        dbt.dateadd(datepart, '1', dbt.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.dateadd", "macro.dbt.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.92175, "supported_languages": null}, "macro.dbt.default__last_day": {"name": "default__last_day", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/last_day.sql", "original_file_path": "macros/utils/last_day.sql", "unique_id": "macro.dbt.default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt.default_last_day(date, datepart)}}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9219193, "supported_languages": null}, "macro.dbt.string_literal": {"name": "string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', 'dbt') (value)) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__string_literal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9221954, "supported_languages": null}, "macro.dbt.default__string_literal": {"name": "default__string_literal", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/literal.sql", "original_file_path": "macros/utils/literal.sql", "unique_id": "macro.dbt.default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9223301, "supported_languages": null}, "macro.dbt.hash": {"name": "hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', 'dbt') (field)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9225905, "supported_languages": null}, "macro.dbt.default__hash": {"name": "default__hash", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/hash.sql", "original_file_path": "macros/utils/hash.sql", "unique_id": "macro.dbt.default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{ field }} as {{ api.Column.translate_type('string') }}))\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.922768, "supported_languages": null}, "macro.dbt.safe_cast": {"name": "safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', 'dbt') (field, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9230669, "supported_languages": null}, "macro.dbt.default__safe_cast": {"name": "default__safe_cast", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/safe_cast.sql", "original_file_path": "macros/utils/safe_cast.sql", "unique_id": "macro.dbt.default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.923451, "supported_languages": null}, "macro.dbt.listagg": {"name": "listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.listagg", "macro_sql": "{% macro listagg(measure, delimiter_text=\"','\", order_by_clause=none, limit_num=none) -%}\n    {{ return(adapter.dispatch('listagg', 'dbt') (measure, delimiter_text, order_by_clause, limit_num)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__listagg"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9240215, "supported_languages": null}, "macro.dbt.default__listagg": {"name": "default__listagg", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/listagg.sql", "original_file_path": "macros/utils/listagg.sql", "unique_id": "macro.dbt.default__listagg", "macro_sql": "{% macro default__listagg(measure, delimiter_text, order_by_clause, limit_num) -%}\n\n    {% if limit_num -%}\n    array_to_string(\n        array_slice(\n            array_agg(\n                {{ measure }}\n            ){% if order_by_clause -%}\n            within group ({{ order_by_clause }})\n            {%- endif %}\n            ,0\n            ,{{ limit_num }}\n        ),\n        {{ delimiter_text }}\n        )\n    {%- else %}\n    listagg(\n        {{ measure }},\n        {{ delimiter_text }}\n        )\n        {% if order_by_clause -%}\n        within group ({{ order_by_clause }})\n        {%- endif %}\n    {%- endif %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9245882, "supported_languages": null}, "macro.dbt.intersect": {"name": "intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__intersect"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9248433, "supported_languages": null}, "macro.dbt.default__intersect": {"name": "default__intersect", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/intersect.sql", "original_file_path": "macros/utils/intersect.sql", "unique_id": "macro.dbt.default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9249341, "supported_languages": null}, "macro.dbt.array_concat": {"name": "array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.array_concat", "macro_sql": "{% macro array_concat(array_1, array_2) -%}\n  {{ return(adapter.dispatch('array_concat', 'dbt')(array_1, array_2)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__array_concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.92524, "supported_languages": null}, "macro.dbt.default__array_concat": {"name": "default__array_concat", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/array_concat.sql", "original_file_path": "macros/utils/array_concat.sql", "unique_id": "macro.dbt.default__array_concat", "macro_sql": "{% macro default__array_concat(array_1, array_2) -%}\n    array_cat({{ array_1 }}, {{ array_2 }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9253967, "supported_languages": null}, "macro.dbt.any_value": {"name": "any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.any_value", "macro_sql": "{% macro any_value(expression) -%}\n    {{ return(adapter.dispatch('any_value', 'dbt') (expression)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__any_value"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9256663, "supported_languages": null}, "macro.dbt.default__any_value": {"name": "default__any_value", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/any_value.sql", "original_file_path": "macros/utils/any_value.sql", "unique_id": "macro.dbt.default__any_value", "macro_sql": "{% macro default__any_value(expression) -%}\n\n    any_value({{ expression }})\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.925789, "supported_languages": null}, "macro.dbt.equals": {"name": "equals", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/equals.sql", "original_file_path": "macros/utils/equals.sql", "unique_id": "macro.dbt.equals", "macro_sql": "{% macro equals(expr1, expr2) %}\n    {{ return(adapter.dispatch('equals', 'dbt') (expr1, expr2)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9261484, "supported_languages": null}, "macro.dbt.default__equals": {"name": "default__equals", "resource_type": "macro", "package_name": "dbt", "path": "macros/utils/equals.sql", "original_file_path": "macros/utils/equals.sql", "unique_id": "macro.dbt.default__equals", "macro_sql": "{% macro default__equals(expr1, expr2) -%}\n{%- if adapter.behavior.enable_truthy_nulls_equals_macro.no_warn %}\n    case when (({{ expr1 }} = {{ expr2 }}) or ({{ expr1 }} is null and {{ expr2 }} is null))\n        then 0\n        else 1\n    end = 0\n{%- else -%}\n    ({{ expr1 }} = {{ expr2 }})\n{%- endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9264781, "supported_languages": null}, "macro.dbt.convert_datetime": {"name": "convert_datetime", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9272544, "supported_languages": null}, "macro.dbt.dates_in_range": {"name": "dates_in_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partition start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.convert_datetime"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9286137, "supported_languages": null}, "macro.dbt.partition_range": {"name": "partition_range", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.dates_in_range"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9294596, "supported_languages": null}, "macro.dbt.py_current_timestring": {"name": "py_current_timestring", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "unique_id": "macro.dbt.py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9297135, "supported_languages": null}, "macro.dbt.statement": {"name": "statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.statement", "macro_sql": "\n{%- macro statement(name=None, fetch_result=False, auto_begin=True, language='sql') -%}\n  {%- if execute: -%}\n    {%- set compiled_code = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime {} for node \"{}\"'.format(language, model['unique_id'])) }}\n      {{ write(compiled_code) }}\n    {%- endif -%}\n    {%- if language == 'sql'-%}\n      {%- set res, table = adapter.execute(compiled_code, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- elif language == 'python' -%}\n      {%- set res = submit_python_job(model, compiled_code) -%}\n      {#-- TODO: What should table be for python models? --#}\n      {%- set table = None -%}\n    {%- else -%}\n      {% do exceptions.raise_compiler_error(\"statement macro didn't get supported language\") %}\n    {%- endif -%}\n\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9311113, "supported_languages": null}, "macro.dbt.noop_statement": {"name": "noop_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.noop_statement", "macro_sql": "{% macro noop_statement(name=None, message=None, code=None, rows_affected=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_raw_result(name, message=message, code=code, rows_affected=rows_affected, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9317365, "supported_languages": null}, "macro.dbt.run_query": {"name": "run_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "unique_id": "macro.dbt.run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9320672, "supported_languages": null}, "macro.dbt.generate_alias_name": {"name": "generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_alias_name', 'dbt')(custom_alias_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_alias_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9324768, "supported_languages": null}, "macro.dbt.default__generate_alias_name": {"name": "default__generate_alias_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "unique_id": "macro.dbt.default__generate_alias_name", "macro_sql": "{% macro default__generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- elif node.version -%}\n\n        {{ return(node.name ~ \"_v\" ~ (node.version | replace(\".\", \"_\"))) }}\n\n    {%- else -%}\n\n        {{ node.name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9329193, "supported_languages": null}, "macro.dbt.generate_schema_name": {"name": "generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name=none, node=none) -%}\n    {{ return(adapter.dispatch('generate_schema_name', 'dbt')(custom_schema_name, node)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__generate_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9333742, "supported_languages": null}, "macro.dbt.default__generate_schema_name": {"name": "default__generate_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.default__generate_schema_name", "macro_sql": "{% macro default__generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9336803, "supported_languages": null}, "macro.dbt.generate_schema_name_for_env": {"name": "generate_schema_name_for_env", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "unique_id": "macro.dbt.generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9340694, "supported_languages": null}, "macro.dbt.generate_database_name": {"name": "generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name', 'dbt')(custom_database_name, node)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9344802, "supported_languages": null}, "macro.dbt.default__generate_database_name": {"name": "default__generate_database_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "unique_id": "macro.dbt.default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9347718, "supported_languages": null}, "macro.dbt.resolve_model_name": {"name": "resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.resolve_model_name", "macro_sql": "{% macro resolve_model_name(input_model_name) %}\n    {{ return(adapter.dispatch('resolve_model_name', 'dbt')(input_model_name)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9355125, "supported_languages": null}, "macro.dbt.default__resolve_model_name": {"name": "default__resolve_model_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.default__resolve_model_name", "macro_sql": "\n\n{%- macro default__resolve_model_name(input_model_name) -%}\n    {{  input_model_name | string | replace('\"', '\\\"') }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9356902, "supported_languages": null}, "macro.dbt.build_ref_function": {"name": "build_ref_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_ref_function", "macro_sql": "{% macro build_ref_function(model) %}\n\n    {%- set ref_dict = {} -%}\n    {%- for _ref in model.refs -%}\n        {% set _ref_args = [_ref.get('package'), _ref['name']] if _ref.get('package') else [_ref['name'],] %}\n        {%- set resolved = ref(*_ref_args, v=_ref.get('version')) -%}\n\n        {#\n            We want to get the string of the returned relation by calling .render() in order to skip sample/empty\n            mode rendering logic. However, people override the default ref macro, and often return a string instead\n            of a relation (like the ref macro does by default). Thus, to make sure we dont blow things up, we have\n            to ensure the resolved relation has a .render() method.\n        #}\n        {%- if resolved.render is defined and resolved.render is callable -%}\n            {%- set resolved = resolved.render() -%}\n        {%- endif -%}\n\n        {%- if _ref.get('version') -%}\n            {% do _ref_args.extend([\"v\" ~ _ref['version']]) %}\n        {%- endif -%}\n       {%- do ref_dict.update({_ref_args | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef ref(*args, **kwargs):\n    refs = {{ ref_dict | tojson }}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9367647, "supported_languages": null}, "macro.dbt.build_source_function": {"name": "build_source_function", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_source_function", "macro_sql": "{% macro build_source_function(model) %}\n\n    {%- set source_dict = {} -%}\n    {%- for _source in model.sources -%}\n        {%- set resolved = source(*_source) -%}\n        {%- do source_dict.update({_source | join('.'): resolve_model_name(resolved)}) -%}\n    {%- endfor -%}\n\ndef source(*args, dbt_load_df_function):\n    sources = {{ source_dict | tojson }}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.resolve_model_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9372365, "supported_languages": null}, "macro.dbt.build_config_dict": {"name": "build_config_dict", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.build_config_dict", "macro_sql": "{% macro build_config_dict(model) %}\n    {%- set config_dict = {} -%}\n    {% set config_dbt_used = zip(model.config.config_keys_used, model.config.config_keys_defaults) | list %}\n    {%- for key, default in config_dbt_used -%}\n        {# weird type testing with enum, would be much easier to write this logic in Python! #}\n        {%- if key == \"language\" -%}\n          {%- set value = \"python\" -%}\n        {%- endif -%}\n        {%- set value = model.config.get(key, default) -%}\n        {%- do config_dict.update({key: value}) -%}\n    {%- endfor -%}\nconfig_dict = {{ config_dict }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9378777, "supported_languages": null}, "macro.dbt.py_script_postfix": {"name": "py_script_postfix", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_postfix", "macro_sql": "{% macro py_script_postfix(model) %}\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\n{{ build_ref_function(model ) }}\n{{ build_source_function(model ) }}\n{{ build_config_dict(model) }}\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"{{ this.database }}\"\n    schema = \"{{ this.schema }}\"\n    identifier = \"{{ this.identifier }}\"\n    {% set this_relation_name = resolve_model_name(this) %}\n    def __repr__(self):\n        return '{{ this_relation_name  }}'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = {{ is_incremental() }}\n\n# COMMAND ----------\n{{py_script_comment()}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.build_ref_function", "macro.dbt.build_source_function", "macro.dbt.build_config_dict", "macro.dbt.resolve_model_name", "macro.dbt.is_incremental", "macro.dbt.py_script_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9383955, "supported_languages": null}, "macro.dbt.py_script_comment": {"name": "py_script_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/python_model/python.sql", "original_file_path": "macros/python_model/python.sql", "unique_id": "macro.dbt.py_script_comment", "macro_sql": "{%macro py_script_comment()%}\n{%endmacro%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9384825, "supported_languages": null}, "macro.dbt.run_hooks": {"name": "run_hooks", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9395795, "supported_languages": null}, "macro.dbt.make_hook_config": {"name": "make_hook_config", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9398382, "supported_languages": null}, "macro.dbt.before_begin": {"name": "before_begin", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9400218, "supported_languages": null}, "macro.dbt.in_transaction": {"name": "in_transaction", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.940214, "supported_languages": null}, "macro.dbt.after_commit": {"name": "after_commit", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "unique_id": "macro.dbt.after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.940395, "supported_languages": null}, "macro.dbt.set_sql_header": {"name": "set_sql_header", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.940713, "supported_languages": null}, "macro.dbt.should_full_refresh": {"name": "should_full_refresh", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9410853, "supported_languages": null}, "macro.dbt.should_store_failures": {"name": "should_store_failures", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "unique_id": "macro.dbt.should_store_failures", "macro_sql": "{% macro should_store_failures() %}\n  {% set config_store_failures = config.get('store_failures') %}\n  {% if config_store_failures is none %}\n    {% set config_store_failures = flags.STORE_FAILURES %}\n  {% endif %}\n  {% do return(config_store_failures) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9414213, "supported_languages": null}, "macro.dbt.snapshot_merge_sql": {"name": "snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql', 'dbt')(target, source, insert_cols) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9418597, "supported_languages": null}, "macro.dbt.default__snapshot_merge_sql": {"name": "default__snapshot_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "unique_id": "macro.dbt.default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    {%- set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() -%}\n\n    merge into {{ target.render() }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.{{ columns.dbt_scd_id }} = DBT_INTERNAL_DEST.{{ columns.dbt_scd_id }}\n\n    when matched\n     {% if config.get(\"dbt_valid_to_current\") %}\n\t{% set source_unique_key = (\"DBT_INTERNAL_DEST.\" ~ columns.dbt_valid_to) | trim %}\n\t{% set target_unique_key = config.get('dbt_valid_to_current') | trim %}\n\tand ({{ equals(source_unique_key, target_unique_key) }} or {{ source_unique_key }} is null)\n\n     {% else %}\n       and DBT_INTERNAL_DEST.{{ columns.dbt_valid_to }} is null\n     {% endif %}\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set {{ columns.dbt_valid_to }} = DBT_INTERNAL_SOURCE.{{ columns.dbt_valid_to }}\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9427848, "supported_languages": null}, "macro.dbt.materialization_snapshot_default": {"name": "materialization_snapshot_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/snapshot.sql", "original_file_path": "macros/materializations/snapshots/snapshot.sql", "unique_id": "macro.dbt.materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  -- grab current tables grants config for comparision later on\n  {%- set grant_config = config.get('grants') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {# The model['config'] parameter below is no longer used, but passing anyway for compatibility #}\n  {# It was a dictionary of config, instead of the config object from the context #}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", model['config'], target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_code']) %}\n      {% set build_or_select_sql = build_sql %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n      {{ adapter.assert_valid_snapshot_target_given_strategy(target_relation, columns, strategy) }}\n\n      {% set build_or_select_sql = snapshot_staging_table(strategy, sql, target_relation) %}\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set remove_columns = ['dbt_change_type', 'DBT_CHANGE_TYPE', 'dbt_unique_key', 'DBT_UNIQUE_KEY'] %}\n      {% if unique_key | is_list %}\n          {% for key in strategy.unique_key %}\n              {{ remove_columns.append('dbt_unique_key_' + loop.index|string) }}\n              {{ remove_columns.append('DBT_UNIQUE_KEY_' + loop.index|string) }}\n          {% endfor %}\n      {% endif %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'in', remove_columns)\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n\n  {{ check_time_data_types(build_or_select_sql) }}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% set should_revoke = should_revoke(target_relation_exists, full_refresh_mode=False) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_staging_table", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.check_time_data_types", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9474857, "supported_languages": ["sql"]}, "macro.dbt.strategy_dispatch": {"name": "strategy_dispatch", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9496853, "supported_languages": null}, "macro.dbt.snapshot_hash_arguments": {"name": "snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments', 'dbt')(args) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.949885, "supported_languages": null}, "macro.dbt.default__snapshot_hash_arguments": {"name": "default__snapshot_hash_arguments", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9501565, "supported_languages": null}, "macro.dbt.snapshot_timestamp_strategy": {"name": "snapshot_timestamp_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, model_config, target_exists) %}\n    {# The model_config parameter is no longer used, but is passed in anyway for compatibility. #}\n    {% set primary_key = config.get('unique_key') %}\n    {% set updated_at = config.get('updated_at') %}\n    {% set hard_deletes = adapter.get_hard_deletes_behavior(config) %}\n    {% set invalidate_hard_deletes = hard_deletes == 'invalidate' %}\n    {% set columns = config.get(\"snapshot_table_column_names\") or get_snapshot_table_column_names() %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/dbt-labs/dbt-core/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.{{ columns.dbt_valid_from }} < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_args = api.Relation.scd_args(primary_key, updated_at) %}\n    {% set scd_id_expr = snapshot_hash_arguments(scd_args) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes,\n        \"hard_deletes\": hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9512625, "supported_languages": null}, "macro.dbt.snapshot_string_as_time": {"name": "snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time', 'dbt')(timestamp) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_string_as_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9514713, "supported_languages": null}, "macro.dbt.default__snapshot_string_as_time": {"name": "default__snapshot_string_as_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9516752, "supported_languages": null}, "macro.dbt.snapshot_check_all_get_existing_columns": {"name": "snapshot_check_all_get_existing_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) -%}\n    {%- if not target_exists -%}\n        {#-- no table yet -> return whatever the query does --#}\n        {{ return((false, query_columns)) }}\n    {%- endif -%}\n\n    {#-- handle any schema changes --#}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=node.alias) -%}\n\n    {% if check_cols_config == 'all' %}\n        {%- set query_columns = get_columns_in_query(node['compiled_code']) -%}\n\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {#-- query for proper casing/quoting, to support comparison below --#}\n        {%- set select_check_cols_from_target -%}\n            {#-- N.B. The whitespace below is necessary to avoid edge case issue with comments --#}\n            {#-- See: https://github.com/dbt-labs/dbt-core/issues/6781 --#}\n            select {{ check_cols_config | join(', ') }} from (\n                {{ node['compiled_code'] }}\n            ) subq\n        {%- endset -%}\n        {% set query_columns = get_columns_in_query(select_check_cols_from_target) %}\n\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set existing_cols = adapter.get_columns_in_relation(target_relation) | map(attribute = 'name') | list -%}\n    {%- set ns = namespace() -%} {#-- handle for-loop scoping with a namespace --#}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(adapter.quote(col)) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return((ns.column_added, intersection)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.953305, "supported_languages": null}, "macro.dbt.snapshot_check_strategy": {"name": "snapshot_check_strategy", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "unique_id": "macro.dbt.snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, model_config, target_exists) %}\n    {# The model_config parameter is no longer used, but is passed in anyway for compatibility. #}\n    {% set check_cols_config = config.get('check_cols') %}\n    {% set primary_key = config.get('unique_key') %}\n    {% set hard_deletes = adapter.get_hard_deletes_behavior(config) %}\n    {% set invalidate_hard_deletes = hard_deletes == 'invalidate' %}\n    {% set updated_at = config.get('updated_at') or snapshot_get_time() %}\n\n    {% set column_added = false %}\n\n    {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists, check_cols_config) %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        {{ get_true_sql() }}\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        (\n            (({{ snapshotted_rel }}.{{ col }} is null) and not ({{ current_rel }}.{{ col }} is null))\n            or\n            ((not {{ snapshotted_rel }}.{{ col }} is null) and ({{ current_rel }}.{{ col }} is null))\n        )\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_args = api.Relation.scd_args(primary_key, updated_at) %}\n    {% set scd_id_expr = snapshot_hash_arguments(scd_args) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes,\n        \"hard_deletes\": hard_deletes\n    }) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.get_true_sql", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9549885, "supported_languages": null}, "macro.dbt.create_columns": {"name": "create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns', 'dbt')(relation, columns) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9569874, "supported_languages": null}, "macro.dbt.default__create_columns": {"name": "default__create_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation.render() }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9573352, "supported_languages": null}, "macro.dbt.post_snapshot": {"name": "post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot', 'dbt')(staging_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9575245, "supported_languages": null}, "macro.dbt.default__post_snapshot": {"name": "default__post_snapshot", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9576309, "supported_languages": null}, "macro.dbt.get_true_sql": {"name": "get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_true_sql", "macro_sql": "{% macro get_true_sql() %}\n  {{ adapter.dispatch('get_true_sql', 'dbt')() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_true_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.957793, "supported_languages": null}, "macro.dbt.default__get_true_sql": {"name": "default__get_true_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__get_true_sql", "macro_sql": "{% macro default__get_true_sql() %}\n    {{ return('TRUE') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9579217, "supported_languages": null}, "macro.dbt.snapshot_staging_table": {"name": "snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n  {{ adapter.dispatch('snapshot_staging_table', 'dbt')(strategy, source_sql, target_relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__snapshot_staging_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9581432, "supported_languages": null}, "macro.dbt.get_snapshot_table_column_names": {"name": "get_snapshot_table_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_snapshot_table_column_names", "macro_sql": "{% macro get_snapshot_table_column_names() %}\n    {{ return({'dbt_valid_to': 'dbt_valid_to', 'dbt_valid_from': 'dbt_valid_from', 'dbt_scd_id': 'dbt_scd_id', 'dbt_updated_at': 'dbt_updated_at', 'dbt_is_deleted': 'dbt_is_deleted'}) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9584312, "supported_languages": null}, "macro.dbt.default__snapshot_staging_table": {"name": "default__snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__snapshot_staging_table", "macro_sql": "{% macro default__snapshot_staging_table(strategy, source_sql, target_relation) -%}\n    {% set columns = config.get('snapshot_table_column_names') or get_snapshot_table_column_names() %}\n    {% if strategy.hard_deletes == 'new_record' %}\n        {% set new_scd_id = snapshot_hash_arguments([columns.dbt_scd_id, snapshot_get_time()]) %}\n    {% endif %}\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }}\n        from {{ target_relation }}\n        where\n            {% if config.get('dbt_valid_to_current') %}\n\t\t{% set source_unique_key = columns.dbt_valid_to | trim %}\n\t\t{% set target_unique_key = config.get('dbt_valid_to_current') | trim %}\n\n\t\t{# The exact equals semantics between NULL values depends on the current behavior flag set. Also, update records if the source field is null #}\n                ( {{ equals(source_unique_key, target_unique_key) }} or {{ source_unique_key }} is null )\n            {% else %}\n                {{ columns.dbt_valid_to }} is null\n            {% endif %}\n\n    ),\n\n    insertions_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }},\n            {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n            {{ get_dbt_valid_to_current(strategy, columns) }},\n            {{ strategy.scd_id }} as {{ columns.dbt_scd_id }}\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }},\n            {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n            {{ strategy.updated_at }} as {{ columns.dbt_valid_to }}\n\n        from snapshot_query\n    ),\n\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n\n    deletes_source_data as (\n\n        select *, {{ unique_key_fields(strategy.unique_key) }}\n        from snapshot_query\n    ),\n    {% endif %}\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            ,'False' as {{ columns.dbt_is_deleted }}\n          {%- endif %}\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n            where {{ unique_key_is_null(strategy.unique_key, \"snapshotted_data\") }}\n            or ({{ unique_key_is_not_null(strategy.unique_key, \"snapshotted_data\") }} and (\n               {{ strategy.row_changed }} {%- if strategy.hard_deletes == 'new_record' -%} or snapshotted_data.{{ columns.dbt_is_deleted }} = 'True' {% endif %}\n            )\n\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.{{ columns.dbt_scd_id }}\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            , snapshotted_data.{{ columns.dbt_is_deleted }}\n          {%- endif %}\n\n        from updates_source_data as source_data\n        join snapshotted_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n        where (\n            {{ strategy.row_changed }}  {%- if strategy.hard_deletes == 'new_record' -%} or snapshotted_data.{{ columns.dbt_is_deleted }} = 'True' {% endif %}\n        )\n    )\n\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n    ,\n    deletes as (\n\n        select\n            'delete' as dbt_change_type,\n            source_data.*,\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_from }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_updated_at }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_to }},\n            snapshotted_data.{{ columns.dbt_scd_id }}\n          {%- if strategy.hard_deletes == 'new_record' -%}\n            , snapshotted_data.{{ columns.dbt_is_deleted }}\n          {%- endif %}\n        from snapshotted_data\n        left join deletes_source_data as source_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n            where {{ unique_key_is_null(strategy.unique_key, \"source_data\") }}\n\n            {%- if strategy.hard_deletes == 'new_record' %}\n            and not (\n                --avoid updating the record's valid_to if the latest entry is marked as deleted\n                snapshotted_data.{{ columns.dbt_is_deleted }} = 'True'\n                and snapshotted_data.{{ columns.dbt_valid_to }} is null\n            )\n            {%- endif %}\n    )\n    {%- endif %}\n\n    {%- if strategy.hard_deletes == 'new_record' %}\n        {% set snapshotted_cols = get_list_of_column_names(get_columns_in_relation(target_relation)) %}\n        {% set source_sql_cols = get_column_schema_from_query(source_sql) %}\n    ,\n    deletion_records as (\n\n        select\n            'insert' as dbt_change_type,\n            {#\n                If a column has been added to the source it won't yet exist in the\n                snapshotted table so we insert a null value as a placeholder for the column.\n             #}\n            {%- for col in source_sql_cols -%}\n            {%- if col.name in snapshotted_cols -%}\n            snapshotted_data.{{ adapter.quote(col.column) }},\n            {%- else -%}\n            NULL as {{ adapter.quote(col.column) }},\n            {%- endif -%}\n            {% endfor -%}\n            {%- if strategy.unique_key | is_list -%}\n                {%- for key in strategy.unique_key -%}\n            snapshotted_data.{{ key }} as dbt_unique_key_{{ loop.index }},\n                {% endfor -%}\n            {%- else -%}\n            snapshotted_data.dbt_unique_key as dbt_unique_key,\n            {% endif -%}\n            {{ snapshot_get_time() }} as {{ columns.dbt_valid_from }},\n            {{ snapshot_get_time() }} as {{ columns.dbt_updated_at }},\n            snapshotted_data.{{ columns.dbt_valid_to }} as {{ columns.dbt_valid_to }},\n            {{ new_scd_id }} as {{ columns.dbt_scd_id }},\n            'True' as {{ columns.dbt_is_deleted }}\n        from snapshotted_data\n        left join deletes_source_data as source_data\n            on {{ unique_key_join_on(strategy.unique_key, \"snapshotted_data\", \"source_data\") }}\n        where {{ unique_key_is_null(strategy.unique_key, \"source_data\") }}\n        and not (\n            --avoid inserting a new record if the latest one is marked as deleted\n            snapshotted_data.{{ columns.dbt_is_deleted }} = 'True'\n            and snapshotted_data.{{ columns.dbt_valid_to }} is null\n            )\n\n    )\n    {%- endif %}\n\n    select * from insertions\n    union all\n    select * from updates\n    {%- if strategy.hard_deletes == 'invalidate' or strategy.hard_deletes == 'new_record' %}\n    union all\n    select * from deletes\n    {%- endif %}\n    {%- if strategy.hard_deletes == 'new_record' %}\n    union all\n    select * from deletion_records\n    {%- endif %}\n\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.snapshot_hash_arguments", "macro.dbt.snapshot_get_time", "macro.dbt.unique_key_fields", "macro.dbt.equals", "macro.dbt.get_dbt_valid_to_current", "macro.dbt.unique_key_join_on", "macro.dbt.unique_key_is_null", "macro.dbt.unique_key_is_not_null", "macro.dbt.get_list_of_column_names", "macro.dbt.get_columns_in_relation", "macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9630911, "supported_languages": null}, "macro.dbt.build_snapshot_table": {"name": "build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) -%}\n  {{ adapter.dispatch('build_snapshot_table', 'dbt')(strategy, sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__build_snapshot_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9633288, "supported_languages": null}, "macro.dbt.default__build_snapshot_table": {"name": "default__build_snapshot_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.default__build_snapshot_table", "macro_sql": "{% macro default__build_snapshot_table(strategy, sql) %}\n    {% set columns = config.get('snapshot_table_column_names') or get_snapshot_table_column_names() %}\n\n    select *,\n        {{ strategy.scd_id }} as {{ columns.dbt_scd_id }},\n        {{ strategy.updated_at }} as {{ columns.dbt_updated_at }},\n        {{ strategy.updated_at }} as {{ columns.dbt_valid_from }},\n        {{ get_dbt_valid_to_current(strategy, columns) }}\n      {%- if strategy.hard_deletes == 'new_record' -%}\n        , 'False' as {{ columns.dbt_is_deleted }}\n      {% endif -%}\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_snapshot_table_column_names", "macro.dbt.get_dbt_valid_to_current"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9639194, "supported_languages": null}, "macro.dbt.build_snapshot_staging_table": {"name": "build_snapshot_staging_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set temp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, temp_relation, select) }}\n    {% endcall %}\n\n    {% do return(temp_relation) %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9644523, "supported_languages": null}, "macro.dbt.get_updated_at_column_data_type": {"name": "get_updated_at_column_data_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_updated_at_column_data_type", "macro_sql": "{% macro get_updated_at_column_data_type(snapshot_sql) %}\n    {% set snapshot_sql_column_schema = get_column_schema_from_query(snapshot_sql) %}\n    {% set dbt_updated_at_data_type = null %}\n    {% set ns = namespace() -%} {#-- handle for-loop scoping with a namespace --#}\n    {% set ns.dbt_updated_at_data_type = null -%}\n    {% for column in snapshot_sql_column_schema %}\n    {%   if ((column.column == 'dbt_updated_at') or (column.column == 'DBT_UPDATED_AT')) %}\n    {%     set ns.dbt_updated_at_data_type = column.dtype %}\n    {%   endif %}\n    {% endfor %}\n    {{ return(ns.dbt_updated_at_data_type or none)  }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9651508, "supported_languages": null}, "macro.dbt.check_time_data_types": {"name": "check_time_data_types", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.check_time_data_types", "macro_sql": "{% macro check_time_data_types(sql) %}\n  {% set dbt_updated_at_data_type = get_updated_at_column_data_type(sql) %}\n  {% set snapshot_get_time_data_type = get_snapshot_get_time_data_type() %}\n  {% if snapshot_get_time_data_type is not none and dbt_updated_at_data_type is not none and snapshot_get_time_data_type != dbt_updated_at_data_type %}\n  {%   if exceptions.warn_snapshot_timestamp_data_types %}\n  {{     exceptions.warn_snapshot_timestamp_data_types(snapshot_get_time_data_type, dbt_updated_at_data_type) }}\n  {%   endif %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_updated_at_column_data_type", "macro.dbt.get_snapshot_get_time_data_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9656322, "supported_languages": null}, "macro.dbt.get_dbt_valid_to_current": {"name": "get_dbt_valid_to_current", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.get_dbt_valid_to_current", "macro_sql": "{% macro get_dbt_valid_to_current(strategy, columns) %}\n  {% set dbt_valid_to_current = config.get('dbt_valid_to_current') or \"null\" %}\n  coalesce(nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}), {{dbt_valid_to_current}})\n  as {{ columns.dbt_valid_to }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9659486, "supported_languages": null}, "macro.dbt.unique_key_fields": {"name": "unique_key_fields", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_fields", "macro_sql": "{% macro unique_key_fields(unique_key) %}\n    {% if unique_key | is_list %}\n        {% for key in unique_key %}\n            {{ key }} as dbt_unique_key_{{ loop.index }}\n            {%- if not loop.last %} , {%- endif %}\n        {% endfor %}\n    {% else %}\n        {{ unique_key }} as dbt_unique_key\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9663353, "supported_languages": null}, "macro.dbt.unique_key_join_on": {"name": "unique_key_join_on", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_join_on", "macro_sql": "{% macro unique_key_join_on(unique_key, identifier, from_identifier) %}\n    {% if unique_key | is_list %}\n        {% for key in unique_key %}\n\t    {% set source_unique_key = (identifier ~ \".dbt_unique_key_\" ~ loop.index) | trim %}\n\t    {% set target_unique_key = (from_identifier ~ \".dbt_unique_key_\" ~ loop.index) | trim %}\n\t    {{ equals(source_unique_key, target_unique_key) }}\n            {%- if not loop.last %} and {%- endif %}\n        {% endfor %}\n    {% else %}\n        {{ identifier }}.dbt_unique_key = {{ from_identifier }}.dbt_unique_key\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.966993, "supported_languages": null}, "macro.dbt.unique_key_is_null": {"name": "unique_key_is_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_is_null", "macro_sql": "{% macro unique_key_is_null(unique_key, identifier) %}\n    {% if unique_key | is_list %}\n        {{ identifier }}.dbt_unique_key_1 is null\n    {% else %}\n        {{ identifier }}.dbt_unique_key is null\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.967232, "supported_languages": null}, "macro.dbt.unique_key_is_not_null": {"name": "unique_key_is_not_null", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "unique_id": "macro.dbt.unique_key_is_not_null", "macro_sql": "{% macro unique_key_is_not_null(unique_key, identifier) %}\n    {% if unique_key | is_list %}\n        {{ identifier }}.dbt_unique_key_1 is not null\n    {% else %}\n        {{ identifier }}.dbt_unique_key is not null\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9674695, "supported_languages": null}, "macro.dbt.materialization_seed_default": {"name": "materialization_seed_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/seed.sql", "original_file_path": "macros/materializations/seeds/seed.sql", "unique_id": "macro.dbt.materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set grant_config = config.get('grants') -%}\n  {%- set agate_table = load_agate_table() -%}\n  -- grab current tables grants config for comparison later on\n\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation.render())) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ get_csv_sql(create_table_sql, sql) }};\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n\n  {% set should_revoke = should_revoke(old_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.get_csv_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9703364, "supported_languages": ["sql"]}, "macro.dbt.create_csv_table": {"name": "create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9714751, "supported_languages": null}, "macro.dbt.default__create_csv_table": {"name": "default__create_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9726303, "supported_languages": null}, "macro.dbt.reset_csv_table": {"name": "reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table', 'dbt')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__reset_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9729288, "supported_languages": null}, "macro.dbt.default__reset_csv_table": {"name": "default__reset_csv_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation.render() %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9735184, "supported_languages": null}, "macro.dbt.get_csv_sql": {"name": "get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_csv_sql", "macro_sql": "{% macro get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ adapter.dispatch('get_csv_sql', 'dbt')(create_or_truncate_sql, insert_sql) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_csv_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9737294, "supported_languages": null}, "macro.dbt.default__get_csv_sql": {"name": "default__get_csv_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_csv_sql", "macro_sql": "{% macro default__get_csv_sql(create_or_truncate_sql, insert_sql) %}\n    {{ create_or_truncate_sql }};\n    -- dbt seed --\n    {{ insert_sql }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9738822, "supported_languages": null}, "macro.dbt.get_binding_char": {"name": "get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_binding_char", "macro_sql": "{% macro get_binding_char() -%}\n  {{ adapter.dispatch('get_binding_char', 'dbt')() }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9740386, "supported_languages": null}, "macro.dbt.default__get_binding_char": {"name": "default__get_binding_char", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_binding_char", "macro_sql": "{% macro default__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9741669, "supported_languages": null}, "macro.dbt.get_batch_size": {"name": "get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_batch_size", "macro_sql": "{% macro get_batch_size() -%}\n  {{ return(adapter.dispatch('get_batch_size', 'dbt')()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_batch_size"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9743383, "supported_languages": null}, "macro.dbt.default__get_batch_size": {"name": "default__get_batch_size", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__get_batch_size", "macro_sql": "{% macro default__get_batch_size() %}\n  {{ return(10000) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.974468, "supported_languages": null}, "macro.dbt.get_seed_column_quoted_csv": {"name": "get_seed_column_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9750855, "supported_languages": null}, "macro.dbt.load_csv_rows": {"name": "load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__load_csv_rows"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9752896, "supported_languages": null}, "macro.dbt.default__load_csv_rows": {"name": "default__load_csv_rows", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "unique_id": "macro.dbt.default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n\n  {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n  {% set bindings = [] %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} ({{ cols_sql }}) values\n          {% for row in chunk -%}\n              ({%- for column in agate_table.column_names -%}\n                  {{ get_binding_char() }}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9767373, "supported_languages": null}, "macro.dbt.materialization_view_default": {"name": "materialization_view_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/view.sql", "original_file_path": "macros/materializations/models/view.sql", "unique_id": "macro.dbt.materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='view') -%}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"existing_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the existing_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the existing_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if existing_relation is not none %}\n     /* Do the equivalent of rename_if_exists. 'existing_relation' could have been dropped\n        since the variable was first set. */\n    {% set existing_relation = load_cached_relation(existing_relation) %}\n    {% if existing_relation is not none %}\n        {{ adapter.rename_relation(existing_relation, backup_relation) }}\n    {% endif %}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.run_hooks", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9790568, "supported_languages": ["sql"]}, "macro.dbt.materialization_table_default": {"name": "materialization_table_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/table.sql", "original_file_path": "macros/materializations/models/table.sql", "unique_id": "macro.dbt.materialization_table_default", "macro_sql": "{% materialization table, default %}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') %}\n  {%- set intermediate_relation =  make_intermediate_relation(target_relation) -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) -%}\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n  -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_table_as_sql(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  {% do create_indexes(intermediate_relation) %}\n\n  -- cleanup\n  {% if existing_relation is not none %}\n     /* Do the equivalent of rename_if_exists. 'existing_relation' could have been dropped\n        since the variable was first set. */\n    {% set existing_relation = load_cached_relation(existing_relation) %}\n    {% if existing_relation is not none %}\n        {{ adapter.rename_relation(existing_relation, backup_relation) }}\n    {% endif %}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.get_create_table_as_sql", "macro.dbt.create_indexes", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.981388, "supported_languages": ["sql"]}, "macro.dbt.materialization_materialized_view_default": {"name": "materialization_materialized_view_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialization_materialized_view_default", "macro_sql": "{% materialization materialized_view, default %}\n    {% set existing_relation = load_cached_relation(this) %}\n    {% set target_relation = this.incorporate(type=this.MaterializedView) %}\n    {% set intermediate_relation = make_intermediate_relation(target_relation) %}\n    {% set backup_relation_type = target_relation.MaterializedView if existing_relation is none else existing_relation.type %}\n    {% set backup_relation = make_backup_relation(target_relation, backup_relation_type) %}\n\n    {{ materialized_view_setup(backup_relation, intermediate_relation, pre_hooks) }}\n\n        {% set build_sql = materialized_view_get_build_sql(existing_relation, target_relation, backup_relation, intermediate_relation) %}\n\n        {% if build_sql == '' %}\n            {{ materialized_view_execute_no_op(target_relation) }}\n        {% else %}\n            {{ materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) }}\n        {% endif %}\n\n    {{ materialized_view_teardown(backup_relation, intermediate_relation, post_hooks) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.materialized_view_setup", "macro.dbt.materialized_view_get_build_sql", "macro.dbt.materialized_view_execute_no_op", "macro.dbt.materialized_view_execute_build_sql", "macro.dbt.materialized_view_teardown"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9830399, "supported_languages": ["sql"]}, "macro.dbt.materialized_view_setup": {"name": "materialized_view_setup", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_setup", "macro_sql": "{% macro materialized_view_setup(backup_relation, intermediate_relation, pre_hooks) %}\n\n    -- backup_relation and intermediate_relation should not already exist in the database\n    -- it's possible these exist because of a previous run that exited unexpectedly\n    {% set preexisting_backup_relation = load_cached_relation(backup_relation) %}\n    {% set preexisting_intermediate_relation = load_cached_relation(intermediate_relation) %}\n\n    -- drop the temp relations if they exist already in the database\n    {{ drop_relation_if_exists(preexisting_backup_relation) }}\n    {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9834657, "supported_languages": null}, "macro.dbt.materialized_view_teardown": {"name": "materialized_view_teardown", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_teardown", "macro_sql": "{% macro materialized_view_teardown(backup_relation, intermediate_relation, post_hooks) %}\n\n    -- drop the temp relations if they exist to leave the database clean for the next run\n    {{ drop_relation_if_exists(backup_relation) }}\n    {{ drop_relation_if_exists(intermediate_relation) }}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9837399, "supported_languages": null}, "macro.dbt.materialized_view_get_build_sql": {"name": "materialized_view_get_build_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_get_build_sql", "macro_sql": "{% macro materialized_view_get_build_sql(existing_relation, target_relation, backup_relation, intermediate_relation) %}\n\n    {% set full_refresh_mode = should_full_refresh() %}\n\n    -- determine the scenario we're in: create, full_refresh, alter, refresh data\n    {% if existing_relation is none %}\n        {% set build_sql = get_create_materialized_view_as_sql(target_relation, sql) %}\n    {% elif full_refresh_mode or not existing_relation.is_materialized_view %}\n        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}\n    {% else %}\n\n        -- get config options\n        {% set on_configuration_change = config.get('on_configuration_change') %}\n        {% set configuration_changes = get_materialized_view_configuration_changes(existing_relation, config) %}\n\n        {% if configuration_changes is none %}\n            {% set build_sql = refresh_materialized_view(target_relation) %}\n\n        {% elif on_configuration_change == 'apply' %}\n            {% set build_sql = get_alter_materialized_view_as_sql(target_relation, configuration_changes, sql, existing_relation, backup_relation, intermediate_relation) %}\n        {% elif on_configuration_change == 'continue' %}\n            {% set build_sql = '' %}\n            {{ exceptions.warn(\"Configuration changes were identified and `on_configuration_change` was set to `continue` for `\" ~ target_relation.render() ~ \"`\") }}\n        {% elif on_configuration_change == 'fail' %}\n            {{ exceptions.raise_fail_fast_error(\"Configuration changes were identified and `on_configuration_change` was set to `fail` for `\" ~ target_relation.render() ~ \"`\") }}\n\n        {% else %}\n            -- this only happens if the user provides a value other than `apply`, 'skip', 'fail'\n            {{ exceptions.raise_compiler_error(\"Unexpected configuration scenario\") }}\n\n        {% endif %}\n\n    {% endif %}\n\n    {% do return(build_sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.get_create_materialized_view_as_sql", "macro.dbt.get_replace_sql", "macro.dbt.get_materialized_view_configuration_changes", "macro.dbt.refresh_materialized_view", "macro.dbt.get_alter_materialized_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.98526, "supported_languages": null}, "macro.dbt.materialized_view_execute_no_op": {"name": "materialized_view_execute_no_op", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_execute_no_op", "macro_sql": "{% macro materialized_view_execute_no_op(target_relation) %}\n    {% do store_raw_result(\n        name=\"main\",\n        message=\"skip \" ~ target_relation,\n        code=\"skip\",\n        rows_affected=\"-1\"\n    ) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9855142, "supported_languages": null}, "macro.dbt.materialized_view_execute_build_sql": {"name": "materialized_view_execute_build_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/materialized_view.sql", "original_file_path": "macros/materializations/models/materialized_view.sql", "unique_id": "macro.dbt.materialized_view_execute_build_sql", "macro_sql": "{% macro materialized_view_execute_build_sql(build_sql, existing_relation, target_relation, post_hooks) %}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% set grant_config = config.get('grants') %}\n\n    {% call statement(name=\"main\") %}\n        {{ build_sql }}\n    {% endcall %}\n\n    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n    {% do persist_docs(target_relation, model) %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {{ adapter.commit() }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9863555, "supported_languages": null}, "macro.dbt.is_incremental": {"name": "is_incremental", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/is_incremental.sql", "original_file_path": "macros/materializations/models/incremental/is_incremental.sql", "unique_id": "macro.dbt.is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9870596, "supported_languages": null}, "macro.dbt.incremental_validate_on_schema_change": {"name": "incremental_validate_on_schema_change", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.incremental_validate_on_schema_change", "macro_sql": "{% macro incremental_validate_on_schema_change(on_schema_change, default='ignore') %}\n\n   {% if on_schema_change not in ['sync_all_columns', 'append_new_columns', 'fail', 'ignore'] %}\n\n     {% set log_message = 'Invalid value for on_schema_change (%s) specified. Setting default value of %s.' % (on_schema_change, default) %}\n     {% do log(log_message) %}\n\n     {{ return(default) }}\n\n   {% else %}\n\n     {{ return(on_schema_change) }}\n\n   {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9882803, "supported_languages": null}, "macro.dbt.check_for_schema_changes": {"name": "check_for_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.check_for_schema_changes", "macro_sql": "{% macro check_for_schema_changes(source_relation, target_relation) %}\n\n  {% set schema_changed = False %}\n\n  {%- set source_columns = adapter.get_columns_in_relation(source_relation) -%}\n  {%- set target_columns = adapter.get_columns_in_relation(target_relation) -%}\n  {%- set source_not_in_target = diff_columns(source_columns, target_columns) -%}\n  {%- set target_not_in_source = diff_columns(target_columns, source_columns) -%}\n\n  {% set new_target_types = diff_column_data_types(source_columns, target_columns) %}\n\n  {% if source_not_in_target != [] %}\n    {% set schema_changed = True %}\n  {% elif target_not_in_source != [] or new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% elif new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% endif %}\n\n  {% set changes_dict = {\n    'schema_changed': schema_changed,\n    'source_not_in_target': source_not_in_target,\n    'target_not_in_source': target_not_in_source,\n    'source_columns': source_columns,\n    'target_columns': target_columns,\n    'new_target_types': new_target_types\n  } %}\n\n  {% set msg %}\n    In {{ target_relation }}:\n        Schema changed: {{ schema_changed }}\n        Source columns not in target: {{ source_not_in_target }}\n        Target columns not in source: {{ target_not_in_source }}\n        New column types: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(msg) %}\n\n  {{ return(changes_dict) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.diff_columns", "macro.dbt.diff_column_data_types"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9897897, "supported_languages": null}, "macro.dbt.sync_column_schemas": {"name": "sync_column_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.sync_column_schemas", "macro_sql": "{% macro sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n  {%- set add_to_target_arr = schema_changes_dict['source_not_in_target'] -%}\n\n  {%- if on_schema_change == 'append_new_columns'-%}\n     {%- if add_to_target_arr | length > 0 -%}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, none) -%}\n     {%- endif -%}\n\n  {% elif on_schema_change == 'sync_all_columns' %}\n     {%- set remove_from_target_arr = schema_changes_dict['target_not_in_source'] -%}\n     {%- set new_target_types = schema_changes_dict['new_target_types'] -%}\n\n     {% if add_to_target_arr | length > 0 or remove_from_target_arr | length > 0 %}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, remove_from_target_arr) -%}\n     {% endif %}\n\n     {% if new_target_types != [] %}\n       {% for ntt in new_target_types %}\n         {% set column_name = ntt['column_name'] %}\n         {% set new_type = ntt['new_type'] %}\n         {% do alter_column_type(target_relation, column_name, new_type) %}\n       {% endfor %}\n     {% endif %}\n\n  {% endif %}\n\n  {% set schema_change_message %}\n    In {{ target_relation }}:\n        Schema change approach: {{ on_schema_change }}\n        Columns added: {{ add_to_target_arr }}\n        Columns removed: {{ remove_from_target_arr }}\n        Data types changed: {{ new_target_types }}\n  {% endset %}\n\n  {% do log(schema_change_message) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.alter_relation_add_remove_columns", "macro.dbt.alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.991168, "supported_languages": null}, "macro.dbt.process_schema_changes": {"name": "process_schema_changes", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "unique_id": "macro.dbt.process_schema_changes", "macro_sql": "{% macro process_schema_changes(on_schema_change, source_relation, target_relation) %}\n\n    {% if on_schema_change == 'ignore' %}\n\n     {{ return({}) }}\n\n    {% else %}\n\n      {% set schema_changes_dict = check_for_schema_changes(source_relation, target_relation) %}\n\n      {% if schema_changes_dict['schema_changed'] %}\n\n        {% if on_schema_change == 'fail' %}\n\n          {% set fail_msg %}\n              The source and target schemas on this incremental model are out of sync!\n              They can be reconciled in several ways:\n                - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.\n                - Re-run the incremental model with `full_refresh: True` to update the target schema.\n                - update the schema manually and re-run the process.\n\n              Additional troubleshooting context:\n                 Source columns not in target: {{ schema_changes_dict['source_not_in_target'] }}\n                 Target columns not in source: {{ schema_changes_dict['target_not_in_source'] }}\n                 New column types: {{ schema_changes_dict['new_target_types'] }}\n          {% endset %}\n\n          {% do exceptions.raise_compiler_error(fail_msg) %}\n\n        {# -- unless we ignore, run the sync operation per the config #}\n        {% else %}\n\n          {% do sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n\n        {% endif %}\n\n      {% endif %}\n\n      {{ return(schema_changes_dict['source_columns']) }}\n\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.check_for_schema_changes", "macro.dbt.sync_column_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9921172, "supported_languages": null}, "macro.dbt.get_merge_sql": {"name": "get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n   -- back compat for old kwarg name\n  {% set incremental_predicates = kwargs.get('predicates', incremental_predicates) %}\n  {{ adapter.dispatch('get_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9932745, "supported_languages": null}, "macro.dbt.default__get_merge_sql": {"name": "default__get_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, incremental_predicates=none) -%}\n    {%- set predicates = [] if incremental_predicates is none else [] + incremental_predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set merge_update_columns = config.get('merge_update_columns') -%}\n    {%- set merge_exclude_columns = config.get('merge_exclude_columns') -%}\n    {%- set update_columns = get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% if unique_key is sequence and unique_key is not mapping and unique_key is not string %}\n            {% for key in unique_key %}\n                {% set this_key_match %}\n                    DBT_INTERNAL_SOURCE.{{ key }} = DBT_INTERNAL_DEST.{{ key }}\n                {% endset %}\n                {% do predicates.append(this_key_match) %}\n            {% endfor %}\n        {% else %}\n            {% set source_unique_key = (\"DBT_INTERNAL_SOURCE.\" ~ unique_key) | trim %}\n\t    {% set target_unique_key = (\"DBT_INTERNAL_DEST.\" ~ unique_key) | trim %}\n\t    {% set unique_key_match = equals(source_unique_key, target_unique_key) | trim %}\n            {% do predicates.append(unique_key_match) %}\n        {% endif %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{\"(\" ~ predicates | join(\") and (\") ~ \")\"}}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column_name in update_columns -%}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv", "macro.dbt.get_merge_update_columns", "macro.dbt.equals"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9952462, "supported_languages": null}, "macro.dbt.get_delete_insert_merge_sql": {"name": "get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql', 'dbt')(target, source, unique_key, dest_columns, incremental_predicates) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.995545, "supported_languages": null}, "macro.dbt.default__get_delete_insert_merge_sql": {"name": "default__get_delete_insert_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key %}\n        {% if unique_key is string %}\n        {% set unique_key = [unique_key] %}\n        {% endif %}\n\n        {%- set unique_key_str = unique_key|join(', ') -%}\n\n        delete from {{ target }} as DBT_INTERNAL_DEST\n        where ({{ unique_key_str }}) in (\n            select distinct {{ unique_key_str }}\n            from {{ source }} as DBT_INTERNAL_SOURCE\n        )\n        {%- if incremental_predicates %}\n            {% for predicate in incremental_predicates %}\n                and {{ predicate }}\n            {% endfor %}\n        {%- endif -%};\n\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    )\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9963627, "supported_languages": null}, "macro.dbt.get_insert_overwrite_merge_sql": {"name": "get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql', 'dbt')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9967337, "supported_languages": null}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"name": "default__get_insert_overwrite_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {#-- The only time include_sql_header is True: --#}\n    {#-- BigQuery + insert_overwrite strategy + \"static\" partitions config --#}\n    {#-- We should consider including the sql header at the materialization level instead --#}\n\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419968.9974415, "supported_languages": null}, "macro.dbt.materialization_incremental_default": {"name": "materialization_incremental_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/incremental.sql", "original_file_path": "macros/materializations/models/incremental/incremental.sql", "unique_id": "macro.dbt.materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  -- relations\n  {%- set existing_relation = load_cached_relation(this) -%}\n  {%- set target_relation = this.incorporate(type='table') -%}\n  {%- set temp_relation = make_temp_relation(target_relation)-%}\n  {%- set intermediate_relation = make_intermediate_relation(target_relation)-%}\n  {%- set backup_relation_type = 'table' if existing_relation is none else existing_relation.type -%}\n  {%- set backup_relation = make_backup_relation(target_relation, backup_relation_type) -%}\n\n  -- configs\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()  or existing_relation.is_view) -%}\n  {%- set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') -%}\n\n  -- the temp_ and backup_ relations should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation. This has to happen before\n  -- BEGIN, in a separate transaction\n  {%- set preexisting_intermediate_relation = load_cached_relation(intermediate_relation)-%}\n  {%- set preexisting_backup_relation = load_cached_relation(backup_relation) -%}\n   -- grab current tables grants config for comparision later on\n  {% set grant_config = config.get('grants') %}\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n\n  {% set incremental_strategy = config.get('incremental_strategy') or 'default' %}\n  {% set strategy_sql_macro_func = adapter.get_incremental_strategy_macro(context, incremental_strategy) %}\n\n  {% if existing_relation is none %}\n      {% set build_sql = get_create_table_as_sql(False, target_relation, sql) %}\n      {% set relation_for_indexes = target_relation %}\n  {% elif full_refresh_mode %}\n      {% set build_sql = get_create_table_as_sql(False, intermediate_relation, sql) %}\n      {% set relation_for_indexes = intermediate_relation %}\n      {% set need_swap = true %}\n  {% else %}\n    {% do run_query(get_create_table_as_sql(True, temp_relation, sql)) %}\n    {% set relation_for_indexes = temp_relation %}\n    {% set contract_config = config.get('contract') %}\n    {% if not contract_config or not contract_config.enforced %}\n      {% do adapter.expand_target_column_types(\n               from_relation=temp_relation,\n               to_relation=target_relation) %}\n    {% endif %}\n    {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n    {% set dest_columns = process_schema_changes(on_schema_change, temp_relation, existing_relation) %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n\n    {#-- Get the incremental_strategy, the macro to use for the strategy, and build the sql --#}\n    {% set incremental_predicates = config.get('predicates', none) or config.get('incremental_predicates', none) %}\n    {% set strategy_arg_dict = ({'target_relation': target_relation, 'temp_relation': temp_relation, 'unique_key': unique_key, 'dest_columns': dest_columns, 'incremental_predicates': incremental_predicates }) %}\n    {% set build_sql = strategy_sql_macro_func(strategy_arg_dict) %}\n\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% if existing_relation is none or existing_relation.is_view or should_full_refresh() %}\n    {% do create_indexes(relation_for_indexes) %}\n  {% endif %}\n\n  {% if need_swap %}\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% do adapter.rename_relation(intermediate_relation, target_relation) %}\n      {% do to_drop.append(backup_relation) %}\n  {% endif %}\n\n  {% set should_revoke = should_revoke(existing_relation, full_refresh_mode) %}\n  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.make_temp_relation", "macro.dbt.make_intermediate_relation", "macro.dbt.make_backup_relation", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.get_create_table_as_sql", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt.statement", "macro.dbt.create_indexes", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0026863, "supported_languages": ["sql"]}, "macro.dbt.get_quoted_csv": {"name": "get_quoted_csv", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0036016, "supported_languages": null}, "macro.dbt.diff_columns": {"name": "diff_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_columns", "macro_sql": "{% macro diff_columns(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% set source_names = source_columns | map(attribute = 'column') | list %}\n  {% set target_names = target_columns | map(attribute = 'column') | list %}\n\n   {# --check whether the name attribute exists in the target - this does not perform a data type check #}\n   {% for sc in source_columns %}\n     {% if sc.name not in target_names %}\n        {{ result.append(sc) }}\n     {% endif %}\n   {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0042243, "supported_languages": null}, "macro.dbt.diff_column_data_types": {"name": "diff_column_data_types", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.diff_column_data_types", "macro_sql": "{% macro diff_column_data_types(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% for sc in source_columns %}\n    {% set tc = target_columns | selectattr(\"name\", \"equalto\", sc.name) | list | first %}\n    {% if tc %}\n      {% if sc.data_type != tc.data_type and not sc.can_expand_to(other_column=tc) %}\n        {{ result.append( { 'column_name': tc.name, 'new_type': sc.data_type } ) }}\n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0050282, "supported_languages": null}, "macro.dbt.get_merge_update_columns": {"name": "get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.get_merge_update_columns", "macro_sql": "{% macro get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {{ return(adapter.dispatch('get_merge_update_columns', 'dbt')(merge_update_columns, merge_exclude_columns, dest_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_merge_update_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.005308, "supported_languages": null}, "macro.dbt.default__get_merge_update_columns": {"name": "default__get_merge_update_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "unique_id": "macro.dbt.default__get_merge_update_columns", "macro_sql": "{% macro default__get_merge_update_columns(merge_update_columns, merge_exclude_columns, dest_columns) %}\n  {%- set default_cols = dest_columns | map(attribute=\"quoted\") | list -%}\n\n  {%- if merge_update_columns and merge_exclude_columns -%}\n    {{ exceptions.raise_compiler_error(\n        'Model cannot specify merge_update_columns and merge_exclude_columns. Please update model to use only one config'\n    )}}\n  {%- elif merge_update_columns -%}\n    {%- set update_columns = merge_update_columns -%}\n  {%- elif merge_exclude_columns -%}\n    {%- set update_columns = [] -%}\n    {%- for column in dest_columns -%}\n      {% if column.column | lower not in merge_exclude_columns | map(\"lower\") | list %}\n        {%- do update_columns.append(column.quoted) -%}\n      {% endif %}\n    {%- endfor -%}\n  {%- else -%}\n    {%- set update_columns = default_cols -%}\n  {%- endif -%}\n\n  {{ return(update_columns) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.006116, "supported_languages": null}, "macro.dbt.get_incremental_append_sql": {"name": "get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_append_sql", "macro_sql": "{% macro get_incremental_append_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_append_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0068014, "supported_languages": null}, "macro.dbt.default__get_incremental_append_sql": {"name": "default__get_incremental_append_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_append_sql", "macro_sql": "{% macro default__get_incremental_append_sql(arg_dict) %}\n\n  {% do return(get_insert_into_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_into_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0070596, "supported_languages": null}, "macro.dbt.get_incremental_delete_insert_sql": {"name": "get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_delete_insert_sql", "macro_sql": "{% macro get_incremental_delete_insert_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_delete_insert_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_delete_insert_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0072756, "supported_languages": null}, "macro.dbt.default__get_incremental_delete_insert_sql": {"name": "default__get_incremental_delete_insert_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_delete_insert_sql", "macro_sql": "{% macro default__get_incremental_delete_insert_sql(arg_dict) %}\n\n  {% do return(get_delete_insert_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0075886, "supported_languages": null}, "macro.dbt.get_incremental_merge_sql": {"name": "get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_merge_sql", "macro_sql": "{% macro get_incremental_merge_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_merge_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0078013, "supported_languages": null}, "macro.dbt.default__get_incremental_merge_sql": {"name": "default__get_incremental_merge_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_merge_sql", "macro_sql": "{% macro default__get_incremental_merge_sql(arg_dict) %}\n\n  {% do return(get_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"unique_key\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.00811, "supported_languages": null}, "macro.dbt.get_incremental_insert_overwrite_sql": {"name": "get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_insert_overwrite_sql", "macro_sql": "{% macro get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_insert_overwrite_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_incremental_insert_overwrite_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0083246, "supported_languages": null}, "macro.dbt.default__get_incremental_insert_overwrite_sql": {"name": "default__get_incremental_insert_overwrite_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_insert_overwrite_sql", "macro_sql": "{% macro default__get_incremental_insert_overwrite_sql(arg_dict) %}\n\n  {% do return(get_insert_overwrite_merge_sql(arg_dict[\"target_relation\"], arg_dict[\"temp_relation\"], arg_dict[\"dest_columns\"], arg_dict[\"incremental_predicates\"])) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0086346, "supported_languages": null}, "macro.dbt.get_incremental_default_sql": {"name": "get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_default_sql", "macro_sql": "{% macro get_incremental_default_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_default_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_default_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0088644, "supported_languages": null}, "macro.dbt.default__get_incremental_default_sql": {"name": "default__get_incremental_default_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_default_sql", "macro_sql": "{% macro default__get_incremental_default_sql(arg_dict) %}\n\n  {% do return(get_incremental_append_sql(arg_dict)) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_incremental_append_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0090442, "supported_languages": null}, "macro.dbt.get_incremental_microbatch_sql": {"name": "get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_incremental_microbatch_sql", "macro_sql": "{% macro get_incremental_microbatch_sql(arg_dict) %}\n\n  {{ return(adapter.dispatch('get_incremental_microbatch_sql', 'dbt')(arg_dict)) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_incremental_microbatch_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.009252, "supported_languages": null}, "macro.dbt.default__get_incremental_microbatch_sql": {"name": "default__get_incremental_microbatch_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.default__get_incremental_microbatch_sql", "macro_sql": "{% macro default__get_incremental_microbatch_sql(arg_dict) %}\n\n  {{ exceptions.raise_not_implemented('microbatch materialization strategy not implemented for adapter ' + adapter.type()) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.009444, "supported_languages": null}, "macro.dbt.get_insert_into_sql": {"name": "get_insert_into_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/incremental/strategies.sql", "original_file_path": "macros/materializations/models/incremental/strategies.sql", "unique_id": "macro.dbt.get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(target_relation, temp_relation, dest_columns) %}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ temp_relation }}\n    )\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0097585, "supported_languages": null}, "macro.dbt.materialization_clone_default": {"name": "materialization_clone_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/clone.sql", "original_file_path": "macros/materializations/models/clone/clone.sql", "unique_id": "macro.dbt.materialization_clone_default", "macro_sql": "{%- materialization clone, default -%}\n\n  {%- set relations = {'relations': []} -%}\n\n  {%- if not defer_relation -%}\n      -- nothing to do\n      {{ log(\"No relation found in state manifest for \" ~ model.unique_id, info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set existing_relation = load_cached_relation(this) -%}\n\n  {%- if existing_relation and not flags.FULL_REFRESH -%}\n      -- noop!\n      {{ log(\"Relation \" ~ existing_relation ~ \" already exists\", info=True) }}\n      {{ return(relations) }}\n  {%- endif -%}\n\n  {%- set other_existing_relation = load_cached_relation(defer_relation) -%}\n\n  -- If this is a database that can do zero-copy cloning of tables, and the other relation is a table, then this will be a table\n  -- Otherwise, this will be a view\n\n  {% set can_clone_table = can_clone_table() %}\n\n  {%- if other_existing_relation and other_existing_relation.type == 'table' and can_clone_table -%}\n\n      {%- set target_relation = this.incorporate(type='table') -%}\n      {% if existing_relation is not none and not existing_relation.is_table %}\n        {{ log(\"Dropping relation \" ~ existing_relation.render() ~ \" because it is of type \" ~ existing_relation.type) }}\n        {{ drop_relation_if_exists(existing_relation) }}\n      {% endif %}\n\n      -- as a general rule, data platforms that can clone tables can also do atomic 'create or replace'\n      {% if target_relation.database == defer_relation.database and\n            target_relation.schema == defer_relation.schema and\n            target_relation.identifier == defer_relation.identifier %}\n        {{ log(\"Target relation and defer relation are the same, skipping clone for relation: \" ~ target_relation.render()) }}\n      {% else %}\n        {% call statement('main') %}\n            {{ create_or_replace_clone(target_relation, defer_relation) }}\n        {% endcall %}\n      {% endif %}\n      {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}\n      {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}\n      {% do persist_docs(target_relation, model) %}\n\n      {{ return({'relations': [target_relation]}) }}\n\n  {%- else -%}\n\n      {%- set target_relation = this.incorporate(type='view') -%}\n\n      -- reuse the view materialization\n      -- TODO: support actual dispatch for materialization macros\n      -- Tracking ticket: https://github.com/dbt-labs/dbt-core/issues/7799\n      {% set search_name = \"materialization_view_\" ~ adapter.type() %}\n      {% if not search_name in context %}\n          {% set search_name = \"materialization_view_default\" %}\n      {% endif %}\n      {% set materialization_macro = context[search_name] %}\n      {% set relations = materialization_macro() %}\n      {{ return(relations) }}\n\n  {%- endif -%}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.load_cached_relation", "macro.dbt.can_clone_table", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_or_replace_clone", "macro.dbt.should_revoke", "macro.dbt.apply_grants", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0126448, "supported_languages": ["sql"]}, "macro.dbt.can_clone_table": {"name": "can_clone_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/can_clone_table.sql", "original_file_path": "macros/materializations/models/clone/can_clone_table.sql", "unique_id": "macro.dbt.can_clone_table", "macro_sql": "{% macro can_clone_table() %}\n    {{ return(adapter.dispatch('can_clone_table', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__can_clone_table"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0129466, "supported_languages": null}, "macro.dbt.default__can_clone_table": {"name": "default__can_clone_table", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/can_clone_table.sql", "original_file_path": "macros/materializations/models/clone/can_clone_table.sql", "unique_id": "macro.dbt.default__can_clone_table", "macro_sql": "{% macro default__can_clone_table() %}\n    {{ return(False) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0130875, "supported_languages": null}, "macro.dbt.create_or_replace_clone": {"name": "create_or_replace_clone", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/create_or_replace_clone.sql", "original_file_path": "macros/materializations/models/clone/create_or_replace_clone.sql", "unique_id": "macro.dbt.create_or_replace_clone", "macro_sql": "{% macro create_or_replace_clone(this_relation, defer_relation) %}\n    {{ return(adapter.dispatch('create_or_replace_clone', 'dbt')(this_relation, defer_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_or_replace_clone"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0134172, "supported_languages": null}, "macro.dbt.default__create_or_replace_clone": {"name": "default__create_or_replace_clone", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/models/clone/create_or_replace_clone.sql", "original_file_path": "macros/materializations/models/clone/create_or_replace_clone.sql", "unique_id": "macro.dbt.default__create_or_replace_clone", "macro_sql": "{% macro default__create_or_replace_clone(this_relation, defer_relation) %}\n    create or replace table {{ this_relation.render() }} clone {{ defer_relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0136144, "supported_languages": null}, "macro.dbt.get_where_subquery": {"name": "get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.get_where_subquery", "macro_sql": "{% macro get_where_subquery(relation) -%}\n    {% do return(adapter.dispatch('get_where_subquery', 'dbt')(relation)) %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_where_subquery"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0139534, "supported_languages": null}, "macro.dbt.default__get_where_subquery": {"name": "default__get_where_subquery", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "unique_id": "macro.dbt.default__get_where_subquery", "macro_sql": "{% macro default__get_where_subquery(relation) -%}\n    {% set where = config.get('where', '') %}\n    {% if where %}\n        {%- set filtered -%}\n            (select * from {{ relation }} where {{ where }}) dbt_subquery\n        {%- endset -%}\n        {% do return(filtered) %}\n    {%- else -%}\n        {% do return(relation) %}\n    {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0144062, "supported_languages": null}, "macro.dbt.materialization_test_default": {"name": "materialization_test_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/test.sql", "original_file_path": "macros/materializations/tests/test.sql", "unique_id": "macro.dbt.materialization_test_default", "macro_sql": "{%- materialization test, default -%}\n\n  {% set relations = [] %}\n  {% set limit = config.get('limit') %}\n\n  {% set sql_with_limit %}\n    {{ get_limit_subquery_sql(sql, limit) }}\n  {% endset %}\n\n  {% if should_store_failures() %}\n\n    {% set identifier = model['alias'] %}\n    {% set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n    {% set store_failures_as = config.get('store_failures_as') %}\n    -- if `--store-failures` is invoked via command line and `store_failures_as` is not set,\n    -- config.get('store_failures_as', 'table') returns None, not 'table'\n    {% if store_failures_as == none %}{% set store_failures_as = 'table' %}{% endif %}\n    {% if store_failures_as not in ['table', 'view'] %}\n        {{ exceptions.raise_compiler_error(\n            \"'\" ~ store_failures_as ~ \"' is not a valid value for `store_failures_as`. \"\n            \"Accepted values are: ['ephemeral', 'table', 'view']\"\n        ) }}\n    {% endif %}\n\n    {% set target_relation = api.Relation.create(\n        identifier=identifier, schema=schema, database=database, type=store_failures_as) -%} %}\n\n    {% if old_relation %}\n        {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n\n    {% call statement(auto_begin=True) %}\n        {{ get_create_sql(target_relation, sql_with_limit) }}\n    {% endcall %}\n\n    {% do relations.append(target_relation) %}\n\n    {# Since the test failures have already been saved to the database, reuse that result rather than querying again #}\n    {% set main_sql %}\n        select *\n        from {{ target_relation }}\n    {% endset %}\n\n    {{ adapter.commit() }}\n\n  {% else %}\n\n      {% set main_sql = sql_with_limit %}\n\n  {% endif %}\n\n  {% set fail_calc = config.get('fail_calc') %}\n  {% set warn_if = config.get('warn_if') %}\n  {% set error_if = config.get('error_if') %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {# The limit has already been included above, and we do not want to duplicate it again. We also want to be safe for macro overrides treating `limit` as a required parameter. #}\n    {{ get_test_sql(main_sql, fail_calc, warn_if, error_if, limit=none)}}\n\n  {%- endcall %}\n\n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.get_limit_subquery_sql", "macro.dbt.should_store_failures", "macro.dbt.statement", "macro.dbt.get_create_sql", "macro.dbt.get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0170329, "supported_languages": ["sql"]}, "macro.dbt.materialization_unit_default": {"name": "materialization_unit_default", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/unit.sql", "original_file_path": "macros/materializations/tests/unit.sql", "unique_id": "macro.dbt.materialization_unit_default", "macro_sql": "{%- materialization unit, default -%}\n\n  {% set relations = [] %}\n\n  {% set expected_rows = config.get('expected_rows') %}\n  {% set expected_sql = config.get('expected_sql') %}\n  {% set tested_expected_column_names = expected_rows[0].keys() if (expected_rows | length ) > 0 else get_columns_in_query(sql) %} %}\n\n  {%- set target_relation = this.incorporate(type='table') -%}\n  {%- set temp_relation = make_temp_relation(target_relation)-%}\n  {% do run_query(get_create_table_as_sql(True, temp_relation, get_empty_subquery_sql(sql))) %}\n  {%- set columns_in_relation = adapter.get_columns_in_relation(temp_relation) -%}\n  {%- set column_name_to_data_types = {} -%}\n  {%- for column in columns_in_relation -%}\n  {%-   do column_name_to_data_types.update({column.name|lower: column.data_type}) -%}\n  {%- endfor -%}\n\n  {% if not expected_sql %}\n  {%   set expected_sql = get_expected_sql(expected_rows, column_name_to_data_types) %}\n  {% endif %}\n  {% set unit_test_sql = get_unit_test_sql(sql, expected_sql, tested_expected_column_names) %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {{ unit_test_sql }}\n\n  {%- endcall %}\n\n  {% do adapter.drop_relation(temp_relation) %}\n\n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "depends_on": {"macros": ["macro.dbt.get_columns_in_query", "macro.dbt.make_temp_relation", "macro.dbt.run_query", "macro.dbt.get_create_table_as_sql", "macro.dbt.get_empty_subquery_sql", "macro.dbt.get_expected_sql", "macro.dbt.get_unit_test_sql", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0187156, "supported_languages": ["sql"]}, "macro.dbt.get_test_sql": {"name": "get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.get_test_sql", "macro_sql": "{% macro get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n  {{ adapter.dispatch('get_test_sql', 'dbt')(main_sql, fail_calc, warn_if, error_if, limit) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0193253, "supported_languages": null}, "macro.dbt.default__get_test_sql": {"name": "default__get_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.default__get_test_sql", "macro_sql": "{% macro default__get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n    select\n      {{ fail_calc }} as failures,\n      {{ fail_calc }} {{ warn_if }} as should_warn,\n      {{ fail_calc }} {{ error_if }} as should_error\n    from (\n      {{ main_sql }}\n      {{ \"limit \" ~ limit if limit != none }}\n    ) dbt_internal_test\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0196807, "supported_languages": null}, "macro.dbt.get_unit_test_sql": {"name": "get_unit_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.get_unit_test_sql", "macro_sql": "{% macro get_unit_test_sql(main_sql, expected_fixture_sql, expected_column_names) -%}\n  {{ adapter.dispatch('get_unit_test_sql', 'dbt')(main_sql, expected_fixture_sql, expected_column_names) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_unit_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0199149, "supported_languages": null}, "macro.dbt.default__get_unit_test_sql": {"name": "default__get_unit_test_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "unique_id": "macro.dbt.default__get_unit_test_sql", "macro_sql": "{% macro default__get_unit_test_sql(main_sql, expected_fixture_sql, expected_column_names) -%}\n-- Build actual result given inputs\nwith dbt_internal_unit_test_actual as (\n  select\n    {% for expected_column_name in expected_column_names %}{{expected_column_name}}{% if not loop.last -%},{% endif %}{%- endfor -%}, {{ dbt.string_literal(\"actual\") }} as {{ adapter.quote(\"actual_or_expected\") }}\n  from (\n    {{ main_sql }}\n  ) _dbt_internal_unit_test_actual\n),\n-- Build expected result\ndbt_internal_unit_test_expected as (\n  select\n    {% for expected_column_name in expected_column_names %}{{expected_column_name}}{% if not loop.last -%}, {% endif %}{%- endfor -%}, {{ dbt.string_literal(\"expected\") }} as {{ adapter.quote(\"actual_or_expected\") }}\n  from (\n    {{ expected_fixture_sql }}\n  ) _dbt_internal_unit_test_expected\n)\n-- Union actual and expected results\nselect * from dbt_internal_unit_test_actual\nunion all\nselect * from dbt_internal_unit_test_expected\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.string_literal"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0206192, "supported_languages": null}, "macro.dbt.get_catalog_relations": {"name": "get_catalog_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog_relations", "macro_sql": "{% macro get_catalog_relations(information_schema, relations) -%}\n  {{ return(adapter.dispatch('get_catalog_relations', 'dbt')(information_schema, relations)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog_relations"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0214741, "supported_languages": null}, "macro.dbt.default__get_catalog_relations": {"name": "default__get_catalog_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog_relations", "macro_sql": "{% macro default__get_catalog_relations(information_schema, relations) -%}\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog_relations not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.021778, "supported_languages": null}, "macro.dbt.get_catalog": {"name": "get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog', 'dbt')(information_schema, schemas)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0220206, "supported_languages": null}, "macro.dbt.default__get_catalog": {"name": "default__get_catalog", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0223327, "supported_languages": null}, "macro.dbt.information_schema_name": {"name": "information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__information_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0225368, "supported_languages": null}, "macro.dbt.default__information_schema_name": {"name": "default__information_schema_name", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.022721, "supported_languages": null}, "macro.dbt.list_schemas": {"name": "list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas', 'dbt')(database)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__list_schemas"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0229537, "supported_languages": null}, "macro.dbt.default__list_schemas": {"name": "default__list_schemas", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.information_schema_name", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.023232, "supported_languages": null}, "macro.dbt.check_schema_exists": {"name": "check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists', 'dbt')(information_schema, schema)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__check_schema_exists"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0234764, "supported_languages": null}, "macro.dbt.default__check_schema_exists": {"name": "default__check_schema_exists", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0238209, "supported_languages": null}, "macro.dbt.list_relations_without_caching": {"name": "list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0240269, "supported_languages": null}, "macro.dbt.default__list_relations_without_caching": {"name": "default__list_relations_without_caching", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0242078, "supported_languages": null}, "macro.dbt.get_catalog_for_single_relation": {"name": "get_catalog_for_single_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_catalog_for_single_relation", "macro_sql": "{% macro get_catalog_for_single_relation(relation) %}\n  {{ return(adapter.dispatch('get_catalog_for_single_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_catalog_for_single_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0244095, "supported_languages": null}, "macro.dbt.default__get_catalog_for_single_relation": {"name": "default__get_catalog_for_single_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_catalog_for_single_relation", "macro_sql": "{% macro default__get_catalog_for_single_relation(relation) %}\n  {{ exceptions.raise_not_implemented(\n    'get_catalog_for_single_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0245955, "supported_languages": null}, "macro.dbt.get_relations": {"name": "get_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_relations", "macro_sql": "{% macro get_relations() %}\n  {{ return(adapter.dispatch('get_relations', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_relations"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.024778, "supported_languages": null}, "macro.dbt.default__get_relations": {"name": "default__get_relations", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_relations", "macro_sql": "{% macro default__get_relations() %}\n  {{ exceptions.raise_not_implemented(\n    'get_relations macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.024971, "supported_languages": null}, "macro.dbt.get_relation_last_modified": {"name": "get_relation_last_modified", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.get_relation_last_modified", "macro_sql": "{% macro get_relation_last_modified(information_schema, relations) %}\n  {{ return(adapter.dispatch('get_relation_last_modified', 'dbt')(information_schema, relations)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_relation_last_modified"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0251963, "supported_languages": null}, "macro.dbt.default__get_relation_last_modified": {"name": "default__get_relation_last_modified", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "unique_id": "macro.dbt.default__get_relation_last_modified", "macro_sql": "{% macro default__get_relation_last_modified(information_schema, relations) %}\n  {{ exceptions.raise_not_implemented(\n    'get_relation_last_modified macro not implemented for adapter ' + adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.025476, "supported_languages": null}, "macro.dbt.make_intermediate_relation": {"name": "make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_intermediate_relation", "macro_sql": "{% macro make_intermediate_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_intermediate_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_intermediate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0264766, "supported_languages": null}, "macro.dbt.default__make_intermediate_relation": {"name": "default__make_intermediate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_intermediate_relation", "macro_sql": "{% macro default__make_intermediate_relation(base_relation, suffix) %}\n    {{ return(default__make_temp_relation(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.026718, "supported_languages": null}, "macro.dbt.make_temp_relation": {"name": "make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {#-- This ensures microbatch batches get unique temp relations to avoid clobbering --#}\n  {% if suffix == '__dbt_tmp' and model.batch %}\n    {% set suffix = suffix ~ '_' ~ model.batch.id %}\n  {% endif %}\n\n  {{ return(adapter.dispatch('make_temp_relation', 'dbt')(base_relation, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0271914, "supported_languages": null}, "macro.dbt.default__make_temp_relation": {"name": "default__make_temp_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {%- set temp_identifier = base_relation.identifier ~ suffix -%}\n    {%- set temp_relation = base_relation.incorporate(\n                                path={\"identifier\": temp_identifier}) -%}\n\n    {{ return(temp_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.027554, "supported_languages": null}, "macro.dbt.make_backup_relation": {"name": "make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.make_backup_relation", "macro_sql": "{% macro make_backup_relation(base_relation, backup_relation_type, suffix='__dbt_backup') %}\n    {{ return(adapter.dispatch('make_backup_relation', 'dbt')(base_relation, backup_relation_type, suffix)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__make_backup_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.027857, "supported_languages": null}, "macro.dbt.default__make_backup_relation": {"name": "default__make_backup_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__make_backup_relation", "macro_sql": "{% macro default__make_backup_relation(base_relation, backup_relation_type, suffix) %}\n    {%- set backup_identifier = base_relation.identifier ~ suffix -%}\n    {%- set backup_relation = base_relation.incorporate(\n                                  path={\"identifier\": backup_identifier},\n                                  type=backup_relation_type\n    ) -%}\n    {{ return(backup_relation) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0282397, "supported_languages": null}, "macro.dbt.truncate_relation": {"name": "truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__truncate_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0284429, "supported_languages": null}, "macro.dbt.default__truncate_relation": {"name": "default__truncate_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation.render() }}\n  {%- endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0286677, "supported_languages": null}, "macro.dbt.get_or_create_relation": {"name": "get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) -%}\n  {{ return(adapter.dispatch('get_or_create_relation', 'dbt')(database, schema, identifier, type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_or_create_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0289578, "supported_languages": null}, "macro.dbt.default__get_or_create_relation": {"name": "default__get_or_create_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.default__get_or_create_relation", "macro_sql": "{% macro default__get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0296388, "supported_languages": null}, "macro.dbt.load_cached_relation": {"name": "load_cached_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_cached_relation", "macro_sql": "{% macro load_cached_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0299463, "supported_languages": null}, "macro.dbt.load_relation": {"name": "load_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "unique_id": "macro.dbt.load_relation", "macro_sql": "{% macro load_relation(relation) %}\n    {{ return(load_cached_relation(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.load_cached_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.030141, "supported_languages": null}, "macro.dbt.get_create_index_sql": {"name": "get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_create_index_sql", "macro_sql": "{% macro get_create_index_sql(relation, index_dict) -%}\n  {{ return(adapter.dispatch('get_create_index_sql', 'dbt')(relation, index_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_create_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0307477, "supported_languages": null}, "macro.dbt.default__get_create_index_sql": {"name": "default__get_create_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_create_index_sql", "macro_sql": "{% macro default__get_create_index_sql(relation, index_dict) -%}\n  {% do return(None) %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.030926, "supported_languages": null}, "macro.dbt.create_indexes": {"name": "create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.create_indexes", "macro_sql": "{% macro create_indexes(relation) -%}\n  {{ adapter.dispatch('create_indexes', 'dbt')(relation) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0311282, "supported_languages": null}, "macro.dbt.default__create_indexes": {"name": "default__create_indexes", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__create_indexes", "macro_sql": "{% macro default__create_indexes(relation) -%}\n  {%- set _indexes = config.get('indexes', default=[]) -%}\n\n  {% for _index_dict in _indexes %}\n    {% set create_index_sql = get_create_index_sql(relation, _index_dict) %}\n    {% if create_index_sql %}\n      {% do run_query(create_index_sql) %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_create_index_sql", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0316775, "supported_languages": null}, "macro.dbt.get_drop_index_sql": {"name": "get_drop_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_drop_index_sql", "macro_sql": "{% macro get_drop_index_sql(relation, index_name) -%}\n    {{ adapter.dispatch('get_drop_index_sql', 'dbt')(relation, index_name) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_drop_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0319326, "supported_languages": null}, "macro.dbt.default__get_drop_index_sql": {"name": "default__get_drop_index_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_drop_index_sql", "macro_sql": "{% macro default__get_drop_index_sql(relation, index_name) -%}\n    {{ exceptions.raise_compiler_error(\"`get_drop_index_sql has not been implemented for this adapter.\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.032142, "supported_languages": null}, "macro.dbt.get_show_indexes_sql": {"name": "get_show_indexes_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.get_show_indexes_sql", "macro_sql": "{% macro get_show_indexes_sql(relation) -%}\n    {{ adapter.dispatch('get_show_indexes_sql', 'dbt')(relation) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_show_indexes_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0323415, "supported_languages": null}, "macro.dbt.default__get_show_indexes_sql": {"name": "default__get_show_indexes_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "unique_id": "macro.dbt.default__get_show_indexes_sql", "macro_sql": "{% macro default__get_show_indexes_sql(relation) -%}\n    {{ exceptions.raise_compiler_error(\"`get_show_indexes_sql has not been implemented for this adapter.\") }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0325649, "supported_languages": null}, "macro.dbt.copy_grants": {"name": "copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.copy_grants", "macro_sql": "{% macro copy_grants() %}\n    {{ return(adapter.dispatch('copy_grants', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0339167, "supported_languages": null}, "macro.dbt.default__copy_grants": {"name": "default__copy_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__copy_grants", "macro_sql": "{% macro default__copy_grants() %}\n    {{ return(True) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.034115, "supported_languages": null}, "macro.dbt.support_multiple_grantees_per_dcl_statement": {"name": "support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.support_multiple_grantees_per_dcl_statement", "macro_sql": "{% macro support_multiple_grantees_per_dcl_statement() %}\n    {{ return(adapter.dispatch('support_multiple_grantees_per_dcl_statement', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0343354, "supported_languages": null}, "macro.dbt.default__support_multiple_grantees_per_dcl_statement": {"name": "default__support_multiple_grantees_per_dcl_statement", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__support_multiple_grantees_per_dcl_statement", "macro_sql": "\n\n{%- macro default__support_multiple_grantees_per_dcl_statement() -%}\n    {{ return(True) }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.034824, "supported_languages": null}, "macro.dbt.should_revoke": {"name": "should_revoke", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.should_revoke", "macro_sql": "{% macro should_revoke(existing_relation, full_refresh_mode=True) %}\n\n    {% if not existing_relation %}\n        {#-- The table doesn't already exist, so no grants to copy over --#}\n        {{ return(False) }}\n    {% elif full_refresh_mode %}\n        {#-- The object is being REPLACED -- whether grants are copied over depends on the value of user config --#}\n        {{ return(copy_grants()) }}\n    {% else %}\n        {#-- The table is being merged/upserted/inserted -- grants will be carried over --#}\n        {{ return(True) }}\n    {% endif %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.copy_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0353012, "supported_languages": null}, "macro.dbt.get_show_grant_sql": {"name": "get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_show_grant_sql", "macro_sql": "{% macro get_show_grant_sql(relation) %}\n    {{ return(adapter.dispatch(\"get_show_grant_sql\", \"dbt\")(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_show_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0355432, "supported_languages": null}, "macro.dbt.default__get_show_grant_sql": {"name": "default__get_show_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_show_grant_sql", "macro_sql": "{% macro default__get_show_grant_sql(relation) %}\n    show grants on {{ relation.render() }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0357006, "supported_languages": null}, "macro.dbt.get_grant_sql": {"name": "get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_grant_sql", "macro_sql": "{% macro get_grant_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_grant_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_grant_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0359726, "supported_languages": null}, "macro.dbt.default__get_grant_sql": {"name": "default__get_grant_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_grant_sql", "macro_sql": "\n\n{%- macro default__get_grant_sql(relation, privilege, grantees) -%}\n    grant {{ privilege }} on {{ relation.render() }} to {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0362513, "supported_languages": null}, "macro.dbt.get_revoke_sql": {"name": "get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_revoke_sql", "macro_sql": "{% macro get_revoke_sql(relation, privilege, grantees) %}\n    {{ return(adapter.dispatch('get_revoke_sql', 'dbt')(relation, privilege, grantees)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_revoke_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0366006, "supported_languages": null}, "macro.dbt.default__get_revoke_sql": {"name": "default__get_revoke_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_revoke_sql", "macro_sql": "\n\n{%- macro default__get_revoke_sql(relation, privilege, grantees) -%}\n    revoke {{ privilege }} on {{ relation.render() }} from {{ grantees | join(', ') }}\n{%- endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0368772, "supported_languages": null}, "macro.dbt.get_dcl_statement_list": {"name": "get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.get_dcl_statement_list", "macro_sql": "{% macro get_dcl_statement_list(relation, grant_config, get_dcl_macro) %}\n    {{ return(adapter.dispatch('get_dcl_statement_list', 'dbt')(relation, grant_config, get_dcl_macro)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_dcl_statement_list"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0371535, "supported_languages": null}, "macro.dbt.default__get_dcl_statement_list": {"name": "default__get_dcl_statement_list", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__get_dcl_statement_list", "macro_sql": "\n\n{%- macro default__get_dcl_statement_list(relation, grant_config, get_dcl_macro) -%}\n    {#\n      -- Unpack grant_config into specific privileges and the set of users who need them granted/revoked.\n      -- Depending on whether this database supports multiple grantees per statement, pass in the list of\n      -- all grantees per privilege, or (if not) template one statement per privilege-grantee pair.\n      -- `get_dcl_macro` will be either `get_grant_sql` or `get_revoke_sql`\n    #}\n    {%- set dcl_statements = [] -%}\n    {%- for privilege, grantees in grant_config.items() %}\n        {%- if support_multiple_grantees_per_dcl_statement() and grantees -%}\n          {%- set dcl = get_dcl_macro(relation, privilege, grantees) -%}\n          {%- do dcl_statements.append(dcl) -%}\n        {%- else -%}\n          {%- for grantee in grantees -%}\n              {% set dcl = get_dcl_macro(relation, privilege, [grantee]) %}\n              {%- do dcl_statements.append(dcl) -%}\n          {% endfor -%}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return(dcl_statements) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.support_multiple_grantees_per_dcl_statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0380008, "supported_languages": null}, "macro.dbt.call_dcl_statements": {"name": "call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.call_dcl_statements", "macro_sql": "{% macro call_dcl_statements(dcl_statement_list) %}\n    {{ return(adapter.dispatch(\"call_dcl_statements\", \"dbt\")(dcl_statement_list)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0382538, "supported_languages": null}, "macro.dbt.default__call_dcl_statements": {"name": "default__call_dcl_statements", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__call_dcl_statements", "macro_sql": "{% macro default__call_dcl_statements(dcl_statement_list) %}\n    {#\n      -- By default, supply all grant + revoke statements in a single semicolon-separated block,\n      -- so that they're all processed together.\n\n      -- Some databases do not support this. Those adapters will need to override this macro\n      -- to run each statement individually.\n    #}\n    {% call statement('grants') %}\n        {% for dcl_statement in dcl_statement_list %}\n            {{ dcl_statement }};\n        {% endfor %}\n    {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.038651, "supported_languages": null}, "macro.dbt.apply_grants": {"name": "apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.apply_grants", "macro_sql": "{% macro apply_grants(relation, grant_config, should_revoke) %}\n    {{ return(adapter.dispatch(\"apply_grants\", \"dbt\")(relation, grant_config, should_revoke)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__apply_grants"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0389512, "supported_languages": null}, "macro.dbt.default__apply_grants": {"name": "default__apply_grants", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/apply_grants.sql", "original_file_path": "macros/adapters/apply_grants.sql", "unique_id": "macro.dbt.default__apply_grants", "macro_sql": "{% macro default__apply_grants(relation, grant_config, should_revoke=True) %}\n    {#-- If grant_config is {} or None, this is a no-op --#}\n    {% if grant_config %}\n        {% if should_revoke %}\n            {#-- We think previous grants may have carried over --#}\n            {#-- Show current grants and calculate diffs --#}\n            {% set current_grants_table = run_query(get_show_grant_sql(relation)) %}\n            {% set current_grants_dict = adapter.standardize_grants_dict(current_grants_table) %}\n            {% set needs_granting = diff_of_two_dicts(grant_config, current_grants_dict) %}\n            {% set needs_revoking = diff_of_two_dicts(current_grants_dict, grant_config) %}\n            {% if not (needs_granting or needs_revoking) %}\n                {{ log('On ' ~ relation.render() ~': All grants are in place, no revocation or granting needed.')}}\n            {% endif %}\n        {% else %}\n            {#-- We don't think there's any chance of previous grants having carried over. --#}\n            {#-- Jump straight to granting what the user has configured. --#}\n            {% set needs_revoking = {} %}\n            {% set needs_granting = grant_config %}\n        {% endif %}\n        {% if needs_granting or needs_revoking %}\n            {% set revoke_statement_list = get_dcl_statement_list(relation, needs_revoking, get_revoke_sql) %}\n            {% set grant_statement_list = get_dcl_statement_list(relation, needs_granting, get_grant_sql) %}\n            {% set dcl_statement_list = revoke_statement_list + grant_statement_list %}\n            {% if dcl_statement_list %}\n                {{ call_dcl_statements(dcl_statement_list) }}\n            {% endif %}\n        {% endif %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.get_show_grant_sql", "macro.dbt.get_dcl_statement_list", "macro.dbt.call_dcl_statements"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0405211, "supported_languages": null}, "macro.dbt.validate_sql": {"name": "validate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/validate_sql.sql", "original_file_path": "macros/adapters/validate_sql.sql", "unique_id": "macro.dbt.validate_sql", "macro_sql": "{% macro validate_sql(sql) -%}\n  {{ return(adapter.dispatch('validate_sql', 'dbt')(sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__validate_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.040903, "supported_languages": null}, "macro.dbt.default__validate_sql": {"name": "default__validate_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/validate_sql.sql", "original_file_path": "macros/adapters/validate_sql.sql", "unique_id": "macro.dbt.default__validate_sql", "macro_sql": "{% macro default__validate_sql(sql) -%}\n  {% call statement('validate_sql') -%}\n    explain {{ sql }}\n  {% endcall %}\n  {{ return(load_result('validate_sql')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0411932, "supported_languages": null}, "macro.dbt.alter_column_comment": {"name": "alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0416853, "supported_languages": null}, "macro.dbt.default__alter_column_comment": {"name": "default__alter_column_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0419033, "supported_languages": null}, "macro.dbt.alter_relation_comment": {"name": "alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment', 'dbt')(relation, relation_comment)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__alter_relation_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0421476, "supported_languages": null}, "macro.dbt.default__alter_relation_comment": {"name": "default__alter_relation_comment", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.042389, "supported_languages": null}, "macro.dbt.persist_docs": {"name": "persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs', 'dbt')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0427144, "supported_languages": null}, "macro.dbt.default__persist_docs": {"name": "default__persist_docs", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "unique_id": "macro.dbt.default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.alter_relation_comment", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.043335, "supported_languages": null}, "macro.dbt.create_schema": {"name": "create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__create_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0437362, "supported_languages": null}, "macro.dbt.default__create_schema": {"name": "default__create_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.043979, "supported_languages": null}, "macro.dbt.drop_schema": {"name": "drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema', 'dbt')(relation) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__drop_schema"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0441802, "supported_languages": null}, "macro.dbt.default__drop_schema": {"name": "default__drop_schema", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "unique_id": "macro.dbt.default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0444357, "supported_languages": null}, "macro.dbt.get_columns_in_relation": {"name": "get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation', 'dbt')(relation)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.045695, "supported_languages": null}, "macro.dbt.default__get_columns_in_relation": {"name": "default__get_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0459032, "supported_languages": null}, "macro.dbt.sql_convert_columns_in_relation": {"name": "sql_convert_columns_in_relation", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0463629, "supported_languages": null}, "macro.dbt.get_list_of_column_names": {"name": "get_list_of_column_names", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_list_of_column_names", "macro_sql": "\n\n{%- macro get_list_of_column_names(columns) -%}\n  {% set col_names = [] %}\n  {% for col in columns %}\n    {% do col_names.append(col.name) %}\n  {% endfor %}\n  {{ return(col_names) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0467389, "supported_languages": null}, "macro.dbt.get_empty_subquery_sql": {"name": "get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_subquery_sql", "macro_sql": "{% macro get_empty_subquery_sql(select_sql, select_sql_header=none) -%}\n  {{ return(adapter.dispatch('get_empty_subquery_sql', 'dbt')(select_sql, select_sql_header)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0470064, "supported_languages": null}, "macro.dbt.default__get_empty_subquery_sql": {"name": "default__get_empty_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_subquery_sql", "macro_sql": "{% macro default__get_empty_subquery_sql(select_sql, select_sql_header=none) %}\n    {%- if select_sql_header is not none -%}\n    {{ select_sql_header }}\n    {%- endif -%}\n    select * from (\n        {{ select_sql }}\n    ) as __dbt_sbq\n    where false\n    limit 0\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.047268, "supported_languages": null}, "macro.dbt.get_empty_schema_sql": {"name": "get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_empty_schema_sql", "macro_sql": "{% macro get_empty_schema_sql(columns) -%}\n  {{ return(adapter.dispatch('get_empty_schema_sql', 'dbt')(columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_empty_schema_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0474875, "supported_languages": null}, "macro.dbt.default__get_empty_schema_sql": {"name": "default__get_empty_schema_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_empty_schema_sql", "macro_sql": "{% macro default__get_empty_schema_sql(columns) %}\n    {%- set col_err = [] -%}\n    {%- set col_naked_numeric = [] -%}\n    select\n    {% for i in columns %}\n      {%- set col = columns[i] -%}\n      {%- if col['data_type'] is not defined -%}\n        {%- do col_err.append(col['name']) -%}\n      {#-- If this column's type is just 'numeric' then it is missing precision/scale, raise a warning --#}\n      {%- elif col['data_type'].strip().lower() in ('numeric', 'decimal', 'number') -%}\n        {%- do col_naked_numeric.append(col['name']) -%}\n      {%- endif -%}\n      {% set col_name = adapter.quote(col['name']) if col.get('quote') else col['name'] %}\n      {{ cast('null', col['data_type']) }} as {{ col_name }}{{ \", \" if not loop.last }}\n    {%- endfor -%}\n    {%- if (col_err | length) > 0 -%}\n      {{ exceptions.column_type_missing(column_names=col_err) }}\n    {%- elif (col_naked_numeric | length) > 0 -%}\n      {{ exceptions.warn(\"Detected columns with numeric type and unspecified precision/scale, this can lead to unintended rounding: \" ~ col_naked_numeric ~ \"`\") }}\n    {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.cast"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0492504, "supported_languages": null}, "macro.dbt.get_column_schema_from_query": {"name": "get_column_schema_from_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_column_schema_from_query", "macro_sql": "{% macro get_column_schema_from_query(select_sql, select_sql_header=none) -%}\n    {% set columns = [] %}\n    {# -- Using an 'empty subquery' here to get the same schema as the given select_sql statement, without necessitating a data scan.#}\n    {% set sql = get_empty_subquery_sql(select_sql, select_sql_header) %}\n    {% set column_schema = adapter.get_column_schema_from_query(sql) %}\n    {{ return(column_schema) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.049755, "supported_languages": null}, "macro.dbt.get_columns_in_query": {"name": "get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query', 'dbt')(select_sql)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0499969, "supported_languages": null}, "macro.dbt.default__get_columns_in_query": {"name": "default__get_columns_in_query", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        {{ get_empty_subquery_sql(select_sql) }}\n    {% endcall %}\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.get_empty_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0504658, "supported_languages": null}, "macro.dbt.alter_column_type": {"name": "alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type', 'dbt')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_spark.spark__alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0507483, "supported_languages": null}, "macro.dbt.default__alter_column_type": {"name": "default__alter_column_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation.render() }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation.render() }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation.render() }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation.render() }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0515635, "supported_languages": null}, "macro.dbt.alter_relation_add_remove_columns": {"name": "alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.alter_relation_add_remove_columns", "macro_sql": "{% macro alter_relation_add_remove_columns(relation, add_columns = none, remove_columns = none) -%}\n  {{ return(adapter.dispatch('alter_relation_add_remove_columns', 'dbt')(relation, add_columns, remove_columns)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_relation_add_remove_columns"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0518727, "supported_languages": null}, "macro.dbt.default__alter_relation_add_remove_columns": {"name": "default__alter_relation_add_remove_columns", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "unique_id": "macro.dbt.default__alter_relation_add_remove_columns", "macro_sql": "{% macro default__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n\n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  {% if remove_columns is none %}\n    {% set remove_columns = [] %}\n  {% endif %}\n\n  {% set sql -%}\n\n     alter {{ relation.type }} {{ relation.render() }}\n\n            {% for column in add_columns %}\n               add column {{ column.quoted }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}{{ ',' if add_columns and remove_columns }}\n\n            {% for column in remove_columns %}\n                drop column {{ column.quoted }}{{ ',' if not loop.last }}\n            {% endfor %}\n\n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.052996, "supported_languages": null}, "macro.dbt.current_timestamp": {"name": "current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp", "macro_sql": "{%- macro current_timestamp() -%}\n    {{ adapter.dispatch('current_timestamp', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_spark.spark__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0535843, "supported_languages": null}, "macro.dbt.default__current_timestamp": {"name": "default__current_timestamp", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter ' + adapter.type()) }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0537822, "supported_languages": null}, "macro.dbt.snapshot_get_time": {"name": "snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.snapshot_get_time", "macro_sql": "\n\n{%- macro snapshot_get_time() -%}\n    {{ adapter.dispatch('snapshot_get_time', 'dbt')() }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0539663, "supported_languages": null}, "macro.dbt.default__snapshot_get_time": {"name": "default__snapshot_get_time", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() %}\n    {{ current_timestamp() }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0541086, "supported_languages": null}, "macro.dbt.get_snapshot_get_time_data_type": {"name": "get_snapshot_get_time_data_type", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.get_snapshot_get_time_data_type", "macro_sql": "{% macro get_snapshot_get_time_data_type() %}\n    {% set snapshot_time = adapter.dispatch('snapshot_get_time', 'dbt')() %}\n    {% set time_data_type_sql = 'select ' ~ snapshot_time ~ ' as dbt_snapshot_time' %}\n    {% set snapshot_time_column_schema = get_column_schema_from_query(time_data_type_sql) %}\n    {% set time_data_type = snapshot_time_column_schema[0].dtype %}\n    {{ return(time_data_type or none) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.default__snapshot_get_time", "macro.dbt.get_column_schema_from_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0546722, "supported_languages": null}, "macro.dbt.current_timestamp_backcompat": {"name": "current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_backcompat", "macro_sql": "{% macro current_timestamp_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0548935, "supported_languages": null}, "macro.dbt.default__current_timestamp_backcompat": {"name": "default__current_timestamp_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_backcompat", "macro_sql": "{% macro default__current_timestamp_backcompat() %}\n    current_timestamp::timestamp\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0549967, "supported_languages": null}, "macro.dbt.current_timestamp_in_utc_backcompat": {"name": "current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.current_timestamp_in_utc_backcompat", "macro_sql": "{% macro current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_in_utc_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__current_timestamp_in_utc_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.055211, "supported_languages": null}, "macro.dbt.default__current_timestamp_in_utc_backcompat": {"name": "default__current_timestamp_in_utc_backcompat", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/timestamps.sql", "original_file_path": "macros/adapters/timestamps.sql", "unique_id": "macro.dbt.default__current_timestamp_in_utc_backcompat", "macro_sql": "{% macro default__current_timestamp_in_utc_backcompat() %}\n    {{ return(adapter.dispatch('current_timestamp_backcompat', 'dbt')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.current_timestamp_backcompat", "macro.dbt.default__current_timestamp_backcompat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0554173, "supported_languages": null}, "macro.dbt.collect_freshness": {"name": "collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness', 'dbt')(source, loaded_at_field, filter))}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0560007, "supported_languages": null}, "macro.dbt.default__collect_freshness": {"name": "default__collect_freshness", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0568042, "supported_languages": null}, "macro.dbt.collect_freshness_custom_sql": {"name": "collect_freshness_custom_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.collect_freshness_custom_sql", "macro_sql": "{% macro collect_freshness_custom_sql(source, loaded_at_query) %}\n  {{ return(adapter.dispatch('collect_freshness_custom_sql', 'dbt')(source, loaded_at_query))}}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.default__collect_freshness_custom_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0572267, "supported_languages": null}, "macro.dbt.default__collect_freshness_custom_sql": {"name": "default__collect_freshness_custom_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "unique_id": "macro.dbt.default__collect_freshness_custom_sql", "macro_sql": "{% macro default__collect_freshness_custom_sql(source, loaded_at_query) %}\n  {% call statement('collect_freshness_custom_sql', fetch_result=True, auto_begin=False) -%}\n  with source_query as (\n    {{ loaded_at_query }}\n  )\n  select\n    (select * from source_query) as max_loaded_at,\n    {{ current_timestamp() }} as snapshotted_at\n  {% endcall %}\n  {{ return(load_result('collect_freshness_custom_sql')) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0576692, "supported_languages": null}, "macro.dbt.get_show_sql": {"name": "get_show_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.get_show_sql", "macro_sql": "{% macro get_show_sql(compiled_code, sql_header, limit) -%}\n  {%- if sql_header is not none -%}\n  {{ sql_header }}\n  {%- endif %}\n  {{ get_limit_subquery_sql(compiled_code, limit) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt.get_limit_subquery_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.058176, "supported_languages": null}, "macro.dbt.get_limit_subquery_sql": {"name": "get_limit_subquery_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.get_limit_subquery_sql", "macro_sql": "\n{%- macro get_limit_subquery_sql(sql, limit) -%}\n  {{ adapter.dispatch('get_limit_sql', 'dbt')(sql, limit) }}\n{%- endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt.default__get_limit_sql"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0584512, "supported_languages": null}, "macro.dbt.default__get_limit_sql": {"name": "default__get_limit_sql", "resource_type": "macro", "package_name": "dbt", "path": "macros/adapters/show.sql", "original_file_path": "macros/adapters/show.sql", "unique_id": "macro.dbt.default__get_limit_sql", "macro_sql": "{% macro default__get_limit_sql(sql, limit) %}\n  {{ sql }}\n  {% if limit is not none %}\n  limit {{ limit }}\n  {%- endif -%}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0587227, "supported_languages": null}, "macro.dbt.test_unique": {"name": "test_unique", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_unique", "macro_sql": "{% test unique(model, column_name) %}\n    {% set macro = adapter.dispatch('test_unique', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_unique"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0592837, "supported_languages": null}, "macro.dbt.test_not_null": {"name": "test_not_null", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_not_null", "macro_sql": "{% test not_null(model, column_name) %}\n    {% set macro = adapter.dispatch('test_not_null', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0596344, "supported_languages": null}, "macro.dbt.test_accepted_values": {"name": "test_accepted_values", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_accepted_values", "macro_sql": "{% test accepted_values(model, column_name, values, quote=True) %}\n    {% set macro = adapter.dispatch('test_accepted_values', 'dbt') %}\n    {{ macro(model, column_name, values, quote) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0601497, "supported_languages": null}, "macro.dbt.test_relationships": {"name": "test_relationships", "resource_type": "macro", "package_name": "dbt", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "unique_id": "macro.dbt.test_relationships", "macro_sql": "{% test relationships(model, column_name, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships', 'dbt') %}\n    {{ macro(model, column_name, to, field) }}\n{% endtest %}", "depends_on": {"macros": ["macro.dbt.default__test_relationships"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0606127, "supported_languages": null}, "macro.dbt_artifacts.get_column_name_list": {"name": "get_column_name_list", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/get_column_name_lists.sql", "original_file_path": "macros/upload_results/get_column_name_lists.sql", "unique_id": "macro.dbt_artifacts.get_column_name_list", "macro_sql": "{% macro get_column_name_list(dataset) -%}\n\n    {% if dataset == \"exposures\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n            type,\n            owner,\n            maturity,\n            path,\n            description,\n            url,\n            package_name,\n            depends_on_nodes,\n            tags,\n            all_results\n        )\n\n    {% elif dataset == \"invocations\" %}\n\n        (\n            command_invocation_id,\n            dbt_version,\n            project_name,\n            run_started_at,\n            dbt_command,\n            full_refresh_flag,\n            target_profile_name,\n            target_name,\n            target_schema,\n            target_threads,\n            dbt_cloud_project_id,\n            dbt_cloud_job_id,\n            dbt_cloud_run_id,\n            dbt_cloud_run_reason_category,\n            dbt_cloud_run_reason,\n            env_vars,\n            dbt_vars,\n            invocation_args,\n            dbt_custom_envs\n        )\n\n    {% elif dataset == \"model_executions\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            {% if target.type == \"bigquery\" %} bytes_processed,\n            {% endif %}\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\",\n            {% else %} schema,\n            {% endif %}\n            name,\n            alias,\n            message,\n            adapter_response\n        )\n\n    {% elif dataset == \"models\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\", \"schema\",\n            {% else %} database, schema,\n            {% endif %}\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            materialization,\n            tags,\n            meta,\n            alias,\n            all_results\n        )\n\n    {% elif dataset == \"seed_executions\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\",\n            {% else %} schema,\n            {% endif %}\n            name,\n            alias,\n            message,\n            adapter_response\n        )\n\n    {% elif dataset == \"seeds\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\", \"schema\",\n            {% else %} database, schema,\n            {% endif %}\n            name,\n            package_name,\n            path,\n            checksum,\n            meta,\n            alias,\n            all_results\n        )\n\n    {% elif dataset == \"snapshot_executions\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            materialization,\n            {% if target.type == \"sqlserver\" %} \"schema\",\n            {% else %} schema,\n            {% endif %}\n            name,\n            alias,\n            message,\n            adapter_response\n        )\n\n    {% elif dataset == \"snapshots\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\", \"schema\",\n            {% else %} database, schema,\n            {% endif %}\n            name,\n            depends_on_nodes,\n            package_name,\n            path,\n            checksum,\n            strategy,\n            meta,\n            alias,\n            all_results\n        )\n\n    {% elif dataset == \"sources\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            {% if target.type == \"sqlserver\" %} \"database\", \"schema\",\n            {% else %} database, schema,\n            {% endif %}\n            source_name,\n            loader,\n            name,\n            identifier,\n            loaded_at_field,\n            freshness,\n            all_results\n        )\n\n    {% elif dataset == \"test_executions\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            was_full_refresh,\n            thread_id,\n            status,\n            compile_started_at,\n            query_completed_at,\n            total_node_runtime,\n            rows_affected,\n            failures,\n            message,\n            adapter_response\n        )\n\n    {% elif dataset == \"tests\" %}\n\n        (\n            command_invocation_id,\n            node_id,\n            run_started_at,\n            name,\n            depends_on_nodes,\n            package_name,\n            test_path,\n            tags,\n            all_results\n        )\n\n    {% else %}\n\n    /* No column list available */\n    {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "A macro to return the list of column names for a particular dataset. Returns a comment if the dataset is not\nvalid.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "dataset", "type": "string", "description": "The name of the dataset to return the column names for e.g. `models`\n"}], "created_at": 1760419970.725055, "supported_languages": null}, "macro.dbt_artifacts.get_table_content_values": {"name": "get_table_content_values", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/get_table_content_values.sql", "original_file_path": "macros/upload_results/get_table_content_values.sql", "unique_id": "macro.dbt_artifacts.get_table_content_values", "macro_sql": "{% macro get_table_content_values(dataset, objects_to_upload) %}\n\n    {# Convert the results to data to be imported #}\n\n    {% if dataset == 'model_executions' %}\n        {% set content = dbt_artifacts.upload_model_executions(objects_to_upload) %}\n    {% elif dataset == 'seed_executions' %}\n        {% set content = dbt_artifacts.upload_seed_executions(objects_to_upload) %}\n    {% elif dataset == 'test_executions' %}\n        {% set content = dbt_artifacts.upload_test_executions(objects_to_upload) %}\n    {% elif dataset == 'snapshot_executions' %}\n        {% set content = dbt_artifacts.upload_snapshot_executions(objects_to_upload) %}\n    {% elif dataset == 'exposures' %}\n        {% set content = dbt_artifacts.upload_exposures(objects_to_upload) %}\n    {% elif dataset == 'models' %}\n        {% set content = dbt_artifacts.upload_models(objects_to_upload) %}\n    {% elif dataset == 'seeds' %}\n        {% set content = dbt_artifacts.upload_seeds(objects_to_upload) %}\n    {% elif dataset == 'snapshots' %}\n        {% set content = dbt_artifacts.upload_snapshots(objects_to_upload) %}\n    {% elif dataset == 'sources' %}\n        {% set content = dbt_artifacts.upload_sources(objects_to_upload) %}\n    {% elif dataset == 'tests' %}\n        {% set content = dbt_artifacts.upload_tests(objects_to_upload) %}\n    {# Invocations only requires data from variables available in the macro #}\n    {% elif dataset == 'invocations' %}\n        {% set content = dbt_artifacts.upload_invocations() %}\n    {% endif %}\n\n    {{ return(content) }}\n\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.upload_model_executions", "macro.dbt_artifacts.upload_seed_executions", "macro.dbt_artifacts.upload_test_executions", "macro.dbt_artifacts.upload_snapshot_executions", "macro.dbt_artifacts.upload_exposures", "macro.dbt_artifacts.upload_models", "macro.dbt_artifacts.upload_seeds", "macro.dbt_artifacts.upload_snapshots", "macro.dbt_artifacts.upload_sources", "macro.dbt_artifacts.upload_tests", "macro.dbt_artifacts.upload_invocations"]}, "description": "A macro to create the insert statement values required to be uploaded to the table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "dataset", "type": "string", "description": "The name of the dataset to return the column names for e.g. `models`\n"}, {"name": "objects_to_upload", "type": "list", "description": "The objects to be used to generate the insert statement values - extracted from `get_dataset_content`\n"}], "created_at": 1760419970.7259953, "supported_languages": null}, "macro.dbt_artifacts.upload_results": {"name": "upload_results", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/upload_results.sql", "original_file_path": "macros/upload_results/upload_results.sql", "unique_id": "macro.dbt_artifacts.upload_results", "macro_sql": "{% macro upload_results(results) -%}\n\n    {% if execute %}\n\n        {% set datasets_to_load = ['exposures', 'seeds', 'snapshots', 'invocations', 'sources', 'tests', 'models'] %}\n        {% if results != [] %}\n            {# When executing, and results are available, then upload the results #}\n            {% set datasets_to_load = ['model_executions', 'seed_executions', 'test_executions', 'snapshot_executions'] + datasets_to_load %}\n        {% endif %}\n\n        {# Upload each data set in turn #}\n        {% for dataset in datasets_to_load %}\n\n            {% do log(\"Uploading \" ~ dataset.replace(\"_\", \" \"), true) %}\n\n            {# Get the results that need to be uploaded #}\n            {% set objects = dbt_artifacts.get_dataset_content(dataset) %}\n\n            {# Upload in chunks to reduce the query size #}\n            {% if dataset == 'models' %}\n                {% set upload_limit = 50 if target.type == 'bigquery' else 100 %}\n            {% else %}\n                {% set upload_limit = 300 if target.type == 'bigquery' else 5000 %}\n            {% endif %}\n\n            {# Loop through each chunk in turn #}\n            {% for i in range(0, objects | length, upload_limit) -%}\n\n                {# Get just the objects to load on this loop #}\n                {% set content = dbt_artifacts.get_table_content_values(dataset, objects[i: i + upload_limit]) %}\n\n                {# Insert the content into the metadata table #}\n                {{ dbt_artifacts.insert_into_metadata_table(\n                    dataset=dataset,\n                    fields=dbt_artifacts.get_column_name_list(dataset),\n                    content=content\n                    )\n                }}\n\n            {# Loop the next 'chunk' #}\n            {% endfor %}\n\n        {# Loop the next 'dataset' #}\n        {% endfor %}\n\n    {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.replace", "macro.dbt_artifacts.get_dataset_content", "macro.dbt_artifacts.get_table_content_values", "macro.dbt_artifacts.insert_into_metadata_table", "macro.dbt_artifacts.get_column_name_list"]}, "description": "The main macro called to upload the metadata into each of the source tables.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "results", "type": "list", "description": "The results object from dbt."}], "created_at": 1760419970.7286427, "supported_languages": null}, "macro.dbt_artifacts.get_dataset_content": {"name": "get_dataset_content", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/get_dataset_content.sql", "original_file_path": "macros/upload_results/get_dataset_content.sql", "unique_id": "macro.dbt_artifacts.get_dataset_content", "macro_sql": "{% macro get_dataset_content(dataset) %}\n\n    {% if dataset in ['model_executions', 'seed_executions', 'test_executions', 'snapshot_executions'] %}\n        {# Executions make use of the results object #}\n        {% set objects = results | selectattr(\"node.resource_type\", \"equalto\", dataset.split(\"_\")[0]) | list %}\n    {% elif dataset in ['seeds', 'snapshots', 'tests', 'models'] %}\n        {# Use the nodes in the [graph](https://docs.getdbt.com/reference/dbt-jinja-functions/graph) to extract details #}\n        {% set objects = graph.nodes.values() | selectattr(\"resource_type\", \"equalto\", dataset[:-1]) | list %}\n    {% elif dataset in ['exposures', 'sources'] %}\n        {# Use the [graph](https://docs.getdbt.com/reference/dbt-jinja-functions/graph) to extract details #}\n        {% set objects = graph.get(dataset).values() | list %}\n    {% elif dataset == 'invocations' %}\n        {#\n            Invocations doesn't need anything input, but we include this so that it will still be picked up\n            as part of the loop below - the length must be >0 to allow for an upload, hence the empty string\n        #}\n        {% set objects = [''] %}\n    {% endif %}\n\n    {{ return(objects) }}\n\n{% endmacro %}", "depends_on": {"macros": []}, "description": "A macro to extract the data to be uploaded from either the results or the graph object.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "dataset", "type": "string", "description": "The name of the dataset to return the data for e.g. `models`\n"}], "created_at": 1760419970.7254322, "supported_languages": null}, "macro.dbt_artifacts.insert_into_metadata_table": {"name": "insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.insert_into_metadata_table", "macro_sql": "{% macro insert_into_metadata_table(dataset, fields, content) -%}\n\n    {% if content != \"\" %}\n\n        {# Get the relation that the results will be uploaded to #}\n        {% set dataset_relation = dbt_artifacts.get_relation(dataset) %}\n        {# Insert the data into the table #}\n        {{ return(adapter.dispatch('insert_into_metadata_table', 'dbt_artifacts')(dataset_relation, fields, content)) }}\n\n    {% endif %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.get_relation", "macro.dbt_artifacts.spark__insert_into_metadata_table"]}, "description": "Dependent on the adapter type, the wrapper to insert the data into a table from a list of values. Used in the\n`upload_results` macro, alongside the `get_column_lists` macro to generate the column names and the\n`upload_dataset` macros to generate the data to be inserted.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "database_name", "type": "string", "description": "The database name for the relation that the data is to be inserted into\n"}, {"name": "schema_name", "type": "string", "description": "The schema name for the relation that the data is to be inserted into\n"}, {"name": "table_name", "type": "string", "description": "The table name for the relation that the data is to be inserted into\n"}, {"name": "fields", "type": "string", "description": "The list of fields for the relation that the data is to be inserted into\n"}, {"name": "content", "type": "string", "description": "The data content to insert into the relation\n"}], "created_at": 1760419970.7277467, "supported_languages": null}, "macro.dbt_artifacts.spark__insert_into_metadata_table": {"name": "spark__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.spark__insert_into_metadata_table", "macro_sql": "{% macro spark__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0705583, "supported_languages": null}, "macro.dbt_artifacts.snowflake__insert_into_metadata_table": {"name": "snowflake__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.snowflake__insert_into_metadata_table", "macro_sql": "{% macro snowflake__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.070879, "supported_languages": null}, "macro.dbt_artifacts.bigquery__insert_into_metadata_table": {"name": "bigquery__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.bigquery__insert_into_metadata_table", "macro_sql": "{% macro bigquery__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    values\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0711944, "supported_languages": null}, "macro.dbt_artifacts.postgres__insert_into_metadata_table": {"name": "postgres__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.postgres__insert_into_metadata_table", "macro_sql": "{% macro postgres__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    values\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0715096, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__insert_into_metadata_table": {"name": "sqlserver__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.sqlserver__insert_into_metadata_table", "macro_sql": "{% macro sqlserver__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0718262, "supported_languages": null}, "macro.dbt_artifacts.default__insert_into_metadata_table": {"name": "default__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.default__insert_into_metadata_table", "macro_sql": "{% macro default__insert_into_metadata_table(relation, fields, content) -%}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0720234, "supported_languages": null}, "macro.dbt_artifacts.trino__insert_into_metadata_table": {"name": "trino__insert_into_metadata_table", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_results/insert_into_metadata_table.sql", "original_file_path": "macros/upload_results/insert_into_metadata_table.sql", "unique_id": "macro.dbt_artifacts.trino__insert_into_metadata_table", "macro_sql": "{% macro trino__insert_into_metadata_table(relation, fields, content) -%}\n\n    {% set insert_into_table_query %}\n    insert into {{ relation }} {{ fields }}\n    values\n    {{ content }}\n    {% endset %}\n\n    {% do run_query(insert_into_table_query) %}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0728092, "supported_languages": null}, "macro.dbt_artifacts.migrate_from_v0_to_v1": {"name": "migrate_from_v0_to_v1", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/migration/migrate_from_v0_to_v1.sql", "original_file_path": "macros/migration/migrate_from_v0_to_v1.sql", "unique_id": "macro.dbt_artifacts.migrate_from_v0_to_v1", "macro_sql": "{%- macro migrate_from_v0_to_v1(old_database, old_schema, new_database, new_schema) -%}\n\n    {% set migrate_model_executions %}\n        insert into {{new_database}}.{{new_schema}}.model_executions (\n            command_invocation_id,\n            compile_started_at,\n            materialization,\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            \"schema\",\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            compile_started_at,\n            model_materialization,\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            model_schema,\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.fct_dbt__model_executions\n    {% endset %}\n\n    {{ log(\"Migrating model_executions\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_model_executions }} {%- endcall -%}\n\n    {% set migrate_tests %}\n        insert into {{new_database}}.{{new_schema}}.tests (\n            command_invocation_id,\n            depends_on_nodes,\n            name,\n            node_id,\n            package_name,\n            tags,\n            test_path,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            depends_on_nodes,\n            name,\n            node_id,\n            package_name,\n            [],\n            test_path,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__tests\n    {% endset %}\n\n    {{ log(\"Migrating tests\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_tests }} {%- endcall -%}\n\n    {% set migrate_test_executions %}\n        insert into {{new_database}}.{{new_schema}}.test_executions (\n            command_invocation_id,\n            compile_started_at,\n            failures,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            compile_started_at,\n            null,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.fct_dbt__test_executions\n    {% endset %}\n\n    {{ log(\"Migrating test_executions\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_test_executions }} {%- endcall -%}\n\n    {% set migrate_models %}\n        insert into {{new_database}}.{{new_schema}}.models (\n            checksum,\n            command_invocation_id,\n            \"database\",\n            depends_on_nodes,\n            materialization,\n            name,\n            node_id,\n            package_name,\n            path,\n            \"schema\",\n            run_started_at\n        )\n        select\n            checksum,\n            command_invocation_id,\n            model_database,\n            depends_on_nodes,\n            model_materialization,\n            name,\n            node_id,\n            package_name,\n            model_path,\n            model_schema,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__models\n    {% endset %}\n\n    {{ log(\"Migrating models\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_models }} {%- endcall -%}\n\n    {% set migrate_seeds %}\n        insert into {{new_database}}.{{new_schema}}.seeds (\n            checksum,\n            command_invocation_id,\n            \"database\",\n            name,\n            node_id,\n            package_name,\n            path,\n            \"schema\",\n            run_started_at\n        )\n        select\n            checksum,\n            command_invocation_id,\n            seed_database,\n            name,\n            node_id,\n            package_name,\n            seed_path,\n            seed_schema,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__seeds\n    {% endset %}\n\n    {{ log(\"Migrating seeds\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_seeds }} {%- endcall -%}\n\n    {% set migrate_seed_executions %}\n        insert into {{new_database}}.{{new_schema}}.seed_executions (\n            command_invocation_id,\n            compile_started_at,\n            materialization,\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            \"schema\",\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            compile_started_at,\n            'seed',\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            seed_schema,\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.fct_dbt__seed_executions\n    {% endset %}\n\n    {{ log(\"Migrating seed_executions\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_seed_executions }} {%- endcall -%}\n\n    {% set migrate_exposures %}\n        insert into {{new_database}}.{{new_schema}}.exposures (\n            command_invocation_id,\n            depends_on_nodes,\n            description,\n            maturity,\n            name,\n            node_id,\n            owner,\n            package_name,\n            path,\n            type,\n            url,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            array_agg(output_feeds), {#- Here we un-flatten the transformation originally done -#}\n            null,\n            any_value(maturity) as maturity,\n            name,\n            node_id,\n            null, {#- v0 is a string, v1 is a variant -#}\n            any_value(package_name) as package_name,\n            null,\n            any_value(type) as type,\n            null,\n            any_value(artifact_generated_at) as artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__exposures\n        group by command_invocation_id, node_id, name, artifact_generated_at\n    {% endset %}\n\n    {{ log(\"Migrating exposures\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_exposures }} {%- endcall -%}\n\n    {% set migrate_snapshots %}\n        insert into {{new_database}}.{{new_schema}}.snapshots (\n            checksum,\n            command_invocation_id,\n            \"database\",\n            depends_on_nodes,\n            name,\n            node_id,\n            package_name,\n            path,\n            \"schema\",\n            strategy,\n            run_started_at\n        )\n        select\n            checksum,\n            command_invocation_id,\n            snapshot_database,\n            depends_on_nodes,\n            name,\n            node_id,\n            package_name,\n            snapshot_path,\n            snapshot_schema,\n            null,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__snapshots\n    {% endset %}\n\n    {{ log(\"Migrating snapshots\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_snapshots }} {%- endcall -%}\n\n    {% set migrate_snapshot_executions %}\n        insert into {{new_database}}.{{new_schema}}.snapshot_executions (\n            command_invocation_id,\n            compile_started_at,\n            materialization,\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            \"schema\",\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            compile_started_at,\n            'snapshot',\n            name,\n            node_id,\n            query_completed_at,\n            rows_affected,\n            snapshot_schema,\n            status,\n            thread_id,\n            total_node_runtime,\n            was_full_refresh,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.fct_dbt__snapshot_executions\n    {% endset %}\n\n    {{ log(\"Migrating snapshot_executions\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_snapshot_executions }} {%- endcall -%}\n\n    {% set migrate_sources %}\n        insert into {{new_database}}.{{new_schema}}.sources (\n            command_invocation_id,\n            \"database\",\n            freshness,\n            identifier,\n            loaded_at_field,\n            loader,\n            name,\n            node_id,\n            \"schema\",\n            source_name,\n            run_started_at\n        )\n        select\n            command_invocation_id,\n            node_database,\n            parse_json('[{\"error_after\":{\"count\":null,\"period\":null},\"filter\":null,\"warn_after\":{\"count\":null,\"period\":null}}]'),\n            name,\n            null,\n            source_loader,\n            name,\n            node_id,\n            source_schema,\n            source_name,\n            artifact_generated_at\n        from {{old_database}}.{{old_schema}}.dim_dbt__sources\n    {% endset %}\n\n    {{ log(\"Migrating sources\", info=True) }}\n    {%- call statement(auto_begin=True) -%} {{ migrate_sources }} {%- endcall -%}\n\n    {{ log(\"Migration complete. You can now safely delete any data from before 1.0.0\", info=True) }}\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "A macro to assist with migrating from v0 to v1 of dbt_artifacts. See\nhttps://github.com/brooklyn-data/dbt_artifacts/blob/main/README.md#migrating-from-100-to-100\nfor details on the usage.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "old_database", "type": "string", "description": "The database of the <1.0.0 output (fct_/dim_) models - does not have to be different to `new_database`\n"}, {"name": "old_schema", "type": "string", "description": "The schema of the <1.0.0 output (fct_/dim_) models - does not have to be different to `new_schema`\n"}, {"name": "new_database", "type": "string", "description": "The target database that the v1 artifact sources are in - does not have to be different to `old_database`\n"}, {"name": "new_schema", "type": "string", "description": "The target schema that the v1 artifact sources are in - does not have to be different to `old_schema`\n"}], "created_at": 1760419970.716478, "supported_languages": null}, "macro.dbt_artifacts.upload_tests": {"name": "upload_tests", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.upload_tests", "macro_sql": "{% macro upload_tests(tests) -%}\n    {{ return(adapter.dispatch(\"get_tests_dml_sql\", \"dbt_artifacts\")(tests)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_tests_dml_sql"]}, "description": "The macro to support upload of the data to the tests table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "tests", "type": "list", "description": "A list of test objects extracted from the dbt graph\n"}], "created_at": 1760419970.7243898, "supported_languages": null}, "macro.dbt_artifacts.default__get_tests_dml_sql": {"name": "default__get_tests_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.default__get_tests_dml_sql", "macro_sql": "{% macro default__get_tests_dml_sql(tests) -%}\n\n    {% if tests != [] %}\n        {% set test_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(5)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(8)) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(9)) }}\n        from values\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ test.name }}', {# name #}\n                '{{ tojson(test.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ test.package_name }}', {# package_name #}\n                '{{ test.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# test_path #}\n                '{{ tojson(test.tags) }}', {# tags #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(test) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_fields #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ test_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0845466, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_tests_dml_sql": {"name": "bigquery__get_tests_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_tests_dml_sql", "macro_sql": "{% macro bigquery__get_tests_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_values %}\n            {% for test in tests -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ test.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ test.name }}', {# name #}\n                    {{ tojson(test.depends_on.nodes) }}, {# depends_on_nodes #}\n                    '{{ test.package_name }}', {# package_name #}\n                    '{{ test.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# test_path #}\n                    {{ tojson(test.tags) }}, {# tags #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(test) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_fields #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ test_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.085963, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_tests_dml_sql": {"name": "postgres__get_tests_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.postgres__get_tests_dml_sql", "macro_sql": "{% macro postgres__get_tests_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_values %}\n            {% for test in tests -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ test.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ test.name }}', {# name #}\n                    $${{ tojson(test.depends_on.nodes) }}$$, {# depends_on_nodes #}\n                    '{{ test.package_name }}', {# package_name #}\n                    '{{ test.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# test_path #}\n                    $${{ tojson(test.tags) }}$$, {# tags #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(test) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ test_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0871263, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_tests_dml_sql": {"name": "sqlserver__get_tests_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_tests_dml_sql", "macro_sql": "{% macro sqlserver__get_tests_dml_sql(tests) -%}\n\n    {% if tests != [] %}\n        {% set test_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"\n        from ( values\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ test.name }}', {# name #}\n                '{{ tojson(test.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ test.package_name }}', {# package_name #}\n                '{{ test.original_file_path }}', {# test_path #}\n                '{{ tojson(test.tags) }}', {# tags #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(test) | replace(\"'\",\"''\") }}' {# all_fields #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\")\n        {% endset %}\n        {{ test_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0881975, "supported_languages": null}, "macro.dbt_artifacts.trino__get_tests_dml_sql": {"name": "trino__get_tests_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_tests.sql", "original_file_path": "macros/upload_individual_datasets/upload_tests.sql", "unique_id": "macro.dbt_artifacts.trino__get_tests_dml_sql", "macro_sql": "{% macro trino__get_tests_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_values %}\n            {% for test in tests -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ test.unique_id }}', {# node_id #}\n                    TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                    '{{ test.name }}', {# name #}\n                    ARRAY {{ test.depends_on.nodes }}, {# depends_on_nodes #}\n                    '{{ test.package_name }}', {# package_name #}\n                    '{{ test.original_file_path }}', {# test_path #}\n                    ARRAY {{ test.tags }}, {# tags #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        '{{ tojson(test) | replace(\"'\", \"''\") }}' {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ test_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0893083, "supported_languages": null}, "macro.dbt_artifacts.upload_snapshot_executions": {"name": "upload_snapshot_executions", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.upload_snapshot_executions", "macro_sql": "{% macro upload_snapshot_executions(snapshots) -%}\n    {{ return(adapter.dispatch(\"get_snapshot_executions_dml_sql\", \"dbt_artifacts\")(snapshots)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_snapshot_executions_dml_sql"]}, "description": "The macro to support upload of the data to the snapshot_executions table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "snapshots", "type": "list", "description": "A list of snapshot execution results objects extracted from the dbt result object\n"}], "created_at": 1760419970.7195673, "supported_languages": null}, "macro.dbt_artifacts.default__get_snapshot_executions_dml_sql": {"name": "default__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.default__get_snapshot_executions_dml_sql", "macro_sql": "{% macro default__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n        from values\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.096852, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_snapshot_executions_dml_sql": {"name": "bigquery__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_snapshot_executions_dml_sql", "macro_sql": "{% macro bigquery__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Databricks #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') | replace(\"\\n\", \"\\\\n\") }}', {# message #}\n                {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.0992696, "supported_languages": null}, "macro.dbt_artifacts.snowflake__get_snapshot_executions_dml_sql": {"name": "snowflake__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.snowflake__get_snapshot_executions_dml_sql", "macro_sql": "{% macro snowflake__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n        from values\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                try_cast('{{ model.adapter_response.rows_affected }}' as int), {# rows_affected #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1031995, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_snapshot_executions_dml_sql": {"name": "postgres__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.postgres__get_snapshot_executions_dml_sql", "macro_sql": "{% macro postgres__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% if model.timing != [] %}\n                    {% for stage in model.timing if stage.name == \"compile\" %}\n                        {% if loop.length == 0 %}\n                            null, {# compile_started_at #}\n                        {% else %}\n                            '{{ stage.started_at }}', {# compile_started_at #}\n                        {% endif %}\n                    {% endfor %}\n\n                    {% for stage in model.timing if stage.name == \"execute\" %}\n                        {% if loop.length == 0 %}\n                            null, {# query_completed_at #}\n                        {% else %}\n                            '{{ stage.completed_at }}', {# query_completed_at #}\n                        {% endif %}\n                    {% endfor %}\n                {% else %}\n                    null, {# compile_started_at #}\n                    null, {# query_completed_at #}\n                {% endif %}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                $${{ model.message }}$$, {# message #}\n                $${{ tojson(model.adapter_response) }}$$ {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.105346, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_snapshot_executions_dml_sql": {"name": "sqlserver__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_snapshot_executions_dml_sql", "macro_sql": "{% macro sqlserver__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"\n        from ( values\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message  | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\")\n\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1074696, "supported_languages": null}, "macro.dbt_artifacts.trino__get_snapshot_executions_dml_sql": {"name": "trino__get_snapshot_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshot_executions.sql", "unique_id": "macro.dbt_artifacts.trino__get_snapshot_executions_dml_sql", "macro_sql": "{% macro trino__get_snapshot_executions_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_execution_values %}\n        {% for model in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                \n                {{ config_full_refresh }}, {# was_full_refresh #}\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n                \n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}TIMESTAMP '{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}TIMESTAMP '{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n                \n                {{ model.execution_time }}, {# total_node_runtime #}\n\n                {% if model.adapter_response.rows_affected is none or model.adapter_response.rows_affected is not defined %}\n                    null\n                {% else %}\n                    {{ model.adapter_response.rows_affected }}\n                {% endif %}\n                , {# rows_affected #}\n\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_execution_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1098225, "supported_languages": null}, "macro.dbt_artifacts.upload_models": {"name": "upload_models", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.upload_models", "macro_sql": "{% macro upload_models(models) -%}\n    {{ return(adapter.dispatch(\"get_models_dml_sql\", \"dbt_artifacts\")(models)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_models_dml_sql"]}, "description": "The macro to support upload of the data to the models table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "models", "type": "list", "description": "A list of test objects extracted from the dbt graph\n"}], "created_at": 1760419970.7185287, "supported_languages": null}, "macro.dbt_artifacts.default__get_models_dml_sql": {"name": "default__get_models_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.default__get_models_dml_sql", "macro_sql": "{% macro default__get_models_dml_sql(models) -%}\n\n    {% if models != [] %}\n        {% set model_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(7)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(12)) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(13)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(15)) }}\n        from values\n        {% for model in models -%}\n                {% set model_copy = dbt_artifacts.copy_model(model) -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model_copy.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ model_copy.database }}', {# database #}\n                '{{ model_copy.schema }}', {# schema #}\n                '{{ model_copy.name }}', {# name #}\n                '{{ tojson(model_copy.depends_on.nodes) | replace('\\\\', '\\\\\\\\') }}', {# depends_on_nodes #}\n                '{{ model_copy.package_name }}', {# package_name #}\n                '{{ model_copy.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                '{{ model_copy.checksum.checksum  | replace('\\\\', '\\\\\\\\') }}', {# checksum #}\n                '{{ model_copy.config.materialized }}', {# materialization #}\n                '{{ tojson(model_copy.tags) }}', {# tags #}\n                '{{ tojson(model_copy.config.meta) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}', {# meta #}\n                '{{ model_copy.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(model_copy) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json", "macro.dbt_artifacts.copy_model"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1157863, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_models_dml_sql": {"name": "bigquery__get_models_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_models_dml_sql", "macro_sql": "{% macro bigquery__get_models_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_values %}\n            {% for model in models -%}\n                {% set model_copy = dbt_artifacts.copy_model(model) -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ model_copy.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ model_copy.database }}', {# database #}\n                    '{{ model_copy.schema }}', {# schema #}\n                    '{{ model_copy.name }}', {# name #}\n                    {{ tojson(model_copy.depends_on.nodes) }}, {# depends_on_nodes #}\n                    '{{ model_copy.package_name }}', {# package_name #}\n                    '{{ model_copy.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    '{{ model_copy.checksum.checksum | replace('\\\\', '\\\\\\\\') }}', {# checksum #}\n                    '{{ model_copy.config.materialized }}', {# materialization #}\n                    {{ tojson(model_copy.tags) }}, {# tags #}\n                    {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(model_copy.config.meta)) }}, {# meta #}\n                    '{{ model_copy.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(model_copy) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ model_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.copy_model", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1178253, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_models_dml_sql": {"name": "postgres__get_models_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.postgres__get_models_dml_sql", "macro_sql": "{% macro postgres__get_models_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_values %}\n            {% for model in models -%}\n                {% set model_copy = dbt_artifacts.copy_model(model) -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ model_copy.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ model_copy.database }}', {# database #}\n                    '{{ model_copy.schema }}', {# schema #}\n                    '{{ model_copy.name }}', {# name #}\n                    '{{ tojson(model_copy.depends_on.nodes) }}', {# depends_on_nodes #}\n                    '{{ model_copy.package_name }}', {# package_name #}\n                    $${{ model_copy.original_file_path | replace('\\\\', '\\\\\\\\') }}$$, {# path #}\n                    '{{ model_copy.checksum.checksum }}', {# checksum #}\n                    '{{ model_copy.config.materialized }}', {# materialization #}\n                    '{{ tojson(model_copy.tags) }}', {# tags #}\n                    $${{ model_copy.config.meta }}$$, {# meta #}\n                    '{{ model_copy.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(model_copy) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ model_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.copy_model"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1193562, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_models_dml_sql": {"name": "sqlserver__get_models_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_models_dml_sql", "macro_sql": "{% macro sqlserver__get_models_dml_sql(models) -%}\n\n    {% if models != [] %}\n        {% set model_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"\n        from ( values\n        {% for model in models -%}\n                {% set model_copy = dbt_artifacts.copy_model(model) -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model_copy.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ model_copy.database }}', {# database #}\n                '{{ model_copy.schema }}', {# schema #}\n                '{{ model_copy.name }}', {# name #}\n                '{{ tojson(model_copy.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ model_copy.package_name }}', {# package_name #}\n                '{{ model_copy.original_file_path }}', {# path #}\n                '{{ model_copy.checksum.checksum }}', {# checksum #}\n                '{{ model_copy.config.materialized }}', {# materialization #}\n                '{{ tojson(model_copy.tags) }}', {# tags #}\n                '{{ tojson(model_copy.config.meta) | replace(\"'\",\"''\") }}', {# meta #}\n                '{{ model_copy.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(model_copy) | replace(\"'\",\"''\") }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\")\n\n        {% endset %}\n        {{ model_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.copy_model"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1209807, "supported_languages": null}, "macro.dbt_artifacts.trino__get_models_dml_sql": {"name": "trino__get_models_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_models.sql", "original_file_path": "macros/upload_individual_datasets/upload_models.sql", "unique_id": "macro.dbt_artifacts.trino__get_models_dml_sql", "macro_sql": "{% macro trino__get_models_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_values %}\n            {% for model in models -%}\n                {% do model.pop('raw_code', None) %}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ model.unique_id }}', {# node_id #}\n                    TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                    '{{ model.database }}', {# database #}\n                    '{{ model.schema }}', {# schema #}\n                    '{{ model.name }}', {# name #}\n                    ARRAY {{ model.depends_on.nodes }}, {# depends_on_nodes #}\n                    '{{ model.package_name }}', {# package_name #}\n                    '{{ model.original_file_path }}', {# path #}\n                    '{{ model.checksum.checksum }}', {# checksum #}\n                    '{{ model.config.materialized }}', {# materialization #}\n                    ARRAY {{ model.tags }}, {# tags #}\n                    '{{ tojson(model.config.meta) | replace(\"'\", \"''\") }}', {# meta #}\n                    '{{ model.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        '{{ tojson(model) | replace(\"'\", \"''\") }}' {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ model_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1224692, "supported_languages": null}, "macro.dbt_artifacts.upload_test_executions": {"name": "upload_test_executions", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.upload_test_executions", "macro_sql": "{% macro upload_test_executions(tests) -%}\n    {{ return(adapter.dispatch(\"get_test_executions_dml_sql\", \"dbt_artifacts\")(tests)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_test_executions_dml_sql"]}, "description": "The macro to support upload of the data to the test_executions table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "tests", "type": "list", "description": "A list of test execution results objects extracted from the dbt result object\n"}], "created_at": 1760419970.7205527, "supported_languages": null}, "macro.dbt_artifacts.default__get_test_executions_dml_sql": {"name": "default__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.default__get_test_executions_dml_sql", "macro_sql": "{% macro default__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(13)) }}\n        from values\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n\n                {% set compile_started_at = (test.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (test.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ test.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected not available in Databricks #}\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                '{{ test.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(test.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1293926, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_test_executions_dml_sql": {"name": "bigquery__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_test_executions_dml_sql", "macro_sql": "{% macro bigquery__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n\n                {% set compile_started_at = (test.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (test.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ test.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected not available in Databricks #}\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                '{{ test.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') | replace(\"\\n\", \"\\\\n\") }}', {# message #}\n                {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(test.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n\n        {%- endfor %}\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1316738, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_test_executions_dml_sql": {"name": "postgres__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.postgres__get_test_executions_dml_sql", "macro_sql": "{% macro postgres__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n\n                {% if test.timing != [] %}\n                    {% for stage in test.timing if stage.name == \"compile\" %}\n                        {% if loop.length == 0 %}\n                            null, {# compile_started_at #}\n                        {% else %}\n                            '{{ stage.started_at }}', {# compile_started_at #}\n                        {% endif %}\n                    {% endfor %}\n\n                    {% for stage in test.timing if stage.name == \"execute\" %}\n                        {% if loop.length == 0 %}\n                            null, {# query_completed_at #}\n                        {% else %}\n                            '{{ stage.completed_at }}', {# query_completed_at #}\n                        {% endif %}\n                    {% endfor %}\n                {% else %}\n                    null, {# compile_started_at #}\n                    null, {# query_completed_at #}\n                {% endif %}\n\n                {{ test.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected not available in Databricks #}\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                $${{ test.message  }}$$, {# message #}\n                $${{ tojson(test.adapter_response) }}$$ {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n\n        {%- endfor %}\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.133642, "supported_languages": null}, "macro.dbt_artifacts.snowflake__get_test_executions_dml_sql": {"name": "snowflake__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.snowflake__get_test_executions_dml_sql", "macro_sql": "{% macro snowflake__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(13)) }}\n        from values\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n\n                {% set compile_started_at = (test.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (test.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ test.execution_time }}, {# total_node_runtime #}\n                try_cast('{{ test.adapter_response.rows_affected }}' as int), {# rows_affected #}\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                '{{ test.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(test.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1371527, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_test_executions_dml_sql": {"name": "sqlserver__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_test_executions_dml_sql", "macro_sql": "{% macro sqlserver__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\"\n        from ( values\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ test.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected not available in Databricks #}\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                '{{ test.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(test.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) AS v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\")\n\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.139141, "supported_languages": null}, "macro.dbt_artifacts.trino__get_test_executions_dml_sql": {"name": "trino__get_test_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_test_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_test_executions.sql", "unique_id": "macro.dbt_artifacts.trino__get_test_executions_dml_sql", "macro_sql": "{% macro trino__get_test_executions_dml_sql(tests) -%}\n    {% if tests != [] %}\n        {% set test_execution_values %}\n        {% for test in tests -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ test.node.unique_id }}', {# node_id #}\n                TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = test.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                \n                {{ config_full_refresh }}, {# was_full_refresh #}\n                '{{ test.thread_id }}', {# thread_id #}\n                '{{ test.status }}', {# status #}\n                \n                {% set compile_started_at = (test.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}TIMESTAMP '{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (test.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}TIMESTAMP '{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n                \n                {{ test.execution_time }}, {# total_node_runtime #}\n\n                {% if test.adapter_response.rows_affected is none or test.adapter_response.rows_affected is not defined %}\n                    null\n                {% else %}\n                    {{ test.adapter_response.rows_affected }}\n                {% endif %}\n                , {# rows_affected #}\n\n                {{ 'null' if test.failures is none else test.failures }}, {# failures #}\n                '{{ test.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(test.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n\n        {%- endfor %}\n        {% endset %}\n        {{ test_execution_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1413662, "supported_languages": null}, "macro.dbt_artifacts.upload_sources": {"name": "upload_sources", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.upload_sources", "macro_sql": "{% macro upload_sources(sources) -%}\n    {{ return(adapter.dispatch(\"get_sources_dml_sql\", \"dbt_artifacts\")(sources)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_sources_dml_sql"]}, "description": "The macro to support upload of the data to the sources table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "sources", "type": "list", "description": "A list of sources objects extracted from the dbt graph\n"}], "created_at": 1760419970.7202075, "supported_languages": null}, "macro.dbt_artifacts.default__get_sources_dml_sql": {"name": "default__get_sources_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.default__get_sources_dml_sql", "macro_sql": "{% macro default__get_sources_dml_sql(sources) -%}\n\n    {% if sources != [] %}\n        {% set source_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(11)) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(12)) }}\n        from values\n        {% for source in sources -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ source.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ source.database }}', {# database #}\n                '{{ source.schema }}', {# schema #}\n                '{{ source.source_name }}', {# source_name #}\n                '{{ source.loader }}', {# loader #}\n                '{{ source.name }}', {# name #}\n                '{{ source.identifier }}', {# identifier #}\n                '{{ source.loaded_at_field | replace(\"'\",\"\\\\'\") }}', {# loaded_at_field #}\n                '{{ tojson(source.freshness) | replace(\"'\",\"\\\\'\") }}', {# freshness #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(source) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ source_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.146374, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_sources_dml_sql": {"name": "bigquery__get_sources_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_sources_dml_sql", "macro_sql": "{% macro bigquery__get_sources_dml_sql(sources) -%}\n    {% if sources != [] %}\n        {% set source_values %}\n            {% for source in sources -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ source.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ source.database }}', {# database #}\n                    '{{ source.schema }}', {# schema #}\n                    '{{ source.source_name }}', {# source_name #}\n                    '{{ source.loader }}', {# loader #}\n                    '{{ source.name }}', {# name #}\n                    '{{ source.identifier }}', {# identifier #}\n                    '{{ source.loaded_at_field | replace(\"'\",\"\\\\'\") }}', {# loaded_at_field #}\n                    {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(source.freshness) | replace(\"'\",\"\\\\'\")) }},  {# freshness #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(source) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ source_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1478477, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_sources_dml_sql": {"name": "postgres__get_sources_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.postgres__get_sources_dml_sql", "macro_sql": "{% macro postgres__get_sources_dml_sql(sources) -%}\n    {% if sources != [] %}\n        {% set source_values %}\n            {% for source in sources -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ source.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ source.database }}', {# database #}\n                    '{{ source.schema }}', {# schema #}\n                    '{{ source.source_name }}', {# source_name #}\n                    '{{ source.loader }}', {# loader #}\n                    '{{ source.name }}', {# name #}\n                    '{{ source.identifier }}', {# identifier #}\n                    $${{ source.loaded_at_field }}$$, {# loaded_at_field #}\n                    $${{ tojson(source.freshness) }}$$,  {# freshness #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(source) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ source_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1489444, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_sources_dml_sql": {"name": "sqlserver__get_sources_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_sources_dml_sql", "macro_sql": "{% macro sqlserver__get_sources_dml_sql(sources) -%}\n\n    {% if sources != [] %}\n        {% set source_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"\n        from ( values\n        {% for source in sources -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ source.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ source.database }}', {# database #}\n                '{{ source.schema }}', {# schema #}\n                '{{ source.source_name }}', {# source_name #}\n                '{{ source.loader }}', {# loader #}\n                '{{ source.name }}', {# name #}\n                '{{ source.identifier }}', {# identifier #}\n                '{{ source.loaded_at_field | replace(\"'\",\"''\") }}', {# loaded_at_field #}\n                '{{ tojson(source.freshness) | replace(\"'\",\"''\") }}', {# freshness #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(source) | replace(\"'\", \"''\") }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\")\n        {% endset %}\n        {{ source_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1501198, "supported_languages": null}, "macro.dbt_artifacts.trino__get_sources_dml_sql": {"name": "trino__get_sources_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_sources.sql", "original_file_path": "macros/upload_individual_datasets/upload_sources.sql", "unique_id": "macro.dbt_artifacts.trino__get_sources_dml_sql", "macro_sql": "{% macro trino__get_sources_dml_sql(sources) -%}\n    {% if sources != [] %}\n        {% set source_values %}\n            {% for source in sources -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ source.unique_id }}', {# node_id #}\n                    TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                    '{{ source.database }}', {# database #}\n                    '{{ source.schema }}', {# schema #}\n                    '{{ source.source_name }}', {# source_name #}\n                    '{{ source.loader }}', {# loader #}\n                    '{{ source.name }}', {# name #}\n                    '{{ source.identifier }}', {# identifier #}\n                    '{{ source.loaded_at_field | replace(\"'\", \"''\") }}', {# loaded_at_field #}\n                    '{{ tojson(source.freshness) | replace(\"'\", \"''\") }}',  {# freshness #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        '{{ tojson(source) | replace(\"'\", \"''\") }}' {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ source_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.151308, "supported_languages": null}, "macro.dbt_artifacts.upload_exposures": {"name": "upload_exposures", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.upload_exposures", "macro_sql": "{% macro upload_exposures(exposures) -%}\n    {{ return(adapter.dispatch(\"get_exposures_dml_sql\", \"dbt_artifacts\")(exposures)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_exposures_dml_sql"]}, "description": "The macro to support upload of the data to the exposures table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "exposures", "type": "list", "description": "A list of exposure objects extracted from the dbt graph\n"}], "created_at": 1760419970.717568, "supported_languages": null}, "macro.dbt_artifacts.default__get_exposures_dml_sql": {"name": "default__get_exposures_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.default__get_exposures_dml_sql", "macro_sql": "{% macro default__get_exposures_dml_sql(exposures) -%}\n\n    {% if exposures != [] %}\n        {% set exposure_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(6)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(12)) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(13)) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(14)) }}\n        from values\n        {% for exposure in exposures -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ exposure.unique_id | replace(\"'\",\"\\\\'\") }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ exposure.name | replace(\"'\",\"\\\\'\") }}', {# name #}\n                '{{ exposure.type }}', {# type #}\n                '{{ tojson(exposure.owner) }}', {# owner #}\n                '{{ exposure.maturity }}', {# maturity #}\n                '{{ exposure.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                '{{ exposure.description | replace(\"'\",\"\\\\'\") }}', {# description #}\n                '{{ exposure.url }}', {# url #}\n                '{{ exposure.package_name }}', {# package_name #}\n                '{{ tojson(exposure.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ tojson(exposure.tags) }}', {# tags #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(exposure) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ exposure_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1565094, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_exposures_dml_sql": {"name": "bigquery__get_exposures_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_exposures_dml_sql", "macro_sql": "{% macro bigquery__get_exposures_dml_sql(exposures) -%}\n    {% if exposures != [] %}\n        {% set exposure_values %}\n            {% for exposure in exposures -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ exposure.unique_id | replace(\"'\",\"\\\\'\") }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ exposure.name | replace(\"'\",\"\\\\'\") }}', {# name #}\n                    '{{ exposure.type }}', {# type #}\n                    {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(exposure.owner) | replace(\"'\",\"\\\\'\")) }}, {# owner #}\n                    '{{ exposure.maturity }}', {# maturity #}\n                    '{{ exposure.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    \"\"\"{{ exposure.description | replace(\"'\",\"\\\\'\") }}\"\"\", {# description #}\n                    '{{ exposure.url }}', {# url #}\n                    '{{ exposure.package_name }}', {# package_name #}\n                    {{ tojson(exposure.depends_on.nodes) }}, {# depends_on_nodes #}\n                    {{ tojson(exposure.tags) }}, {# tags #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(exposure) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ exposure_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.158341, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_exposures_dml_sql": {"name": "postgres__get_exposures_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.postgres__get_exposures_dml_sql", "macro_sql": "{% macro postgres__get_exposures_dml_sql(exposures) -%}\n    {% if exposures != [] %}\n\n        {% set exposure_values %}\n            {% for exposure in exposures -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    $${{ exposure.unique_id }}$$, {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    $${{ exposure.name }}$$, {# name #}\n                    '{{ exposure.type }}', {# type #}\n                    $${{ tojson(exposure.owner) }}$$, {# owner #}\n                    '{{ exposure.maturity }}', {# maturity #}\n                    $${{ exposure.original_file_path }}$$, {# path #}\n                    $${{ exposure.description }}$$, {# description #}\n                    '{{ exposure.url }}', {# url #}\n                    '{{ exposure.package_name }}', {# package_name #}\n                    $${{ tojson(exposure.depends_on.nodes) }}$$, {# depends_on_nodes #}\n                    $${{ tojson(exposure.tags) }}$$, {# tags #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(exposure) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ exposure_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.15955, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_exposures_dml_sql": {"name": "sqlserver__get_exposures_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_exposures_dml_sql", "macro_sql": "{% macro sqlserver__get_exposures_dml_sql(exposures) -%}\n\n    {% if exposures != [] %}\n        {% set exposure_values %}\n        select \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\"\n        from ( values\n        {% for exposure in exposures -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ exposure.unique_id | replace(\"'\",\"''\") }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ exposure.name | replace(\"'\",\"''\") }}', {# name #}\n                '{{ exposure.type }}', {# type #}\n                '{{ tojson(exposure.owner) }}', {# owner #}\n                '{{ exposure.maturity }}', {# maturity #}\n                '{{ exposure.original_file_path }}', {# path #}\n                '{{ exposure.description | replace(\"'\",\"''\") }}', {# description #}\n                '{{ exposure.url }}', {# url #}\n                '{{ exposure.package_name }}', {# package_name #}\n                '{{ tojson(exposure.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ tojson(exposure.tags) }}', {# tags #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(exposure) | replace(\"'\", \"''\") }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\")\n\n        {% endset %}\n        {{ exposure_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1617184, "supported_languages": null}, "macro.dbt_artifacts.trino__get_exposures_dml_sql": {"name": "trino__get_exposures_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_exposures.sql", "original_file_path": "macros/upload_individual_datasets/upload_exposures.sql", "unique_id": "macro.dbt_artifacts.trino__get_exposures_dml_sql", "macro_sql": "{% macro trino__get_exposures_dml_sql(exposures) -%}\n    {% if exposures != [] %}\n\n        {% set exposure_values %}\n            {% for exposure in exposures -%}\n                (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ exposure.unique_id | replace(\"'\",\"''\") }}', {# node_id #}\n                TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                '{{ exposure.name | replace(\"'\",\"''\") }}', {# name #}\n                '{{ exposure.type }}', {# type #}\n                '{{ tojson(exposure.owner) | replace(\"'\",\"''\") }}', {# owner #}\n                '{{ exposure.maturity }}', {# maturity #}\n                '{{ exposure.original_file_path }}', {# path #}\n                '{{ exposure.description | replace(\"'\",\"''\") }}', {# description #}\n                '{{ exposure.url }}', {# url #}\n                '{{ exposure.package_name }}', {# package_name #}\n                ARRAY {{ exposure.depends_on.nodes}}, {# depends_on_nodes #}\n                ARRAY {{ exposure.tags}}, {# tags #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(exposure) | replace(\"'\",\"''\") }}' {# all_results #}\n                {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ exposure_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1638854, "supported_languages": null}, "macro.dbt_artifacts.upload_model_executions": {"name": "upload_model_executions", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.upload_model_executions", "macro_sql": "{% macro upload_model_executions(models) -%}\n    {{ return(adapter.dispatch(\"get_model_executions_dml_sql\", \"dbt_artifacts\")(models)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_model_executions_dml_sql"]}, "description": "The macro to support upload of the data to the model_executions table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "models", "type": "list", "description": "A list of model execution results objects extracted from the dbt result object\n"}], "created_at": 1760419970.7181797, "supported_languages": null}, "macro.dbt_artifacts.default__get_model_executions_dml_sql": {"name": "default__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.default__get_model_executions_dml_sql", "macro_sql": "{% macro default__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n\n        from values\n        {% for model in models -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake & BigQuery #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1706977, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_model_executions_dml_sql": {"name": "bigquery__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_model_executions_dml_sql", "macro_sql": "{% macro bigquery__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        {% for model in models -%}\n            (\n            '{{ invocation_id }}', {# command_invocation_id #}\n            '{{ model.node.unique_id }}', {# node_id #}\n            '{{ run_started_at }}', {# run_started_at #}\n\n            {% set config_full_refresh = model.node.config.full_refresh %}\n            {% if config_full_refresh is none %}\n                {% set config_full_refresh = flags.FULL_REFRESH %}\n            {% endif %}\n            {{ config_full_refresh }}, {# was_full_refresh #}\n\n            '{{ model.thread_id }}', {# thread_id #}\n            '{{ model.status }}', {# status #}\n\n            {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n            {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n            {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n            {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n            {{ model.execution_time }}, {# total_node_runtime #}\n            safe_cast('{{ model.adapter_response.rows_affected }}' as int64),\n            safe_cast('{{ model.adapter_response.bytes_processed }}' as int64),\n            '{{ model.node.config.materialized }}', {# materialization #}\n            '{{ model.node.schema }}', {# schema #}\n            '{{ model.node.name }}', {# name #}\n            '{{ model.node.alias }}', {# alias #}\n            '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') | replace(\"\\n\", \"\\\\n\") }}', {# message #}\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1730375, "supported_languages": null}, "macro.dbt_artifacts.snowflake__get_model_executions_dml_sql": {"name": "snowflake__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.snowflake__get_model_executions_dml_sql", "macro_sql": "{% macro snowflake__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n        from values\n        {% for model in models -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                try_cast('{{ model.adapter_response.rows_affected }}' as int), {# rows_affected #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1767123, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_model_executions_dml_sql": {"name": "postgres__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.postgres__get_model_executions_dml_sql", "macro_sql": "{% macro postgres__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        {% for model in models -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, {# rows_affected #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                $${{ model.message }}$$, {# message #}\n                $${{ tojson(model.adapter_response) }}$$ {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.178949, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_model_executions_dml_sql": {"name": "sqlserver__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_model_executions_dml_sql", "macro_sql": "{% macro sqlserver__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"\n        from ( values\n        {% for model in models -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake & BigQuery #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        ) v ( \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\" )\n\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1811728, "supported_languages": null}, "macro.dbt_artifacts.trino__get_model_executions_dml_sql": {"name": "trino__get_model_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_model_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_model_executions.sql", "unique_id": "macro.dbt_artifacts.trino__get_model_executions_dml_sql", "macro_sql": "{% macro trino__get_model_executions_dml_sql(models) -%}\n    {% if models != [] %}\n        {% set model_execution_values %}\n        {% for model in models -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                \n                {{ config_full_refresh }}, {# was_full_refresh #}\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n                \n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}TIMESTAMP '{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}TIMESTAMP '{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n                \n                {{ model.execution_time }}, {# total_node_runtime #}\n\n                {% if model.adapter_response.rows_affected is none or model.adapter_response.rows_affected is not defined %}\n                \n                    null\n                {% else %}\n                    {{ model.adapter_response.rows_affected }}\n                {% endif %}\n                , {# rows_affected #}\n\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ model_execution_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1832666, "supported_languages": null}, "macro.dbt_artifacts.upload_snapshots": {"name": "upload_snapshots", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.upload_snapshots", "macro_sql": "{% macro upload_snapshots(snapshots) -%}\n\n    {{ return(adapter.dispatch(\"get_snapshots_dml_sql\", \"dbt_artifacts\")(snapshots)) }}\n\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_snapshots_dml_sql"]}, "description": "The macro to support upload of the data to the snapshots table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "snapshots", "type": "list", "description": "A list of snapshots objects extracted from the dbt graph\n"}], "created_at": 1760419970.7198956, "supported_languages": null}, "macro.dbt_artifacts.default__get_snapshots_dml_sql": {"name": "default__get_snapshots_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.default__get_snapshots_dml_sql", "macro_sql": "{% macro default__get_snapshots_dml_sql(snapshots) -%}\n\n    {% if snapshots != [] %}\n        {% set snapshot_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(7)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(12)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(14)) }}\n        from values\n        {% for snapshot in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ snapshot.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ snapshot.database }}', {# database #}\n                '{{ snapshot.schema }}', {# schema #}\n                '{{ snapshot.name }}', {# name #}\n                '{{ tojson(snapshot.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ snapshot.package_name }}', {# package_name #}\n                '{{ snapshot.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                '{{ snapshot.checksum.checksum | replace('\\\\', '\\\\\\\\') }}', {# checksum #}\n                '{{ snapshot.config.strategy }}', {# strategy #}\n                '{{ tojson(snapshot.config.meta) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}', {# meta #}\n                '{{ snapshot.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(snapshot) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ snapshot_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1881588, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_snapshots_dml_sql": {"name": "bigquery__get_snapshots_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_snapshots_dml_sql", "macro_sql": "{% macro bigquery__get_snapshots_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_values %}\n            {% for snapshot in snapshots -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ snapshot.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ snapshot.database }}', {# database #}\n                    '{{ snapshot.schema }}', {# schema #}\n                    '{{ snapshot.name }}', {# name #}\n                    {{ tojson(snapshot.depends_on.nodes) }}, {# depends_on_nodes #}\n                    '{{ snapshot.package_name }}', {# package_name #}\n                    '{{ snapshot.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    '{{ snapshot.checksum.checksum | replace('\\\\', '\\\\\\\\') }}', {# checksum #}\n                    '{{ snapshot.config.strategy }}', {# strategy #}\n                    {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(snapshot.config.meta)) }}, {# meta #}\n                    '{{ snapshot.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(snapshot) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ snapshot_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.189685, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_snapshots_dml_sql": {"name": "postgres__get_snapshots_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.postgres__get_snapshots_dml_sql", "macro_sql": "{% macro postgres__get_snapshots_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_values %}\n            {% for snapshot in snapshots -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ snapshot.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ snapshot.database }}', {# database #}\n                    '{{ snapshot.schema }}', {# schema #}\n                    '{{ snapshot.name }}', {# name #}\n                    $${{ tojson(snapshot.depends_on.nodes) }}$$, {# depends_on_nodes #}\n                    '{{ snapshot.package_name }}', {# package_name #}\n                    '{{ snapshot.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    '{{ snapshot.checksum.checksum }}', {# checksum #}\n                    '{{ snapshot.config.strategy }}', {# strategy #}\n                    $${{ tojson(snapshot.config.meta) }}$$, {# meta #}\n                    '{{ snapshot.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(snapshot) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ snapshot_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1909266, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_snapshots_dml_sql": {"name": "sqlserver__get_snapshots_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_snapshots_dml_sql", "macro_sql": "{% macro sqlserver__get_snapshots_dml_sql(snapshots) -%}\n\n    {% if snapshots != [] %}\n        {% set snapshot_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\"\n        from ( values\n        {% for snapshot in snapshots -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ snapshot.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ snapshot.database }}', {# database #}\n                '{{ snapshot.schema }}', {# schema #}\n                '{{ snapshot.name }}', {# name #}\n                '{{ tojson(snapshot.depends_on.nodes) }}', {# depends_on_nodes #}\n                '{{ snapshot.package_name }}', {# package_name #}\n                '{{ snapshot.original_file_path }}', {# path #}\n                '{{ snapshot.checksum.checksum }}', {# checksum #}\n                '{{ snapshot.config.strategy }}', {# strategy #}\n                '{{ tojson(snapshot.config.meta) | replace(\"'\",\"''\") }}', {# meta #}\n                '{{ snapshot.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(snapshot) | replace(\"'\",\"''\") }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\")\n\n        {% endset %}\n        {{ snapshot_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1922646, "supported_languages": null}, "macro.dbt_artifacts.trino__get_snapshots_dml_sql": {"name": "trino__get_snapshots_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_snapshots.sql", "original_file_path": "macros/upload_individual_datasets/upload_snapshots.sql", "unique_id": "macro.dbt_artifacts.trino__get_snapshots_dml_sql", "macro_sql": "{% macro trino__get_snapshots_dml_sql(snapshots) -%}\n    {% if snapshots != [] %}\n        {% set snapshot_values %}\n            {% for snapshot in snapshots -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ snapshot.unique_id }}', {# node_id #}\n                    TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                    '{{ snapshot.database }}', {# database #}\n                    '{{ snapshot.schema }}', {# schema #}\n                    '{{ snapshot.name }}', {# name #}\n                    ARRAY {{snapshot.depends_on.nodes }}, {# depends_on_nodes #}\n                    '{{ snapshot.package_name }}', {# package_name #}\n                    '{{ snapshot.original_file_path }}', {# path #}\n                    '{{ snapshot.checksum.checksum }}', {# checksum #}\n                    '{{ snapshot.config.strategy }}', {# strategy #}\n                    '{{ tojson(snapshot.config.meta) | replace(\"'\",\"''\") }}', {# meta #}\n                    '{{ snapshot.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        '{{ tojson(snapshot) | replace(\"'\",\"''\") }}' {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ snapshot_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.1936386, "supported_languages": null}, "macro.dbt_artifacts.upload_invocations": {"name": "upload_invocations", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.upload_invocations", "macro_sql": "{% macro upload_invocations() -%}\n\n    {# Need to remove keys with results that can't be handled properly #}\n    {# warn_error_options - returns a python object in 1.5 #}\n    {% if \"warn_error_options\" in invocation_args_dict %}\n        {% if invocation_args_dict.warn_error_options is not string %}\n            {% if invocation_args_dict.warn_error_options.include %}\n                {% set include_options = invocation_args_dict.warn_error_options.include %}\n            {% else %} {% set include_options = \"\" %}\n            {% endif %}\n            {% if invocation_args_dict.warn_error_options.exclude %}\n                {% set exclude_options = invocation_args_dict.warn_error_options.exclude %}\n            {% else %} {% set exclude_options = \"\" %}\n            {% endif %}\n            {% set warn_error_options = {\"include\": include_options, \"exclude\": exclude_options} %}\n            {%- do invocation_args_dict.update({\"warn_error_options\": warn_error_options}) %}\n        {% endif %}\n    {% endif %}\n\n    {% if \"event_time_start\" in invocation_args_dict %}\n        {% if invocation_args_dict.event_time_start is not string %}\n            {% do invocation_args_dict.update(\n                {\"event_time_start\": invocation_args_dict.event_time_start.strftime(dbt_artifacts.get_strftime_format())}\n            ) %}\n        {% endif%}\n    {% endif %}\n    {% if \"event_time_end\" in invocation_args_dict %}\n        {% if invocation_args_dict.event_time_end is not string %}\n            {% do invocation_args_dict.update(\n                {\"event_time_end\": invocation_args_dict.event_time_end.strftime(dbt_artifacts.get_strftime_format())}\n            ) %}\n        {% endif%}\n    {% endif %}\n\n    {{ log(invocation_args_dict) }}\n    {{ return(adapter.dispatch(\"get_invocations_dml_sql\", \"dbt_artifacts\")()) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.get_strftime_format", "macro.dbt_artifacts.default__get_invocations_dml_sql"]}, "description": "The macro to support upload of the data to the invocations table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [], "created_at": 1760419970.7178578, "supported_languages": null}, "macro.dbt_artifacts.default__get_invocations_dml_sql": {"name": "default__get_invocations_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.default__get_invocations_dml_sql", "macro_sql": "{% macro default__get_invocations_dml_sql() -%}\n    {% set invocation_values %}\n    select\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n        {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n        nullif({{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }}, ''),\n        nullif({{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }}, ''),\n        nullif({{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }}, ''),\n        nullif({{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }}, ''),\n        nullif({{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }}, ''),\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }},\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(17)) }},\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(18)) }},\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(19)) }}\n    from values\n    (\n        '{{ invocation_id }}', {# command_invocation_id #}\n        '{{ dbt_version }}', {# dbt_version #}\n        '{{ project_name }}', {# project_name #}\n        '{{ run_started_at }}', {# run_started_at #}\n        '{{ flags.WHICH }}', {# dbt_command #}\n        '{{ flags.FULL_REFRESH }}', {# full_refresh_flag #}\n        '{{ target.profile_name }}', {# target_profile_name #}\n        '{{ target.name }}', {# target_name #}\n        '{{ target.schema }}', {# target_schema #}\n        {{ target.threads }}, {# target_threads #}\n\n        '{{ env_var('DBT_CLOUD_PROJECT_ID', '') }}', {# dbt_cloud_project_id #}\n        '{{ env_var('DBT_CLOUD_JOB_ID', '') }}', {# dbt_cloud_job_id #}\n        '{{ env_var('DBT_CLOUD_RUN_ID', '') }}', {# dbt_cloud_run_id #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON_CATEGORY', '') }}', {# dbt_cloud_run_reason_category #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON', '') | replace(\"'\",\"\\\\'\") }}', {# dbt_cloud_run_reason #}\n\n        {% if var('env_vars', none) %}\n            {% set env_vars_dict = {} %}\n            {% for env_variable in var('env_vars') %}\n                {% do env_vars_dict.update({env_variable: (env_var(env_variable, '') | replace(\"'\", \"''\"))}) %}\n            {% endfor %}\n            '{{ tojson(env_vars_dict) }}', {# env_vars #}\n        {% else %}\n            null, {# env_vars #}\n        {% endif %}\n\n        {% if var('dbt_vars', none) %}\n            {% set dbt_vars_dict = {} %}\n            {% for dbt_var in var('dbt_vars') %}\n                {% do dbt_vars_dict.update({dbt_var: (var(dbt_var, '') | replace(\"'\", \"''\"))}) %}\n            {% endfor %}\n            '{{ tojson(dbt_vars_dict) }}', {# dbt_vars #}\n        {% else %}\n            null, {# dbt_vars #}\n        {% endif %}\n\n        '{{ tojson(invocation_args_dict) | replace('\\\\', '\\\\\\\\') | replace(\"'\", \"\\\\'\") }}', {# invocation_args #}\n\n        {% set metadata_env = {} %}\n        {% for key, value in dbt_metadata_envs.items() %}\n            {% do metadata_env.update({key: (value | replace(\"'\", \"''\"))}) %}\n        {% endfor %}\n        '{{ tojson(metadata_env) | replace('\\\\', '\\\\\\\\') }}' {# dbt_custom_envs #}\n\n    )\n    {% endset %}\n    {{ invocation_values }}\n\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2033558, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_invocations_dml_sql": {"name": "bigquery__get_invocations_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_invocations_dml_sql", "macro_sql": "{% macro bigquery__get_invocations_dml_sql() -%}\n    {% set invocation_values %}\n        (\n        '{{ invocation_id }}', {# command_invocation_id #}\n        '{{ dbt_version }}', {# dbt_version #}\n        '{{ project_name }}', {# project_name #}\n        '{{ run_started_at }}', {# run_started_at #}\n        '{{ flags.WHICH }}', {# dbt_command #}\n        {{ flags.FULL_REFRESH }}, {# full_refresh_flag #}\n        '{{ target.profile_name }}', {# target_profile_name #}\n        '{{ target.name }}', {# target_name #}\n        '{{ target.schema }}', {# target_schema #}\n        {{ target.threads }}, {# target_threads #}\n\n        '{{ env_var('DBT_CLOUD_PROJECT_ID', '') }}', {# dbt_cloud_project_id #}\n        '{{ env_var('DBT_CLOUD_JOB_ID', '') }}', {# dbt_cloud_job_id #}\n        '{{ env_var('DBT_CLOUD_RUN_ID', '') }}', {# dbt_cloud_run_id #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON_CATEGORY', '') }}', {# dbt_cloud_run_reason_category #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON', '') | replace(\"'\",\"\\\\'\") }}', {# dbt_cloud_run_reason #}\n\n        {% if var('env_vars', none) %}\n            {% set env_vars_dict = {} %}\n            {% for env_variable in var('env_vars') %}\n                {% do env_vars_dict.update({env_variable: (env_var(env_variable, ''))}) %}\n            {% endfor %}\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(env_vars_dict)) }}, {# env_vars #}\n        {% else %}\n            null, {# env_vars #}\n        {% endif %}\n\n        {% if var('dbt_vars', none) %}\n            {% set dbt_vars_dict = {} %}\n            {% for dbt_var in var('dbt_vars') %}\n                {% do dbt_vars_dict.update({dbt_var: (var(dbt_var, ''))}) %}\n            {% endfor %}\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(dbt_vars_dict)) }}, {# dbt_vars #}\n        {% else %}\n            null, {# dbt_vars #}\n        {% endif %}\n\n        {% if invocation_args_dict.vars %}\n            {# vars - different format for pre v1.5 (yaml vs list) #}\n            {% if invocation_args_dict.vars is string %}\n                {# BigQuery does not handle the yaml-string from \"--vars\" well, when passed to \"parse_json\". Workaround is to parse the string, and then \"tojson\" will properly format the dict as a json-object. #}\n                {% set parsed_inv_args_vars = fromyaml(invocation_args_dict.vars) %}\n                {% do invocation_args_dict.update({'vars': parsed_inv_args_vars}) %}\n            {% endif %}\n        {% endif %}\n\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(invocation_args_dict) | replace(\"'\", \"\\\\'\")) }}, {# invocation_args #}\n\n        {% set metadata_env = {} %}\n        {% for key, value in dbt_metadata_envs.items() %}\n            {% do metadata_env.update({key: value}) %}\n        {% endfor %}\n        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(metadata_env) | replace('\\\\', '\\\\\\\\')) }} {# dbt_custom_envs #}\n\n        )\n    {% endset %}\n    {{ invocation_values }}\n\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2063556, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_invocations_dml_sql": {"name": "postgres__get_invocations_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.postgres__get_invocations_dml_sql", "macro_sql": "{% macro postgres__get_invocations_dml_sql() -%}\n    {% set invocation_values %}\n        (\n            '{{ invocation_id }}', {# command_invocation_id #}\n            '{{ dbt_version }}', {# dbt_version #}\n            '{{ project_name }}', {# project_name #}\n            '{{ run_started_at }}', {# run_started_at #}\n            '{{ flags.WHICH }}', {# dbt_command #}\n            {{ flags.FULL_REFRESH }}, {# full_refresh_flag #}\n            '{{ target.profile_name }}', {# target_profile_name #}\n            '{{ target.name }}', {# target_name #}\n            '{{ target.schema }}', {# target_schema #}\n            {{ target.threads }}, {# target_threads #}\n\n            '{{ env_var(\"DBT_CLOUD_PROJECT_ID\", \"\") }}', {# dbt_cloud_project_id #}\n            '{{ env_var(\"DBT_CLOUD_JOB_ID\", \"\") }}', {# dbt_cloud_job_id #}\n            '{{ env_var(\"DBT_CLOUD_RUN_ID\", \"\") }}', {# dbt_cloud_run_id #}\n            '{{ env_var(\"DBT_CLOUD_RUN_REASON_CATEGORY\", \"\") }}', {# dbt_cloud_run_reason_category #}\n            $${{ env_var('DBT_CLOUD_RUN_REASON', '') }}$$, {# dbt_cloud_run_reason #}\n\n            {% if var('env_vars', none) %}\n                {% set env_vars_dict = {} %}\n                {% for env_variable in var('env_vars') %}\n                    {% do env_vars_dict.update({env_variable: (env_var(env_variable, ''))}) %}\n                {% endfor %}\n                $${{ tojson(env_vars_dict) }}$$, {# env_vars #}\n            {% else %}\n                null, {# env_vars #}\n            {% endif %}\n\n            {% if var('dbt_vars', none) %}\n                {% set dbt_vars_dict = {} %}\n                {% for dbt_var in var('dbt_vars') %}\n                    {% do dbt_vars_dict.update({dbt_var: (var(dbt_var, ''))}) %}\n                {% endfor %}\n                $${{ tojson(dbt_vars_dict) }}$$, {# dbt_vars #}\n            {% else %}\n                null, {# dbt_vars #}\n            {% endif %}\n\n            {% if invocation_args_dict.vars %}\n                {# vars - different format for pre v1.5 (yaml vs list) #}\n                {% if invocation_args_dict.vars is string %}\n                    {# BigQuery does not handle the yaml-string from \"--vars\" well, when passed to \"parse_json\". Workaround is to parse the string, and then \"tojson\" will properly format the dict as a json-object. #}\n                    {% set parsed_inv_args_vars = fromyaml(invocation_args_dict.vars) %}\n                    {% do invocation_args_dict.update({'vars': parsed_inv_args_vars}) %}\n                {% endif %}\n            {% endif %}\n\n            $${{ tojson(invocation_args_dict) }}$$, {# invocation_args #}\n\n            {% set metadata_env = {} %}\n            {% for key, value in dbt_metadata_envs.items() %}\n                {% do metadata_env.update({key: value}) %}\n            {% endfor %}\n            $${{ tojson(metadata_env) }}$$ {# dbt_custom_envs #}\n        )\n    {% endset %}\n    {{ invocation_values }}\n\n{% endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2092323, "supported_languages": null}, "macro.dbt_artifacts.trino__get_invocations_dml_sql": {"name": "trino__get_invocations_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.trino__get_invocations_dml_sql", "macro_sql": "{% macro trino__get_invocations_dml_sql() -%}\n    {% set invocation_values %}\n        (\n            '{{ invocation_id }}', {# command_invocation_id #}\n            '{{ dbt_version }}', {# dbt_version #}\n            '{{ project_name }}', {# project_name #}\n            TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n            '{{ flags.WHICH }}', {# dbt_command #}\n            {{ flags.FULL_REFRESH }}, {# full_refresh_flag #}\n            '{{ target.profile_name }}', {# target_profile_name #}\n            '{{ target.name }}', {# target_name #}\n            '{{ target.schema }}', {# target_schema #}\n            {{ target.threads }}, {# target_threads #}\n\n            '{{ env_var(\"DBT_CLOUD_PROJECT_ID\", \"\") }}', {# dbt_cloud_project_id #}\n            '{{ env_var(\"DBT_CLOUD_JOB_ID\", \"\") }}', {# dbt_cloud_job_id #}\n            '{{ env_var(\"DBT_CLOUD_RUN_ID\", \"\") }}', {# dbt_cloud_run_id #}\n            '{{ env_var(\"DBT_CLOUD_RUN_REASON_CATEGORY\", \"\") }}', {# dbt_cloud_run_reason_category #}\n            '{{ env_var('DBT_CLOUD_RUN_REASON', '') | replace(\"'\",\"''\") }}', {# dbt_cloud_run_reason #}\n\n            {% if var('env_vars', none) %}\n                {% set env_vars_dict = {} %}\n                {% for env_variable in var('env_vars') %}\n                    {% do env_vars_dict.update({env_variable: (env_var(env_variable, ''))}) %}\n                {% endfor %}\n                '{{ tojson(env_vars_dict) | replace(\"'\",\"''\") }}', {# env_vars #}\n            {% else %}\n                null, {# env_vars #}\n            {% endif %}\n\n            {% if var('dbt_vars', none) %}\n                {% set dbt_vars_dict = {} %}\n                {% for dbt_var in var('dbt_vars') %}\n                    {% do dbt_vars_dict.update({dbt_var: (var(dbt_var, ''))}) %}\n                {% endfor %}\n                '{{ tojson(dbt_vars_dict) | replace(\"'\",\"''\") }}', {# dbt_vars #}\n            {% else %}\n                null, {# dbt_vars #}\n            {% endif %}\n\n            {% if invocation_args_dict.vars %}\n                {# vars - different format for pre v1.5 (yaml vs list) #}\n                {% if invocation_args_dict.vars is string %}\n                    {% set parsed_inv_args_vars = fromyaml(invocation_args_dict.vars) %}\n                    {% do invocation_args_dict.update({'vars': parsed_inv_args_vars}) %}\n                {% endif %}\n            {% endif %}\n\n            '{{ invocation_args_dict | replace(\"'\",\"''\") }}', {# invocation_args #}\n\n            {% set metadata_env = {} %}\n            {% for key, value in dbt_metadata_envs.items() %}\n                {% do metadata_env.update({key: value}) %}\n            {% endfor %}\n            '{{ tojson(metadata_env) | replace(\"'\",\"''\") }}' {# dbt_custom_envs #}\n        )\n    {% endset %}\n    {{ invocation_values }}\n\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.212324, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_invocations_dml_sql": {"name": "sqlserver__get_invocations_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_invocations.sql", "original_file_path": "macros/upload_individual_datasets/upload_invocations.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_invocations_dml_sql", "macro_sql": "{% macro sqlserver__get_invocations_dml_sql() -%}\n    {% set invocation_values %}\n    select\n        \"1\",\n        \"2\",\n        \"3\",\n        \"4\",\n        \"5\",\n        \"6\",\n        \"7\",\n        \"8\",\n        \"9\",\n        \"10\",\n        nullif(\"11\", ''),\n        nullif(\"12\", ''),\n        nullif(\"13\", ''),\n        nullif(\"14\", ''),\n        nullif(\"15\", ''),\n        \"16\",\n        \"17\",\n        \"18\",\n        \"19\"\n    from (values\n    (\n        '{{ invocation_id }}', {# command_invocation_id #}\n        '{{ dbt_version }}', {# dbt_version #}\n        '{{ project_name }}', {# project_name #}\n        '{{ run_started_at }}', {# run_started_at #}\n        '{{ flags.WHICH }}', {# dbt_command #}\n        '{{ flags.FULL_REFRESH }}', {# full_refresh_flag #}\n        '{{ target.profile_name }}', {# target_profile_name #}\n        '{{ target.name }}', {# target_name #}\n        '{{ target.schema }}', {# target_schema #}\n        {{ target.threads }}, {# target_threads #}\n\n        '{{ env_var('DBT_CLOUD_PROJECT_ID', '') }}', {# dbt_cloud_project_id #}\n        '{{ env_var('DBT_CLOUD_JOB_ID', '') }}', {# dbt_cloud_job_id #}\n        '{{ env_var('DBT_CLOUD_RUN_ID', '') }}', {# dbt_cloud_run_id #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON_CATEGORY', '') }}', {# dbt_cloud_run_reason_category #}\n        '{{ env_var('DBT_CLOUD_RUN_REASON', '') | replace(\"'\",\"''\") }}', {# dbt_cloud_run_reason #}\n        {% if var('env_vars', none) %}\n            {% set env_vars_dict = {} %}\n            {% for env_variable in var('env_vars') %}\n                {% do env_vars_dict.update({env_variable: (env_var(env_variable, '') | replace(\"'\", \"''\"))}) %}\n            {% endfor %}\n            '{{ tojson(env_vars_dict) }}', {# env_vars #}\n        {% else %}\n            null, {# env_vars #}\n        {% endif %}\n        {% if var('dbt_vars', none) %}\n            {% set dbt_vars_dict = {} %}\n            {% for dbt_var in var('dbt_vars') %}\n                {% do dbt_vars_dict.update({dbt_var: (var(dbt_var, '') | replace(\"'\", \"''\"))}) %}\n            {% endfor %}\n            '{{ tojson(dbt_vars_dict) }}', {# dbt_vars #}\n        {% else %}\n            null, {# dbt_vars #}\n        {% endif %}\n        '{{ tojson(invocation_args_dict)  | replace(\"'\", \"''\") }}', {# invocation_args #}\n\n        {% set metadata_env = {} %}\n        {% for key, value in dbt_metadata_envs.items() %}\n            {% do metadata_env.update({key: (value | replace(\"'\", \"''\"))}) %}\n        {% endfor %}\n        '{{ tojson(metadata_env) }}' {# dbt_custom_envs #}\n\n    )\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\")\n\n    {% endset %}\n    {{ invocation_values }}\n\n{% endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.215269, "supported_languages": null}, "macro.dbt_artifacts.upload_seeds": {"name": "upload_seeds", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.upload_seeds", "macro_sql": "{% macro upload_seeds(seeds) -%}\n    {{ return(adapter.dispatch(\"get_seeds_dml_sql\", \"dbt_artifacts\")(seeds)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_seeds_dml_sql"]}, "description": "The macro to support upload of the data to the seeds table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "seeds", "type": "list", "description": "A list of seeds objects extracted from the dbt graph\n"}], "created_at": 1760419970.719242, "supported_languages": null}, "macro.dbt_artifacts.default__get_seeds_dml_sql": {"name": "default__get_seeds_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.default__get_seeds_dml_sql", "macro_sql": "{% macro default__get_seeds_dml_sql(seeds) -%}\n\n    {% if seeds != [] %}\n        {% set seed_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(10)) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(12)) }}\n        from values\n        {% for seed in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ seed.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ seed.database }}', {# database #}\n                '{{ seed.schema }}', {# schema #}\n                '{{ seed.name }}', {# name #}\n                '{{ seed.package_name }}', {# package_name #}\n                '{{ seed.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                '{{ seed.checksum.checksum | replace('\\\\', '\\\\\\\\') }}', {# checksum #}\n                '{{ tojson(seed.config.meta) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}', {# meta #}\n                '{{ seed.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(seed) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"') }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2202666, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_seeds_dml_sql": {"name": "bigquery__get_seeds_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_seeds_dml_sql", "macro_sql": "{% macro bigquery__get_seeds_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_values %}\n            {% for seed in seeds -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ seed.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ seed.database }}', {# database #}\n                    '{{ seed.schema }}', {# schema #}\n                    '{{ seed.name }}', {# name #}\n                    '{{ seed.package_name }}', {# package_name #}\n                    '{{ seed.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    '{{ seed.checksum.checksum | replace('\\\\', '\\\\\\\\')}}', {# checksum #}\n                    {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(seed.config.meta)) }}, {# meta #}\n                    '{{ seed.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(seed) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\",\"\\\\'\") | replace('\"', '\\\\\"')) }} {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ seed_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2218587, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_seeds_dml_sql": {"name": "postgres__get_seeds_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.postgres__get_seeds_dml_sql", "macro_sql": "{% macro postgres__get_seeds_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_values %}\n            {% for seed in seeds -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ seed.unique_id }}', {# node_id #}\n                    '{{ run_started_at }}', {# run_started_at #}\n                    '{{ seed.database }}', {# database #}\n                    '{{ seed.schema }}', {# schema #}\n                    '{{ seed.name }}', {# name #}\n                    '{{ seed.package_name }}', {# package_name #}\n                    '{{ seed.original_file_path | replace('\\\\', '\\\\\\\\') }}', {# path #}\n                    '{{ seed.checksum.checksum }}', {# checksum #}\n                    $${{ tojson(seed.config.meta) }}$$, {# meta #}\n                    '{{ seed.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        $${{ tojson(seed) }}$$ {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ seed_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2230577, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_seeds_dml_sql": {"name": "sqlserver__get_seeds_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_seeds_dml_sql", "macro_sql": "{% macro sqlserver__get_seeds_dml_sql(seeds) -%}\n\n    {% if seeds != [] %}\n        {% set seed_values %}\n        select \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"\n        from ( values\n        {% for seed in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ seed.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n                '{{ seed.database }}', {# database #}\n                '{{ seed.schema }}', {# schema #}\n                '{{ seed.name }}', {# name #}\n                '{{ seed.package_name }}', {# package_name #}\n                '{{ seed.original_file_path }}', {# path #}\n                '{{ seed.checksum.checksum }}', {# checksum #}\n                '{{ tojson(seed.config.meta) | replace(\"'\",\"''\") }}', {# meta #}\n                '{{ seed.alias }}', {# alias #}\n                {% if var('dbt_artifacts_exclude_all_results', false) %}\n                    null\n                {% else %}\n                    '{{ tojson(seed) | replace(\"'\",\"''\") }}' {# all_results #}\n                {% endif %}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\")\n\n        {% endset %}\n        {{ seed_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.224323, "supported_languages": null}, "macro.dbt_artifacts.trino__get_seeds_dml_sql": {"name": "trino__get_seeds_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seeds.sql", "original_file_path": "macros/upload_individual_datasets/upload_seeds.sql", "unique_id": "macro.dbt_artifacts.trino__get_seeds_dml_sql", "macro_sql": "{% macro trino__get_seeds_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_values %}\n            {% for seed in seeds -%}\n                (\n                    '{{ invocation_id }}', {# command_invocation_id #}\n                    '{{ seed.unique_id }}', {# node_id #}\n                    TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n                    '{{ seed.database }}', {# database #}\n                    '{{ seed.schema }}', {# schema #}\n                    '{{ seed.name }}', {# name #}\n                    '{{ seed.package_name }}', {# package_name #}\n                    '{{ seed.original_file_path }}', {# path #}\n                    '{{ seed.checksum.checksum }}', {# checksum #}\n                    '{{ tojson(seed.config.meta) | replace(\"'\", \"''\") }}', {# meta #}\n                    '{{ seed.alias }}', {# alias #}\n                    {% if var('dbt_artifacts_exclude_all_results', false) %}\n                        null\n                    {% else %}\n                        '{{ tojson(seed) | replace(\"'\", \"''\") }}' {# all_results #}\n                    {% endif %}\n                )\n                {%- if not loop.last %},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n        {{ seed_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2258513, "supported_languages": null}, "macro.dbt_artifacts.upload_seed_executions": {"name": "upload_seed_executions", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.upload_seed_executions", "macro_sql": "{% macro upload_seed_executions(seeds) -%}\n    {{ return(adapter.dispatch(\"get_seed_executions_dml_sql\", \"dbt_artifacts\")(seeds)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__get_seed_executions_dml_sql"]}, "description": "The macro to support upload of the data to the seed_executions table.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "seeds", "type": "list", "description": "A list of seed execution results objects extracted from the dbt result object\n"}], "created_at": 1760419970.7188754, "supported_languages": null}, "macro.dbt_artifacts.default__get_seed_executions_dml_sql": {"name": "default__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.default__get_seed_executions_dml_sql", "macro_sql": "{% macro default__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n        from values\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2329423, "supported_languages": null}, "macro.dbt_artifacts.bigquery__get_seed_executions_dml_sql": {"name": "bigquery__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.bigquery__get_seed_executions_dml_sql", "macro_sql": "{% macro bigquery__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Databricks #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') | replace(\"\\n\", \"\\\\n\") }}', {# message #}\n                {{ adapter.dispatch('parse_json', 'dbt_artifacts')(tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"')) }} {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.235293, "supported_languages": null}, "macro.dbt_artifacts.snowflake__get_seed_executions_dml_sql": {"name": "snowflake__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.snowflake__get_seed_executions_dml_sql", "macro_sql": "{% macro snowflake__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        select\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(1) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(2) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(3) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(4) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(5) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(6) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(7) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(8) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(9) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(10) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(11) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(12) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(13) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(14) }},\n            {{ adapter.dispatch('column_identifier', 'dbt_artifacts')(15) }},\n            {{ adapter.dispatch('parse_json', 'dbt_artifacts')(adapter.dispatch('column_identifier', 'dbt_artifacts')(16)) }}\n        from values\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                try_cast('{{ model.adapter_response.rows_affected }}' as int), {# rows_affected #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"\\\\\", \"\\\\\\\\\") | replace(\"'\", \"\\\\'\") | replace('\"', '\\\\\"') }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": ["macro.dbt_artifacts.column_identifier", "macro.dbt_artifacts.spark__column_identifier", "macro.dbt_artifacts.parse_json", "macro.dbt_artifacts.default__parse_json"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.239234, "supported_languages": null}, "macro.dbt_artifacts.postgres__get_seed_executions_dml_sql": {"name": "postgres__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.postgres__get_seed_executions_dml_sql", "macro_sql": "{% macro postgres__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% if model.timing != [] %}\n                    {% for stage in model.timing if stage.name == \"compile\" %}\n                        {% if loop.length == 0 %}\n                            null, {# compile_started_at #}\n                        {% else %}\n                            '{{ stage.started_at }}', {# compile_started_at #}\n                        {% endif %}\n                    {% endfor %}\n\n                    {% for stage in model.timing if stage.name == \"execute\" %}\n                        {% if loop.length == 0 %}\n                            null, {# query_completed_at #}\n                        {% else %}\n                            '{{ stage.completed_at }}', {# query_completed_at #}\n                        {% endif %}\n                    {% endfor %}\n                {% else %}\n                    null, {# compile_started_at #}\n                    null, {# query_completed_at #}\n                {% endif %}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Databricks #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                $${{ model.message }}$$, {# message #}\n                $${{ tojson(model.adapter_response) }}$$ {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2415187, "supported_languages": null}, "macro.dbt_artifacts.sqlserver__get_seed_executions_dml_sql": {"name": "sqlserver__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.sqlserver__get_seed_executions_dml_sql", "macro_sql": "{% macro sqlserver__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        select\n            \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"\n        from ( values\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                '{{ config_full_refresh }}', {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}'{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}'{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n\n                {{ model.execution_time }}, {# total_node_runtime #}\n                null, -- rows_affected not available {# Only available in Snowflake #}\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n\n        ) v (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\")\n\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %} {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}\n\n\n", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2437649, "supported_languages": null}, "macro.dbt_artifacts.trino__get_seed_executions_dml_sql": {"name": "trino__get_seed_executions_dml_sql", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/upload_individual_datasets/upload_seed_executions.sql", "original_file_path": "macros/upload_individual_datasets/upload_seed_executions.sql", "unique_id": "macro.dbt_artifacts.trino__get_seed_executions_dml_sql", "macro_sql": "{% macro trino__get_seed_executions_dml_sql(seeds) -%}\n    {% if seeds != [] %}\n        {% set seed_execution_values %}\n        {% for model in seeds -%}\n            (\n                '{{ invocation_id }}', {# command_invocation_id #}\n                '{{ model.node.unique_id }}', {# node_id #}\n                TIMESTAMP '{{ run_started_at }}', {# run_started_at #}\n\n                {% set config_full_refresh = model.node.config.full_refresh %}\n                {% if config_full_refresh is none %}\n                    {% set config_full_refresh = flags.FULL_REFRESH %}\n                {% endif %}\n                {{ config_full_refresh }}, {# was_full_refresh #}\n\n                '{{ model.thread_id }}', {# thread_id #}\n                '{{ model.status }}', {# status #}\n\n                {% set compile_started_at = (model.timing | selectattr(\"name\", \"eq\", \"compile\") | first | default({}))[\"started_at\"] %}\n                {% if compile_started_at %}TIMESTAMP '{{ compile_started_at }}'{% else %}null{% endif %}, {# compile_started_at #}\n                {% set query_completed_at = (model.timing | selectattr(\"name\", \"eq\", \"execute\") | first | default({}))[\"completed_at\"] %}\n                {% if query_completed_at %}TIMESTAMP '{{ query_completed_at }}'{% else %}null{% endif %}, {# query_completed_at #}\n                \n                {{ model.execution_time }}, {# total_node_runtime #}\n                \n                {% if model.adapter_response.rows_affected is none or model.adapter_response.rows_affected is not defined %}\n                    null\n                {% else %}\n                    {{ model.adapter_response.rows_affected }}\n                {% endif %}\n                , {# rows_affected #}\n\n                '{{ model.node.config.materialized }}', {# materialization #}\n                '{{ model.node.schema }}', {# schema #}\n                '{{ model.node.name }}', {# name #}\n                '{{ model.node.alias }}', {# alias #}\n                '{{ model.message | replace(\"'\", \"''\") }}', {# message #}\n                '{{ tojson(model.adapter_response) | replace(\"'\", \"''\") }}' {# adapter_response #}\n            )\n            {%- if not loop.last %},{%- endif %}\n        {%- endfor %}\n        {% endset %}\n        {{ seed_execution_values }}\n    {% else %}\n        {{ return(\"\") }}\n    {% endif %}\n{% endmacro -%}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2461193, "supported_languages": null}, "macro.dbt_artifacts.get_strftime_format": {"name": "get_strftime_format", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/utils/get_strftime_fmt.sql", "original_file_path": "macros/utils/get_strftime_fmt.sql", "unique_id": "macro.dbt_artifacts.get_strftime_format", "macro_sql": "{% macro get_strftime_format() %}\n    {{ return(\"%Y-%m-%dT%H:%M:%S.%f\") }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2463784, "supported_languages": null}, "macro.dbt_artifacts.copy_model": {"name": "copy_model", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/utils/copy_model.sql", "original_file_path": "macros/utils/copy_model.sql", "unique_id": "macro.dbt_artifacts.copy_model", "macro_sql": "{% macro copy_model(model) %}\n    {% set model_copy = model.copy() %}\n    {% do model_copy.pop('raw_code', None) %}\n    {# We assume that the begin value is a datetime object if not a string#}\n    {% if model_copy.config.begin and model_copy.config.begin is not string %}\n        {% set _ = model_copy.config.update({\"begin\": model_copy.config.begin.strftime(dbt_artifacts.get_strftime_format())}) %}\n    {% endif %}\n\n    {{ return(model_copy) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.get_strftime_format"]}, "description": "A macro to help encapsulate model copying, specifically for the upload_model macro. Namely, this macro is helpful as the\ncontract for the graph nodes is prone to change without warning. This macro makes handling for these changes easier and more DRY.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "model", "type": "Node", "description": "A node object from the dbt graph"}], "created_at": 1760419970.717215, "supported_languages": null}, "macro.dbt_artifacts.str_left": {"name": "str_left", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/string_functions.sql", "original_file_path": "macros/database_specific_helpers/string_functions.sql", "unique_id": "macro.dbt_artifacts.str_left", "macro_sql": "{% macro str_left(col, length) %}\n    {{ return(adapter.dispatch('str_left', 'dbt_artifacts')(col, length)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__str_left"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2475598, "supported_languages": null}, "macro.dbt_artifacts.default__str_left": {"name": "default__str_left", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/string_functions.sql", "original_file_path": "macros/database_specific_helpers/string_functions.sql", "unique_id": "macro.dbt_artifacts.default__str_left", "macro_sql": "{% macro default__str_left(col, length) %}\n   left({{ col }}, {{ length }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2477565, "supported_languages": null}, "macro.dbt_artifacts.trino__str_left": {"name": "trino__str_left", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/string_functions.sql", "original_file_path": "macros/database_specific_helpers/string_functions.sql", "unique_id": "macro.dbt_artifacts.trino__str_left", "macro_sql": "{% macro trino__str_left(col, length) %}\n    substring({{ col }}, 1, {{ length }})\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2479374, "supported_languages": null}, "macro.dbt_artifacts.column_identifier": {"name": "column_identifier", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/column_identifier.sql", "original_file_path": "macros/database_specific_helpers/column_identifier.sql", "unique_id": "macro.dbt_artifacts.column_identifier", "macro_sql": "{% macro column_identifier(column_index) -%}\n  {{ return(adapter.dispatch('column_identifier')(column_index)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.spark__column_identifier"]}, "description": "Dependent on the adapter type, return the identifier for a column using a numerical index.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "column_index", "type": "integer", "description": "The index of the column to return the identifier for\n"}], "created_at": 1760419970.7118378, "supported_languages": null}, "macro.dbt_artifacts.default__column_identifier": {"name": "default__column_identifier", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/column_identifier.sql", "original_file_path": "macros/database_specific_helpers/column_identifier.sql", "unique_id": "macro.dbt_artifacts.default__column_identifier", "macro_sql": "{% macro default__column_identifier(column_index) -%}\n    {{ column_index }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2484088, "supported_languages": null}, "macro.dbt_artifacts.snowflake__column_identifier": {"name": "snowflake__column_identifier", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/column_identifier.sql", "original_file_path": "macros/database_specific_helpers/column_identifier.sql", "unique_id": "macro.dbt_artifacts.snowflake__column_identifier", "macro_sql": "{% macro snowflake__column_identifier(column_index) -%}\n    ${{ column_index }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2485504, "supported_languages": null}, "macro.dbt_artifacts.spark__column_identifier": {"name": "spark__column_identifier", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/column_identifier.sql", "original_file_path": "macros/database_specific_helpers/column_identifier.sql", "unique_id": "macro.dbt_artifacts.spark__column_identifier", "macro_sql": "{% macro spark__column_identifier(column_index) -%}\n    col{{ column_index }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2486863, "supported_languages": null}, "macro.dbt_artifacts.parse_json": {"name": "parse_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/parse_json.sql", "original_file_path": "macros/database_specific_helpers/parse_json.sql", "unique_id": "macro.dbt_artifacts.parse_json", "macro_sql": "{% macro parse_json(field) -%}\n  {{ return(adapter.dispatch('parse_json')(field)) }}\n{%- endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__parse_json"]}, "description": "Dependent on the adapter type, return a column which parses the JSON field.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "field", "type": "string", "description": "The name of the field to parse\n"}], "created_at": 1760419970.7142653, "supported_languages": null}, "macro.dbt_artifacts.default__parse_json": {"name": "default__parse_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/parse_json.sql", "original_file_path": "macros/database_specific_helpers/parse_json.sql", "unique_id": "macro.dbt_artifacts.default__parse_json", "macro_sql": "{% macro default__parse_json(field) -%}\n    {{ field }}\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2491364, "supported_languages": null}, "macro.dbt_artifacts.snowflake__parse_json": {"name": "snowflake__parse_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/parse_json.sql", "original_file_path": "macros/database_specific_helpers/parse_json.sql", "unique_id": "macro.dbt_artifacts.snowflake__parse_json", "macro_sql": "{% macro snowflake__parse_json(field) -%}\n    try_parse_json({{ field }})\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.249272, "supported_languages": null}, "macro.dbt_artifacts.bigquery__parse_json": {"name": "bigquery__parse_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/parse_json.sql", "original_file_path": "macros/database_specific_helpers/parse_json.sql", "unique_id": "macro.dbt_artifacts.bigquery__parse_json", "macro_sql": "{% macro bigquery__parse_json(field) -%}\n    safe.parse_json(\"\"\"{{ field }}\"\"\", wide_number_mode=>'round')\n{%- endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.249426, "supported_languages": null}, "macro.dbt_artifacts.get_relation": {"name": "get_relation", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/get_relation.sql", "original_file_path": "macros/database_specific_helpers/get_relation.sql", "unique_id": "macro.dbt_artifacts.get_relation", "macro_sql": "{% macro get_relation(relation_name) %}\n    {% if execute %}\n        {% set model_get_relation_node = graph.nodes.values() | selectattr('name', 'equalto', relation_name) | first %}\n        {% set relation = api.Relation.create(\n            database = model_get_relation_node.database,\n            schema = model_get_relation_node.schema,\n            identifier = model_get_relation_node.alias\n        )\n        %}\n        {% do return(relation) %}\n    {% else %}\n        {% do return(api.Relation.create()) %}\n    {% endif %}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "Identify a relation in the graph from a relation name\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "get_relation_name", "type": "string", "description": "The name of the relation to return from the graph\n"}], "created_at": 1760419970.713734, "supported_languages": null}, "macro.dbt_artifacts.type_boolean": {"name": "type_boolean", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.type_boolean", "macro_sql": "{% macro type_boolean() %}\n    {{ return(adapter.dispatch('type_boolean', 'dbt_artifacts')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__type_boolean"]}, "description": "Dependent on the adapter type, returns the native boolean type.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [], "created_at": 1760419970.7148569, "supported_languages": null}, "macro.dbt_artifacts.default__type_boolean": {"name": "default__type_boolean", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.default__type_boolean", "macro_sql": "{% macro default__type_boolean() %}\n   {{ return(api.Column.translate_type(\"boolean\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2510247, "supported_languages": null}, "macro.dbt_artifacts.type_json": {"name": "type_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.type_json", "macro_sql": "{% macro type_json() %}\n    {{ return(adapter.dispatch('type_json', 'dbt_artifacts')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__type_json"]}, "description": "Dependent on the adapter type, returns the native type for storing JSON.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [], "created_at": 1760419970.715208, "supported_languages": null}, "macro.dbt_artifacts.default__type_json": {"name": "default__type_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.default__type_json", "macro_sql": "{% macro default__type_json() %}\n   {{ return(api.Column.translate_type(\"string\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2514446, "supported_languages": null}, "macro.dbt_artifacts.snowflake__type_json": {"name": "snowflake__type_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.snowflake__type_json", "macro_sql": "{% macro snowflake__type_json() %}\n   object\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2515452, "supported_languages": null}, "macro.dbt_artifacts.bigquery__type_json": {"name": "bigquery__type_json", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.bigquery__type_json", "macro_sql": "{% macro bigquery__type_json() %}\n   json\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2516415, "supported_languages": null}, "macro.dbt_artifacts.type_array": {"name": "type_array", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.type_array", "macro_sql": "{% macro type_array() %}\n    {{ return(adapter.dispatch('type_array', 'dbt_artifacts')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__type_array"]}, "description": "Dependent on the adapter type, returns the native type for storing an array.\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [], "created_at": 1760419970.7145677, "supported_languages": null}, "macro.dbt_artifacts.default__type_array": {"name": "default__type_array", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.default__type_array", "macro_sql": "{% macro default__type_array() %}\n   {{ return(api.Column.translate_type(\"string\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2520375, "supported_languages": null}, "macro.dbt_artifacts.snowflake__type_array": {"name": "snowflake__type_array", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.snowflake__type_array", "macro_sql": "{% macro snowflake__type_array() %}\n   array\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2521372, "supported_languages": null}, "macro.dbt_artifacts.bigquery__type_array": {"name": "bigquery__type_array", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.bigquery__type_array", "macro_sql": "{% macro bigquery__type_array() %}\n   array<string>\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2522328, "supported_languages": null}, "macro.dbt_artifacts.trino__type_array": {"name": "trino__type_array", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.trino__type_array", "macro_sql": "{% macro trino__type_array() %}\n   array(varchar)\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2523441, "supported_languages": null}, "macro.dbt_artifacts.type_numeric": {"name": "type_numeric", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.type_numeric", "macro_sql": "{% macro type_numeric() %}\n    {{ return(adapter.dispatch('type_numeric', 'dbt_artifacts')()) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2525644, "supported_languages": null}, "macro.dbt_artifacts.default__type_numeric": {"name": "default__type_numeric", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n   {{ return(api.Column.translate_type(\"numeric\")) }}\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2527504, "supported_languages": null}, "macro.dbt_artifacts.trino__type_numeric": {"name": "trino__type_numeric", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/type_helpers.sql", "original_file_path": "macros/database_specific_helpers/type_helpers.sql", "unique_id": "macro.dbt_artifacts.trino__type_numeric", "macro_sql": "{% macro trino__type_numeric() %}\n   double\n{% endmacro %}", "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2528458, "supported_languages": null}, "macro.dbt_artifacts.generate_surrogate_key": {"name": "generate_surrogate_key", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/generate_surrogate_key.sql", "original_file_path": "macros/database_specific_helpers/generate_surrogate_key.sql", "unique_id": "macro.dbt_artifacts.generate_surrogate_key", "macro_sql": "\n\n{%- macro generate_surrogate_key(field_list) -%}\n    {# Note - update the reference to `dbt_utils` to `dbt_artifacts` here #}\n    {{ return(adapter.dispatch('generate_surrogate_key', 'dbt_artifacts')(field_list)) }}\n{% endmacro %}", "depends_on": {"macros": ["macro.dbt_artifacts.default__generate_surrogate_key"]}, "description": "Since folks commonly install dbt_artifacts alongside a myriad of other packages,\nwe copy the dbt_utils implementation of the surrogate_key macro so we don't have\nany dependencies to make conflicts worse!\n\nThis version is:\nURL: https://github.com/dbt-labs/dbt-utils/blob/main/macros/sql/generate_surrogate_key.sql\nCommit SHA: eaa0e41b033bdf252eff0ae014ec11888f37ebff\nDate: 2023-04-28\n", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": "dbt_artifacts://macros/_macros.yml", "arguments": [{"name": "field_list", "type": "list", "description": "A list of fields to concatenate together to form the surrogate key\n"}], "created_at": 1760419970.7128632, "supported_languages": null}, "macro.dbt_artifacts.default__generate_surrogate_key": {"name": "default__generate_surrogate_key", "resource_type": "macro", "package_name": "dbt_artifacts", "path": "macros/database_specific_helpers/generate_surrogate_key.sql", "original_file_path": "macros/database_specific_helpers/generate_surrogate_key.sql", "unique_id": "macro.dbt_artifacts.default__generate_surrogate_key", "macro_sql": "\n\n{%- macro default__generate_surrogate_key(field_list) -%}\n\n{# Note - Removed this logic to retain consistency with the previous surrogate_key logic #}\n{# {%- if var('surrogate_key_treat_nulls_as_empty_strings', False) -%} #}\n{%- set default_null_value = \"\" -%}\n{# {%- else -%}\n    {%- set default_null_value = '_dbt_utils_surrogate_key_null_' -%}\n{%- endif -%} #}\n\n{%- set fields = [] -%}\n\n{%- for field in field_list -%}\n\n    {%- do fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt.type_string() ~ \"), '\" ~ default_null_value  ~\"')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- do fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{ dbt.hash(dbt.concat(fields)) }}\n\n{%- endmacro -%}", "depends_on": {"macros": ["macro.dbt.type_string", "macro.dbt.hash", "macro.dbt.concat"]}, "description": "", "meta": {}, "docs": {"show": true, "node_color": null}, "patch_path": null, "arguments": [], "created_at": 1760419969.2540085, "supported_languages": null}}, "docs": {"doc.dbt.__overview__": {"name": "__overview__", "resource_type": "doc", "package_name": "dbt", "path": "overview.md", "original_file_path": "docs/overview.md", "unique_id": "doc.dbt.__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--select` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/introduction)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [dbt Community](https://www.getdbt.com/community/) for questions and discussion"}, "doc.dbt_artifacts.command_invocation_id": {"name": "command_invocation_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.command_invocation_id", "block_contents": "The invocation_id is a UUID generated by dbt for each invocation. It can be used to link records which were generated by the same dbt invocation."}, "doc.dbt_artifacts.node_id": {"name": "node_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.node_id", "block_contents": "Unique node identifier."}, "doc.dbt_artifacts.name": {"name": "name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.name", "block_contents": "Name of the node."}, "doc.dbt_artifacts.schema": {"name": "schema", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.schema", "block_contents": "Configured schema for the node."}, "doc.dbt_artifacts.package_name": {"name": "package_name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.package_name", "block_contents": "Name of the dbt package which contains the node."}, "doc.dbt_artifacts.total_node_runtime": {"name": "total_node_runtime", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.total_node_runtime", "block_contents": "Total time spent executing this node (seconds)."}, "doc.dbt_artifacts.compile_started_at": {"name": "compile_started_at", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.compile_started_at", "block_contents": "Timestamp when the node started compiling."}, "doc.dbt_artifacts.depends_on_nodes": {"name": "depends_on_nodes", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.depends_on_nodes", "block_contents": "Array of node identifiers that this node depends on in the execution graph."}, "doc.dbt_artifacts.status": {"name": "status", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.status", "block_contents": "Represents the execution status of a node, can be success, failure, or error."}, "doc.dbt_artifacts.query_completed_at": {"name": "query_completed_at", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.query_completed_at", "block_contents": "Timestamp when the node's SQL query completed."}, "doc.dbt_artifacts.materialization": {"name": "materialization", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.materialization", "block_contents": "The materialization of the model."}, "doc.dbt_artifacts.database": {"name": "database", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.database", "block_contents": "The configured database for the node."}, "doc.dbt_artifacts.rows_affected": {"name": "rows_affected", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.rows_affected", "block_contents": "Number of rows affected by the model execution."}, "doc.dbt_artifacts.bytes_processed": {"name": "bytes_processed", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.bytes_processed", "block_contents": "Number of bytes processed by the model execution."}, "doc.dbt_artifacts.thread_id": {"name": "thread_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.thread_id", "block_contents": "Which thread executed this node? E.g. Thread-1"}, "doc.dbt_artifacts.path": {"name": "path", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.path", "block_contents": "Path to the model on the local filesystem."}, "doc.dbt_artifacts.was_full_refresh": {"name": "was_full_refresh", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.was_full_refresh", "block_contents": "Boolean flag indicating whether the nodes run was a full refresh or not."}, "doc.dbt_artifacts.checksum": {"name": "checksum", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.checksum", "block_contents": "Checksum of the model."}, "doc.dbt_artifacts.seed_execution_id": {"name": "seed_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.seed_execution_id", "block_contents": "Execution ID of the seed node."}, "doc.dbt_artifacts.test_execution_id": {"name": "test_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.test_execution_id", "block_contents": "Execution ID of the test node."}, "doc.dbt_artifacts.snapshot_execution_id": {"name": "snapshot_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.snapshot_execution_id", "block_contents": "Execution ID of the snapshot node."}, "doc.dbt_artifacts.model_execution_id": {"name": "model_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.model_execution_id", "block_contents": "Execution ID of the model node."}, "doc.dbt_artifacts.loader": {"name": "loader", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.loader", "block_contents": "Describes the tool that loads this source into your warehouse."}, "doc.dbt_artifacts.freshness": {"name": "freshness", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.freshness", "block_contents": "The specified freshness of the source model."}, "doc.dbt_artifacts.url": {"name": "url", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.url", "block_contents": "The URL of the BI tool where the data defined by the exposure can be viewed."}, "doc.dbt_artifacts.identifier": {"name": "identifier", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.identifier", "block_contents": "Source identifier."}, "doc.dbt_artifacts.source_name": {"name": "source_name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.source_name", "block_contents": "Source name."}, "doc.dbt_artifacts.test_path": {"name": "test_path", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.test_path", "block_contents": "Path to the yaml (SQL in case of a singular test) file describing the test."}, "doc.dbt_artifacts.tags": {"name": "tags", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.tags", "block_contents": "Tags used in resource selection associated with the node."}, "doc.dbt_artifacts.strategy": {"name": "strategy", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.strategy", "block_contents": "Snapshot \"strategies\" define how dbt knows if a row has changed. There are two strategies built-in to dbt \u2014 timestamp\nand check."}, "doc.dbt_artifacts.failures": {"name": "failures", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.failures", "block_contents": "Test failures. Value is 1 if the test failed, 0 if successful."}, "doc.dbt_artifacts.loaded_at_field": {"name": "loaded_at_field", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.loaded_at_field", "block_contents": "A column name (or expression) that returns a timestamp indicating freshness."}, "doc.dbt_artifacts.type": {"name": "type", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.type", "block_contents": "Exposure type; one of dashboard, notebook, analysis, ml, application (used to organize on docs site)"}, "doc.dbt_artifacts.description": {"name": "description", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.description", "block_contents": "Node description."}, "doc.dbt_artifacts.maturity": {"name": "maturity", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.maturity", "block_contents": "Exposure maturity; one of high, medium, low."}, "doc.dbt_artifacts.owner": {"name": "owner", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.owner", "block_contents": "Owner of the exposure, usually an email address."}, "doc.dbt_artifacts.source_execution_id": {"name": "source_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.source_execution_id", "block_contents": "Execution ID of the source node."}, "doc.dbt_artifacts.exposure_execution_id": {"name": "exposure_execution_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.exposure_execution_id", "block_contents": "Execution ID of the exposure node."}, "doc.dbt_artifacts.dbt_version": {"name": "dbt_version", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_version", "block_contents": "Installed version of dbt that is currently running."}, "doc.dbt_artifacts.project_name": {"name": "project_name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.project_name", "block_contents": "Name for the root-level project which is being run by dbt."}, "doc.dbt_artifacts.run_started_at": {"name": "run_started_at", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.run_started_at", "block_contents": "The start timestamp of the dbt execution which generated the record."}, "doc.dbt_artifacts.dbt_command": {"name": "dbt_command", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_command", "block_contents": "dbt command of this run."}, "doc.dbt_artifacts.full_refresh_flag": {"name": "full_refresh_flag", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.full_refresh_flag", "block_contents": "Boolean flag indicating whether the dbt run was in full refresh mode or not."}, "doc.dbt_artifacts.target_profile_name": {"name": "target_profile_name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.target_profile_name", "block_contents": "The name of the active profile."}, "doc.dbt_artifacts.target_name": {"name": "target_name", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.target_name", "block_contents": "The name of the active target."}, "doc.dbt_artifacts.target_schema": {"name": "target_schema", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.target_schema", "block_contents": "The name of the target dbt schema."}, "doc.dbt_artifacts.target_threads": {"name": "target_threads", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.target_threads", "block_contents": "The number of threads in use by dbt."}, "doc.dbt_artifacts.dbt_cloud_project_id": {"name": "dbt_cloud_project_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_cloud_project_id", "block_contents": "The ID of the dbt Cloud Project for this run."}, "doc.dbt_artifacts.dbt_cloud_job_id": {"name": "dbt_cloud_job_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_cloud_job_id", "block_contents": "The ID of the dbt Cloud Job for this run."}, "doc.dbt_artifacts.dbt_cloud_run_id": {"name": "dbt_cloud_run_id", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_cloud_run_id", "block_contents": "The ID of this particular run."}, "doc.dbt_artifacts.dbt_cloud_run_reason_category": {"name": "dbt_cloud_run_reason_category", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_cloud_run_reason_category", "block_contents": "The \"category\" of the trigger for this run."}, "doc.dbt_artifacts.dbt_cloud_run_reason": {"name": "dbt_cloud_run_reason", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_cloud_run_reason", "block_contents": "The specific trigger for this run."}, "doc.dbt_artifacts.env_vars": {"name": "env_vars", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.env_vars", "block_contents": "Key-value pairs of environment variables to be capture."}, "doc.dbt_artifacts.dbt_vars": {"name": "dbt_vars", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_vars", "block_contents": "Key-value pairs of project variables to be capture."}, "doc.dbt_artifacts.last_full_refresh_run_completed_at": {"name": "last_full_refresh_run_completed_at", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_full_refresh_run_completed_at", "block_contents": "Timestamp when the node's SQL query completed on the last full (non-incremental) run."}, "doc.dbt_artifacts.last_full_refresh_run_rows_affected": {"name": "last_full_refresh_run_rows_affected", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_full_refresh_run_rows_affected", "block_contents": "Number of rows affected by the node's last full (non-incremental) run."}, "doc.dbt_artifacts.last_full_refresh_run_bytes_processed": {"name": "last_full_refresh_run_bytes_processed", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_full_refresh_run_bytes_processed", "block_contents": "Number of bytes processed by the node's last full (non-incremental) run."}, "doc.dbt_artifacts.last_full_refresh_run_total_runtime": {"name": "last_full_refresh_run_total_runtime", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_full_refresh_run_total_runtime", "block_contents": "Total time spent executing the node's last full (non-incremental) run (seconds)."}, "doc.dbt_artifacts.last_run_completed_at": {"name": "last_run_completed_at", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_run_completed_at", "block_contents": "Timestamp when the node's SQL query completed on the last run."}, "doc.dbt_artifacts.last_run_rows_affected": {"name": "last_run_rows_affected", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_run_rows_affected", "block_contents": "Number of rows affected by the node's last run."}, "doc.dbt_artifacts.last_run_bytes_processed": {"name": "last_run_bytes_processed", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_run_bytes_processed", "block_contents": "Number of bytes processed by the node's last run."}, "doc.dbt_artifacts.last_run_total_runtime": {"name": "last_run_total_runtime", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.last_run_total_runtime", "block_contents": "Total time spent executing the node's last run (seconds)."}, "doc.dbt_artifacts.meta": {"name": "meta", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.meta", "block_contents": "The meta field of the config associated with the node."}, "doc.dbt_artifacts.invocation_args": {"name": "invocation_args", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.invocation_args", "block_contents": "Key-value pairs of args passed to invocation."}, "doc.dbt_artifacts.dbt_custom_envs": {"name": "dbt_custom_envs", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.dbt_custom_envs", "block_contents": "Key-value pairs of environment variables passed to invocation that have the prefix DBT_ENV_CUSTOM_ENV_"}, "doc.dbt_artifacts.alias": {"name": "alias", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.alias", "block_contents": "Alias of the node."}, "doc.dbt_artifacts.message": {"name": "message", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.message", "block_contents": "Result report, based on information returned from the database"}, "doc.dbt_artifacts.adapter_response": {"name": "adapter_response", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.adapter_response", "block_contents": "Response provided by the adapter as JSON."}, "doc.dbt_artifacts.all_results": {"name": "all_results", "resource_type": "doc", "package_name": "dbt_artifacts", "path": "docs.md", "original_file_path": "models/docs.md", "unique_id": "doc.dbt_artifacts.all_results", "block_contents": "All results as a JSON blob"}}, "exposures": {}, "metrics": {}, "groups": {}, "selectors": {}, "disabled": {}, "parent_map": {"model.dbt_dbx.silver_orders": ["model.dbt_dbx.bronze_orders"], "model.dbt_dbx.silver_products": ["model.dbt_dbx.bronze_products"], "model.dbt_dbx.silver_users": ["model.dbt_dbx.bronze_users"], "model.dbt_dbx.bronze_reviews": ["source.dbt_dbx.landing_s.reviews"], "model.dbt_dbx.bronze_orders": ["source.dbt_dbx.landing_s.orders"], "model.dbt_dbx.bronze_users": ["source.dbt_dbx.landing_s.users"], "model.dbt_dbx.bronze_products": ["source.dbt_dbx.landing_s.products"], "operation.dbt_dbx.dbt_dbx-on-run-end-0": [], "model.dbt_artifacts.dim_dbt__sources": ["model.dbt_artifacts.stg_dbt__sources"], "model.dbt_artifacts.dim_dbt__tests": ["model.dbt_artifacts.stg_dbt__tests"], "model.dbt_artifacts.fct_dbt__seed_executions": ["model.dbt_artifacts.stg_dbt__seed_executions"], "model.dbt_artifacts.fct_dbt__test_executions": ["model.dbt_artifacts.stg_dbt__test_executions"], "model.dbt_artifacts.dim_dbt__current_models": ["model.dbt_artifacts.stg_dbt__model_executions", "model.dbt_artifacts.stg_dbt__models"], "model.dbt_artifacts.dim_dbt__snapshots": ["model.dbt_artifacts.stg_dbt__snapshots"], "model.dbt_artifacts.fct_dbt__snapshot_executions": ["model.dbt_artifacts.stg_dbt__snapshot_executions"], "model.dbt_artifacts.dim_dbt__models": ["model.dbt_artifacts.stg_dbt__models"], "model.dbt_artifacts.fct_dbt__model_executions": ["model.dbt_artifacts.stg_dbt__model_executions"], "model.dbt_artifacts.fct_dbt__invocations": ["model.dbt_artifacts.stg_dbt__invocations"], "model.dbt_artifacts.dim_dbt__seeds": ["model.dbt_artifacts.stg_dbt__seeds"], "model.dbt_artifacts.dim_dbt__exposures": ["model.dbt_artifacts.stg_dbt__exposures"], "model.dbt_artifacts.stg_dbt__seed_executions": ["model.dbt_artifacts.seed_executions"], "model.dbt_artifacts.stg_dbt__snapshots": ["model.dbt_artifacts.snapshots"], "model.dbt_artifacts.stg_dbt__seeds": ["model.dbt_artifacts.seeds"], "model.dbt_artifacts.stg_dbt__invocations": ["model.dbt_artifacts.invocations"], "model.dbt_artifacts.stg_dbt__test_executions": ["model.dbt_artifacts.test_executions"], "model.dbt_artifacts.stg_dbt__snapshot_executions": ["model.dbt_artifacts.snapshot_executions"], "model.dbt_artifacts.stg_dbt__exposures": ["model.dbt_artifacts.exposures"], "model.dbt_artifacts.stg_dbt__models": ["model.dbt_artifacts.models"], "model.dbt_artifacts.stg_dbt__model_executions": ["model.dbt_artifacts.model_executions"], "model.dbt_artifacts.stg_dbt__sources": ["model.dbt_artifacts.sources"], "model.dbt_artifacts.stg_dbt__tests": ["model.dbt_artifacts.tests"], "model.dbt_artifacts.seed_executions": [], "model.dbt_artifacts.test_executions": [], "model.dbt_artifacts.model_executions": [], "model.dbt_artifacts.sources": [], "model.dbt_artifacts.exposures": [], "model.dbt_artifacts.seeds": [], "model.dbt_artifacts.invocations": [], "model.dbt_artifacts.tests": [], "model.dbt_artifacts.snapshots": [], "model.dbt_artifacts.snapshot_executions": [], "model.dbt_artifacts.models": [], "source.dbt_dbx.landing_s.orders": [], "source.dbt_dbx.landing_s.users": [], "source.dbt_dbx.landing_s.products": [], "source.dbt_dbx.landing_s.reviews": []}, "child_map": {"model.dbt_dbx.silver_orders": [], "model.dbt_dbx.silver_products": [], "model.dbt_dbx.silver_users": [], "model.dbt_dbx.bronze_reviews": [], "model.dbt_dbx.bronze_orders": ["model.dbt_dbx.silver_orders"], "model.dbt_dbx.bronze_users": ["model.dbt_dbx.silver_users"], "model.dbt_dbx.bronze_products": ["model.dbt_dbx.silver_products"], "operation.dbt_dbx.dbt_dbx-on-run-end-0": [], "model.dbt_artifacts.dim_dbt__sources": [], "model.dbt_artifacts.dim_dbt__tests": [], "model.dbt_artifacts.fct_dbt__seed_executions": [], "model.dbt_artifacts.fct_dbt__test_executions": [], "model.dbt_artifacts.dim_dbt__current_models": [], "model.dbt_artifacts.dim_dbt__snapshots": [], "model.dbt_artifacts.fct_dbt__snapshot_executions": [], "model.dbt_artifacts.dim_dbt__models": [], "model.dbt_artifacts.fct_dbt__model_executions": [], "model.dbt_artifacts.fct_dbt__invocations": [], "model.dbt_artifacts.dim_dbt__seeds": [], "model.dbt_artifacts.dim_dbt__exposures": [], "model.dbt_artifacts.stg_dbt__seed_executions": ["model.dbt_artifacts.fct_dbt__seed_executions"], "model.dbt_artifacts.stg_dbt__snapshots": ["model.dbt_artifacts.dim_dbt__snapshots"], "model.dbt_artifacts.stg_dbt__seeds": ["model.dbt_artifacts.dim_dbt__seeds"], "model.dbt_artifacts.stg_dbt__invocations": ["model.dbt_artifacts.fct_dbt__invocations"], "model.dbt_artifacts.stg_dbt__test_executions": ["model.dbt_artifacts.fct_dbt__test_executions"], "model.dbt_artifacts.stg_dbt__snapshot_executions": ["model.dbt_artifacts.fct_dbt__snapshot_executions"], "model.dbt_artifacts.stg_dbt__exposures": ["model.dbt_artifacts.dim_dbt__exposures"], "model.dbt_artifacts.stg_dbt__models": ["model.dbt_artifacts.dim_dbt__current_models", "model.dbt_artifacts.dim_dbt__models"], "model.dbt_artifacts.stg_dbt__model_executions": ["model.dbt_artifacts.dim_dbt__current_models", "model.dbt_artifacts.fct_dbt__model_executions"], "model.dbt_artifacts.stg_dbt__sources": ["model.dbt_artifacts.dim_dbt__sources"], "model.dbt_artifacts.stg_dbt__tests": ["model.dbt_artifacts.dim_dbt__tests"], "model.dbt_artifacts.seed_executions": ["model.dbt_artifacts.stg_dbt__seed_executions"], "model.dbt_artifacts.test_executions": ["model.dbt_artifacts.stg_dbt__test_executions"], "model.dbt_artifacts.model_executions": ["model.dbt_artifacts.stg_dbt__model_executions"], "model.dbt_artifacts.sources": ["model.dbt_artifacts.stg_dbt__sources"], "model.dbt_artifacts.exposures": ["model.dbt_artifacts.stg_dbt__exposures"], "model.dbt_artifacts.seeds": ["model.dbt_artifacts.stg_dbt__seeds"], "model.dbt_artifacts.invocations": ["model.dbt_artifacts.stg_dbt__invocations"], "model.dbt_artifacts.tests": ["model.dbt_artifacts.stg_dbt__tests"], "model.dbt_artifacts.snapshots": ["model.dbt_artifacts.stg_dbt__snapshots"], "model.dbt_artifacts.snapshot_executions": ["model.dbt_artifacts.stg_dbt__snapshot_executions"], "model.dbt_artifacts.models": ["model.dbt_artifacts.stg_dbt__models"], "source.dbt_dbx.landing_s.orders": ["model.dbt_dbx.bronze_orders"], "source.dbt_dbx.landing_s.users": ["model.dbt_dbx.bronze_users"], "source.dbt_dbx.landing_s.products": ["model.dbt_dbx.bronze_products"], "source.dbt_dbx.landing_s.reviews": ["model.dbt_dbx.bronze_reviews"]}, "group_map": {}, "saved_queries": {}, "semantic_models": {}, "unit_tests": {}}
\ No newline at end of file
diff --git a/dbt_dbx_guided/logs/dbt.log b/dbt_dbx_guided/logs/dbt.log
index 4e2c5df..fce80b7 100644
--- a/dbt_dbx_guided/logs/dbt.log
+++ b/dbt_dbx_guided/logs/dbt.log
@@ -367,3 +367,163 @@ KeyboardInterrupt
 [0m19:45:58.134531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ded4152fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ded4135cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ded41663f00>]}
 [0m19:45:58.134854 [debug] [MainThread]: Flushing usage events
 [0m19:45:58.887035 [debug] [MainThread]: An error was encountered while trying to flush usage events
+[0m16:11:55.819512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4f7094050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4f61bbed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4f61bb9d0>]}
+
+
+============================== 16:11:55.825468 | 272d7cdc-bbee-4eda-b094-38ee9aa4ffa5 ==============================
+[0m16:11:55.825468 [info ] [MainThread]: Running with dbt=1.10.13
+[0m16:11:55.826083 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'empty': 'None', 'static_parser': 'True', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'profiles_dir': '/home/kisaraf/.dbt', 'target_path': 'None', 'introspect': 'True', 'invocation_command': 'dbt debug', 'no_print': 'None', 'log_path': 'logs'}
+[0m16:11:55.851616 [info ] [MainThread]: dbt version: 1.10.13
+[0m16:11:55.852030 [info ] [MainThread]: python version: 3.13.7
+[0m16:11:55.852441 [info ] [MainThread]: python path: /home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/bin/python
+[0m16:11:55.852831 [info ] [MainThread]: os info: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.42
+[0m16:11:56.654252 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
+[0m16:11:56.654674 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
+[0m16:11:56.654995 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
+[0m16:11:57.575031 [info ] [MainThread]: Using profiles dir at /home/kisaraf/.dbt
+[0m16:11:57.575516 [info ] [MainThread]: Using profiles.yml file at /home/kisaraf/.dbt/profiles.yml
+[0m16:11:57.575842 [info ] [MainThread]: Using dbt_project.yml file at /home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/dbt_project.yml
+[0m16:11:57.576226 [info ] [MainThread]: adapter type: databricks
+[0m16:11:57.576592 [info ] [MainThread]: adapter version: 1.10.9
+[0m16:11:57.576932 [info ] [MainThread]: Configuration:
+[0m16:11:57.577225 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
+[0m16:11:57.577541 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
+[0m16:11:57.577840 [info ] [MainThread]: Required dependencies:
+[0m16:11:57.578176 [debug] [MainThread]: Executing "git --help"
+[0m16:11:57.581099 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
+[0m16:11:57.581489 [debug] [MainThread]: STDERR: "b''"
+[0m16:11:57.581750 [info ] [MainThread]:  - git [[32mOK found[0m]
+
+[0m16:11:57.582041 [info ] [MainThread]: Connection:
+[0m16:11:57.582348 [info ] [MainThread]:   host: adb-2381312836840869.9.azuredatabricks.net
+[0m16:11:57.582649 [info ] [MainThread]:   http_path: sql/protocolv1/o/2381312836840869/0926-075655-mfor5uhu
+[0m16:11:57.583086 [info ] [MainThread]:   catalog: dbt_project_catalog
+[0m16:11:57.583477 [info ] [MainThread]:   schema: dbt_kisara
+[0m16:11:57.583959 [info ] [MainThread]: Registered adapter: databricks=1.10.9
+[0m16:11:57.667708 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
+[0m16:11:57.668087 [debug] [MainThread]: Acquiring new databricks connection 'debug'
+[0m16:11:57.668402 [debug] [MainThread]: Using databricks connection "debug"
+[0m16:11:57.668692 [debug] [MainThread]: On debug: select 1 as id
+[0m16:11:57.668954 [debug] [MainThread]: Opening a new connection, currently in state init
+[0m16:12:07.758533 [error] [MainThread]: Encountered an error:
+
+[0m16:12:07.776538 [error] [MainThread]: Traceback (most recent call last):
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/cli/requires.py", line 178, in wrapper
+    result, success = func(*args, **kwargs)
+                      ~~~~^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/cli/requires.py", line 128, in wrapper
+    return func(*args, **kwargs)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/cli/main.py", line 420, in debug
+    results = task.run()
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/task/debug.py", line 144, in run
+    connection_status = self.test_connection()
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/task/debug.py", line 465, in test_connection
+    connection_result = self.attempt_connection(self.profile)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/task/debug.py", line 443, in attempt_connection
+    adapter.debug_query()
+    ~~~~~~~~~~~~~~~~~~~^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/spark/impl.py", line 519, in debug_query
+    self.execute("select 1 as id")
+    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/impl.py", line 329, in execute
+    return super().execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
+           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt_common/record.py", line 512, in record_replay_wrapper
+    return func_to_record(*call_args, **kwargs)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/base/impl.py", line 438, in execute
+    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
+           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/connections.py", line 297, in execute
+    _, cursor = self.add_query(sql, auto_begin)
+                ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/connections.py", line 270, in add_query
+    handle: DatabricksHandle = connection.handle
+                               ^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/contracts/connection.py", line 96, in handle
+    self._handle.resolve(self)
+    ~~~~~~~~~~~~~~~~~~~~^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/contracts/connection.py", line 120, in resolve
+    return self.opener(connection)
+           ~~~~~~~~~~~^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/connections.py", line 424, in open
+    return cls.retry_connection(
+           ~~~~~~~~~~~~~~~~~~~~^
+        connection,
+        ^^^^^^^^^^^
+    ...<4 lines>...
+        retry_timeout=(timeout if timeout is not None else exponential_backoff),
+        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+    )
+    ^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/base/connections.py", line 237, in retry_connection
+    connection.handle = connect()
+                        ~~~~~~~^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/connections.py", line 404, in connect
+    conn = DatabricksHandle.from_connection_args(
+        conn_args, creds.cluster_id is not None
+    )
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/dbt/adapters/databricks/handle.py", line 211, in from_connection_args
+    conn = dbsql.connect(**conn_args)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/__init__.py", line 90, in connect
+    return Connection(server_hostname, http_path, access_token, **kwargs)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/client.py", line 274, in __init__
+    self.session.open()
+    ~~~~~~~~~~~~~~~~~^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/session.py", line 132, in open
+    self._session_id = self.backend.open_session(
+                       ~~~~~~~~~~~~~~~~~~~~~~~~~^
+        session_configuration=self.session_configuration,
+        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+        catalog=self.catalog,
+        ^^^^^^^^^^^^^^^^^^^^^
+        schema=self.schema,
+        ^^^^^^^^^^^^^^^^^^^
+    )
+    ^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/backend/thrift_backend.py", line 601, in open_session
+    response = self.make_request(self._client.OpenSession, open_session_req)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/backend/thrift_backend.py", line 512, in make_request
+    response_or_error_info = attempt_request(attempt)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/backend/thrift_backend.py", line 417, in attempt_request
+    response = method(request)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/thrift_api/TCLIService/TCLIService.py", line 204, in OpenSession
+    self.send_OpenSession(req)
+    ~~~~~~~~~~~~~~~~~~~~~^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/thrift_api/TCLIService/TCLIService.py", line 213, in send_OpenSession
+    self._oprot.trans.flush()
+    ~~~~~~~~~~~~~~~~~~~~~~~^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/auth/thrift_http_client.py", line 193, in flush
+    self.__resp = self.__pool.request(
+                  ~~~~~~~~~~~~~~~~~~~^
+        "POST",
+        ^^^^^^^
+    ...<5 lines>...
+        retries=self.retry_policy,
+        ^^^^^^^^^^^^^^^^^^^^^^^^^^
+    )
+    ^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/urllib3/_request_methods.py", line 143, in request
+    return self.request_encode_body(
+           ~~~~~~~~~~~~~~~~~~~~~~~~^
+        method, url, fields=fields, headers=headers, **urlopen_kw
+        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+    )
+    ^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/urllib3/_request_methods.py", line 278, in request_encode_body
+    return self.urlopen(method, url, **extra_kw)
+           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 940, in urlopen
+    retries.sleep(response)
+    ~~~~~~~~~~~~~^^^^^^^^^^
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 359, in sleep
+    slept = self.sleep_for_retry(response)
+  File "/home/kisaraf/sandbox_dev/DBT_Projects/dbt_dbx_guided/.venv/lib64/python3.13/site-packages/databricks/sql/auth/retry.py", line 300, in sleep_for_retry
+    time.sleep(proposed_wait)
+    ~~~~~~~~~~^^^^^^^^^^^^^^^
+KeyboardInterrupt
+
+[0m16:12:07.778842 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 12.003262, "process_in_blocks": "278520", "process_kernel_time": 0.380905, "process_mem_max_rss": "236240", "process_out_blocks": "40", "process_user_time": 3.006725}
+[0m16:12:07.779423 [debug] [MainThread]: Command `dbt debug` failed at 16:12:07.779315 after 12.00 seconds
+[0m16:12:07.779800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d506b6f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d4e2ca70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d4d187c0>]}
+[0m16:12:07.780174 [debug] [MainThread]: Flushing usage events
+[0m16:12:08.584284 [debug] [MainThread]: An error was encountered while trying to flush usage events
diff --git a/fda-animal-adverse-events/pyproject.toml b/fda-animal-adverse-events/pyproject.toml
index 8b7aab7..c27e019 100644
--- a/fda-animal-adverse-events/pyproject.toml
+++ b/fda-animal-adverse-events/pyproject.toml
@@ -5,6 +5,9 @@ description = "Add your description here"
 readme = "README.md"
 requires-python = ">=3.9"
 dependencies = [
+    "databricks-sdk<0.16.0",
+    "dbt-core>=1.7.19",
+    "dbt-databricks==1.7.1",
     "duckdb>=1.4.2",
     "ipykernel>=6.31.0",
     "logging>=0.4.9.6",
diff --git a/fda-animal-adverse-events/uv.lock b/fda-animal-adverse-events/uv.lock
index 6451873..9d62da1 100644
--- a/fda-animal-adverse-events/uv.lock
+++ b/fda-animal-adverse-events/uv.lock
@@ -2,12 +2,82 @@ version = 1
 revision = 3
 requires-python = ">=3.9"
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
     "python_full_version < '3.10'",
 ]
 
+[[package]]
+name = "agate"
+version = "1.7.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "babel" },
+    { name = "isodate" },
+    { name = "leather" },
+    { name = "parsedatetime" },
+    { name = "python-slugify" },
+    { name = "pytimeparse" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/07/12/c95569f05a85164e14ba13f974dca942a75b727bedab3925f2a29e175589/agate-1.7.1.tar.gz", hash = "sha256:eadf46d980168b8922d5d396d6258eecd5e7dbef7e6f0c0b71e968545ea96389", size = 202018, upload-time = "2023-01-04T20:12:21.769Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/20/6e/bbebad0213fce2081902cf7565322b42a5a991c550857cfbb4741f69b8f6/agate-1.7.1-py2.py3-none-any.whl", hash = "sha256:23f9f412f74f97b72f82b1525ab235cc816bc8c8525d968a091576a0dbc54a5f", size = 97149, upload-time = "2023-01-04T20:12:20.268Z" },
+]
+
+[[package]]
+name = "alembic"
+version = "1.16.5"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+dependencies = [
+    { name = "mako", marker = "python_full_version < '3.10'" },
+    { name = "sqlalchemy", marker = "python_full_version < '3.10'" },
+    { name = "tomli", marker = "python_full_version < '3.10'" },
+    { name = "typing-extensions", marker = "python_full_version < '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/9a/ca/4dc52902cf3491892d464f5265a81e9dff094692c8a049a3ed6a05fe7ee8/alembic-1.16.5.tar.gz", hash = "sha256:a88bb7f6e513bd4301ecf4c7f2206fe93f9913f9b48dac3b78babde2d6fe765e", size = 1969868, upload-time = "2025-08-27T18:02:05.668Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/39/4a/4c61d4c84cfd9befb6fa08a702535b27b21fff08c946bc2f6139decbf7f7/alembic-1.16.5-py3-none-any.whl", hash = "sha256:e845dfe090c5ffa7b92593ae6687c5cb1a101e91fa53868497dbd79847f9dbe3", size = 247355, upload-time = "2025-08-27T18:02:07.37Z" },
+]
+
+[[package]]
+name = "alembic"
+version = "1.17.2"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+]
+dependencies = [
+    { name = "mako", marker = "python_full_version >= '3.10'" },
+    { name = "sqlalchemy", marker = "python_full_version >= '3.10'" },
+    { name = "tomli", marker = "python_full_version == '3.10.*'" },
+    { name = "typing-extensions", marker = "python_full_version >= '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/02/a6/74c8cadc2882977d80ad756a13857857dbcf9bd405bc80b662eb10651282/alembic-1.17.2.tar.gz", hash = "sha256:bbe9751705c5e0f14877f02d46c53d10885e377e3d90eda810a016f9baa19e8e", size = 1988064, upload-time = "2025-11-14T20:35:04.057Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/ba/88/6237e97e3385b57b5f1528647addea5cc03d4d65d5979ab24327d41fb00d/alembic-1.17.2-py3-none-any.whl", hash = "sha256:f483dd1fe93f6c5d49217055e4d15b905b425b6af906746abb35b69c1996c4e6", size = 248554, upload-time = "2025-11-14T20:35:05.699Z" },
+]
+
+[[package]]
+name = "annotated-types"
+version = "0.7.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081, upload-time = "2024-05-20T21:33:25.928Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643, upload-time = "2024-05-20T21:33:24.1Z" },
+]
+
 [[package]]
 name = "appnope"
 version = "0.1.4"
@@ -26,6 +96,42 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/d2/39/e7eaf1799466a4aef85b6a4fe7bd175ad2b1c6345066aa33f1f58d4b18d0/asttokens-3.0.1-py3-none-any.whl", hash = "sha256:15a3ebc0f43c2d0a50eeafea25e19046c68398e487b9f1f5b517f7c0f40f976a", size = 27047, upload-time = "2025-11-15T16:43:16.109Z" },
 ]
 
+[[package]]
+name = "attrs"
+version = "25.4.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/6b/5c/685e6633917e101e5dcb62b9dd76946cbb57c26e133bae9e0cd36033c0a9/attrs-25.4.0.tar.gz", hash = "sha256:16d5969b87f0859ef33a48b35d55ac1be6e42ae49d5e853b597db70c35c57e11", size = 934251, upload-time = "2025-10-06T13:54:44.725Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl", hash = "sha256:adcf7e2a1fb3b36ac48d97835bb6d8ade15b8dcce26aba8bf1d14847b57a3373", size = 67615, upload-time = "2025-10-06T13:54:43.17Z" },
+]
+
+[[package]]
+name = "babel"
+version = "2.17.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/7d/6b/d52e42361e1aa00709585ecc30b3f9684b3ab62530771402248b1b1d6240/babel-2.17.0.tar.gz", hash = "sha256:0c54cffb19f690cdcc52a3b50bcbf71e07a808d1c80d549f2459b9d2cf0afb9d", size = 9951852, upload-time = "2025-02-01T15:17:41.026Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b7/b8/3fe70c75fe32afc4bb507f75563d39bc5642255d1d94f1f23604725780bf/babel-2.17.0-py3-none-any.whl", hash = "sha256:4d0b53093fdfb4b21c92b5213dba5a1b23885afa8383709427046b21c366e5f2", size = 10182537, upload-time = "2025-02-01T15:17:37.39Z" },
+]
+
+[[package]]
+name = "backports-tarfile"
+version = "1.2.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/86/72/cd9b395f25e290e633655a100af28cb253e4393396264a98bd5f5951d50f/backports_tarfile-1.2.0.tar.gz", hash = "sha256:d75e02c268746e1b8144c278978b6e98e85de6ad16f8e4b0844a154557eca991", size = 86406, upload-time = "2024-05-28T17:01:54.731Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b9/fa/123043af240e49752f1c4bd24da5053b6bd00cad78c2be53c0d1e8b975bc/backports.tarfile-1.2.0-py3-none-any.whl", hash = "sha256:77e284d754527b01fb1e6fa8a1afe577858ebe4e9dad8919e34c862cb399bc34", size = 30181, upload-time = "2024-05-28T17:01:53.112Z" },
+]
+
+[[package]]
+name = "cachetools"
+version = "6.2.2"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/fb/44/ca1675be2a83aeee1886ab745b28cda92093066590233cc501890eb8417a/cachetools-6.2.2.tar.gz", hash = "sha256:8e6d266b25e539df852251cfd6f990b4bc3a141db73b939058d809ebd2590fc6", size = 31571, upload-time = "2025-11-13T17:42:51.465Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/e6/46/eb6eca305c77a4489affe1c5d8f4cae82f285d9addd8de4ec084a7184221/cachetools-6.2.2-py3-none-any.whl", hash = "sha256:6c09c98183bf58560c97b2abfcedcbaf6a896a490f534b031b661d3723b45ace", size = 11503, upload-time = "2025-11-13T17:42:50.232Z" },
+]
+
 [[package]]
 name = "certifi"
 version = "2025.11.12"
@@ -37,96 +143,71 @@ wheels = [
 
 [[package]]
 name = "cffi"
-version = "2.0.0"
+version = "1.17.1"
 source = { registry = "https://pypi.org/simple" }
 dependencies = [
-    { name = "pycparser", marker = "implementation_name != 'PyPy'" },
-]
-sdist = { url = "https://files.pythonhosted.org/packages/eb/56/b1ba7935a17738ae8453301356628e8147c79dbb825bcbc73dc7401f9846/cffi-2.0.0.tar.gz", hash = "sha256:44d1b5909021139fe36001ae048dbdde8214afa20200eda0f64c068cac5d5529", size = 523588, upload-time = "2025-09-08T23:24:04.541Z" }
-wheels = [
-    { url = "https://files.pythonhosted.org/packages/93/d7/516d984057745a6cd96575eea814fe1edd6646ee6efd552fb7b0921dec83/cffi-2.0.0-cp310-cp310-macosx_10_13_x86_64.whl", hash = "sha256:0cf2d91ecc3fcc0625c2c530fe004f82c110405f101548512cce44322fa8ac44", size = 184283, upload-time = "2025-09-08T23:22:08.01Z" },
-    { url = "https://files.pythonhosted.org/packages/9e/84/ad6a0b408daa859246f57c03efd28e5dd1b33c21737c2db84cae8c237aa5/cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:f73b96c41e3b2adedc34a7356e64c8eb96e03a3782b535e043a986276ce12a49", size = 180504, upload-time = "2025-09-08T23:22:10.637Z" },
-    { url = "https://files.pythonhosted.org/packages/50/bd/b1a6362b80628111e6653c961f987faa55262b4002fcec42308cad1db680/cffi-2.0.0-cp310-cp310-manylinux1_i686.manylinux2014_i686.manylinux_2_17_i686.manylinux_2_5_i686.whl", hash = "sha256:53f77cbe57044e88bbd5ed26ac1d0514d2acf0591dd6bb02a3ae37f76811b80c", size = 208811, upload-time = "2025-09-08T23:22:12.267Z" },
-    { url = "https://files.pythonhosted.org/packages/4f/27/6933a8b2562d7bd1fb595074cf99cc81fc3789f6a6c05cdabb46284a3188/cffi-2.0.0-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:3e837e369566884707ddaf85fc1744b47575005c0a229de3327f8f9a20f4efeb", size = 216402, upload-time = "2025-09-08T23:22:13.455Z" },
-    { url = "https://files.pythonhosted.org/packages/05/eb/b86f2a2645b62adcfff53b0dd97e8dfafb5c8aa864bd0d9a2c2049a0d551/cffi-2.0.0-cp310-cp310-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:5eda85d6d1879e692d546a078b44251cdd08dd1cfb98dfb77b670c97cee49ea0", size = 203217, upload-time = "2025-09-08T23:22:14.596Z" },
-    { url = "https://files.pythonhosted.org/packages/9f/e0/6cbe77a53acf5acc7c08cc186c9928864bd7c005f9efd0d126884858a5fe/cffi-2.0.0-cp310-cp310-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:9332088d75dc3241c702d852d4671613136d90fa6881da7d770a483fd05248b4", size = 203079, upload-time = "2025-09-08T23:22:15.769Z" },
-    { url = "https://files.pythonhosted.org/packages/98/29/9b366e70e243eb3d14a5cb488dfd3a0b6b2f1fb001a203f653b93ccfac88/cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:fc7de24befaeae77ba923797c7c87834c73648a05a4bde34b3b7e5588973a453", size = 216475, upload-time = "2025-09-08T23:22:17.427Z" },
-    { url = "https://files.pythonhosted.org/packages/21/7a/13b24e70d2f90a322f2900c5d8e1f14fa7e2a6b3332b7309ba7b2ba51a5a/cffi-2.0.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:cf364028c016c03078a23b503f02058f1814320a56ad535686f90565636a9495", size = 218829, upload-time = "2025-09-08T23:22:19.069Z" },
-    { url = "https://files.pythonhosted.org/packages/60/99/c9dc110974c59cc981b1f5b66e1d8af8af764e00f0293266824d9c4254bc/cffi-2.0.0-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:e11e82b744887154b182fd3e7e8512418446501191994dbf9c9fc1f32cc8efd5", size = 211211, upload-time = "2025-09-08T23:22:20.588Z" },
-    { url = "https://files.pythonhosted.org/packages/49/72/ff2d12dbf21aca1b32a40ed792ee6b40f6dc3a9cf1644bd7ef6e95e0ac5e/cffi-2.0.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:8ea985900c5c95ce9db1745f7933eeef5d314f0565b27625d9a10ec9881e1bfb", size = 218036, upload-time = "2025-09-08T23:22:22.143Z" },
-    { url = "https://files.pythonhosted.org/packages/e2/cc/027d7fb82e58c48ea717149b03bcadcbdc293553edb283af792bd4bcbb3f/cffi-2.0.0-cp310-cp310-win32.whl", hash = "sha256:1f72fb8906754ac8a2cc3f9f5aaa298070652a0ffae577e0ea9bd480dc3c931a", size = 172184, upload-time = "2025-09-08T23:22:23.328Z" },
-    { url = "https://files.pythonhosted.org/packages/33/fa/072dd15ae27fbb4e06b437eb6e944e75b068deb09e2a2826039e49ee2045/cffi-2.0.0-cp310-cp310-win_amd64.whl", hash = "sha256:b18a3ed7d5b3bd8d9ef7a8cb226502c6bf8308df1525e1cc676c3680e7176739", size = 182790, upload-time = "2025-09-08T23:22:24.752Z" },
-    { url = "https://files.pythonhosted.org/packages/12/4a/3dfd5f7850cbf0d06dc84ba9aa00db766b52ca38d8b86e3a38314d52498c/cffi-2.0.0-cp311-cp311-macosx_10_13_x86_64.whl", hash = "sha256:b4c854ef3adc177950a8dfc81a86f5115d2abd545751a304c5bcf2c2c7283cfe", size = 184344, upload-time = "2025-09-08T23:22:26.456Z" },
-    { url = "https://files.pythonhosted.org/packages/4f/8b/f0e4c441227ba756aafbe78f117485b25bb26b1c059d01f137fa6d14896b/cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:2de9a304e27f7596cd03d16f1b7c72219bd944e99cc52b84d0145aefb07cbd3c", size = 180560, upload-time = "2025-09-08T23:22:28.197Z" },
-    { url = "https://files.pythonhosted.org/packages/b1/b7/1200d354378ef52ec227395d95c2576330fd22a869f7a70e88e1447eb234/cffi-2.0.0-cp311-cp311-manylinux1_i686.manylinux2014_i686.manylinux_2_17_i686.manylinux_2_5_i686.whl", hash = "sha256:baf5215e0ab74c16e2dd324e8ec067ef59e41125d3eade2b863d294fd5035c92", size = 209613, upload-time = "2025-09-08T23:22:29.475Z" },
-    { url = "https://files.pythonhosted.org/packages/b8/56/6033f5e86e8cc9bb629f0077ba71679508bdf54a9a5e112a3c0b91870332/cffi-2.0.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:730cacb21e1bdff3ce90babf007d0a0917cc3e6492f336c2f0134101e0944f93", size = 216476, upload-time = "2025-09-08T23:22:31.063Z" },
-    { url = "https://files.pythonhosted.org/packages/dc/7f/55fecd70f7ece178db2f26128ec41430d8720f2d12ca97bf8f0a628207d5/cffi-2.0.0-cp311-cp311-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:6824f87845e3396029f3820c206e459ccc91760e8fa24422f8b0c3d1731cbec5", size = 203374, upload-time = "2025-09-08T23:22:32.507Z" },
-    { url = "https://files.pythonhosted.org/packages/84/ef/a7b77c8bdc0f77adc3b46888f1ad54be8f3b7821697a7b89126e829e676a/cffi-2.0.0-cp311-cp311-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:9de40a7b0323d889cf8d23d1ef214f565ab154443c42737dfe52ff82cf857664", size = 202597, upload-time = "2025-09-08T23:22:34.132Z" },
-    { url = "https://files.pythonhosted.org/packages/d7/91/500d892b2bf36529a75b77958edfcd5ad8e2ce4064ce2ecfeab2125d72d1/cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:8941aaadaf67246224cee8c3803777eed332a19d909b47e29c9842ef1e79ac26", size = 215574, upload-time = "2025-09-08T23:22:35.443Z" },
-    { url = "https://files.pythonhosted.org/packages/44/64/58f6255b62b101093d5df22dcb752596066c7e89dd725e0afaed242a61be/cffi-2.0.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:a05d0c237b3349096d3981b727493e22147f934b20f6f125a3eba8f994bec4a9", size = 218971, upload-time = "2025-09-08T23:22:36.805Z" },
-    { url = "https://files.pythonhosted.org/packages/ab/49/fa72cebe2fd8a55fbe14956f9970fe8eb1ac59e5df042f603ef7c8ba0adc/cffi-2.0.0-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:94698a9c5f91f9d138526b48fe26a199609544591f859c870d477351dc7b2414", size = 211972, upload-time = "2025-09-08T23:22:38.436Z" },
-    { url = "https://files.pythonhosted.org/packages/0b/28/dd0967a76aab36731b6ebfe64dec4e981aff7e0608f60c2d46b46982607d/cffi-2.0.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:5fed36fccc0612a53f1d4d9a816b50a36702c28a2aa880cb8a122b3466638743", size = 217078, upload-time = "2025-09-08T23:22:39.776Z" },
-    { url = "https://files.pythonhosted.org/packages/2b/c0/015b25184413d7ab0a410775fdb4a50fca20f5589b5dab1dbbfa3baad8ce/cffi-2.0.0-cp311-cp311-win32.whl", hash = "sha256:c649e3a33450ec82378822b3dad03cc228b8f5963c0c12fc3b1e0ab940f768a5", size = 172076, upload-time = "2025-09-08T23:22:40.95Z" },
-    { url = "https://files.pythonhosted.org/packages/ae/8f/dc5531155e7070361eb1b7e4c1a9d896d0cb21c49f807a6c03fd63fc877e/cffi-2.0.0-cp311-cp311-win_amd64.whl", hash = "sha256:66f011380d0e49ed280c789fbd08ff0d40968ee7b665575489afa95c98196ab5", size = 182820, upload-time = "2025-09-08T23:22:42.463Z" },
-    { url = "https://files.pythonhosted.org/packages/95/5c/1b493356429f9aecfd56bc171285a4c4ac8697f76e9bbbbb105e537853a1/cffi-2.0.0-cp311-cp311-win_arm64.whl", hash = "sha256:c6638687455baf640e37344fe26d37c404db8b80d037c3d29f58fe8d1c3b194d", size = 177635, upload-time = "2025-09-08T23:22:43.623Z" },
-    { url = "https://files.pythonhosted.org/packages/ea/47/4f61023ea636104d4f16ab488e268b93008c3d0bb76893b1b31db1f96802/cffi-2.0.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:6d02d6655b0e54f54c4ef0b94eb6be0607b70853c45ce98bd278dc7de718be5d", size = 185271, upload-time = "2025-09-08T23:22:44.795Z" },
-    { url = "https://files.pythonhosted.org/packages/df/a2/781b623f57358e360d62cdd7a8c681f074a71d445418a776eef0aadb4ab4/cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8eca2a813c1cb7ad4fb74d368c2ffbbb4789d377ee5bb8df98373c2cc0dee76c", size = 181048, upload-time = "2025-09-08T23:22:45.938Z" },
-    { url = "https://files.pythonhosted.org/packages/ff/df/a4f0fbd47331ceeba3d37c2e51e9dfc9722498becbeec2bd8bc856c9538a/cffi-2.0.0-cp312-cp312-manylinux1_i686.manylinux2014_i686.manylinux_2_17_i686.manylinux_2_5_i686.whl", hash = "sha256:21d1152871b019407d8ac3985f6775c079416c282e431a4da6afe7aefd2bccbe", size = 212529, upload-time = "2025-09-08T23:22:47.349Z" },
-    { url = "https://files.pythonhosted.org/packages/d5/72/12b5f8d3865bf0f87cf1404d8c374e7487dcf097a1c91c436e72e6badd83/cffi-2.0.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:b21e08af67b8a103c71a250401c78d5e0893beff75e28c53c98f4de42f774062", size = 220097, upload-time = "2025-09-08T23:22:48.677Z" },
-    { url = "https://files.pythonhosted.org/packages/c2/95/7a135d52a50dfa7c882ab0ac17e8dc11cec9d55d2c18dda414c051c5e69e/cffi-2.0.0-cp312-cp312-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:1e3a615586f05fc4065a8b22b8152f0c1b00cdbc60596d187c2a74f9e3036e4e", size = 207983, upload-time = "2025-09-08T23:22:50.06Z" },
-    { url = "https://files.pythonhosted.org/packages/3a/c8/15cb9ada8895957ea171c62dc78ff3e99159ee7adb13c0123c001a2546c1/cffi-2.0.0-cp312-cp312-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:81afed14892743bbe14dacb9e36d9e0e504cd204e0b165062c488942b9718037", size = 206519, upload-time = "2025-09-08T23:22:51.364Z" },
-    { url = "https://files.pythonhosted.org/packages/78/2d/7fa73dfa841b5ac06c7b8855cfc18622132e365f5b81d02230333ff26e9e/cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:3e17ed538242334bf70832644a32a7aae3d83b57567f9fd60a26257e992b79ba", size = 219572, upload-time = "2025-09-08T23:22:52.902Z" },
-    { url = "https://files.pythonhosted.org/packages/07/e0/267e57e387b4ca276b90f0434ff88b2c2241ad72b16d31836adddfd6031b/cffi-2.0.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:3925dd22fa2b7699ed2617149842d2e6adde22b262fcbfada50e3d195e4b3a94", size = 222963, upload-time = "2025-09-08T23:22:54.518Z" },
-    { url = "https://files.pythonhosted.org/packages/b6/75/1f2747525e06f53efbd878f4d03bac5b859cbc11c633d0fb81432d98a795/cffi-2.0.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:2c8f814d84194c9ea681642fd164267891702542f028a15fc97d4674b6206187", size = 221361, upload-time = "2025-09-08T23:22:55.867Z" },
-    { url = "https://files.pythonhosted.org/packages/7b/2b/2b6435f76bfeb6bbf055596976da087377ede68df465419d192acf00c437/cffi-2.0.0-cp312-cp312-win32.whl", hash = "sha256:da902562c3e9c550df360bfa53c035b2f241fed6d9aef119048073680ace4a18", size = 172932, upload-time = "2025-09-08T23:22:57.188Z" },
-    { url = "https://files.pythonhosted.org/packages/f8/ed/13bd4418627013bec4ed6e54283b1959cf6db888048c7cf4b4c3b5b36002/cffi-2.0.0-cp312-cp312-win_amd64.whl", hash = "sha256:da68248800ad6320861f129cd9c1bf96ca849a2771a59e0344e88681905916f5", size = 183557, upload-time = "2025-09-08T23:22:58.351Z" },
-    { url = "https://files.pythonhosted.org/packages/95/31/9f7f93ad2f8eff1dbc1c3656d7ca5bfd8fb52c9d786b4dcf19b2d02217fa/cffi-2.0.0-cp312-cp312-win_arm64.whl", hash = "sha256:4671d9dd5ec934cb9a73e7ee9676f9362aba54f7f34910956b84d727b0d73fb6", size = 177762, upload-time = "2025-09-08T23:22:59.668Z" },
-    { url = "https://files.pythonhosted.org/packages/4b/8d/a0a47a0c9e413a658623d014e91e74a50cdd2c423f7ccfd44086ef767f90/cffi-2.0.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:00bdf7acc5f795150faa6957054fbbca2439db2f775ce831222b66f192f03beb", size = 185230, upload-time = "2025-09-08T23:23:00.879Z" },
-    { url = "https://files.pythonhosted.org/packages/4a/d2/a6c0296814556c68ee32009d9c2ad4f85f2707cdecfd7727951ec228005d/cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:45d5e886156860dc35862657e1494b9bae8dfa63bf56796f2fb56e1679fc0bca", size = 181043, upload-time = "2025-09-08T23:23:02.231Z" },
-    { url = "https://files.pythonhosted.org/packages/b0/1e/d22cc63332bd59b06481ceaac49d6c507598642e2230f201649058a7e704/cffi-2.0.0-cp313-cp313-manylinux1_i686.manylinux2014_i686.manylinux_2_17_i686.manylinux_2_5_i686.whl", hash = "sha256:07b271772c100085dd28b74fa0cd81c8fb1a3ba18b21e03d7c27f3436a10606b", size = 212446, upload-time = "2025-09-08T23:23:03.472Z" },
-    { url = "https://files.pythonhosted.org/packages/a9/f5/a2c23eb03b61a0b8747f211eb716446c826ad66818ddc7810cc2cc19b3f2/cffi-2.0.0-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:d48a880098c96020b02d5a1f7d9251308510ce8858940e6fa99ece33f610838b", size = 220101, upload-time = "2025-09-08T23:23:04.792Z" },
-    { url = "https://files.pythonhosted.org/packages/f2/7f/e6647792fc5850d634695bc0e6ab4111ae88e89981d35ac269956605feba/cffi-2.0.0-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:f93fd8e5c8c0a4aa1f424d6173f14a892044054871c771f8566e4008eaa359d2", size = 207948, upload-time = "2025-09-08T23:23:06.127Z" },
-    { url = "https://files.pythonhosted.org/packages/cb/1e/a5a1bd6f1fb30f22573f76533de12a00bf274abcdc55c8edab639078abb6/cffi-2.0.0-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:dd4f05f54a52fb558f1ba9f528228066954fee3ebe629fc1660d874d040ae5a3", size = 206422, upload-time = "2025-09-08T23:23:07.753Z" },
-    { url = "https://files.pythonhosted.org/packages/98/df/0a1755e750013a2081e863e7cd37e0cdd02664372c754e5560099eb7aa44/cffi-2.0.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:c8d3b5532fc71b7a77c09192b4a5a200ea992702734a2e9279a37f2478236f26", size = 219499, upload-time = "2025-09-08T23:23:09.648Z" },
-    { url = "https://files.pythonhosted.org/packages/50/e1/a969e687fcf9ea58e6e2a928ad5e2dd88cc12f6f0ab477e9971f2309b57c/cffi-2.0.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:d9b29c1f0ae438d5ee9acb31cadee00a58c46cc9c0b2f9038c6b0b3470877a8c", size = 222928, upload-time = "2025-09-08T23:23:10.928Z" },
-    { url = "https://files.pythonhosted.org/packages/36/54/0362578dd2c9e557a28ac77698ed67323ed5b9775ca9d3fe73fe191bb5d8/cffi-2.0.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:6d50360be4546678fc1b79ffe7a66265e28667840010348dd69a314145807a1b", size = 221302, upload-time = "2025-09-08T23:23:12.42Z" },
-    { url = "https://files.pythonhosted.org/packages/eb/6d/bf9bda840d5f1dfdbf0feca87fbdb64a918a69bca42cfa0ba7b137c48cb8/cffi-2.0.0-cp313-cp313-win32.whl", hash = "sha256:74a03b9698e198d47562765773b4a8309919089150a0bb17d829ad7b44b60d27", size = 172909, upload-time = "2025-09-08T23:23:14.32Z" },
-    { url = "https://files.pythonhosted.org/packages/37/18/6519e1ee6f5a1e579e04b9ddb6f1676c17368a7aba48299c3759bbc3c8b3/cffi-2.0.0-cp313-cp313-win_amd64.whl", hash = "sha256:19f705ada2530c1167abacb171925dd886168931e0a7b78f5bffcae5c6b5be75", size = 183402, upload-time = "2025-09-08T23:23:15.535Z" },
-    { url = "https://files.pythonhosted.org/packages/cb/0e/02ceeec9a7d6ee63bb596121c2c8e9b3a9e150936f4fbef6ca1943e6137c/cffi-2.0.0-cp313-cp313-win_arm64.whl", hash = "sha256:256f80b80ca3853f90c21b23ee78cd008713787b1b1e93eae9f3d6a7134abd91", size = 177780, upload-time = "2025-09-08T23:23:16.761Z" },
-    { url = "https://files.pythonhosted.org/packages/92/c4/3ce07396253a83250ee98564f8d7e9789fab8e58858f35d07a9a2c78de9f/cffi-2.0.0-cp314-cp314-macosx_10_13_x86_64.whl", hash = "sha256:fc33c5141b55ed366cfaad382df24fe7dcbc686de5be719b207bb248e3053dc5", size = 185320, upload-time = "2025-09-08T23:23:18.087Z" },
-    { url = "https://files.pythonhosted.org/packages/59/dd/27e9fa567a23931c838c6b02d0764611c62290062a6d4e8ff7863daf9730/cffi-2.0.0-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:c654de545946e0db659b3400168c9ad31b5d29593291482c43e3564effbcee13", size = 181487, upload-time = "2025-09-08T23:23:19.622Z" },
-    { url = "https://files.pythonhosted.org/packages/d6/43/0e822876f87ea8a4ef95442c3d766a06a51fc5298823f884ef87aaad168c/cffi-2.0.0-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:24b6f81f1983e6df8db3adc38562c83f7d4a0c36162885ec7f7b77c7dcbec97b", size = 220049, upload-time = "2025-09-08T23:23:20.853Z" },
-    { url = "https://files.pythonhosted.org/packages/b4/89/76799151d9c2d2d1ead63c2429da9ea9d7aac304603de0c6e8764e6e8e70/cffi-2.0.0-cp314-cp314-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:12873ca6cb9b0f0d3a0da705d6086fe911591737a59f28b7936bdfed27c0d47c", size = 207793, upload-time = "2025-09-08T23:23:22.08Z" },
-    { url = "https://files.pythonhosted.org/packages/bb/dd/3465b14bb9e24ee24cb88c9e3730f6de63111fffe513492bf8c808a3547e/cffi-2.0.0-cp314-cp314-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:d9b97165e8aed9272a6bb17c01e3cc5871a594a446ebedc996e2397a1c1ea8ef", size = 206300, upload-time = "2025-09-08T23:23:23.314Z" },
-    { url = "https://files.pythonhosted.org/packages/47/d9/d83e293854571c877a92da46fdec39158f8d7e68da75bf73581225d28e90/cffi-2.0.0-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:afb8db5439b81cf9c9d0c80404b60c3cc9c3add93e114dcae767f1477cb53775", size = 219244, upload-time = "2025-09-08T23:23:24.541Z" },
-    { url = "https://files.pythonhosted.org/packages/2b/0f/1f177e3683aead2bb00f7679a16451d302c436b5cbf2505f0ea8146ef59e/cffi-2.0.0-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:737fe7d37e1a1bffe70bd5754ea763a62a066dc5913ca57e957824b72a85e205", size = 222828, upload-time = "2025-09-08T23:23:26.143Z" },
-    { url = "https://files.pythonhosted.org/packages/c6/0f/cafacebd4b040e3119dcb32fed8bdef8dfe94da653155f9d0b9dc660166e/cffi-2.0.0-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:38100abb9d1b1435bc4cc340bb4489635dc2f0da7456590877030c9b3d40b0c1", size = 220926, upload-time = "2025-09-08T23:23:27.873Z" },
-    { url = "https://files.pythonhosted.org/packages/3e/aa/df335faa45b395396fcbc03de2dfcab242cd61a9900e914fe682a59170b1/cffi-2.0.0-cp314-cp314-win32.whl", hash = "sha256:087067fa8953339c723661eda6b54bc98c5625757ea62e95eb4898ad5e776e9f", size = 175328, upload-time = "2025-09-08T23:23:44.61Z" },
-    { url = "https://files.pythonhosted.org/packages/bb/92/882c2d30831744296ce713f0feb4c1cd30f346ef747b530b5318715cc367/cffi-2.0.0-cp314-cp314-win_amd64.whl", hash = "sha256:203a48d1fb583fc7d78a4c6655692963b860a417c0528492a6bc21f1aaefab25", size = 185650, upload-time = "2025-09-08T23:23:45.848Z" },
-    { url = "https://files.pythonhosted.org/packages/9f/2c/98ece204b9d35a7366b5b2c6539c350313ca13932143e79dc133ba757104/cffi-2.0.0-cp314-cp314-win_arm64.whl", hash = "sha256:dbd5c7a25a7cb98f5ca55d258b103a2054f859a46ae11aaf23134f9cc0d356ad", size = 180687, upload-time = "2025-09-08T23:23:47.105Z" },
-    { url = "https://files.pythonhosted.org/packages/3e/61/c768e4d548bfa607abcda77423448df8c471f25dbe64fb2ef6d555eae006/cffi-2.0.0-cp314-cp314t-macosx_10_13_x86_64.whl", hash = "sha256:9a67fc9e8eb39039280526379fb3a70023d77caec1852002b4da7e8b270c4dd9", size = 188773, upload-time = "2025-09-08T23:23:29.347Z" },
-    { url = "https://files.pythonhosted.org/packages/2c/ea/5f76bce7cf6fcd0ab1a1058b5af899bfbef198bea4d5686da88471ea0336/cffi-2.0.0-cp314-cp314t-macosx_11_0_arm64.whl", hash = "sha256:7a66c7204d8869299919db4d5069a82f1561581af12b11b3c9f48c584eb8743d", size = 185013, upload-time = "2025-09-08T23:23:30.63Z" },
-    { url = "https://files.pythonhosted.org/packages/be/b4/c56878d0d1755cf9caa54ba71e5d049479c52f9e4afc230f06822162ab2f/cffi-2.0.0-cp314-cp314t-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:7cc09976e8b56f8cebd752f7113ad07752461f48a58cbba644139015ac24954c", size = 221593, upload-time = "2025-09-08T23:23:31.91Z" },
-    { url = "https://files.pythonhosted.org/packages/e0/0d/eb704606dfe8033e7128df5e90fee946bbcb64a04fcdaa97321309004000/cffi-2.0.0-cp314-cp314t-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:92b68146a71df78564e4ef48af17551a5ddd142e5190cdf2c5624d0c3ff5b2e8", size = 209354, upload-time = "2025-09-08T23:23:33.214Z" },
-    { url = "https://files.pythonhosted.org/packages/d8/19/3c435d727b368ca475fb8742ab97c9cb13a0de600ce86f62eab7fa3eea60/cffi-2.0.0-cp314-cp314t-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:b1e74d11748e7e98e2f426ab176d4ed720a64412b6a15054378afdb71e0f37dc", size = 208480, upload-time = "2025-09-08T23:23:34.495Z" },
-    { url = "https://files.pythonhosted.org/packages/d0/44/681604464ed9541673e486521497406fadcc15b5217c3e326b061696899a/cffi-2.0.0-cp314-cp314t-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:28a3a209b96630bca57cce802da70c266eb08c6e97e5afd61a75611ee6c64592", size = 221584, upload-time = "2025-09-08T23:23:36.096Z" },
-    { url = "https://files.pythonhosted.org/packages/25/8e/342a504ff018a2825d395d44d63a767dd8ebc927ebda557fecdaca3ac33a/cffi-2.0.0-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:7553fb2090d71822f02c629afe6042c299edf91ba1bf94951165613553984512", size = 224443, upload-time = "2025-09-08T23:23:37.328Z" },
-    { url = "https://files.pythonhosted.org/packages/e1/5e/b666bacbbc60fbf415ba9988324a132c9a7a0448a9a8f125074671c0f2c3/cffi-2.0.0-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:6c6c373cfc5c83a975506110d17457138c8c63016b563cc9ed6e056a82f13ce4", size = 223437, upload-time = "2025-09-08T23:23:38.945Z" },
-    { url = "https://files.pythonhosted.org/packages/a0/1d/ec1a60bd1a10daa292d3cd6bb0b359a81607154fb8165f3ec95fe003b85c/cffi-2.0.0-cp314-cp314t-win32.whl", hash = "sha256:1fc9ea04857caf665289b7a75923f2c6ed559b8298a1b8c49e59f7dd95c8481e", size = 180487, upload-time = "2025-09-08T23:23:40.423Z" },
-    { url = "https://files.pythonhosted.org/packages/bf/41/4c1168c74fac325c0c8156f04b6749c8b6a8f405bbf91413ba088359f60d/cffi-2.0.0-cp314-cp314t-win_amd64.whl", hash = "sha256:d68b6cef7827e8641e8ef16f4494edda8b36104d79773a334beaa1e3521430f6", size = 191726, upload-time = "2025-09-08T23:23:41.742Z" },
-    { url = "https://files.pythonhosted.org/packages/ae/3a/dbeec9d1ee0844c679f6bb5d6ad4e9f198b1224f4e7a32825f47f6192b0c/cffi-2.0.0-cp314-cp314t-win_arm64.whl", hash = "sha256:0a1527a803f0a659de1af2e1fd700213caba79377e27e4693648c2923da066f9", size = 184195, upload-time = "2025-09-08T23:23:43.004Z" },
-    { url = "https://files.pythonhosted.org/packages/c0/cc/08ed5a43f2996a16b462f64a7055c6e962803534924b9b2f1371d8c00b7b/cffi-2.0.0-cp39-cp39-macosx_10_13_x86_64.whl", hash = "sha256:fe562eb1a64e67dd297ccc4f5addea2501664954f2692b69a76449ec7913ecbf", size = 184288, upload-time = "2025-09-08T23:23:48.404Z" },
-    { url = "https://files.pythonhosted.org/packages/3d/de/38d9726324e127f727b4ecc376bc85e505bfe61ef130eaf3f290c6847dd4/cffi-2.0.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:de8dad4425a6ca6e4e5e297b27b5c824ecc7581910bf9aee86cb6835e6812aa7", size = 180509, upload-time = "2025-09-08T23:23:49.73Z" },
-    { url = "https://files.pythonhosted.org/packages/9b/13/c92e36358fbcc39cf0962e83223c9522154ee8630e1df7c0b3a39a8124e2/cffi-2.0.0-cp39-cp39-manylinux1_i686.manylinux2014_i686.manylinux_2_17_i686.manylinux_2_5_i686.whl", hash = "sha256:4647afc2f90d1ddd33441e5b0e85b16b12ddec4fca55f0d9671fef036ecca27c", size = 208813, upload-time = "2025-09-08T23:23:51.263Z" },
-    { url = "https://files.pythonhosted.org/packages/15/12/a7a79bd0df4c3bff744b2d7e52cc1b68d5e7e427b384252c42366dc1ecbc/cffi-2.0.0-cp39-cp39-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:3f4d46d8b35698056ec29bca21546e1551a205058ae1a181d871e278b0b28165", size = 216498, upload-time = "2025-09-08T23:23:52.494Z" },
-    { url = "https://files.pythonhosted.org/packages/a3/ad/5c51c1c7600bdd7ed9a24a203ec255dccdd0ebf4527f7b922a0bde2fb6ed/cffi-2.0.0-cp39-cp39-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:e6e73b9e02893c764e7e8d5bb5ce277f1a009cd5243f8228f75f842bf937c534", size = 203243, upload-time = "2025-09-08T23:23:53.836Z" },
-    { url = "https://files.pythonhosted.org/packages/32/f2/81b63e288295928739d715d00952c8c6034cb6c6a516b17d37e0c8be5600/cffi-2.0.0-cp39-cp39-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:cb527a79772e5ef98fb1d700678fe031e353e765d1ca2d409c92263c6d43e09f", size = 203158, upload-time = "2025-09-08T23:23:55.169Z" },
-    { url = "https://files.pythonhosted.org/packages/1f/74/cc4096ce66f5939042ae094e2e96f53426a979864aa1f96a621ad128be27/cffi-2.0.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:61d028e90346df14fedc3d1e5441df818d095f3b87d286825dfcbd6459b7ef63", size = 216548, upload-time = "2025-09-08T23:23:56.506Z" },
-    { url = "https://files.pythonhosted.org/packages/e8/be/f6424d1dc46b1091ffcc8964fa7c0ab0cd36839dd2761b49c90481a6ba1b/cffi-2.0.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:0f6084a0ea23d05d20c3edcda20c3d006f9b6f3fefeac38f59262e10cef47ee2", size = 218897, upload-time = "2025-09-08T23:23:57.825Z" },
-    { url = "https://files.pythonhosted.org/packages/f7/e0/dda537c2309817edf60109e39265f24f24aa7f050767e22c98c53fe7f48b/cffi-2.0.0-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:1cd13c99ce269b3ed80b417dcd591415d3372bcac067009b6e0f59c7d4015e65", size = 211249, upload-time = "2025-09-08T23:23:59.139Z" },
-    { url = "https://files.pythonhosted.org/packages/2b/e7/7c769804eb75e4c4b35e658dba01de1640a351a9653c3d49ca89d16ccc91/cffi-2.0.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:89472c9762729b5ae1ad974b777416bfda4ac5642423fa93bd57a09204712322", size = 218041, upload-time = "2025-09-08T23:24:00.496Z" },
-    { url = "https://files.pythonhosted.org/packages/aa/d9/6218d78f920dcd7507fc16a766b5ef8f3b913cc7aa938e7fc80b9978d089/cffi-2.0.0-cp39-cp39-win32.whl", hash = "sha256:2081580ebb843f759b9f617314a24ed5738c51d2aee65d31e02f6f7a2b97707a", size = 172138, upload-time = "2025-09-08T23:24:01.7Z" },
-    { url = "https://files.pythonhosted.org/packages/54/8f/a1e836f82d8e32a97e6b29cc8f641779181ac7363734f12df27db803ebda/cffi-2.0.0-cp39-cp39-win_amd64.whl", hash = "sha256:b882b3df248017dba09d6b16defe9b5c407fe32fc7c65a9c69798e6175601be9", size = 182794, upload-time = "2025-09-08T23:24:02.943Z" },
+    { name = "pycparser" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/fc/97/c783634659c2920c3fc70419e3af40972dbaf758daa229a7d6ea6135c90d/cffi-1.17.1.tar.gz", hash = "sha256:1c39c6016c32bc48dd54561950ebd6836e1670f2ae46128f67cf49e789c52824", size = 516621, upload-time = "2024-09-04T20:45:21.852Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/90/07/f44ca684db4e4f08a3fdc6eeb9a0d15dc6883efc7b8c90357fdbf74e186c/cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:df8b1c11f177bc2313ec4b2d46baec87a5f3e71fc8b45dab2ee7cae86d9aba14", size = 182191, upload-time = "2024-09-04T20:43:30.027Z" },
+    { url = "https://files.pythonhosted.org/packages/08/fd/cc2fedbd887223f9f5d170c96e57cbf655df9831a6546c1727ae13fa977a/cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8f2cdc858323644ab277e9bb925ad72ae0e67f69e804f4898c070998d50b1a67", size = 178592, upload-time = "2024-09-04T20:43:32.108Z" },
+    { url = "https://files.pythonhosted.org/packages/de/cc/4635c320081c78d6ffc2cab0a76025b691a91204f4aa317d568ff9280a2d/cffi-1.17.1-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:edae79245293e15384b51f88b00613ba9f7198016a5948b5dddf4917d4d26382", size = 426024, upload-time = "2024-09-04T20:43:34.186Z" },
+    { url = "https://files.pythonhosted.org/packages/b6/7b/3b2b250f3aab91abe5f8a51ada1b717935fdaec53f790ad4100fe2ec64d1/cffi-1.17.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:45398b671ac6d70e67da8e4224a065cec6a93541bb7aebe1b198a61b58c7b702", size = 448188, upload-time = "2024-09-04T20:43:36.286Z" },
+    { url = "https://files.pythonhosted.org/packages/d3/48/1b9283ebbf0ec065148d8de05d647a986c5f22586b18120020452fff8f5d/cffi-1.17.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ad9413ccdeda48c5afdae7e4fa2192157e991ff761e7ab8fdd8926f40b160cc3", size = 455571, upload-time = "2024-09-04T20:43:38.586Z" },
+    { url = "https://files.pythonhosted.org/packages/40/87/3b8452525437b40f39ca7ff70276679772ee7e8b394934ff60e63b7b090c/cffi-1.17.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5da5719280082ac6bd9aa7becb3938dc9f9cbd57fac7d2871717b1feb0902ab6", size = 436687, upload-time = "2024-09-04T20:43:40.084Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/fb/4da72871d177d63649ac449aec2e8a29efe0274035880c7af59101ca2232/cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2bb1a08b8008b281856e5971307cc386a8e9c5b625ac297e853d36da6efe9c17", size = 446211, upload-time = "2024-09-04T20:43:41.526Z" },
+    { url = "https://files.pythonhosted.org/packages/ab/a0/62f00bcb411332106c02b663b26f3545a9ef136f80d5df746c05878f8c4b/cffi-1.17.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:045d61c734659cc045141be4bae381a41d89b741f795af1dd018bfb532fd0df8", size = 461325, upload-time = "2024-09-04T20:43:43.117Z" },
+    { url = "https://files.pythonhosted.org/packages/36/83/76127035ed2e7e27b0787604d99da630ac3123bfb02d8e80c633f218a11d/cffi-1.17.1-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:6883e737d7d9e4899a8a695e00ec36bd4e5e4f18fabe0aca0efe0a4b44cdb13e", size = 438784, upload-time = "2024-09-04T20:43:45.256Z" },
+    { url = "https://files.pythonhosted.org/packages/21/81/a6cd025db2f08ac88b901b745c163d884641909641f9b826e8cb87645942/cffi-1.17.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:6b8b4a92e1c65048ff98cfe1f735ef8f1ceb72e3d5f0c25fdb12087a23da22be", size = 461564, upload-time = "2024-09-04T20:43:46.779Z" },
+    { url = "https://files.pythonhosted.org/packages/f8/fe/4d41c2f200c4a457933dbd98d3cf4e911870877bd94d9656cc0fcb390681/cffi-1.17.1-cp310-cp310-win32.whl", hash = "sha256:c9c3d058ebabb74db66e431095118094d06abf53284d9c81f27300d0e0d8bc7c", size = 171804, upload-time = "2024-09-04T20:43:48.186Z" },
+    { url = "https://files.pythonhosted.org/packages/d1/b6/0b0f5ab93b0df4acc49cae758c81fe4e5ef26c3ae2e10cc69249dfd8b3ab/cffi-1.17.1-cp310-cp310-win_amd64.whl", hash = "sha256:0f048dcf80db46f0098ccac01132761580d28e28bc0f78ae0d58048063317e15", size = 181299, upload-time = "2024-09-04T20:43:49.812Z" },
+    { url = "https://files.pythonhosted.org/packages/6b/f4/927e3a8899e52a27fa57a48607ff7dc91a9ebe97399b357b85a0c7892e00/cffi-1.17.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a45e3c6913c5b87b3ff120dcdc03f6131fa0065027d0ed7ee6190736a74cd401", size = 182264, upload-time = "2024-09-04T20:43:51.124Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/f5/6c3a8efe5f503175aaddcbea6ad0d2c96dad6f5abb205750d1b3df44ef29/cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:30c5e0cb5ae493c04c8b42916e52ca38079f1b235c2f8ae5f4527b963c401caf", size = 178651, upload-time = "2024-09-04T20:43:52.872Z" },
+    { url = "https://files.pythonhosted.org/packages/94/dd/a3f0118e688d1b1a57553da23b16bdade96d2f9bcda4d32e7d2838047ff7/cffi-1.17.1-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f75c7ab1f9e4aca5414ed4d8e5c0e303a34f4421f8a0d47a4d019ceff0ab6af4", size = 445259, upload-time = "2024-09-04T20:43:56.123Z" },
+    { url = "https://files.pythonhosted.org/packages/2e/ea/70ce63780f096e16ce8588efe039d3c4f91deb1dc01e9c73a287939c79a6/cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a1ed2dd2972641495a3ec98445e09766f077aee98a1c896dcb4ad0d303628e41", size = 469200, upload-time = "2024-09-04T20:43:57.891Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/a0/a4fa9f4f781bda074c3ddd57a572b060fa0df7655d2a4247bbe277200146/cffi-1.17.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:46bf43160c1a35f7ec506d254e5c890f3c03648a4dbac12d624e4490a7046cd1", size = 477235, upload-time = "2024-09-04T20:44:00.18Z" },
+    { url = "https://files.pythonhosted.org/packages/62/12/ce8710b5b8affbcdd5c6e367217c242524ad17a02fe5beec3ee339f69f85/cffi-1.17.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a24ed04c8ffd54b0729c07cee15a81d964e6fee0e3d4d342a27b020d22959dc6", size = 459721, upload-time = "2024-09-04T20:44:01.585Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/6b/d45873c5e0242196f042d555526f92aa9e0c32355a1be1ff8c27f077fd37/cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:610faea79c43e44c71e1ec53a554553fa22321b65fae24889706c0a84d4ad86d", size = 467242, upload-time = "2024-09-04T20:44:03.467Z" },
+    { url = "https://files.pythonhosted.org/packages/1a/52/d9a0e523a572fbccf2955f5abe883cfa8bcc570d7faeee06336fbd50c9fc/cffi-1.17.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a9b15d491f3ad5d692e11f6b71f7857e7835eb677955c00cc0aefcd0669adaf6", size = 477999, upload-time = "2024-09-04T20:44:05.023Z" },
+    { url = "https://files.pythonhosted.org/packages/44/74/f2a2460684a1a2d00ca799ad880d54652841a780c4c97b87754f660c7603/cffi-1.17.1-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:de2ea4b5833625383e464549fec1bc395c1bdeeb5f25c4a3a82b5a8c756ec22f", size = 454242, upload-time = "2024-09-04T20:44:06.444Z" },
+    { url = "https://files.pythonhosted.org/packages/f8/4a/34599cac7dfcd888ff54e801afe06a19c17787dfd94495ab0c8d35fe99fb/cffi-1.17.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:fc48c783f9c87e60831201f2cce7f3b2e4846bf4d8728eabe54d60700b318a0b", size = 478604, upload-time = "2024-09-04T20:44:08.206Z" },
+    { url = "https://files.pythonhosted.org/packages/34/33/e1b8a1ba29025adbdcda5fb3a36f94c03d771c1b7b12f726ff7fef2ebe36/cffi-1.17.1-cp311-cp311-win32.whl", hash = "sha256:85a950a4ac9c359340d5963966e3e0a94a676bd6245a4b55bc43949eee26a655", size = 171727, upload-time = "2024-09-04T20:44:09.481Z" },
+    { url = "https://files.pythonhosted.org/packages/3d/97/50228be003bb2802627d28ec0627837ac0bf35c90cf769812056f235b2d1/cffi-1.17.1-cp311-cp311-win_amd64.whl", hash = "sha256:caaf0640ef5f5517f49bc275eca1406b0ffa6aa184892812030f04c2abf589a0", size = 181400, upload-time = "2024-09-04T20:44:10.873Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/84/e94227139ee5fb4d600a7a4927f322e1d4aea6fdc50bd3fca8493caba23f/cffi-1.17.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:805b4371bf7197c329fcb3ead37e710d1bca9da5d583f5073b799d5c5bd1eee4", size = 183178, upload-time = "2024-09-04T20:44:12.232Z" },
+    { url = "https://files.pythonhosted.org/packages/da/ee/fb72c2b48656111c4ef27f0f91da355e130a923473bf5ee75c5643d00cca/cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:733e99bc2df47476e3848417c5a4540522f234dfd4ef3ab7fafdf555b082ec0c", size = 178840, upload-time = "2024-09-04T20:44:13.739Z" },
+    { url = "https://files.pythonhosted.org/packages/cc/b6/db007700f67d151abadf508cbfd6a1884f57eab90b1bb985c4c8c02b0f28/cffi-1.17.1-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1257bdabf294dceb59f5e70c64a3e2f462c30c7ad68092d01bbbfb1c16b1ba36", size = 454803, upload-time = "2024-09-04T20:44:15.231Z" },
+    { url = "https://files.pythonhosted.org/packages/1a/df/f8d151540d8c200eb1c6fba8cd0dfd40904f1b0682ea705c36e6c2e97ab3/cffi-1.17.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:da95af8214998d77a98cc14e3a3bd00aa191526343078b530ceb0bd710fb48a5", size = 478850, upload-time = "2024-09-04T20:44:17.188Z" },
+    { url = "https://files.pythonhosted.org/packages/28/c0/b31116332a547fd2677ae5b78a2ef662dfc8023d67f41b2a83f7c2aa78b1/cffi-1.17.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d63afe322132c194cf832bfec0dc69a99fb9bb6bbd550f161a49e9e855cc78ff", size = 485729, upload-time = "2024-09-04T20:44:18.688Z" },
+    { url = "https://files.pythonhosted.org/packages/91/2b/9a1ddfa5c7f13cab007a2c9cc295b70fbbda7cb10a286aa6810338e60ea1/cffi-1.17.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f79fc4fc25f1c8698ff97788206bb3c2598949bfe0fef03d299eb1b5356ada99", size = 471256, upload-time = "2024-09-04T20:44:20.248Z" },
+    { url = "https://files.pythonhosted.org/packages/b2/d5/da47df7004cb17e4955df6a43d14b3b4ae77737dff8bf7f8f333196717bf/cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b62ce867176a75d03a665bad002af8e6d54644fad99a3c70905c543130e39d93", size = 479424, upload-time = "2024-09-04T20:44:21.673Z" },
+    { url = "https://files.pythonhosted.org/packages/0b/ac/2a28bcf513e93a219c8a4e8e125534f4f6db03e3179ba1c45e949b76212c/cffi-1.17.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:386c8bf53c502fff58903061338ce4f4950cbdcb23e2902d86c0f722b786bbe3", size = 484568, upload-time = "2024-09-04T20:44:23.245Z" },
+    { url = "https://files.pythonhosted.org/packages/d4/38/ca8a4f639065f14ae0f1d9751e70447a261f1a30fa7547a828ae08142465/cffi-1.17.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ceb10419a9adf4460ea14cfd6bc43d08701f0835e979bf821052f1805850fe8", size = 488736, upload-time = "2024-09-04T20:44:24.757Z" },
+    { url = "https://files.pythonhosted.org/packages/86/c5/28b2d6f799ec0bdecf44dced2ec5ed43e0eb63097b0f58c293583b406582/cffi-1.17.1-cp312-cp312-win32.whl", hash = "sha256:a08d7e755f8ed21095a310a693525137cfe756ce62d066e53f502a83dc550f65", size = 172448, upload-time = "2024-09-04T20:44:26.208Z" },
+    { url = "https://files.pythonhosted.org/packages/50/b9/db34c4755a7bd1cb2d1603ac3863f22bcecbd1ba29e5ee841a4bc510b294/cffi-1.17.1-cp312-cp312-win_amd64.whl", hash = "sha256:51392eae71afec0d0c8fb1a53b204dbb3bcabcb3c9b807eedf3e1e6ccf2de903", size = 181976, upload-time = "2024-09-04T20:44:27.578Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/f8/dd6c246b148639254dad4d6803eb6a54e8c85c6e11ec9df2cffa87571dbe/cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f3a2b4222ce6b60e2e8b337bb9596923045681d71e5a082783484d845390938e", size = 182989, upload-time = "2024-09-04T20:44:28.956Z" },
+    { url = "https://files.pythonhosted.org/packages/8b/f1/672d303ddf17c24fc83afd712316fda78dc6fce1cd53011b839483e1ecc8/cffi-1.17.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:0984a4925a435b1da406122d4d7968dd861c1385afe3b45ba82b750f229811e2", size = 178802, upload-time = "2024-09-04T20:44:30.289Z" },
+    { url = "https://files.pythonhosted.org/packages/0e/2d/eab2e858a91fdff70533cab61dcff4a1f55ec60425832ddfdc9cd36bc8af/cffi-1.17.1-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d01b12eeeb4427d3110de311e1774046ad344f5b1a7403101878976ecd7a10f3", size = 454792, upload-time = "2024-09-04T20:44:32.01Z" },
+    { url = "https://files.pythonhosted.org/packages/75/b2/fbaec7c4455c604e29388d55599b99ebcc250a60050610fadde58932b7ee/cffi-1.17.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:706510fe141c86a69c8ddc029c7910003a17353970cff3b904ff0686a5927683", size = 478893, upload-time = "2024-09-04T20:44:33.606Z" },
+    { url = "https://files.pythonhosted.org/packages/4f/b7/6e4a2162178bf1935c336d4da8a9352cccab4d3a5d7914065490f08c0690/cffi-1.17.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:de55b766c7aa2e2a3092c51e0483d700341182f08e67c63630d5b6f200bb28e5", size = 485810, upload-time = "2024-09-04T20:44:35.191Z" },
+    { url = "https://files.pythonhosted.org/packages/c7/8a/1d0e4a9c26e54746dc08c2c6c037889124d4f59dffd853a659fa545f1b40/cffi-1.17.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c59d6e989d07460165cc5ad3c61f9fd8f1b4796eacbd81cee78957842b834af4", size = 471200, upload-time = "2024-09-04T20:44:36.743Z" },
+    { url = "https://files.pythonhosted.org/packages/26/9f/1aab65a6c0db35f43c4d1b4f580e8df53914310afc10ae0397d29d697af4/cffi-1.17.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dd398dbc6773384a17fe0d3e7eeb8d1a21c2200473ee6806bb5e6a8e62bb73dd", size = 479447, upload-time = "2024-09-04T20:44:38.492Z" },
+    { url = "https://files.pythonhosted.org/packages/5f/e4/fb8b3dd8dc0e98edf1135ff067ae070bb32ef9d509d6cb0f538cd6f7483f/cffi-1.17.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:3edc8d958eb099c634dace3c7e16560ae474aa3803a5df240542b305d14e14ed", size = 484358, upload-time = "2024-09-04T20:44:40.046Z" },
+    { url = "https://files.pythonhosted.org/packages/f1/47/d7145bf2dc04684935d57d67dff9d6d795b2ba2796806bb109864be3a151/cffi-1.17.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:72e72408cad3d5419375fc87d289076ee319835bdfa2caad331e377589aebba9", size = 488469, upload-time = "2024-09-04T20:44:41.616Z" },
+    { url = "https://files.pythonhosted.org/packages/bf/ee/f94057fa6426481d663b88637a9a10e859e492c73d0384514a17d78ee205/cffi-1.17.1-cp313-cp313-win32.whl", hash = "sha256:e03eab0a8677fa80d646b5ddece1cbeaf556c313dcfac435ba11f107ba117b5d", size = 172475, upload-time = "2024-09-04T20:44:43.733Z" },
+    { url = "https://files.pythonhosted.org/packages/7c/fc/6a8cb64e5f0324877d503c854da15d76c1e50eb722e320b15345c4d0c6de/cffi-1.17.1-cp313-cp313-win_amd64.whl", hash = "sha256:f6a16c31041f09ead72d69f583767292f750d24913dadacf5756b966aacb3f1a", size = 182009, upload-time = "2024-09-04T20:44:45.309Z" },
+    { url = "https://files.pythonhosted.org/packages/b9/ea/8bb50596b8ffbc49ddd7a1ad305035daa770202a6b782fc164647c2673ad/cffi-1.17.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:b2ab587605f4ba0bf81dc0cb08a41bd1c0a5906bd59243d56bad7668a6fc6c16", size = 182220, upload-time = "2024-09-04T20:45:01.577Z" },
+    { url = "https://files.pythonhosted.org/packages/ae/11/e77c8cd24f58285a82c23af484cf5b124a376b32644e445960d1a4654c3a/cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:28b16024becceed8c6dfbc75629e27788d8a3f9030691a1dbf9821a128b22c36", size = 178605, upload-time = "2024-09-04T20:45:03.837Z" },
+    { url = "https://files.pythonhosted.org/packages/ed/65/25a8dc32c53bf5b7b6c2686b42ae2ad58743f7ff644844af7cdb29b49361/cffi-1.17.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1d599671f396c4723d016dbddb72fe8e0397082b0a77a4fab8028923bec050e8", size = 424910, upload-time = "2024-09-04T20:45:05.315Z" },
+    { url = "https://files.pythonhosted.org/packages/42/7a/9d086fab7c66bd7c4d0f27c57a1b6b068ced810afc498cc8c49e0088661c/cffi-1.17.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca74b8dbe6e8e8263c0ffd60277de77dcee6c837a3d0881d8c1ead7268c9e576", size = 447200, upload-time = "2024-09-04T20:45:06.903Z" },
+    { url = "https://files.pythonhosted.org/packages/da/63/1785ced118ce92a993b0ec9e0d0ac8dc3e5dbfbcaa81135be56c69cabbb6/cffi-1.17.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f7f5baafcc48261359e14bcd6d9bff6d4b28d9103847c9e136694cb0501aef87", size = 454565, upload-time = "2024-09-04T20:45:08.975Z" },
+    { url = "https://files.pythonhosted.org/packages/74/06/90b8a44abf3556599cdec107f7290277ae8901a58f75e6fe8f970cd72418/cffi-1.17.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:98e3969bcff97cae1b2def8ba499ea3d6f31ddfdb7635374834cf89a1a08ecf0", size = 435635, upload-time = "2024-09-04T20:45:10.64Z" },
+    { url = "https://files.pythonhosted.org/packages/bd/62/a1f468e5708a70b1d86ead5bab5520861d9c7eacce4a885ded9faa7729c3/cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cdf5ce3acdfd1661132f2a9c19cac174758dc2352bfe37d98aa7512c6b7178b3", size = 445218, upload-time = "2024-09-04T20:45:12.366Z" },
+    { url = "https://files.pythonhosted.org/packages/5b/95/b34462f3ccb09c2594aa782d90a90b045de4ff1f70148ee79c69d37a0a5a/cffi-1.17.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:9755e4345d1ec879e3849e62222a18c7174d65a6a92d5b346b1863912168b595", size = 460486, upload-time = "2024-09-04T20:45:13.935Z" },
+    { url = "https://files.pythonhosted.org/packages/fc/fc/a1e4bebd8d680febd29cf6c8a40067182b64f00c7d105f8f26b5bc54317b/cffi-1.17.1-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:f1e22e8c4419538cb197e4dd60acc919d7696e5ef98ee4da4e01d3f8cfa4cc5a", size = 437911, upload-time = "2024-09-04T20:45:15.696Z" },
+    { url = "https://files.pythonhosted.org/packages/e6/c3/21cab7a6154b6a5ea330ae80de386e7665254835b9e98ecc1340b3a7de9a/cffi-1.17.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:c03e868a0b3bc35839ba98e74211ed2b05d2119be4e8a0f224fba9384f1fe02e", size = 460632, upload-time = "2024-09-04T20:45:17.284Z" },
+    { url = "https://files.pythonhosted.org/packages/cb/b5/fd9f8b5a84010ca169ee49f4e4ad6f8c05f4e3545b72ee041dbbcb159882/cffi-1.17.1-cp39-cp39-win32.whl", hash = "sha256:e31ae45bc2e29f6b2abd0de1cc3b9d5205aa847cafaecb8af1476a609a2f6eb7", size = 171820, upload-time = "2024-09-04T20:45:18.762Z" },
+    { url = "https://files.pythonhosted.org/packages/8c/52/b08750ce0bce45c143e1b5d7357ee8c55341b52bdef4b0f081af1eb248c2/cffi-1.17.1-cp39-cp39-win_amd64.whl", hash = "sha256:d016c76bdd850f3c626af19b0542c9677ba156e4ee4fccfdd7848803533ef662", size = 181290, upload-time = "2024-09-04T20:45:20.226Z" },
 ]
 
 [[package]]
@@ -263,7 +344,10 @@ name = "click"
 version = "8.3.0"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -293,6 +377,251 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/60/97/891a0971e1e4a8c5d2b20bbe0e524dc04548d2307fee33cdeba148fd4fc7/comm-0.2.3-py3-none-any.whl", hash = "sha256:c615d91d75f7f04f095b30d1c1711babd43bdc6419c1be9886a85f2f4e489417", size = 7294, upload-time = "2025-07-25T14:02:02.896Z" },
 ]
 
+[[package]]
+name = "cryptography"
+version = "45.0.7"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+]
+dependencies = [
+    { name = "cffi", marker = "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/a7/35/c495bffc2056f2dadb32434f1feedd79abde2a7f8363e1974afa9c33c7e2/cryptography-45.0.7.tar.gz", hash = "sha256:4b1654dfc64ea479c242508eb8c724044f1e964a47d1d1cacc5132292d851971", size = 744980, upload-time = "2025-09-01T11:15:03.146Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/fc/63/43641c5acce3a6105cf8bd5baeceeb1846bb63067d26dae3e5db59f1513a/cryptography-45.0.7-cp311-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:67285f8a611b0ebc0857ced2081e30302909f571a46bfa7a3cc0ad303fe015c6", size = 4205799, upload-time = "2025-09-01T11:14:02.517Z" },
+    { url = "https://files.pythonhosted.org/packages/bc/29/c238dd9107f10bfde09a4d1c52fd38828b1aa353ced11f358b5dd2507d24/cryptography-45.0.7-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:577470e39e60a6cd7780793202e63536026d9b8641de011ed9d8174da9ca5339", size = 4430504, upload-time = "2025-09-01T11:14:04.522Z" },
+    { url = "https://files.pythonhosted.org/packages/62/62/24203e7cbcc9bd7c94739428cd30680b18ae6b18377ae66075c8e4771b1b/cryptography-45.0.7-cp311-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:4bd3e5c4b9682bc112d634f2c6ccc6736ed3635fc3319ac2bb11d768cc5a00d8", size = 4209542, upload-time = "2025-09-01T11:14:06.309Z" },
+    { url = "https://files.pythonhosted.org/packages/cd/e3/e7de4771a08620eef2389b86cd87a2c50326827dea5528feb70595439ce4/cryptography-45.0.7-cp311-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:465ccac9d70115cd4de7186e60cfe989de73f7bb23e8a7aa45af18f7412e75bf", size = 3889244, upload-time = "2025-09-01T11:14:08.152Z" },
+    { url = "https://files.pythonhosted.org/packages/96/b8/bca71059e79a0bb2f8e4ec61d9c205fbe97876318566cde3b5092529faa9/cryptography-45.0.7-cp311-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:16ede8a4f7929b4b7ff3642eba2bf79aa1d71f24ab6ee443935c0d269b6bc513", size = 4461975, upload-time = "2025-09-01T11:14:09.755Z" },
+    { url = "https://files.pythonhosted.org/packages/58/67/3f5b26937fe1218c40e95ef4ff8d23c8dc05aa950d54200cc7ea5fb58d28/cryptography-45.0.7-cp311-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:8978132287a9d3ad6b54fcd1e08548033cc09dc6aacacb6c004c73c3eb5d3ac3", size = 4209082, upload-time = "2025-09-01T11:14:11.229Z" },
+    { url = "https://files.pythonhosted.org/packages/0e/e4/b3e68a4ac363406a56cf7b741eeb80d05284d8c60ee1a55cdc7587e2a553/cryptography-45.0.7-cp311-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:b6a0e535baec27b528cb07a119f321ac024592388c5681a5ced167ae98e9fff3", size = 4460397, upload-time = "2025-09-01T11:14:12.924Z" },
+    { url = "https://files.pythonhosted.org/packages/22/49/2c93f3cd4e3efc8cb22b02678c1fad691cff9dd71bb889e030d100acbfe0/cryptography-45.0.7-cp311-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:a24ee598d10befaec178efdff6054bc4d7e883f615bfbcd08126a0f4931c83a6", size = 4337244, upload-time = "2025-09-01T11:14:14.431Z" },
+    { url = "https://files.pythonhosted.org/packages/04/19/030f400de0bccccc09aa262706d90f2ec23d56bc4eb4f4e8268d0ddf3fb8/cryptography-45.0.7-cp311-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:fa26fa54c0a9384c27fcdc905a2fb7d60ac6e47d14bc2692145f2b3b1e2cfdbd", size = 4568862, upload-time = "2025-09-01T11:14:16.185Z" },
+    { url = "https://files.pythonhosted.org/packages/bc/4c/8f57f2500d0ccd2675c5d0cc462095adf3faa8c52294ba085c036befb901/cryptography-45.0.7-cp37-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:81823935e2f8d476707e85a78a405953a03ef7b7b4f55f93f7c2d9680e5e0691", size = 4202233, upload-time = "2025-09-01T11:14:22.454Z" },
+    { url = "https://files.pythonhosted.org/packages/eb/ac/59b7790b4ccaed739fc44775ce4645c9b8ce54cbec53edf16c74fd80cb2b/cryptography-45.0.7-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:3994c809c17fc570c2af12c9b840d7cea85a9fd3e5c0e0491f4fa3c029216d59", size = 4423075, upload-time = "2025-09-01T11:14:24.287Z" },
+    { url = "https://files.pythonhosted.org/packages/b8/56/d4f07ea21434bf891faa088a6ac15d6d98093a66e75e30ad08e88aa2b9ba/cryptography-45.0.7-cp37-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:dad43797959a74103cb59c5dac71409f9c27d34c8a05921341fb64ea8ccb1dd4", size = 4204517, upload-time = "2025-09-01T11:14:25.679Z" },
+    { url = "https://files.pythonhosted.org/packages/e8/ac/924a723299848b4c741c1059752c7cfe09473b6fd77d2920398fc26bfb53/cryptography-45.0.7-cp37-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:ce7a453385e4c4693985b4a4a3533e041558851eae061a58a5405363b098fcd3", size = 3882893, upload-time = "2025-09-01T11:14:27.1Z" },
+    { url = "https://files.pythonhosted.org/packages/83/dc/4dab2ff0a871cc2d81d3ae6d780991c0192b259c35e4d83fe1de18b20c70/cryptography-45.0.7-cp37-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:b04f85ac3a90c227b6e5890acb0edbaf3140938dbecf07bff618bf3638578cf1", size = 4450132, upload-time = "2025-09-01T11:14:28.58Z" },
+    { url = "https://files.pythonhosted.org/packages/12/dd/b2882b65db8fc944585d7fb00d67cf84a9cef4e77d9ba8f69082e911d0de/cryptography-45.0.7-cp37-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:48c41a44ef8b8c2e80ca4527ee81daa4c527df3ecbc9423c41a420a9559d0e27", size = 4204086, upload-time = "2025-09-01T11:14:30.572Z" },
+    { url = "https://files.pythonhosted.org/packages/5d/fa/1d5745d878048699b8eb87c984d4ccc5da4f5008dfd3ad7a94040caca23a/cryptography-45.0.7-cp37-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:f3df7b3d0f91b88b2106031fd995802a2e9ae13e02c36c1fc075b43f420f3a17", size = 4449383, upload-time = "2025-09-01T11:14:32.046Z" },
+    { url = "https://files.pythonhosted.org/packages/36/8b/fc61f87931bc030598e1876c45b936867bb72777eac693e905ab89832670/cryptography-45.0.7-cp37-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:dd342f085542f6eb894ca00ef70236ea46070c8a13824c6bde0dfdcd36065b9b", size = 4332186, upload-time = "2025-09-01T11:14:33.95Z" },
+    { url = "https://files.pythonhosted.org/packages/0b/11/09700ddad7443ccb11d674efdbe9a832b4455dc1f16566d9bd3834922ce5/cryptography-45.0.7-cp37-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:1993a1bb7e4eccfb922b6cd414f072e08ff5816702a0bdb8941c247a6b1b287c", size = 4561639, upload-time = "2025-09-01T11:14:35.343Z" },
+    { url = "https://files.pythonhosted.org/packages/59/aa/e947693ab08674a2663ed2534cd8d345cf17bf6a1facf99273e8ec8986dc/cryptography-45.0.7-pp310-pypy310_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:a20e442e917889d1a6b3c570c9e3fa2fdc398c20868abcea268ea33c024c4083", size = 4142233, upload-time = "2025-09-01T11:14:41.305Z" },
+    { url = "https://files.pythonhosted.org/packages/24/06/09b6f6a2fc43474a32b8fe259038eef1500ee3d3c141599b57ac6c57612c/cryptography-45.0.7-pp310-pypy310_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:258e0dff86d1d891169b5af222d362468a9570e2532923088658aa866eb11130", size = 4376202, upload-time = "2025-09-01T11:14:43.047Z" },
+    { url = "https://files.pythonhosted.org/packages/00/f2/c166af87e95ce6ae6d38471a7e039d3a0549c2d55d74e059680162052824/cryptography-45.0.7-pp310-pypy310_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:d97cf502abe2ab9eff8bd5e4aca274da8d06dd3ef08b759a8d6143f4ad65d4b4", size = 4141900, upload-time = "2025-09-01T11:14:45.089Z" },
+    { url = "https://files.pythonhosted.org/packages/16/b9/e96e0b6cb86eae27ea51fa8a3151535a18e66fe7c451fa90f7f89c85f541/cryptography-45.0.7-pp310-pypy310_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:c987dad82e8c65ebc985f5dae5e74a3beda9d0a2a4daf8a1115f3772b59e5141", size = 4375562, upload-time = "2025-09-01T11:14:47.166Z" },
+    { url = "https://files.pythonhosted.org/packages/16/ce/5f6ff59ea9c7779dba51b84871c19962529bdcc12e1a6ea172664916c550/cryptography-45.0.7-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:06ce84dc14df0bf6ea84666f958e6080cdb6fe1231be2a51f3fc1267d9f3fb34", size = 4149533, upload-time = "2025-09-01T11:14:52.091Z" },
+    { url = "https://files.pythonhosted.org/packages/ce/13/b3cfbd257ac96da4b88b46372e662009b7a16833bfc5da33bb97dd5631ae/cryptography-45.0.7-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:d0c5c6bac22b177bf8da7435d9d27a6834ee130309749d162b26c3105c0795a9", size = 4385557, upload-time = "2025-09-01T11:14:53.551Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/c5/8c59d6b7c7b439ba4fc8d0cab868027fd095f215031bc123c3a070962912/cryptography-45.0.7-pp311-pypy311_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:2f641b64acc00811da98df63df7d59fd4706c0df449da71cb7ac39a0732b40ae", size = 4149023, upload-time = "2025-09-01T11:14:55.022Z" },
+    { url = "https://files.pythonhosted.org/packages/55/32/05385c86d6ca9ab0b4d5bb442d2e3d85e727939a11f3e163fc776ce5eb40/cryptography-45.0.7-pp311-pypy311_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:f5414a788ecc6ee6bc58560e85ca624258a55ca434884445440a810796ea0e0b", size = 4385722, upload-time = "2025-09-01T11:14:57.319Z" },
+]
+
+[[package]]
+name = "cryptography"
+version = "46.0.0"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+    "python_full_version < '3.10'",
+]
+dependencies = [
+    { name = "cffi", marker = "python_full_version < '3.14' and platform_python_implementation != 'PyPy'" },
+    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/80/ee/04cd4314db26ffc951c1ea90bde30dd226880ab9343759d7abbecef377ee/cryptography-46.0.0.tar.gz", hash = "sha256:99f64a6d15f19f3afd78720ad2978f6d8d4c68cd4eb600fab82ab1a7c2071dca", size = 749158, upload-time = "2025-09-16T21:07:49.091Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c7/ee/dd17f412ce64b347871d7752657c5084940d42af4d9c25b1b91c7ee53362/cryptography-46.0.0-cp311-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:4f70cbade61a16f5e238c4b0eb4e258d177a2fcb59aa0aae1236594f7b0ae338", size = 4308218, upload-time = "2025-09-16T21:05:55.653Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/53/f0b865a971e4e8b3e90e648b6f828950dea4c221bb699421e82ef45f0ef9/cryptography-46.0.0-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:d1eccae15d5c28c74b2bea228775c63ac5b6c36eedb574e002440c0bc28750d3", size = 4571982, upload-time = "2025-09-16T21:05:57.322Z" },
+    { url = "https://files.pythonhosted.org/packages/d4/c8/035be5fd63a98284fd74df9e04156f9fed7aa45cef41feceb0d06cbdadd0/cryptography-46.0.0-cp311-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:1b4fba84166d906a22027f0d958e42f3a4dbbb19c28ea71f0fb7812380b04e3c", size = 4307996, upload-time = "2025-09-16T21:05:59.043Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/4a/dbb6d7d0a48b95984e2d4caf0a4c7d6606cea5d30241d984c0c02b47f1b6/cryptography-46.0.0-cp311-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:523153480d7575a169933f083eb47b1edd5fef45d87b026737de74ffeb300f69", size = 4015692, upload-time = "2025-09-16T21:06:01.324Z" },
+    { url = "https://files.pythonhosted.org/packages/65/48/aafcffdde716f6061864e56a0a5908f08dcb8523dab436228957c8ebd5df/cryptography-46.0.0-cp311-abi3-manylinux_2_28_ppc64le.whl", hash = "sha256:f09a3a108223e319168b7557810596631a8cb864657b0c16ed7a6017f0be9433", size = 4982192, upload-time = "2025-09-16T21:06:03.367Z" },
+    { url = "https://files.pythonhosted.org/packages/4c/ab/1e73cfc181afc3054a09e5e8f7753a8fba254592ff50b735d7456d197353/cryptography-46.0.0-cp311-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:c1f6ccd6f2eef3b2eb52837f0463e853501e45a916b3fc42e5d93cf244a4b97b", size = 4603944, upload-time = "2025-09-16T21:06:05.29Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/02/d71dac90b77c606c90c366571edf264dc8bd37cf836e7f902253cbf5aa77/cryptography-46.0.0-cp311-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:80a548a5862d6912a45557a101092cd6c64ae1475b82cef50ee305d14a75f598", size = 4308149, upload-time = "2025-09-16T21:06:07.006Z" },
+    { url = "https://files.pythonhosted.org/packages/29/e6/4dcb67fdc6addf4e319a99c4bed25776cb691f3aa6e0c4646474748816c6/cryptography-46.0.0-cp311-abi3-manylinux_2_34_ppc64le.whl", hash = "sha256:6c39fd5cd9b7526afa69d64b5e5645a06e1b904f342584b3885254400b63f1b3", size = 4947449, upload-time = "2025-09-16T21:06:11.244Z" },
+    { url = "https://files.pythonhosted.org/packages/26/04/91e3fad8ee33aa87815c8f25563f176a58da676c2b14757a4d3b19f0253c/cryptography-46.0.0-cp311-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:d5c0cbb2fb522f7e39b59a5482a1c9c5923b7c506cfe96a1b8e7368c31617ac0", size = 4603549, upload-time = "2025-09-16T21:06:13.268Z" },
+    { url = "https://files.pythonhosted.org/packages/9c/6e/caf4efadcc8f593cbaacfbb04778f78b6d0dac287b45cec25e5054de38b7/cryptography-46.0.0-cp311-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:6d8945bc120dcd90ae39aa841afddaeafc5f2e832809dc54fb906e3db829dfdc", size = 4435976, upload-time = "2025-09-16T21:06:16.514Z" },
+    { url = "https://files.pythonhosted.org/packages/c1/c0/704710f349db25c5b91965c3662d5a758011b2511408d9451126429b6cd6/cryptography-46.0.0-cp311-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:88c09da8a94ac27798f6b62de6968ac78bb94805b5d272dbcfd5fdc8c566999f", size = 4709447, upload-time = "2025-09-16T21:06:19.246Z" },
+    { url = "https://files.pythonhosted.org/packages/9c/9e/d20925af5f0484c5049cf7254c91b79776a9b555af04493de6bdd419b495/cryptography-46.0.0-cp314-cp314t-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:65e9117ebed5b16b28154ed36b164c20021f3a480e9cbb4b4a2a59b95e74c25d", size = 4293519, upload-time = "2025-09-16T21:06:30.143Z" },
+    { url = "https://files.pythonhosted.org/packages/5f/b9/07aec6b183ef0054b5f826ae43f0b4db34c50b56aff18f67babdcc2642a3/cryptography-46.0.0-cp314-cp314t-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:da7f93551d39d462263b6b5c9056c49f780b9200bf9fc2656d7c88c7bdb9b363", size = 4545583, upload-time = "2025-09-16T21:06:31.914Z" },
+    { url = "https://files.pythonhosted.org/packages/39/4a/7d25158be8c607e2b9ebda49be762404d675b47df335d0d2a3b979d80213/cryptography-46.0.0-cp314-cp314t-manylinux_2_28_aarch64.whl", hash = "sha256:be7479f9504bfb46628544ec7cb4637fe6af8b70445d4455fbb9c395ad9b7290", size = 4299196, upload-time = "2025-09-16T21:06:33.724Z" },
+    { url = "https://files.pythonhosted.org/packages/15/3f/65c8753c0dbebe769cc9f9d87d52bce8b74e850ef2818c59bfc7e4248663/cryptography-46.0.0-cp314-cp314t-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:f85e6a7d42ad60024fa1347b1d4ef82c4df517a4deb7f829d301f1a92ded038c", size = 3994419, upload-time = "2025-09-16T21:06:35.877Z" },
+    { url = "https://files.pythonhosted.org/packages/d5/b4/69a271873cfc333a236443c94aa07e0233bc36b384e182da2263703b5759/cryptography-46.0.0-cp314-cp314t-manylinux_2_28_ppc64le.whl", hash = "sha256:d349af4d76a93562f1dce4d983a4a34d01cb22b48635b0d2a0b8372cdb4a8136", size = 4960228, upload-time = "2025-09-16T21:06:38.182Z" },
+    { url = "https://files.pythonhosted.org/packages/af/e0/ab62ee938b8d17bd1025cff569803cfc1c62dfdf89ffc78df6e092bff35f/cryptography-46.0.0-cp314-cp314t-manylinux_2_28_x86_64.whl", hash = "sha256:35aa1a44bd3e0efc3ef09cf924b3a0e2a57eda84074556f4506af2d294076685", size = 4577257, upload-time = "2025-09-16T21:06:39.998Z" },
+    { url = "https://files.pythonhosted.org/packages/49/67/09a581c21da7189676678edd2bd37b64888c88c2d2727f2c3e0350194fba/cryptography-46.0.0-cp314-cp314t-manylinux_2_34_aarch64.whl", hash = "sha256:c457ad3f151d5fb380be99425b286167b358f76d97ad18b188b68097193ed95a", size = 4299023, upload-time = "2025-09-16T21:06:42.182Z" },
+    { url = "https://files.pythonhosted.org/packages/af/28/2cb6d3d0d2c8ce8be4f19f4d83956c845c760a9e6dfe5b476cebed4f4f00/cryptography-46.0.0-cp314-cp314t-manylinux_2_34_ppc64le.whl", hash = "sha256:399ef4c9be67f3902e5ca1d80e64b04498f8b56c19e1bc8d0825050ea5290410", size = 4925802, upload-time = "2025-09-16T21:06:44.31Z" },
+    { url = "https://files.pythonhosted.org/packages/88/0b/1f31b6658c1dfa04e82b88de2d160e0e849ffb94353b1526dfb3a225a100/cryptography-46.0.0-cp314-cp314t-manylinux_2_34_x86_64.whl", hash = "sha256:378eff89b040cbce6169528f130ee75dceeb97eef396a801daec03b696434f06", size = 4577107, upload-time = "2025-09-16T21:06:46.324Z" },
+    { url = "https://files.pythonhosted.org/packages/c2/af/507de3a1d4ded3068ddef188475d241bfc66563d99161585c8f2809fee01/cryptography-46.0.0-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:c3648d6a5878fd1c9a22b1d43fa75efc069d5f54de12df95c638ae7ba88701d0", size = 4422506, upload-time = "2025-09-16T21:06:47.963Z" },
+    { url = "https://files.pythonhosted.org/packages/47/aa/08e514756504d92334cabfe7fe792d10d977f2294ef126b2056b436450eb/cryptography-46.0.0-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:2fc30be952dd4334801d345d134c9ef0e9ccbaa8c3e1bc18925cbc4247b3e29c", size = 4684081, upload-time = "2025-09-16T21:06:49.667Z" },
+    { url = "https://files.pythonhosted.org/packages/3d/b8/a5ed987f5c11b242713076121dddfff999d81fb492149c006a579d0e4099/cryptography-46.0.0-cp38-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:83af84ebe7b6e9b6de05050c79f8cc0173c864ce747b53abce6a11e940efdc0d", size = 4301182, upload-time = "2025-09-16T21:07:01.624Z" },
+    { url = "https://files.pythonhosted.org/packages/da/94/f1c1f30110c05fa5247bf460b17acfd52fa3f5c77e94ba19cff8957dc5e6/cryptography-46.0.0-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:c3cd09b1490c1509bf3892bde9cef729795fae4a2fee0621f19be3321beca7e4", size = 4562561, upload-time = "2025-09-16T21:07:03.386Z" },
+    { url = "https://files.pythonhosted.org/packages/5d/54/8decbf2f707350bedcd525833d3a0cc0203d8b080d926ad75d5c4de701ba/cryptography-46.0.0-cp38-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:d14eaf1569d6252280516bedaffdd65267428cdbc3a8c2d6de63753cf0863d5e", size = 4301974, upload-time = "2025-09-16T21:07:04.962Z" },
+    { url = "https://files.pythonhosted.org/packages/82/63/c34a2f3516c6b05801f129616a5a1c68a8c403b91f23f9db783ee1d4f700/cryptography-46.0.0-cp38-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:ab3a14cecc741c8c03ad0ad46dfbf18de25218551931a23bca2731d46c706d83", size = 4009462, upload-time = "2025-09-16T21:07:06.569Z" },
+    { url = "https://files.pythonhosted.org/packages/cd/c5/92ef920a4cf8ff35fcf9da5a09f008a6977dcb9801c709799ec1bf2873fb/cryptography-46.0.0-cp38-abi3-manylinux_2_28_ppc64le.whl", hash = "sha256:8e8b222eb54e3e7d3743a7c2b1f7fa7df7a9add790307bb34327c88ec85fe087", size = 4980769, upload-time = "2025-09-16T21:07:08.269Z" },
+    { url = "https://files.pythonhosted.org/packages/a9/8f/1705f7ea3b9468c4a4fef6cce631db14feb6748499870a4772993cbeb729/cryptography-46.0.0-cp38-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:7f3f88df0c9b248dcc2e76124f9140621aca187ccc396b87bc363f890acf3a30", size = 4591812, upload-time = "2025-09-16T21:07:10.288Z" },
+    { url = "https://files.pythonhosted.org/packages/34/b9/2d797ce9d346b8bac9f570b43e6e14226ff0f625f7f6f2f95d9065e316e3/cryptography-46.0.0-cp38-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:9aa85222f03fdb30defabc7a9e1e3d4ec76eb74ea9fe1504b2800844f9c98440", size = 4301844, upload-time = "2025-09-16T21:07:12.522Z" },
+    { url = "https://files.pythonhosted.org/packages/a8/2d/8efc9712997b46aea2ac8f74adc31f780ac4662e3b107ecad0d5c1a0c7f8/cryptography-46.0.0-cp38-abi3-manylinux_2_34_ppc64le.whl", hash = "sha256:f9aaf2a91302e1490c068d2f3af7df4137ac2b36600f5bd26e53d9ec320412d3", size = 4943257, upload-time = "2025-09-16T21:07:14.289Z" },
+    { url = "https://files.pythonhosted.org/packages/c4/0c/bc365287a97d28aa7feef8810884831b2a38a8dc4cf0f8d6927ad1568d27/cryptography-46.0.0-cp38-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:32670ca085150ff36b438c17f2dfc54146fe4a074ebf0a76d72fb1b419a974bc", size = 4591154, upload-time = "2025-09-16T21:07:16.271Z" },
+    { url = "https://files.pythonhosted.org/packages/51/3b/0b15107277b0c558c02027da615f4e78c892f22c6a04d29c6ad43fcddca6/cryptography-46.0.0-cp38-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:0f58183453032727a65e6605240e7a3824fd1d6a7e75d2b537e280286ab79a52", size = 4428200, upload-time = "2025-09-16T21:07:18.118Z" },
+    { url = "https://files.pythonhosted.org/packages/cf/24/814d69418247ea2cfc985eec6678239013500d745bc7a0a35a32c2e2f3be/cryptography-46.0.0-cp38-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:4bc257c2d5d865ed37d0bd7c500baa71f939a7952c424f28632298d80ccd5ec1", size = 4699862, upload-time = "2025-09-16T21:07:20.219Z" },
+    { url = "https://files.pythonhosted.org/packages/f5/69/ff831514209e68a7e32fef655abfd9ef9ee4608d151636fa11eb8d7e589a/cryptography-46.0.0-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:f9f85d9cf88e3ba2b2b6da3c2310d1cf75bdf04a5bc1a2e972603054f82c4dd5", size = 4249520, upload-time = "2025-09-16T21:07:34.409Z" },
+    { url = "https://files.pythonhosted.org/packages/19/4a/19960010da2865f521a5bd657eaf647d6a4368568e96f6d9ec635e47ad55/cryptography-46.0.0-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:834af45296083d892e23430e3b11df77e2ac5c042caede1da29c9bf59016f4d2", size = 4528031, upload-time = "2025-09-16T21:07:36.721Z" },
+    { url = "https://files.pythonhosted.org/packages/79/92/88970c2b5b270d232213a971e74afa6d0e82d8aeee0964765a78ee1f55c8/cryptography-46.0.0-pp311-pypy311_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:c39f0947d50f74b1b3523cec3931315072646286fb462995eb998f8136779319", size = 4249072, upload-time = "2025-09-16T21:07:38.382Z" },
+    { url = "https://files.pythonhosted.org/packages/63/50/b0b90a269d64b479602d948f40ef6131f3704546ce003baa11405aa4093b/cryptography-46.0.0-pp311-pypy311_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:6460866a92143a24e3ed68eaeb6e98d0cedd85d7d9a8ab1fc293ec91850b1b38", size = 4527173, upload-time = "2025-09-16T21:07:40.742Z" },
+]
+
+[[package]]
+name = "databricks-sdk"
+version = "0.15.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "google-auth" },
+    { name = "requests" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/c3/7b/9ac9b9b7b076eb754e35ed64eb18aa07075ba95778dada3eb539af27d833/databricks-sdk-0.15.0.tar.gz", hash = "sha256:e5b21ea8bfae1727e102f4e977950bed615bbf8113f072e0341687f52041f89b", size = 435080, upload-time = "2023-12-12T14:51:27.1Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/89/8d/980657a6a33f41145a3d28ea88dfcebe9eca6b07e2a5655e8a77eec8026a/databricks_sdk-0.15.0-py3-none-any.whl", hash = "sha256:5d355df235c06d003e31c05b65f9ef6ccdc115fe9062b9b5e488de9e97d63c3c", size = 431024, upload-time = "2023-12-12T14:51:24.42Z" },
+]
+
+[[package]]
+name = "databricks-sql-connector"
+version = "2.9.6"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "alembic", version = "1.16.5", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "alembic", version = "1.17.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "lz4" },
+    { name = "numpy", version = "2.0.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "numpy", version = "2.2.6", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version == '3.10.*'" },
+    { name = "numpy", version = "2.3.5", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.11'" },
+    { name = "oauthlib" },
+    { name = "openpyxl" },
+    { name = "pandas" },
+    { name = "pyarrow", version = "21.0.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "pyarrow", version = "22.0.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "requests" },
+    { name = "sqlalchemy" },
+    { name = "thrift" },
+    { name = "urllib3" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/5f/fc/aaf10de12cd970a10c774b66e9fe57a47c6ff7483683c2bcb76e13ede96a/databricks_sql_connector-2.9.6.tar.gz", hash = "sha256:e55f5b8ede8ae6c6f31416a4cf6352f0ac019bf6875896c668c7574ceaf6e813", size = 288798, upload-time = "2024-04-18T17:39:35.129Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/05/69/74fcf07b6ad65640a5f40c6cee6f14654bec7d19de80b30ed95dd0ef48be/databricks_sql_connector-2.9.6-py3-none-any.whl", hash = "sha256:d830abf86e71d2eb83c6a7b7264d6c03926a8a83cec58541ddd6b83d693bde8f", size = 298568, upload-time = "2024-04-18T17:39:32.461Z" },
+]
+
+[[package]]
+name = "dbt-core"
+version = "1.7.19"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "agate" },
+    { name = "cffi" },
+    { name = "click", version = "8.1.8", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "click", version = "8.3.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "colorama" },
+    { name = "dbt-extractor" },
+    { name = "dbt-semantic-interfaces" },
+    { name = "idna" },
+    { name = "isodate" },
+    { name = "jinja2" },
+    { name = "jsonschema" },
+    { name = "logbook" },
+    { name = "mashumaro", extra = ["msgpack"] },
+    { name = "minimal-snowplow-tracker" },
+    { name = "networkx", version = "3.2.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "networkx", version = "3.4.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version == '3.10.*'" },
+    { name = "networkx", version = "3.5", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.11'" },
+    { name = "packaging" },
+    { name = "pathspec" },
+    { name = "protobuf" },
+    { name = "pytz" },
+    { name = "pyyaml" },
+    { name = "requests" },
+    { name = "sqlparse" },
+    { name = "typing-extensions" },
+    { name = "urllib3" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/b7/66/32e97ff2dd9560a1b7e2b88a4fbaacc5bc1d0f668fede072c0a4c7f6c9a0/dbt_core-1.7.19.tar.gz", hash = "sha256:39f868f050be4f66f7791a6aad550b59b4f096cf79859e8efa2794fae5a7e318", size = 916539, upload-time = "2024-12-02T18:23:00.55Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b0/63/d8f91045e96d653c5301636aed29a5d7ab096c865863617ac36fd71d8f9b/dbt_core-1.7.19-py3-none-any.whl", hash = "sha256:682ef2ef36571b1d180462b54af0cbf4be4a2f042494f104063365bd26e0f32b", size = 1025955, upload-time = "2024-12-02T18:22:55.382Z" },
+]
+
+[[package]]
+name = "dbt-databricks"
+version = "1.7.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "databricks-sdk" },
+    { name = "databricks-sql-connector" },
+    { name = "dbt-spark" },
+    { name = "keyring" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/38/16/75ff6ff63abc7d81d245c2ecbead12bde67230c70c6a01dc055909337b04/dbt-databricks-1.7.1.tar.gz", hash = "sha256:b590b40559140b06d6f790abd73cceb9442148b414049fbfe082bb36a88e0020", size = 43012, upload-time = "2023-11-13T23:26:29.508Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/3d/7d/b8e27a71a384e2f5ece9b68f7e73b607ce35833972f7c39fc23cc653d819/dbt_databricks-1.7.1-py3-none-any.whl", hash = "sha256:bef03a17a76e378eb54c98833b402f7ebed89bc52ed45e29c4bd0fb98818eecc", size = 52131, upload-time = "2023-11-13T23:26:26.802Z" },
+]
+
+[[package]]
+name = "dbt-extractor"
+version = "0.5.1"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/2c/d0/4ee14955ad0214da695b3c15dc0acf2ab54c9d263242f36073c999cb699a/dbt_extractor-0.5.1.tar.gz", hash = "sha256:cd5d95576a8dea4190240aaf9936a37fd74b4b7913ca69a3c368fc4472bb7e13", size = 266278, upload-time = "2023-11-28T17:25:19.934Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/77/1f/ca6d66d67464df1ea8e814d09b1100d15672ae4ce7f0dff41f67956e5f7f/dbt_extractor-0.5.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl", hash = "sha256:3b91e6106b967d908b34f83929d3f50ee2b498876a1be9c055fe060ed728c556", size = 865677, upload-time = "2023-11-28T17:24:52.457Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/be/0ae4a5c6c721ee42d849482084b5f4544acafe3c8cf4c84170f35c63fe50/dbt_extractor-0.5.1-cp38-abi3-macosx_10_12_x86_64.whl", hash = "sha256:3614ce9f83ae4cd0dc95f77730034a793a1c090a52dcf698ba1c94050afe3a8b", size = 438730, upload-time = "2023-11-28T17:24:54.004Z" },
+    { url = "https://files.pythonhosted.org/packages/a9/ac/bbe5d223a03632d4192414a8af0aa6e2c16555a6e7d33515225b4c978096/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_12_i686.manylinux2010_i686.whl", hash = "sha256:ea4edf33035d0a060b1e01c42fb2d99316457d44c954d6ed4eed9f1948664d87", size = 1385155, upload-time = "2023-11-28T17:24:55.783Z" },
+    { url = "https://files.pythonhosted.org/packages/6d/96/caef63d79f3a06bcae1aca43302c1b9efa58590644efca41c4404607510e/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d3b9bf50eb062b4344d9546fe42038996c6e7e7daa10724aa955d64717260e5d", size = 1344382, upload-time = "2023-11-28T17:24:57.753Z" },
+    { url = "https://files.pythonhosted.org/packages/66/ce/8c248ba3def50203925a1404d21a03999e2fe32bf7611e6f9de1006817ba/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:c0ce901d4ebf0664977e4e1cbf596d4afc6c1339fcc7d2cf67ce3481566a626f", size = 1343152, upload-time = "2023-11-28T17:24:59.357Z" },
+    { url = "https://files.pythonhosted.org/packages/11/73/5ead77c8b742453e1a34a064d921933bbca4f8941ad8f14fd47d0a15c49c/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_ppc64.manylinux2014_ppc64.whl", hash = "sha256:cbe338b76e9ffaa18275456e041af56c21bb517f6fbda7a58308138703da0996", size = 1498587, upload-time = "2023-11-28T17:25:01.2Z" },
+    { url = "https://files.pythonhosted.org/packages/51/e6/140058fbeb482071a7b199986c40385dfdc97f23b0ea20b0740762d2e116/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1b25fa7a276ab26aa2d70ff6e0cf4cfb1490d7831fb57ee1337c24d2b0333b84", size = 1482391, upload-time = "2023-11-28T17:25:03.274Z" },
+    { url = "https://files.pythonhosted.org/packages/63/e6/a40a89c75701fa91fc7297b9d77f303fc93669a32a10be4457a02de0584f/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c5651e458be910ff567c0da3ea2eb084fd01884cc88888ac2cf1e240dcddacc2", size = 1517273, upload-time = "2023-11-28T17:25:04.789Z" },
+    { url = "https://files.pythonhosted.org/packages/30/da/a9528ca8224317aad1dab22f77468dd13e94c46b56db953b5b1e3b698a8f/dbt_extractor-0.5.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:62e4f040fd338b652683421ce48e903812e27fd6e7af58b1b70a4e1f9f2c79e3", size = 1346957, upload-time = "2023-11-28T17:25:06.814Z" },
+    { url = "https://files.pythonhosted.org/packages/7b/2b/48ad70e0490e492b1f59e260d447b3c9eaaad661eb4b46baacc2f328dabf/dbt_extractor-0.5.1-cp38-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:91e25ad78f1f4feadd27587ebbcc46ad909cfad843118908f30336d08d8400ca", size = 1524362, upload-time = "2023-11-28T17:25:09.55Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/cc/6dce67509e94080535b400b03d7d13fecd2acba72c10c21df8b7755212ce/dbt_extractor-0.5.1-cp38-abi3-musllinux_1_2_armv7l.whl", hash = "sha256:cdf9938b36cd098bcdd80f43dc03864da3f69f57d903a9160a32236540d4ddcd", size = 1603552, upload-time = "2023-11-28T17:25:11.452Z" },
+    { url = "https://files.pythonhosted.org/packages/58/b6/14ab2c80385a29ad013a0a0642522b393bf1220d6c01587aad4796784cc1/dbt_extractor-0.5.1-cp38-abi3-musllinux_1_2_i686.whl", hash = "sha256:475e2c05b17eb4976eff6c8f7635be42bec33f15a74ceb87a40242c94a99cebf", size = 1550461, upload-time = "2023-11-28T17:25:12.875Z" },
+    { url = "https://files.pythonhosted.org/packages/7c/04/19af8b0cb0e341d091cca21ff3cfed95f152e39f598b7313c79a6804f32f/dbt_extractor-0.5.1-cp38-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:100453ba06e169cbdb118234ab3f06f6722a2e0e316089b81c88dea701212abc", size = 1520792, upload-time = "2023-11-28T17:25:14.449Z" },
+    { url = "https://files.pythonhosted.org/packages/10/dd/b3c440b8eeac318a2d3b0f190783feedad60b962fe984d6d0cb482b128b4/dbt_extractor-0.5.1-cp38-abi3-win32.whl", hash = "sha256:6916aae085fd5f2af069fd6947933e78b742c9e3d2165e1740c2e28ae543309a", size = 261615, upload-time = "2023-11-28T17:25:15.961Z" },
+    { url = "https://files.pythonhosted.org/packages/8c/ad/fa331537dbe97250dda06342775891ae2b1fb8b54cf9219e47781f641657/dbt_extractor-0.5.1-cp38-abi3-win_amd64.whl", hash = "sha256:eecc08f3743e802a8ede60c89f7b2bce872acc86120cbc0ae7df229bb8a95083", size = 283481, upload-time = "2023-11-28T17:25:17.947Z" },
+]
+
+[[package]]
+name = "dbt-semantic-interfaces"
+version = "0.4.4"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "click", version = "8.1.8", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "click", version = "8.3.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "importlib-metadata" },
+    { name = "jinja2" },
+    { name = "jsonschema" },
+    { name = "more-itertools" },
+    { name = "pydantic" },
+    { name = "python-dateutil" },
+    { name = "pyyaml" },
+    { name = "typing-extensions" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/2e/38/e889ad15d281093e53a7ec1e692a387a92dc056fff56b8c2961634b1968b/dbt_semantic_interfaces-0.4.4.tar.gz", hash = "sha256:3b8126deb964c03d14e8af1cb4bdfb9f20c53dfcef28fa3a0bc158a8312e4070", size = 75128, upload-time = "2024-02-26T19:34:34.962Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/9d/a8/718950dfc5975f49f5b05cd3604d266a5d68c37e2e2e95d353363d33a01c/dbt_semantic_interfaces-0.4.4-py3-none-any.whl", hash = "sha256:0149a4fd7fd4f25309edf5f856410536eaf2019f29dad58967dcf6d0625e6914", size = 118618, upload-time = "2024-02-26T19:34:36.853Z" },
+]
+
+[[package]]
+name = "dbt-spark"
+version = "1.7.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "dbt-core" },
+    { name = "sqlparams" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/af/ca/b65c5c0fa81e58c26984cfef7a2d538ea4e853d0d9260439227f016a3db1/dbt-spark-1.7.1.tar.gz", hash = "sha256:a10e5d1bfdb2ca98e7ae2badd06150e2695d9d4fa18ae2354ed5bd093d77f947", size = 36547, upload-time = "2023-11-08T00:35:47.044Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/fb/67/da2511fbb20a5d309098ce1d0376712ea3caa0ebf2a6e14c4cc54047875b/dbt_spark-1.7.1-py3-none-any.whl", hash = "sha256:99b5002edcdb82058a3b0ad33eb18b91a4bdde887d94855e8bd6f633d78837dc", size = 44394, upload-time = "2023-11-08T00:35:45.03Z" },
+]
+
 [[package]]
 name = "debugpy"
 version = "1.8.17"
@@ -394,6 +723,15 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/7c/58/193850c3a2b5f677b439afafbe1f671dfe6aebe4864698cbd8557bc748e3/duckdb-1.4.2-cp39-cp39-win_amd64.whl", hash = "sha256:c6d41fea4f9038663e6b9c325075a843fd105eaff0ec3d5fe31dfa9014114c3e", size = 12319492, upload-time = "2025-11-12T13:18:01.152Z" },
 ]
 
+[[package]]
+name = "et-xmlfile"
+version = "2.0.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/d3/38/af70d7ab1ae9d4da450eeec1fa3918940a5fafb9055e934af8d6eb0c2313/et_xmlfile-2.0.0.tar.gz", hash = "sha256:dab3f4764309081ce75662649be815c4c9081e88f0837825f90fd28317d4da54", size = 17234, upload-time = "2024-10-25T17:25:40.039Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl", hash = "sha256:7a91720bc756843502c3b7504c77b8fe44217c85c537d85037f0f536151b2caa", size = 18059, upload-time = "2024-10-25T17:25:39.051Z" },
+]
+
 [[package]]
 name = "exceptiongroup"
 version = "1.3.0"
@@ -420,6 +758,9 @@ name = "fda-animal-adverse-events"
 version = "0.1.0"
 source = { virtual = "." }
 dependencies = [
+    { name = "databricks-sdk" },
+    { name = "dbt-core" },
+    { name = "dbt-databricks" },
     { name = "duckdb" },
     { name = "ipykernel", version = "6.31.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
     { name = "ipykernel", version = "7.1.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
@@ -432,6 +773,9 @@ dependencies = [
 
 [package.metadata]
 requires-dist = [
+    { name = "databricks-sdk", specifier = "<0.16.0" },
+    { name = "dbt-core", specifier = ">=1.7.19" },
+    { name = "dbt-databricks", specifier = "==1.7.1" },
     { name = "duckdb", specifier = ">=1.4.2" },
     { name = "ipykernel", specifier = ">=6.31.0" },
     { name = "logging", specifier = ">=0.4.9.6" },
@@ -441,6 +785,93 @@ requires-dist = [
     { name = "sqlfluff", specifier = ">=3.5.0" },
 ]
 
+[[package]]
+name = "google-auth"
+version = "2.43.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "cachetools" },
+    { name = "pyasn1-modules" },
+    { name = "rsa" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/ff/ef/66d14cf0e01b08d2d51ffc3c20410c4e134a1548fc246a6081eae585a4fe/google_auth-2.43.0.tar.gz", hash = "sha256:88228eee5fc21b62a1b5fe773ca15e67778cb07dc8363adcb4a8827b52d81483", size = 296359, upload-time = "2025-11-06T00:13:36.587Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/6f/d1/385110a9ae86d91cc14c5282c61fe9f4dc41c0b9f7d423c6ad77038c4448/google_auth-2.43.0-py2.py3-none-any.whl", hash = "sha256:af628ba6fa493f75c7e9dbe9373d148ca9f4399b5ea29976519e0a3848eddd16", size = 223114, upload-time = "2025-11-06T00:13:35.209Z" },
+]
+
+[[package]]
+name = "greenlet"
+version = "3.2.4"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/03/b8/704d753a5a45507a7aab61f18db9509302ed3d0a27ac7e0359ec2905b1a6/greenlet-3.2.4.tar.gz", hash = "sha256:0dca0d95ff849f9a364385f36ab49f50065d76964944638be9691e1832e9f86d", size = 188260, upload-time = "2025-08-07T13:24:33.51Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/7d/ed/6bfa4109fcb23a58819600392564fea69cdc6551ffd5e69ccf1d52a40cbc/greenlet-3.2.4-cp310-cp310-macosx_11_0_universal2.whl", hash = "sha256:8c68325b0d0acf8d91dde4e6f930967dd52a5302cd4062932a6b2e7c2969f47c", size = 271061, upload-time = "2025-08-07T13:17:15.373Z" },
+    { url = "https://files.pythonhosted.org/packages/2a/fc/102ec1a2fc015b3a7652abab7acf3541d58c04d3d17a8d3d6a44adae1eb1/greenlet-3.2.4-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:94385f101946790ae13da500603491f04a76b6e4c059dab271b3ce2e283b2590", size = 629475, upload-time = "2025-08-07T13:42:54.009Z" },
+    { url = "https://files.pythonhosted.org/packages/c5/26/80383131d55a4ac0fb08d71660fd77e7660b9db6bdb4e8884f46d9f2cc04/greenlet-3.2.4-cp310-cp310-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:f10fd42b5ee276335863712fa3da6608e93f70629c631bf77145021600abc23c", size = 640802, upload-time = "2025-08-07T13:45:25.52Z" },
+    { url = "https://files.pythonhosted.org/packages/9f/7c/e7833dbcd8f376f3326bd728c845d31dcde4c84268d3921afcae77d90d08/greenlet-3.2.4-cp310-cp310-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:c8c9e331e58180d0d83c5b7999255721b725913ff6bc6cf39fa2a45841a4fd4b", size = 636703, upload-time = "2025-08-07T13:53:12.622Z" },
+    { url = "https://files.pythonhosted.org/packages/e9/49/547b93b7c0428ede7b3f309bc965986874759f7d89e4e04aeddbc9699acb/greenlet-3.2.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:58b97143c9cc7b86fc458f215bd0932f1757ce649e05b640fea2e79b54cedb31", size = 635417, upload-time = "2025-08-07T13:18:25.189Z" },
+    { url = "https://files.pythonhosted.org/packages/7f/91/ae2eb6b7979e2f9b035a9f612cf70f1bf54aad4e1d125129bef1eae96f19/greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:c2ca18a03a8cfb5b25bc1cbe20f3d9a4c80d8c3b13ba3df49ac3961af0b1018d", size = 584358, upload-time = "2025-08-07T13:18:23.708Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/85/433de0c9c0252b22b16d413c9407e6cb3b41df7389afc366ca204dbc1393/greenlet-3.2.4-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:9fe0a28a7b952a21e2c062cd5756d34354117796c6d9215a87f55e38d15402c5", size = 1113550, upload-time = "2025-08-07T13:42:37.467Z" },
+    { url = "https://files.pythonhosted.org/packages/a1/8d/88f3ebd2bc96bf7747093696f4335a0a8a4c5acfcf1b757717c0d2474ba3/greenlet-3.2.4-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:8854167e06950ca75b898b104b63cc646573aa5fef1353d4508ecdd1ee76254f", size = 1137126, upload-time = "2025-08-07T13:18:20.239Z" },
+    { url = "https://files.pythonhosted.org/packages/f1/29/74242b7d72385e29bcc5563fba67dad94943d7cd03552bac320d597f29b2/greenlet-3.2.4-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:f47617f698838ba98f4ff4189aef02e7343952df3a615f847bb575c3feb177a7", size = 1544904, upload-time = "2025-11-04T12:42:04.763Z" },
+    { url = "https://files.pythonhosted.org/packages/c8/e2/1572b8eeab0f77df5f6729d6ab6b141e4a84ee8eb9bc8c1e7918f94eda6d/greenlet-3.2.4-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:af41be48a4f60429d5cad9d22175217805098a9ef7c40bfef44f7669fb9d74d8", size = 1611228, upload-time = "2025-11-04T12:42:08.423Z" },
+    { url = "https://files.pythonhosted.org/packages/d6/6f/b60b0291d9623c496638c582297ead61f43c4b72eef5e9c926ef4565ec13/greenlet-3.2.4-cp310-cp310-win_amd64.whl", hash = "sha256:73f49b5368b5359d04e18d15828eecc1806033db5233397748f4ca813ff1056c", size = 298654, upload-time = "2025-08-07T13:50:00.469Z" },
+    { url = "https://files.pythonhosted.org/packages/a4/de/f28ced0a67749cac23fecb02b694f6473f47686dff6afaa211d186e2ef9c/greenlet-3.2.4-cp311-cp311-macosx_11_0_universal2.whl", hash = "sha256:96378df1de302bc38e99c3a9aa311967b7dc80ced1dcc6f171e99842987882a2", size = 272305, upload-time = "2025-08-07T13:15:41.288Z" },
+    { url = "https://files.pythonhosted.org/packages/09/16/2c3792cba130000bf2a31c5272999113f4764fd9d874fb257ff588ac779a/greenlet-3.2.4-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:1ee8fae0519a337f2329cb78bd7a8e128ec0f881073d43f023c7b8d4831d5246", size = 632472, upload-time = "2025-08-07T13:42:55.044Z" },
+    { url = "https://files.pythonhosted.org/packages/ae/8f/95d48d7e3d433e6dae5b1682e4292242a53f22df82e6d3dda81b1701a960/greenlet-3.2.4-cp311-cp311-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:94abf90142c2a18151632371140b3dba4dee031633fe614cb592dbb6c9e17bc3", size = 644646, upload-time = "2025-08-07T13:45:26.523Z" },
+    { url = "https://files.pythonhosted.org/packages/d5/5e/405965351aef8c76b8ef7ad370e5da58d57ef6068df197548b015464001a/greenlet-3.2.4-cp311-cp311-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:4d1378601b85e2e5171b99be8d2dc85f594c79967599328f95c1dc1a40f1c633", size = 640519, upload-time = "2025-08-07T13:53:13.928Z" },
+    { url = "https://files.pythonhosted.org/packages/25/5d/382753b52006ce0218297ec1b628e048c4e64b155379331f25a7316eb749/greenlet-3.2.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:0db5594dce18db94f7d1650d7489909b57afde4c580806b8d9203b6e79cdc079", size = 639707, upload-time = "2025-08-07T13:18:27.146Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/8e/abdd3f14d735b2929290a018ecf133c901be4874b858dd1c604b9319f064/greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:2523e5246274f54fdadbce8494458a2ebdcdbc7b802318466ac5606d3cded1f8", size = 587684, upload-time = "2025-08-07T13:18:25.164Z" },
+    { url = "https://files.pythonhosted.org/packages/5d/65/deb2a69c3e5996439b0176f6651e0052542bb6c8f8ec2e3fba97c9768805/greenlet-3.2.4-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:1987de92fec508535687fb807a5cea1560f6196285a4cde35c100b8cd632cc52", size = 1116647, upload-time = "2025-08-07T13:42:38.655Z" },
+    { url = "https://files.pythonhosted.org/packages/3f/cc/b07000438a29ac5cfb2194bfc128151d52f333cee74dd7dfe3fb733fc16c/greenlet-3.2.4-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:55e9c5affaa6775e2c6b67659f3a71684de4c549b3dd9afca3bc773533d284fa", size = 1142073, upload-time = "2025-08-07T13:18:21.737Z" },
+    { url = "https://files.pythonhosted.org/packages/67/24/28a5b2fa42d12b3d7e5614145f0bd89714c34c08be6aabe39c14dd52db34/greenlet-3.2.4-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:c9c6de1940a7d828635fbd254d69db79e54619f165ee7ce32fda763a9cb6a58c", size = 1548385, upload-time = "2025-11-04T12:42:11.067Z" },
+    { url = "https://files.pythonhosted.org/packages/6a/05/03f2f0bdd0b0ff9a4f7b99333d57b53a7709c27723ec8123056b084e69cd/greenlet-3.2.4-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:03c5136e7be905045160b1b9fdca93dd6727b180feeafda6818e6496434ed8c5", size = 1613329, upload-time = "2025-11-04T12:42:12.928Z" },
+    { url = "https://files.pythonhosted.org/packages/d8/0f/30aef242fcab550b0b3520b8e3561156857c94288f0332a79928c31a52cf/greenlet-3.2.4-cp311-cp311-win_amd64.whl", hash = "sha256:9c40adce87eaa9ddb593ccb0fa6a07caf34015a29bf8d344811665b573138db9", size = 299100, upload-time = "2025-08-07T13:44:12.287Z" },
+    { url = "https://files.pythonhosted.org/packages/44/69/9b804adb5fd0671f367781560eb5eb586c4d495277c93bde4307b9e28068/greenlet-3.2.4-cp312-cp312-macosx_11_0_universal2.whl", hash = "sha256:3b67ca49f54cede0186854a008109d6ee71f66bd57bb36abd6d0a0267b540cdd", size = 274079, upload-time = "2025-08-07T13:15:45.033Z" },
+    { url = "https://files.pythonhosted.org/packages/46/e9/d2a80c99f19a153eff70bc451ab78615583b8dac0754cfb942223d2c1a0d/greenlet-3.2.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:ddf9164e7a5b08e9d22511526865780a576f19ddd00d62f8a665949327fde8bb", size = 640997, upload-time = "2025-08-07T13:42:56.234Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/16/035dcfcc48715ccd345f3a93183267167cdd162ad123cd93067d86f27ce4/greenlet-3.2.4-cp312-cp312-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:f28588772bb5fb869a8eb331374ec06f24a83a9c25bfa1f38b6993afe9c1e968", size = 655185, upload-time = "2025-08-07T13:45:27.624Z" },
+    { url = "https://files.pythonhosted.org/packages/31/da/0386695eef69ffae1ad726881571dfe28b41970173947e7c558d9998de0f/greenlet-3.2.4-cp312-cp312-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:5c9320971821a7cb77cfab8d956fa8e39cd07ca44b6070db358ceb7f8797c8c9", size = 649926, upload-time = "2025-08-07T13:53:15.251Z" },
+    { url = "https://files.pythonhosted.org/packages/68/88/69bf19fd4dc19981928ceacbc5fd4bb6bc2215d53199e367832e98d1d8fe/greenlet-3.2.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:c60a6d84229b271d44b70fb6e5fa23781abb5d742af7b808ae3f6efd7c9c60f6", size = 651839, upload-time = "2025-08-07T13:18:30.281Z" },
+    { url = "https://files.pythonhosted.org/packages/19/0d/6660d55f7373b2ff8152401a83e02084956da23ae58cddbfb0b330978fe9/greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:3b3812d8d0c9579967815af437d96623f45c0f2ae5f04e366de62a12d83a8fb0", size = 607586, upload-time = "2025-08-07T13:18:28.544Z" },
+    { url = "https://files.pythonhosted.org/packages/8e/1a/c953fdedd22d81ee4629afbb38d2f9d71e37d23caace44775a3a969147d4/greenlet-3.2.4-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:abbf57b5a870d30c4675928c37278493044d7c14378350b3aa5d484fa65575f0", size = 1123281, upload-time = "2025-08-07T13:42:39.858Z" },
+    { url = "https://files.pythonhosted.org/packages/3f/c7/12381b18e21aef2c6bd3a636da1088b888b97b7a0362fac2e4de92405f97/greenlet-3.2.4-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:20fb936b4652b6e307b8f347665e2c615540d4b42b3b4c8a321d8286da7e520f", size = 1151142, upload-time = "2025-08-07T13:18:22.981Z" },
+    { url = "https://files.pythonhosted.org/packages/27/45/80935968b53cfd3f33cf99ea5f08227f2646e044568c9b1555b58ffd61c2/greenlet-3.2.4-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:ee7a6ec486883397d70eec05059353b8e83eca9168b9f3f9a361971e77e0bcd0", size = 1564846, upload-time = "2025-11-04T12:42:15.191Z" },
+    { url = "https://files.pythonhosted.org/packages/69/02/b7c30e5e04752cb4db6202a3858b149c0710e5453b71a3b2aec5d78a1aab/greenlet-3.2.4-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:326d234cbf337c9c3def0676412eb7040a35a768efc92504b947b3e9cfc7543d", size = 1633814, upload-time = "2025-11-04T12:42:17.175Z" },
+    { url = "https://files.pythonhosted.org/packages/e9/08/b0814846b79399e585f974bbeebf5580fbe59e258ea7be64d9dfb253c84f/greenlet-3.2.4-cp312-cp312-win_amd64.whl", hash = "sha256:a7d4e128405eea3814a12cc2605e0e6aedb4035bf32697f72deca74de4105e02", size = 299899, upload-time = "2025-08-07T13:38:53.448Z" },
+    { url = "https://files.pythonhosted.org/packages/49/e8/58c7f85958bda41dafea50497cbd59738c5c43dbbea5ee83d651234398f4/greenlet-3.2.4-cp313-cp313-macosx_11_0_universal2.whl", hash = "sha256:1a921e542453fe531144e91e1feedf12e07351b1cf6c9e8a3325ea600a715a31", size = 272814, upload-time = "2025-08-07T13:15:50.011Z" },
+    { url = "https://files.pythonhosted.org/packages/62/dd/b9f59862e9e257a16e4e610480cfffd29e3fae018a68c2332090b53aac3d/greenlet-3.2.4-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:cd3c8e693bff0fff6ba55f140bf390fa92c994083f838fece0f63be121334945", size = 641073, upload-time = "2025-08-07T13:42:57.23Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/0b/bc13f787394920b23073ca3b6c4a7a21396301ed75a655bcb47196b50e6e/greenlet-3.2.4-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:710638eb93b1fa52823aa91bf75326f9ecdfd5e0466f00789246a5280f4ba0fc", size = 655191, upload-time = "2025-08-07T13:45:29.752Z" },
+    { url = "https://files.pythonhosted.org/packages/f2/d6/6adde57d1345a8d0f14d31e4ab9c23cfe8e2cd39c3baf7674b4b0338d266/greenlet-3.2.4-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:c5111ccdc9c88f423426df3fd1811bfc40ed66264d35aa373420a34377efc98a", size = 649516, upload-time = "2025-08-07T13:53:16.314Z" },
+    { url = "https://files.pythonhosted.org/packages/7f/3b/3a3328a788d4a473889a2d403199932be55b1b0060f4ddd96ee7cdfcad10/greenlet-3.2.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:d76383238584e9711e20ebe14db6c88ddcedc1829a9ad31a584389463b5aa504", size = 652169, upload-time = "2025-08-07T13:18:32.861Z" },
+    { url = "https://files.pythonhosted.org/packages/ee/43/3cecdc0349359e1a527cbf2e3e28e5f8f06d3343aaf82ca13437a9aa290f/greenlet-3.2.4-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:23768528f2911bcd7e475210822ffb5254ed10d71f4028387e5a99b4c6699671", size = 610497, upload-time = "2025-08-07T13:18:31.636Z" },
+    { url = "https://files.pythonhosted.org/packages/b8/19/06b6cf5d604e2c382a6f31cafafd6f33d5dea706f4db7bdab184bad2b21d/greenlet-3.2.4-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:00fadb3fedccc447f517ee0d3fd8fe49eae949e1cd0f6a611818f4f6fb7dc83b", size = 1121662, upload-time = "2025-08-07T13:42:41.117Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/15/0d5e4e1a66fab130d98168fe984c509249c833c1a3c16806b90f253ce7b9/greenlet-3.2.4-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:d25c5091190f2dc0eaa3f950252122edbbadbb682aa7b1ef2f8af0f8c0afefae", size = 1149210, upload-time = "2025-08-07T13:18:24.072Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/53/f9c440463b3057485b8594d7a638bed53ba531165ef0ca0e6c364b5cc807/greenlet-3.2.4-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:6e343822feb58ac4d0a1211bd9399de2b3a04963ddeec21530fc426cc121f19b", size = 1564759, upload-time = "2025-11-04T12:42:19.395Z" },
+    { url = "https://files.pythonhosted.org/packages/47/e4/3bb4240abdd0a8d23f4f88adec746a3099f0d86bfedb623f063b2e3b4df0/greenlet-3.2.4-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:ca7f6f1f2649b89ce02f6f229d7c19f680a6238af656f61e0115b24857917929", size = 1634288, upload-time = "2025-11-04T12:42:21.174Z" },
+    { url = "https://files.pythonhosted.org/packages/0b/55/2321e43595e6801e105fcfdee02b34c0f996eb71e6ddffca6b10b7e1d771/greenlet-3.2.4-cp313-cp313-win_amd64.whl", hash = "sha256:554b03b6e73aaabec3745364d6239e9e012d64c68ccd0b8430c64ccc14939a8b", size = 299685, upload-time = "2025-08-07T13:24:38.824Z" },
+    { url = "https://files.pythonhosted.org/packages/22/5c/85273fd7cc388285632b0498dbbab97596e04b154933dfe0f3e68156c68c/greenlet-3.2.4-cp314-cp314-macosx_11_0_universal2.whl", hash = "sha256:49a30d5fda2507ae77be16479bdb62a660fa51b1eb4928b524975b3bde77b3c0", size = 273586, upload-time = "2025-08-07T13:16:08.004Z" },
+    { url = "https://files.pythonhosted.org/packages/d1/75/10aeeaa3da9332c2e761e4c50d4c3556c21113ee3f0afa2cf5769946f7a3/greenlet-3.2.4-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:299fd615cd8fc86267b47597123e3f43ad79c9d8a22bebdce535e53550763e2f", size = 686346, upload-time = "2025-08-07T13:42:59.944Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/aa/687d6b12ffb505a4447567d1f3abea23bd20e73a5bed63871178e0831b7a/greenlet-3.2.4-cp314-cp314-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:c17b6b34111ea72fc5a4e4beec9711d2226285f0386ea83477cbb97c30a3f3a5", size = 699218, upload-time = "2025-08-07T13:45:30.969Z" },
+    { url = "https://files.pythonhosted.org/packages/dc/8b/29aae55436521f1d6f8ff4e12fb676f3400de7fcf27fccd1d4d17fd8fecd/greenlet-3.2.4-cp314-cp314-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:b4a1870c51720687af7fa3e7cda6d08d801dae660f75a76f3845b642b4da6ee1", size = 694659, upload-time = "2025-08-07T13:53:17.759Z" },
+    { url = "https://files.pythonhosted.org/packages/92/2e/ea25914b1ebfde93b6fc4ff46d6864564fba59024e928bdc7de475affc25/greenlet-3.2.4-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:061dc4cf2c34852b052a8620d40f36324554bc192be474b9e9770e8c042fd735", size = 695355, upload-time = "2025-08-07T13:18:34.517Z" },
+    { url = "https://files.pythonhosted.org/packages/72/60/fc56c62046ec17f6b0d3060564562c64c862948c9d4bc8aa807cf5bd74f4/greenlet-3.2.4-cp314-cp314-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:44358b9bf66c8576a9f57a590d5f5d6e72fa4228b763d0e43fee6d3b06d3a337", size = 657512, upload-time = "2025-08-07T13:18:33.969Z" },
+    { url = "https://files.pythonhosted.org/packages/23/6e/74407aed965a4ab6ddd93a7ded3180b730d281c77b765788419484cdfeef/greenlet-3.2.4-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:2917bdf657f5859fbf3386b12d68ede4cf1f04c90c3a6bc1f013dd68a22e2269", size = 1612508, upload-time = "2025-11-04T12:42:23.427Z" },
+    { url = "https://files.pythonhosted.org/packages/0d/da/343cd760ab2f92bac1845ca07ee3faea9fe52bee65f7bcb19f16ad7de08b/greenlet-3.2.4-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:015d48959d4add5d6c9f6c5210ee3803a830dce46356e3bc326d6776bde54681", size = 1680760, upload-time = "2025-11-04T12:42:25.341Z" },
+    { url = "https://files.pythonhosted.org/packages/e3/a5/6ddab2b4c112be95601c13428db1d8b6608a8b6039816f2ba09c346c08fc/greenlet-3.2.4-cp314-cp314-win_amd64.whl", hash = "sha256:e37ab26028f12dbb0ff65f29a8d3d44a765c61e729647bf2ddfbbed621726f01", size = 303425, upload-time = "2025-08-07T13:32:27.59Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/c0/93885c4106d2626bf51fdec377d6aef740dfa5c4877461889a7cf8e565cc/greenlet-3.2.4-cp39-cp39-macosx_11_0_universal2.whl", hash = "sha256:b6a7c19cf0d2742d0809a4c05975db036fdff50cd294a93632d6a310bf9ac02c", size = 269859, upload-time = "2025-08-07T13:16:16.003Z" },
+    { url = "https://files.pythonhosted.org/packages/4d/f5/33f05dc3ba10a02dedb1485870cf81c109227d3d3aa280f0e48486cac248/greenlet-3.2.4-cp39-cp39-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:27890167f55d2387576d1f41d9487ef171849ea0359ce1510ca6e06c8bece11d", size = 627610, upload-time = "2025-08-07T13:43:01.345Z" },
+    { url = "https://files.pythonhosted.org/packages/b2/a7/9476decef51a0844195f99ed5dc611d212e9b3515512ecdf7321543a7225/greenlet-3.2.4-cp39-cp39-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:18d9260df2b5fbf41ae5139e1be4e796d99655f023a636cd0e11e6406cca7d58", size = 639417, upload-time = "2025-08-07T13:45:32.094Z" },
+    { url = "https://files.pythonhosted.org/packages/bd/e0/849b9159cbb176f8c0af5caaff1faffdece7a8417fcc6fe1869770e33e21/greenlet-3.2.4-cp39-cp39-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:671df96c1f23c4a0d4077a325483c1503c96a1b7d9db26592ae770daa41233d4", size = 634751, upload-time = "2025-08-07T13:53:18.848Z" },
+    { url = "https://files.pythonhosted.org/packages/5f/d3/844e714a9bbd39034144dca8b658dcd01839b72bb0ec7d8014e33e3705f0/greenlet-3.2.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:16458c245a38991aa19676900d48bd1a6f2ce3e16595051a4db9d012154e8433", size = 634020, upload-time = "2025-08-07T13:18:36.841Z" },
+    { url = "https://files.pythonhosted.org/packages/6b/4c/f3de2a8de0e840ecb0253ad0dc7e2bb3747348e798ec7e397d783a3cb380/greenlet-3.2.4-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:c9913f1a30e4526f432991f89ae263459b1c64d1608c0d22a5c79c287b3c70df", size = 582817, upload-time = "2025-08-07T13:18:35.48Z" },
+    { url = "https://files.pythonhosted.org/packages/89/80/7332915adc766035c8980b161c2e5d50b2f941f453af232c164cff5e0aeb/greenlet-3.2.4-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:b90654e092f928f110e0007f572007c9727b5265f7632c2fa7415b4689351594", size = 1111985, upload-time = "2025-08-07T13:42:42.425Z" },
+    { url = "https://files.pythonhosted.org/packages/66/71/1928e2c80197353bcb9b50aa19c4d8e26ee6d7a900c564907665cf4b9a41/greenlet-3.2.4-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:81701fd84f26330f0d5f4944d4e92e61afe6319dcd9775e39396e39d7c3e5f98", size = 1136137, upload-time = "2025-08-07T13:18:26.168Z" },
+    { url = "https://files.pythonhosted.org/packages/4b/bf/7bd33643e48ed45dcc0e22572f650767832bd4e1287f97434943cc402148/greenlet-3.2.4-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:28a3c6b7cd72a96f61b0e4b2a36f681025b60ae4779cc73c1535eb5f29560b10", size = 1542941, upload-time = "2025-11-04T12:42:27.427Z" },
+    { url = "https://files.pythonhosted.org/packages/9b/74/4bc433f91d0d09a1c22954a371f9df928cb85e72640870158853a83415e5/greenlet-3.2.4-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:52206cd642670b0b320a1fd1cbfd95bca0e043179c1d8a045f2c6109dfe973be", size = 1609685, upload-time = "2025-11-04T12:42:29.242Z" },
+    { url = "https://files.pythonhosted.org/packages/89/48/a5dc74dde38aeb2b15d418cec76ed50e1dd3d620ccda84d8199703248968/greenlet-3.2.4-cp39-cp39-win32.whl", hash = "sha256:65458b409c1ed459ea899e939f0e1cdb14f58dbc803f2f93c5eab5694d32671b", size = 281400, upload-time = "2025-08-07T14:02:20.263Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/44/342c4591db50db1076b8bda86ed0ad59240e3e1da17806a4cf10a6d0e447/greenlet-3.2.4-cp39-cp39-win_amd64.whl", hash = "sha256:d2e685ade4dafd447ede19c31277a224a239a0a1a4eca4e6390efedf20260cfb", size = 298533, upload-time = "2025-08-07T13:56:34.168Z" },
+]
+
 [[package]]
 name = "idna"
 version = "3.11"
@@ -452,14 +883,14 @@ wheels = [
 
 [[package]]
 name = "importlib-metadata"
-version = "8.7.0"
+version = "6.11.0"
 source = { registry = "https://pypi.org/simple" }
 dependencies = [
-    { name = "zipp", marker = "python_full_version < '3.10'" },
+    { name = "zipp" },
 ]
-sdist = { url = "https://files.pythonhosted.org/packages/76/66/650a33bd90f786193e4de4b3ad86ea60b53c89b669a5c7be931fac31cdb0/importlib_metadata-8.7.0.tar.gz", hash = "sha256:d13b81ad223b890aa16c5471f2ac3056cf76c5f10f82d6f9292f0b415f389000", size = 56641, upload-time = "2025-04-27T15:29:01.736Z" }
+sdist = { url = "https://files.pythonhosted.org/packages/ee/eb/58c2ab27ee628ad801f56d4017fe62afab0293116f6d0b08f1d5bd46e06f/importlib_metadata-6.11.0.tar.gz", hash = "sha256:1231cf92d825c9e03cfc4da076a16de6422c863558229ea0b22b675657463443", size = 54593, upload-time = "2023-12-03T17:33:10.693Z" }
 wheels = [
-    { url = "https://files.pythonhosted.org/packages/20/b0/36bd937216ec521246249be3bf9855081de4c5e06a0c9b4219dbeda50373/importlib_metadata-8.7.0-py3-none-any.whl", hash = "sha256:e5dd1551894c77868a30651cef00984d50e1002d06942a7101d34870c5f02afd", size = 27656, upload-time = "2025-04-27T15:29:00.214Z" },
+    { url = "https://files.pythonhosted.org/packages/59/9b/ecce94952ab5ea74c31dcf9ccf78ccd484eebebef06019bf8cb579ab4519/importlib_metadata-6.11.0-py3-none-any.whl", hash = "sha256:f0afba6205ad8f8947c7d338b5342d5db2afbfd82f9cbef7879a9539cc12eb9b", size = 23427, upload-time = "2023-12-03T17:33:08.965Z" },
 ]
 
 [[package]]
@@ -479,7 +910,10 @@ name = "iniconfig"
 version = "2.3.0"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -520,7 +954,10 @@ name = "ipykernel"
 version = "7.1.0"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -600,7 +1037,10 @@ name = "ipython"
 version = "9.7.0"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
 ]
 dependencies = [
@@ -633,6 +1073,54 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/d9/33/1f075bf72b0b747cb3288d011319aaf64083cf2efef8354174e3ed4540e2/ipython_pygments_lexers-1.1.1-py3-none-any.whl", hash = "sha256:a9462224a505ade19a605f71f8fa63c2048833ce50abc86768a0d81d876dc81c", size = 8074, upload-time = "2025-01-17T11:24:33.271Z" },
 ]
 
+[[package]]
+name = "isodate"
+version = "0.6.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "six" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/db/7a/c0a56c7d56c7fa723988f122fa1f1ccf8c5c4ccc48efad0d214b49e5b1af/isodate-0.6.1.tar.gz", hash = "sha256:48c5881de7e8b0a0d648cb024c8062dc84e7b840ed81e864c7614fd3c127bde9", size = 28443, upload-time = "2021-12-13T20:28:31.525Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b6/85/7882d311924cbcfc70b1890780763e36ff0b140c7e51c110fc59a532f087/isodate-0.6.1-py2.py3-none-any.whl", hash = "sha256:0751eece944162659049d35f4f549ed815792b38793f07cf73381c1c87cbed96", size = 41722, upload-time = "2021-12-13T20:28:29.073Z" },
+]
+
+[[package]]
+name = "jaraco-classes"
+version = "3.4.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "more-itertools" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/06/c0/ed4a27bc5571b99e3cff68f8a9fa5b56ff7df1c2251cc715a652ddd26402/jaraco.classes-3.4.0.tar.gz", hash = "sha256:47a024b51d0239c0dd8c8540c6c7f484be3b8fcf0b2d85c13825780d3b3f3acd", size = 11780, upload-time = "2024-03-31T07:27:36.643Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/7f/66/b15ce62552d84bbfcec9a4873ab79d993a1dd4edb922cbfccae192bd5b5f/jaraco.classes-3.4.0-py3-none-any.whl", hash = "sha256:f662826b6bed8cace05e7ff873ce0f9283b5c924470fe664fff1c2f00f581790", size = 6777, upload-time = "2024-03-31T07:27:34.792Z" },
+]
+
+[[package]]
+name = "jaraco-context"
+version = "6.0.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "backports-tarfile", marker = "python_full_version < '3.12'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/df/ad/f3777b81bf0b6e7bc7514a1656d3e637b2e8e15fab2ce3235730b3e7a4e6/jaraco_context-6.0.1.tar.gz", hash = "sha256:9bae4ea555cf0b14938dc0aee7c9f32ed303aa20a3b73e7dc80111628792d1b3", size = 13912, upload-time = "2024-08-20T03:39:27.358Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/ff/db/0c52c4cf5e4bd9f5d7135ec7669a3a767af21b3a308e1ed3674881e52b62/jaraco.context-6.0.1-py3-none-any.whl", hash = "sha256:f797fc481b490edb305122c9181830a3a5b76d84ef6d1aef2fb9b47ab956f9e4", size = 6825, upload-time = "2024-08-20T03:39:25.966Z" },
+]
+
+[[package]]
+name = "jaraco-functools"
+version = "4.3.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "more-itertools" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/f7/ed/1aa2d585304ec07262e1a83a9889880701079dde796ac7b1d1826f40c63d/jaraco_functools-4.3.0.tar.gz", hash = "sha256:cfd13ad0dd2c47a3600b439ef72d8615d482cedcff1632930d6f28924d92f294", size = 19755, upload-time = "2025-08-18T20:05:09.91Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b4/09/726f168acad366b11e420df31bf1c702a54d373a83f968d94141a8c3fde0/jaraco_functools-4.3.0-py3-none-any.whl", hash = "sha256:227ff8ed6f7b8f62c56deff101545fa7543cf2c8e7b82a7c2116e672f29c26e8", size = 10408, upload-time = "2025-08-18T20:05:08.69Z" },
+]
+
 [[package]]
 name = "jedi"
 version = "0.19.2"
@@ -645,6 +1133,15 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/c0/5a/9cac0c82afec3d09ccd97c8b6502d48f165f9124db81b4bcb90b4af974ee/jedi-0.19.2-py2.py3-none-any.whl", hash = "sha256:a8ef22bde8490f57fe5c7681a3c83cb58874daf72b4784de3cce5b6ef6edb5b9", size = 1572278, upload-time = "2024-11-11T01:41:40.175Z" },
 ]
 
+[[package]]
+name = "jeepney"
+version = "0.9.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/7b/6f/357efd7602486741aa73ffc0617fb310a29b588ed0fd69c2399acbb85b0c/jeepney-0.9.0.tar.gz", hash = "sha256:cf0e9e845622b81e4a28df94c40345400256ec608d0e55bb8a3feaa9163f5732", size = 106758, upload-time = "2025-02-27T18:51:01.684Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b2/a3/e137168c9c44d18eff0376253da9f1e9234d0239e0ee230d2fee6cea8e55/jeepney-0.9.0-py3-none-any.whl", hash = "sha256:97e5714520c16fc0a45695e5365a2e11b81ea79bba796e26f9f1d178cb182683", size = 49010, upload-time = "2025-02-27T18:51:00.104Z" },
+]
+
 [[package]]
 name = "jinja2"
 version = "3.1.6"
@@ -657,6 +1154,36 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl", hash = "sha256:85ece4451f492d0c13c5dd7c13a64681a86afae63a5f347908daf103ce6d2f67", size = 134899, upload-time = "2025-03-05T20:05:00.369Z" },
 ]
 
+[[package]]
+name = "jsonschema"
+version = "4.25.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "attrs" },
+    { name = "jsonschema-specifications" },
+    { name = "referencing", version = "0.36.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "referencing", version = "0.37.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "rpds-py", version = "0.27.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "rpds-py", version = "0.29.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/74/69/f7185de793a29082a9f3c7728268ffb31cb5095131a9c139a74078e27336/jsonschema-4.25.1.tar.gz", hash = "sha256:e4a9655ce0da0c0b67a085847e00a3a51449e1157f4f75e9fb5aa545e122eb85", size = 357342, upload-time = "2025-08-18T17:03:50.038Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/bf/9c/8c95d856233c1f82500c2450b8c68576b4cf1c871db3afac5c34ff84e6fd/jsonschema-4.25.1-py3-none-any.whl", hash = "sha256:3fba0169e345c7175110351d456342c364814cfcf3b964ba4587f22915230a63", size = 90040, upload-time = "2025-08-18T17:03:48.373Z" },
+]
+
+[[package]]
+name = "jsonschema-specifications"
+version = "2025.9.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "referencing", version = "0.36.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "referencing", version = "0.37.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/19/74/a633ee74eb36c44aa6d1095e7cc5569bebf04342ee146178e2d36600708b/jsonschema_specifications-2025.9.1.tar.gz", hash = "sha256:b540987f239e745613c7a9176f3edb72b832a4ac465cf02712288397832b5e8d", size = 32855, upload-time = "2025-09-08T01:34:59.186Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/41/45/1a4ed80516f02155c51f51e8cedb3c1902296743db0bbc66608a0db2814f/jsonschema_specifications-2025.9.1-py3-none-any.whl", hash = "sha256:98802fee3a11ee76ecaca44429fda8a41bff98b00a0f2838151b113f210cc6fe", size = 18437, upload-time = "2025-09-08T01:34:57.871Z" },
+]
+
 [[package]]
 name = "jupyter-client"
 version = "8.6.3"
@@ -697,7 +1224,10 @@ name = "jupyter-core"
 version = "5.9.1"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -710,12 +1240,122 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/e7/e7/80988e32bf6f73919a113473a604f5a8f09094de312b9d52b79c2df7612b/jupyter_core-5.9.1-py3-none-any.whl", hash = "sha256:ebf87fdc6073d142e114c72c9e29a9d7ca03fad818c5d300ce2adc1fb0743407", size = 29032, upload-time = "2025-10-16T19:19:16.783Z" },
 ]
 
+[[package]]
+name = "keyring"
+version = "25.7.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "importlib-metadata", marker = "python_full_version < '3.12'" },
+    { name = "jaraco-classes" },
+    { name = "jaraco-context" },
+    { name = "jaraco-functools" },
+    { name = "jeepney", marker = "sys_platform == 'linux'" },
+    { name = "pywin32-ctypes", marker = "sys_platform == 'win32'" },
+    { name = "secretstorage", version = "3.3.3", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10' and sys_platform == 'linux'" },
+    { name = "secretstorage", version = "3.4.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10' and sys_platform == 'linux'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/43/4b/674af6ef2f97d56f0ab5153bf0bfa28ccb6c3ed4d1babf4305449668807b/keyring-25.7.0.tar.gz", hash = "sha256:fe01bd85eb3f8fb3dd0405defdeac9a5b4f6f0439edbb3149577f244a2e8245b", size = 63516, upload-time = "2025-11-16T16:26:09.482Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/81/db/e655086b7f3a705df045bf0933bdd9c2f79bb3c97bfef1384598bb79a217/keyring-25.7.0-py3-none-any.whl", hash = "sha256:be4a0b195f149690c166e850609a477c532ddbfbaed96a404d4e43f8d5e2689f", size = 39160, upload-time = "2025-11-16T16:26:08.402Z" },
+]
+
+[[package]]
+name = "leather"
+version = "0.4.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/ed/6e/48a05e2f7f62a616d675cfee182643f2dd8023bf7429aa326f4bebd629c8/leather-0.4.0.tar.gz", hash = "sha256:f964bec2086f3153a6c16e707f20cb718f811f57af116075f4c0f4805c608b95", size = 43877, upload-time = "2024-02-23T22:03:36.657Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a1/30/9ec597c962c5249ebd5c580386e4b5f2884cd943af42634291ee3b406415/leather-0.4.0-py2.py3-none-any.whl", hash = "sha256:18290bc93749ae39039af5e31e871fcfad74d26c4c3ea28ea4f681f4571b3a2b", size = 30256, upload-time = "2024-02-23T22:03:34.75Z" },
+]
+
+[[package]]
+name = "logbook"
+version = "1.5.3"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/2f/d9/16ac346f7c0102835814cc9e5b684aaadea101560bb932a2403bd26b2320/Logbook-1.5.3.tar.gz", hash = "sha256:66f454ada0f56eae43066f604a222b09893f98c1adc18df169710761b8f32fe8", size = 85783, upload-time = "2019-10-16T18:00:26.666Z" }
+
 [[package]]
 name = "logging"
 version = "0.4.9.6"
 source = { registry = "https://pypi.org/simple" }
 sdist = { url = "https://files.pythonhosted.org/packages/93/4b/979db9e44be09f71e85c9c8cfc42f258adfb7d93ce01deed2788b2948919/logging-0.4.9.6.tar.gz", hash = "sha256:26f6b50773f085042d301085bd1bf5d9f3735704db9f37c1ce6d8b85c38f2417", size = 96029, upload-time = "2013-06-04T23:43:22.086Z" }
 
+[[package]]
+name = "lz4"
+version = "4.4.5"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/57/51/f1b86d93029f418033dddf9b9f79c8d2641e7454080478ee2aab5123173e/lz4-4.4.5.tar.gz", hash = "sha256:5f0b9e53c1e82e88c10d7c180069363980136b9d7a8306c4dca4f760d60c39f0", size = 172886, upload-time = "2025-11-03T13:02:36.061Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/7b/45/2466d73d79e3940cad4b26761f356f19fd33f4409c96f100e01a5c566909/lz4-4.4.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:d221fa421b389ab2345640a508db57da36947a437dfe31aeddb8d5c7b646c22d", size = 207396, upload-time = "2025-11-03T13:01:24.965Z" },
+    { url = "https://files.pythonhosted.org/packages/72/12/7da96077a7e8918a5a57a25f1254edaf76aefb457666fcc1066deeecd609/lz4-4.4.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:7dc1e1e2dbd872f8fae529acd5e4839efd0b141eaa8ae7ce835a9fe80fbad89f", size = 207154, upload-time = "2025-11-03T13:01:26.922Z" },
+    { url = "https://files.pythonhosted.org/packages/b8/0e/0fb54f84fd1890d4af5bc0a3c1fa69678451c1a6bd40de26ec0561bb4ec5/lz4-4.4.5-cp310-cp310-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:e928ec2d84dc8d13285b4a9288fd6246c5cde4f5f935b479f50d986911f085e3", size = 1291053, upload-time = "2025-11-03T13:01:28.396Z" },
+    { url = "https://files.pythonhosted.org/packages/15/45/8ce01cc2715a19c9e72b0e423262072c17d581a8da56e0bd4550f3d76a79/lz4-4.4.5-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:daffa4807ef54b927451208f5f85750c545a4abbff03d740835fc444cd97f758", size = 1278586, upload-time = "2025-11-03T13:01:29.906Z" },
+    { url = "https://files.pythonhosted.org/packages/6d/34/7be9b09015e18510a09b8d76c304d505a7cbc66b775ec0b8f61442316818/lz4-4.4.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:2a2b7504d2dffed3fd19d4085fe1cc30cf221263fd01030819bdd8d2bb101cf1", size = 1367315, upload-time = "2025-11-03T13:01:31.054Z" },
+    { url = "https://files.pythonhosted.org/packages/2a/94/52cc3ec0d41e8d68c985ec3b2d33631f281d8b748fb44955bc0384c2627b/lz4-4.4.5-cp310-cp310-win32.whl", hash = "sha256:0846e6e78f374156ccf21c631de80967e03cc3c01c373c665789dc0c5431e7fc", size = 88173, upload-time = "2025-11-03T13:01:32.643Z" },
+    { url = "https://files.pythonhosted.org/packages/ca/35/c3c0bdc409f551404355aeeabc8da343577d0e53592368062e371a3620e1/lz4-4.4.5-cp310-cp310-win_amd64.whl", hash = "sha256:7c4e7c44b6a31de77d4dc9772b7d2561937c9588a734681f70ec547cfbc51ecd", size = 99492, upload-time = "2025-11-03T13:01:33.813Z" },
+    { url = "https://files.pythonhosted.org/packages/1d/02/4d88de2f1e97f9d05fd3d278fe412b08969bc94ff34942f5a3f09318144a/lz4-4.4.5-cp310-cp310-win_arm64.whl", hash = "sha256:15551280f5656d2206b9b43262799c89b25a25460416ec554075a8dc568e4397", size = 91280, upload-time = "2025-11-03T13:01:35.081Z" },
+    { url = "https://files.pythonhosted.org/packages/93/5b/6edcd23319d9e28b1bedf32768c3d1fd56eed8223960a2c47dacd2cec2af/lz4-4.4.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:d6da84a26b3aa5da13a62e4b89ab36a396e9327de8cd48b436a3467077f8ccd4", size = 207391, upload-time = "2025-11-03T13:01:36.644Z" },
+    { url = "https://files.pythonhosted.org/packages/34/36/5f9b772e85b3d5769367a79973b8030afad0d6b724444083bad09becd66f/lz4-4.4.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:61d0ee03e6c616f4a8b69987d03d514e8896c8b1b7cc7598ad029e5c6aedfd43", size = 207146, upload-time = "2025-11-03T13:01:37.928Z" },
+    { url = "https://files.pythonhosted.org/packages/04/f4/f66da5647c0d72592081a37c8775feacc3d14d2625bbdaabd6307c274565/lz4-4.4.5-cp311-cp311-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:33dd86cea8375d8e5dd001e41f321d0a4b1eb7985f39be1b6a4f466cd480b8a7", size = 1292623, upload-time = "2025-11-03T13:01:39.341Z" },
+    { url = "https://files.pythonhosted.org/packages/85/fc/5df0f17467cdda0cad464a9197a447027879197761b55faad7ca29c29a04/lz4-4.4.5-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:609a69c68e7cfcfa9d894dc06be13f2e00761485b62df4e2472f1b66f7b405fb", size = 1279982, upload-time = "2025-11-03T13:01:40.816Z" },
+    { url = "https://files.pythonhosted.org/packages/25/3b/b55cb577aa148ed4e383e9700c36f70b651cd434e1c07568f0a86c9d5fbb/lz4-4.4.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:75419bb1a559af00250b8f1360d508444e80ed4b26d9d40ec5b09fe7875cb989", size = 1368674, upload-time = "2025-11-03T13:01:42.118Z" },
+    { url = "https://files.pythonhosted.org/packages/fb/31/e97e8c74c59ea479598e5c55cbe0b1334f03ee74ca97726e872944ed42df/lz4-4.4.5-cp311-cp311-win32.whl", hash = "sha256:12233624f1bc2cebc414f9efb3113a03e89acce3ab6f72035577bc61b270d24d", size = 88168, upload-time = "2025-11-03T13:01:43.282Z" },
+    { url = "https://files.pythonhosted.org/packages/18/47/715865a6c7071f417bef9b57c8644f29cb7a55b77742bd5d93a609274e7e/lz4-4.4.5-cp311-cp311-win_amd64.whl", hash = "sha256:8a842ead8ca7c0ee2f396ca5d878c4c40439a527ebad2b996b0444f0074ed004", size = 99491, upload-time = "2025-11-03T13:01:44.167Z" },
+    { url = "https://files.pythonhosted.org/packages/14/e7/ac120c2ca8caec5c945e6356ada2aa5cfabd83a01e3170f264a5c42c8231/lz4-4.4.5-cp311-cp311-win_arm64.whl", hash = "sha256:83bc23ef65b6ae44f3287c38cbf82c269e2e96a26e560aa551735883388dcc4b", size = 91271, upload-time = "2025-11-03T13:01:45.016Z" },
+    { url = "https://files.pythonhosted.org/packages/1b/ac/016e4f6de37d806f7cc8f13add0a46c9a7cfc41a5ddc2bc831d7954cf1ce/lz4-4.4.5-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:df5aa4cead2044bab83e0ebae56e0944cc7fcc1505c7787e9e1057d6d549897e", size = 207163, upload-time = "2025-11-03T13:01:45.895Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/df/0fadac6e5bd31b6f34a1a8dbd4db6a7606e70715387c27368586455b7fc9/lz4-4.4.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:6d0bf51e7745484d2092b3a51ae6eb58c3bd3ce0300cf2b2c14f76c536d5697a", size = 207150, upload-time = "2025-11-03T13:01:47.205Z" },
+    { url = "https://files.pythonhosted.org/packages/b7/17/34e36cc49bb16ca73fb57fbd4c5eaa61760c6b64bce91fcb4e0f4a97f852/lz4-4.4.5-cp312-cp312-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:7b62f94b523c251cf32aa4ab555f14d39bd1a9df385b72443fd76d7c7fb051f5", size = 1292045, upload-time = "2025-11-03T13:01:48.667Z" },
+    { url = "https://files.pythonhosted.org/packages/90/1c/b1d8e3741e9fc89ed3b5f7ef5f22586c07ed6bb04e8343c2e98f0fa7ff04/lz4-4.4.5-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:2c3ea562c3af274264444819ae9b14dbbf1ab070aff214a05e97db6896c7597e", size = 1279546, upload-time = "2025-11-03T13:01:50.159Z" },
+    { url = "https://files.pythonhosted.org/packages/55/d9/e3867222474f6c1b76e89f3bd914595af69f55bf2c1866e984c548afdc15/lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:24092635f47538b392c4eaeff14c7270d2c8e806bf4be2a6446a378591c5e69e", size = 1368249, upload-time = "2025-11-03T13:01:51.273Z" },
+    { url = "https://files.pythonhosted.org/packages/b2/e7/d667d337367686311c38b580d1ca3d5a23a6617e129f26becd4f5dc458df/lz4-4.4.5-cp312-cp312-win32.whl", hash = "sha256:214e37cfe270948ea7eb777229e211c601a3e0875541c1035ab408fbceaddf50", size = 88189, upload-time = "2025-11-03T13:01:52.605Z" },
+    { url = "https://files.pythonhosted.org/packages/a5/0b/a54cd7406995ab097fceb907c7eb13a6ddd49e0b231e448f1a81a50af65c/lz4-4.4.5-cp312-cp312-win_amd64.whl", hash = "sha256:713a777de88a73425cf08eb11f742cd2c98628e79a8673d6a52e3c5f0c116f33", size = 99497, upload-time = "2025-11-03T13:01:53.477Z" },
+    { url = "https://files.pythonhosted.org/packages/6a/7e/dc28a952e4bfa32ca16fa2eb026e7a6ce5d1411fcd5986cd08c74ec187b9/lz4-4.4.5-cp312-cp312-win_arm64.whl", hash = "sha256:a88cbb729cc333334ccfb52f070463c21560fca63afcf636a9f160a55fac3301", size = 91279, upload-time = "2025-11-03T13:01:54.419Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/46/08fd8ef19b782f301d56a9ccfd7dafec5fd4fc1a9f017cf22a1accb585d7/lz4-4.4.5-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:6bb05416444fafea170b07181bc70640975ecc2a8c92b3b658c554119519716c", size = 207171, upload-time = "2025-11-03T13:01:56.595Z" },
+    { url = "https://files.pythonhosted.org/packages/8f/3f/ea3334e59de30871d773963997ecdba96c4584c5f8007fd83cfc8f1ee935/lz4-4.4.5-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:b424df1076e40d4e884cfcc4c77d815368b7fb9ebcd7e634f937725cd9a8a72a", size = 207163, upload-time = "2025-11-03T13:01:57.721Z" },
+    { url = "https://files.pythonhosted.org/packages/41/7b/7b3a2a0feb998969f4793c650bb16eff5b06e80d1f7bff867feb332f2af2/lz4-4.4.5-cp313-cp313-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:216ca0c6c90719731c64f41cfbd6f27a736d7e50a10b70fad2a9c9b262ec923d", size = 1292136, upload-time = "2025-11-03T13:02:00.375Z" },
+    { url = "https://files.pythonhosted.org/packages/89/d1/f1d259352227bb1c185288dd694121ea303e43404aa77560b879c90e7073/lz4-4.4.5-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:533298d208b58b651662dd972f52d807d48915176e5b032fb4f8c3b6f5fe535c", size = 1279639, upload-time = "2025-11-03T13:02:01.649Z" },
+    { url = "https://files.pythonhosted.org/packages/d2/fb/ba9256c48266a09012ed1d9b0253b9aa4fe9cdff094f8febf5b26a4aa2a2/lz4-4.4.5-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:451039b609b9a88a934800b5fc6ee401c89ad9c175abf2f4d9f8b2e4ef1afc64", size = 1368257, upload-time = "2025-11-03T13:02:03.35Z" },
+    { url = "https://files.pythonhosted.org/packages/a5/6d/dee32a9430c8b0e01bbb4537573cabd00555827f1a0a42d4e24ca803935c/lz4-4.4.5-cp313-cp313-win32.whl", hash = "sha256:a5f197ffa6fc0e93207b0af71b302e0a2f6f29982e5de0fbda61606dd3a55832", size = 88191, upload-time = "2025-11-03T13:02:04.406Z" },
+    { url = "https://files.pythonhosted.org/packages/18/e0/f06028aea741bbecb2a7e9648f4643235279a770c7ffaf70bd4860c73661/lz4-4.4.5-cp313-cp313-win_amd64.whl", hash = "sha256:da68497f78953017deb20edff0dba95641cc86e7423dfadf7c0264e1ac60dc22", size = 99502, upload-time = "2025-11-03T13:02:05.886Z" },
+    { url = "https://files.pythonhosted.org/packages/61/72/5bef44afb303e56078676b9f2486f13173a3c1e7f17eaac1793538174817/lz4-4.4.5-cp313-cp313-win_arm64.whl", hash = "sha256:c1cfa663468a189dab510ab231aad030970593f997746d7a324d40104db0d0a9", size = 91285, upload-time = "2025-11-03T13:02:06.77Z" },
+    { url = "https://files.pythonhosted.org/packages/49/55/6a5c2952971af73f15ed4ebfdd69774b454bd0dc905b289082ca8664fba1/lz4-4.4.5-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:67531da3b62f49c939e09d56492baf397175ff39926d0bd5bd2d191ac2bff95f", size = 207348, upload-time = "2025-11-03T13:02:08.117Z" },
+    { url = "https://files.pythonhosted.org/packages/4e/d7/fd62cbdbdccc35341e83aabdb3f6d5c19be2687d0a4eaf6457ddf53bba64/lz4-4.4.5-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:a1acbbba9edbcbb982bc2cac5e7108f0f553aebac1040fbec67a011a45afa1ba", size = 207340, upload-time = "2025-11-03T13:02:09.152Z" },
+    { url = "https://files.pythonhosted.org/packages/77/69/225ffadaacb4b0e0eb5fd263541edd938f16cd21fe1eae3cd6d5b6a259dc/lz4-4.4.5-cp313-cp313t-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:a482eecc0b7829c89b498fda883dbd50e98153a116de612ee7c111c8bcf82d1d", size = 1293398, upload-time = "2025-11-03T13:02:10.272Z" },
+    { url = "https://files.pythonhosted.org/packages/c6/9e/2ce59ba4a21ea5dc43460cba6f34584e187328019abc0e66698f2b66c881/lz4-4.4.5-cp313-cp313t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:e099ddfaa88f59dd8d36c8a3c66bd982b4984edf127eb18e30bb49bdba68ce67", size = 1281209, upload-time = "2025-11-03T13:02:12.091Z" },
+    { url = "https://files.pythonhosted.org/packages/80/4f/4d946bd1624ec229b386a3bc8e7a85fa9a963d67d0a62043f0af0978d3da/lz4-4.4.5-cp313-cp313t-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a2af2897333b421360fdcce895c6f6281dc3fab018d19d341cf64d043fc8d90d", size = 1369406, upload-time = "2025-11-03T13:02:13.683Z" },
+    { url = "https://files.pythonhosted.org/packages/02/a2/d429ba4720a9064722698b4b754fb93e42e625f1318b8fe834086c7c783b/lz4-4.4.5-cp313-cp313t-win32.whl", hash = "sha256:66c5de72bf4988e1b284ebdd6524c4bead2c507a2d7f172201572bac6f593901", size = 88325, upload-time = "2025-11-03T13:02:14.743Z" },
+    { url = "https://files.pythonhosted.org/packages/4b/85/7ba10c9b97c06af6c8f7032ec942ff127558863df52d866019ce9d2425cf/lz4-4.4.5-cp313-cp313t-win_amd64.whl", hash = "sha256:cdd4bdcbaf35056086d910d219106f6a04e1ab0daa40ec0eeef1626c27d0fddb", size = 99643, upload-time = "2025-11-03T13:02:15.978Z" },
+    { url = "https://files.pythonhosted.org/packages/77/4d/a175459fb29f909e13e57c8f475181ad8085d8d7869bd8ad99033e3ee5fa/lz4-4.4.5-cp313-cp313t-win_arm64.whl", hash = "sha256:28ccaeb7c5222454cd5f60fcd152564205bcb801bd80e125949d2dfbadc76bbd", size = 91504, upload-time = "2025-11-03T13:02:17.313Z" },
+    { url = "https://files.pythonhosted.org/packages/63/9c/70bdbdb9f54053a308b200b4678afd13efd0eafb6ddcbb7f00077213c2e5/lz4-4.4.5-cp314-cp314-macosx_10_15_x86_64.whl", hash = "sha256:c216b6d5275fc060c6280936bb3bb0e0be6126afb08abccde27eed23dead135f", size = 207586, upload-time = "2025-11-03T13:02:18.263Z" },
+    { url = "https://files.pythonhosted.org/packages/b6/cb/bfead8f437741ce51e14b3c7d404e3a1f6b409c440bad9b8f3945d4c40a7/lz4-4.4.5-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:c8e71b14938082ebaf78144f3b3917ac715f72d14c076f384a4c062df96f9df6", size = 207161, upload-time = "2025-11-03T13:02:19.286Z" },
+    { url = "https://files.pythonhosted.org/packages/e7/18/b192b2ce465dfbeabc4fc957ece7a1d34aded0d95a588862f1c8a86ac448/lz4-4.4.5-cp314-cp314-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:9b5e6abca8df9f9bdc5c3085f33ff32cdc86ed04c65e0355506d46a5ac19b6e9", size = 1292415, upload-time = "2025-11-03T13:02:20.829Z" },
+    { url = "https://files.pythonhosted.org/packages/67/79/a4e91872ab60f5e89bfad3e996ea7dc74a30f27253faf95865771225ccba/lz4-4.4.5-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:3b84a42da86e8ad8537aabef062e7f661f4a877d1c74d65606c49d835d36d668", size = 1279920, upload-time = "2025-11-03T13:02:22.013Z" },
+    { url = "https://files.pythonhosted.org/packages/f1/01/d52c7b11eaa286d49dae619c0eec4aabc0bf3cda7a7467eb77c62c4471f3/lz4-4.4.5-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:0bba042ec5a61fa77c7e380351a61cb768277801240249841defd2ff0a10742f", size = 1368661, upload-time = "2025-11-03T13:02:23.208Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/da/137ddeea14c2cb86864838277b2607d09f8253f152156a07f84e11768a28/lz4-4.4.5-cp314-cp314-win32.whl", hash = "sha256:bd85d118316b53ed73956435bee1997bd06cc66dd2fa74073e3b1322bd520a67", size = 90139, upload-time = "2025-11-03T13:02:24.301Z" },
+    { url = "https://files.pythonhosted.org/packages/18/2c/8332080fd293f8337779a440b3a143f85e374311705d243439a3349b81ad/lz4-4.4.5-cp314-cp314-win_amd64.whl", hash = "sha256:92159782a4502858a21e0079d77cdcaade23e8a5d252ddf46b0652604300d7be", size = 101497, upload-time = "2025-11-03T13:02:25.187Z" },
+    { url = "https://files.pythonhosted.org/packages/ca/28/2635a8141c9a4f4bc23f5135a92bbcf48d928d8ca094088c962df1879d64/lz4-4.4.5-cp314-cp314-win_arm64.whl", hash = "sha256:d994b87abaa7a88ceb7a37c90f547b8284ff9da694e6afcfaa8568d739faf3f7", size = 93812, upload-time = "2025-11-03T13:02:26.133Z" },
+    { url = "https://files.pythonhosted.org/packages/da/34/508f2ee73c126e4de53a3b8523ad14d666aeb00a6795425315f770dbf2f4/lz4-4.4.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:f6538aaaedd091d6e5abdaa19b99e6e82697d67518f114721b5248709b639fad", size = 207384, upload-time = "2025-11-03T13:02:27.043Z" },
+    { url = "https://files.pythonhosted.org/packages/64/84/da7fda86dcc7b6d40d45dd28201fc136adfc390815126db41411bf1e5205/lz4-4.4.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:13254bd78fef50105872989a2dc3418ff09aefc7d0765528adc21646a7288294", size = 207137, upload-time = "2025-11-03T13:02:28.021Z" },
+    { url = "https://files.pythonhosted.org/packages/01/95/fb9c5bffed0f985eab70daf2087a94ad55cbbf83024175f39ff663f48b22/lz4-4.4.5-cp39-cp39-manylinux1_i686.manylinux_2_28_i686.manylinux_2_5_i686.whl", hash = "sha256:e64e61f29cf95afb43549063d8433b46352baf0c8a70aa45e2585618fcf59d86", size = 1290508, upload-time = "2025-11-03T13:02:29.485Z" },
+    { url = "https://files.pythonhosted.org/packages/57/6e/6a39b5ca9b9538cc9d61248c431065ad76cc0f10b40cb07d60b5bdde7750/lz4-4.4.5-cp39-cp39-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:ff1b50aeeec64df5603f17984e4b5be6166058dcf8f1e26a3da40d7a0f6ab547", size = 1278102, upload-time = "2025-11-03T13:02:30.878Z" },
+    { url = "https://files.pythonhosted.org/packages/73/57/551a7f95825c9721d8bee4ec02d8b139b1a44796e63d09a737ca0d67b6b1/lz4-4.4.5-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:1dd4d91d25937c2441b9fc0f4af01704a2d09f30a38c5798bc1d1b5a15ec9581", size = 1366651, upload-time = "2025-11-03T13:02:32.31Z" },
+    { url = "https://files.pythonhosted.org/packages/4f/85/daa1ae5695ce40924813257d7f5a8990ba5dd78a9170f912dd85c498f97c/lz4-4.4.5-cp39-cp39-win32.whl", hash = "sha256:d64141085864918392c3159cdad15b102a620a67975c786777874e1e90ef15ce", size = 88165, upload-time = "2025-11-03T13:02:33.413Z" },
+    { url = "https://files.pythonhosted.org/packages/df/db/3e84e506fdd5e04c9e8564d30bb08b0f3103dd9a2fb863c86bd46accb99a/lz4-4.4.5-cp39-cp39-win_amd64.whl", hash = "sha256:f32b9e65d70f3684532358255dc053f143835c5f5991e28a5ac4c93ce94b9ea7", size = 99487, upload-time = "2025-11-03T13:02:34.246Z" },
+    { url = "https://files.pythonhosted.org/packages/6a/85/40aa9d006fdebc4ae868c86ce2108a9453c2b524284817427de1284b5b00/lz4-4.4.5-cp39-cp39-win_arm64.whl", hash = "sha256:f9b8bde9909a010c75b3aea58ec3910393b758f3c219beed67063693df854db0", size = 91275, upload-time = "2025-11-03T13:02:35.117Z" },
+]
+
+[[package]]
+name = "mako"
+version = "1.3.10"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "markupsafe" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/9e/38/bd5b78a920a64d708fe6bc8e0a2c075e1389d53bef8413725c63ba041535/mako-1.3.10.tar.gz", hash = "sha256:99579a6f39583fa7e5630a28c3c1f440e4e97a414b80372649c0ce338da2ea28", size = 392474, upload-time = "2025-04-10T12:44:31.16Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/87/fb/99f81ac72ae23375f22b7afdb7642aba97c00a713c217124420147681a2f/mako-1.3.10-py3-none-any.whl", hash = "sha256:baef24a52fc4fc514a0887ac600f9f1cff3d82c61d4d700a1fa84d597b88db59", size = 78509, upload-time = "2025-04-10T12:50:53.297Z" },
+]
+
 [[package]]
 name = "markupsafe"
 version = "3.0.3"
@@ -812,6 +1452,23 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/4e/d3/fe08482b5cd995033556d45041a4f4e76e7f0521112a9c9991d40d39825f/markupsafe-3.0.3-cp39-cp39-win_arm64.whl", hash = "sha256:38664109c14ffc9e7437e86b4dceb442b0096dfe3541d7864d9cbe1da4cf36c8", size = 13928, upload-time = "2025-09-27T18:37:39.037Z" },
 ]
 
+[[package]]
+name = "mashumaro"
+version = "3.14"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "typing-extensions" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/eb/47/0a450b281bef2d7e97ec02c8e1168d821e283f58e02e6c403b2bb4d73c1c/mashumaro-3.14.tar.gz", hash = "sha256:5ef6f2b963892cbe9a4ceb3441dfbea37f8c3412523f25d42e9b3a7186555f1d", size = 166160, upload-time = "2024-10-23T21:48:40.164Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/1b/35/8d63733a2c12149d0c7663c29bf626bdbeea5f0ff963afe58a42b4810981/mashumaro-3.14-py3-none-any.whl", hash = "sha256:c12a649599a8f7b1a0b35d18f12e678423c3066189f7bc7bd8dd431c5c8132c3", size = 92183, upload-time = "2024-10-23T21:48:38.334Z" },
+]
+
+[package.optional-dependencies]
+msgpack = [
+    { name = "msgpack" },
+]
+
 [[package]]
 name = "matplotlib-inline"
 version = "0.2.1"
@@ -824,6 +1481,94 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/af/33/ee4519fa02ed11a94aef9559552f3b17bb863f2ecfe1a35dc7f548cde231/matplotlib_inline-0.2.1-py3-none-any.whl", hash = "sha256:d56ce5156ba6085e00a9d54fead6ed29a9c47e215cd1bba2e976ef39f5710a76", size = 9516, upload-time = "2025-10-23T09:00:20.675Z" },
 ]
 
+[[package]]
+name = "minimal-snowplow-tracker"
+version = "0.0.2"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "requests" },
+    { name = "six" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/e4/9f/004f810169a48ed5c520279d98327e7793b6491f09d42cb2c5636c994f34/minimal-snowplow-tracker-0.0.2.tar.gz", hash = "sha256:acabf7572db0e7f5cbf6983d495eef54081f71be392330eb3aadb9ccb39daaa4", size = 12542, upload-time = "2018-10-13T12:58:37.368Z" }
+
+[[package]]
+name = "more-itertools"
+version = "10.8.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/ea/5d/38b681d3fce7a266dd9ab73c66959406d565b3e85f21d5e66e1181d93721/more_itertools-10.8.0.tar.gz", hash = "sha256:f638ddf8a1a0d134181275fb5d58b086ead7c6a72429ad725c67503f13ba30bd", size = 137431, upload-time = "2025-09-02T15:23:11.018Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a4/8e/469e5a4a2f5855992e425f3cb33804cc07bf18d48f2db061aec61ce50270/more_itertools-10.8.0-py3-none-any.whl", hash = "sha256:52d4362373dcf7c52546bc4af9a86ee7c4579df9a8dc268be0a2f949d376cc9b", size = 69667, upload-time = "2025-09-02T15:23:09.635Z" },
+]
+
+[[package]]
+name = "msgpack"
+version = "1.1.2"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/4d/f2/bfb55a6236ed8725a96b0aa3acbd0ec17588e6a2c3b62a93eb513ed8783f/msgpack-1.1.2.tar.gz", hash = "sha256:3b60763c1373dd60f398488069bcdc703cd08a711477b5d480eecc9f9626f47e", size = 173581, upload-time = "2025-10-08T09:15:56.596Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/f5/a2/3b68a9e769db68668b25c6108444a35f9bd163bb848c0650d516761a59c0/msgpack-1.1.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0051fffef5a37ca2cd16978ae4f0aef92f164df86823871b5162812bebecd8e2", size = 81318, upload-time = "2025-10-08T09:14:38.722Z" },
+    { url = "https://files.pythonhosted.org/packages/5b/e1/2b720cc341325c00be44e1ed59e7cfeae2678329fbf5aa68f5bda57fe728/msgpack-1.1.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:a605409040f2da88676e9c9e5853b3449ba8011973616189ea5ee55ddbc5bc87", size = 83786, upload-time = "2025-10-08T09:14:40.082Z" },
+    { url = "https://files.pythonhosted.org/packages/71/e5/c2241de64bfceac456b140737812a2ab310b10538a7b34a1d393b748e095/msgpack-1.1.2-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:8b696e83c9f1532b4af884045ba7f3aa741a63b2bc22617293a2c6a7c645f251", size = 398240, upload-time = "2025-10-08T09:14:41.151Z" },
+    { url = "https://files.pythonhosted.org/packages/b7/09/2a06956383c0fdebaef5aa9246e2356776f12ea6f2a44bd1368abf0e46c4/msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:365c0bbe981a27d8932da71af63ef86acc59ed5c01ad929e09a0b88c6294e28a", size = 406070, upload-time = "2025-10-08T09:14:42.821Z" },
+    { url = "https://files.pythonhosted.org/packages/0e/74/2957703f0e1ef20637d6aead4fbb314330c26f39aa046b348c7edcf6ca6b/msgpack-1.1.2-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:41d1a5d875680166d3ac5c38573896453bbbea7092936d2e107214daf43b1d4f", size = 393403, upload-time = "2025-10-08T09:14:44.38Z" },
+    { url = "https://files.pythonhosted.org/packages/a5/09/3bfc12aa90f77b37322fc33e7a8a7c29ba7c8edeadfa27664451801b9860/msgpack-1.1.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:354e81bcdebaab427c3df4281187edc765d5d76bfb3a7c125af9da7a27e8458f", size = 398947, upload-time = "2025-10-08T09:14:45.56Z" },
+    { url = "https://files.pythonhosted.org/packages/4b/4f/05fcebd3b4977cb3d840f7ef6b77c51f8582086de5e642f3fefee35c86fc/msgpack-1.1.2-cp310-cp310-win32.whl", hash = "sha256:e64c8d2f5e5d5fda7b842f55dec6133260ea8f53c4257d64494c534f306bf7a9", size = 64769, upload-time = "2025-10-08T09:14:47.334Z" },
+    { url = "https://files.pythonhosted.org/packages/d0/3e/b4547e3a34210956382eed1c85935fff7e0f9b98be3106b3745d7dec9c5e/msgpack-1.1.2-cp310-cp310-win_amd64.whl", hash = "sha256:db6192777d943bdaaafb6ba66d44bf65aa0e9c5616fa1d2da9bb08828c6b39aa", size = 71293, upload-time = "2025-10-08T09:14:48.665Z" },
+    { url = "https://files.pythonhosted.org/packages/2c/97/560d11202bcd537abca693fd85d81cebe2107ba17301de42b01ac1677b69/msgpack-1.1.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:2e86a607e558d22985d856948c12a3fa7b42efad264dca8a3ebbcfa2735d786c", size = 82271, upload-time = "2025-10-08T09:14:49.967Z" },
+    { url = "https://files.pythonhosted.org/packages/83/04/28a41024ccbd67467380b6fb440ae916c1e4f25e2cd4c63abe6835ac566e/msgpack-1.1.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:283ae72fc89da59aa004ba147e8fc2f766647b1251500182fac0350d8af299c0", size = 84914, upload-time = "2025-10-08T09:14:50.958Z" },
+    { url = "https://files.pythonhosted.org/packages/71/46/b817349db6886d79e57a966346cf0902a426375aadc1e8e7a86a75e22f19/msgpack-1.1.2-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:61c8aa3bd513d87c72ed0b37b53dd5c5a0f58f2ff9f26e1555d3bd7948fb7296", size = 416962, upload-time = "2025-10-08T09:14:51.997Z" },
+    { url = "https://files.pythonhosted.org/packages/da/e0/6cc2e852837cd6086fe7d8406af4294e66827a60a4cf60b86575a4a65ca8/msgpack-1.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:454e29e186285d2ebe65be34629fa0e8605202c60fbc7c4c650ccd41870896ef", size = 426183, upload-time = "2025-10-08T09:14:53.477Z" },
+    { url = "https://files.pythonhosted.org/packages/25/98/6a19f030b3d2ea906696cedd1eb251708e50a5891d0978b012cb6107234c/msgpack-1.1.2-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:7bc8813f88417599564fafa59fd6f95be417179f76b40325b500b3c98409757c", size = 411454, upload-time = "2025-10-08T09:14:54.648Z" },
+    { url = "https://files.pythonhosted.org/packages/b7/cd/9098fcb6adb32187a70b7ecaabf6339da50553351558f37600e53a4a2a23/msgpack-1.1.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:bafca952dc13907bdfdedfc6a5f579bf4f292bdd506fadb38389afa3ac5b208e", size = 422341, upload-time = "2025-10-08T09:14:56.328Z" },
+    { url = "https://files.pythonhosted.org/packages/e6/ae/270cecbcf36c1dc85ec086b33a51a4d7d08fc4f404bdbc15b582255d05ff/msgpack-1.1.2-cp311-cp311-win32.whl", hash = "sha256:602b6740e95ffc55bfb078172d279de3773d7b7db1f703b2f1323566b878b90e", size = 64747, upload-time = "2025-10-08T09:14:57.882Z" },
+    { url = "https://files.pythonhosted.org/packages/2a/79/309d0e637f6f37e83c711f547308b91af02b72d2326ddd860b966080ef29/msgpack-1.1.2-cp311-cp311-win_amd64.whl", hash = "sha256:d198d275222dc54244bf3327eb8cbe00307d220241d9cec4d306d49a44e85f68", size = 71633, upload-time = "2025-10-08T09:14:59.177Z" },
+    { url = "https://files.pythonhosted.org/packages/73/4d/7c4e2b3d9b1106cd0aa6cb56cc57c6267f59fa8bfab7d91df5adc802c847/msgpack-1.1.2-cp311-cp311-win_arm64.whl", hash = "sha256:86f8136dfa5c116365a8a651a7d7484b65b13339731dd6faebb9a0242151c406", size = 64755, upload-time = "2025-10-08T09:15:00.48Z" },
+    { url = "https://files.pythonhosted.org/packages/ad/bd/8b0d01c756203fbab65d265859749860682ccd2a59594609aeec3a144efa/msgpack-1.1.2-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:70a0dff9d1f8da25179ffcf880e10cf1aad55fdb63cd59c9a49a1b82290062aa", size = 81939, upload-time = "2025-10-08T09:15:01.472Z" },
+    { url = "https://files.pythonhosted.org/packages/34/68/ba4f155f793a74c1483d4bdef136e1023f7bcba557f0db4ef3db3c665cf1/msgpack-1.1.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:446abdd8b94b55c800ac34b102dffd2f6aa0ce643c55dfc017ad89347db3dbdb", size = 85064, upload-time = "2025-10-08T09:15:03.764Z" },
+    { url = "https://files.pythonhosted.org/packages/f2/60/a064b0345fc36c4c3d2c743c82d9100c40388d77f0b48b2f04d6041dbec1/msgpack-1.1.2-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:c63eea553c69ab05b6747901b97d620bb2a690633c77f23feb0c6a947a8a7b8f", size = 417131, upload-time = "2025-10-08T09:15:05.136Z" },
+    { url = "https://files.pythonhosted.org/packages/65/92/a5100f7185a800a5d29f8d14041f61475b9de465ffcc0f3b9fba606e4505/msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:372839311ccf6bdaf39b00b61288e0557916c3729529b301c52c2d88842add42", size = 427556, upload-time = "2025-10-08T09:15:06.837Z" },
+    { url = "https://files.pythonhosted.org/packages/f5/87/ffe21d1bf7d9991354ad93949286f643b2bb6ddbeab66373922b44c3b8cc/msgpack-1.1.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:2929af52106ca73fcb28576218476ffbb531a036c2adbcf54a3664de124303e9", size = 404920, upload-time = "2025-10-08T09:15:08.179Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/41/8543ed2b8604f7c0d89ce066f42007faac1eaa7d79a81555f206a5cdb889/msgpack-1.1.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:be52a8fc79e45b0364210eef5234a7cf8d330836d0a64dfbb878efa903d84620", size = 415013, upload-time = "2025-10-08T09:15:09.83Z" },
+    { url = "https://files.pythonhosted.org/packages/41/0d/2ddfaa8b7e1cee6c490d46cb0a39742b19e2481600a7a0e96537e9c22f43/msgpack-1.1.2-cp312-cp312-win32.whl", hash = "sha256:1fff3d825d7859ac888b0fbda39a42d59193543920eda9d9bea44d958a878029", size = 65096, upload-time = "2025-10-08T09:15:11.11Z" },
+    { url = "https://files.pythonhosted.org/packages/8c/ec/d431eb7941fb55a31dd6ca3404d41fbb52d99172df2e7707754488390910/msgpack-1.1.2-cp312-cp312-win_amd64.whl", hash = "sha256:1de460f0403172cff81169a30b9a92b260cb809c4cb7e2fc79ae8d0510c78b6b", size = 72708, upload-time = "2025-10-08T09:15:12.554Z" },
+    { url = "https://files.pythonhosted.org/packages/c5/31/5b1a1f70eb0e87d1678e9624908f86317787b536060641d6798e3cf70ace/msgpack-1.1.2-cp312-cp312-win_arm64.whl", hash = "sha256:be5980f3ee0e6bd44f3a9e9dea01054f175b50c3e6cdb692bc9424c0bbb8bf69", size = 64119, upload-time = "2025-10-08T09:15:13.589Z" },
+    { url = "https://files.pythonhosted.org/packages/6b/31/b46518ecc604d7edf3a4f94cb3bf021fc62aa301f0cb849936968164ef23/msgpack-1.1.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:4efd7b5979ccb539c221a4c4e16aac1a533efc97f3b759bb5a5ac9f6d10383bf", size = 81212, upload-time = "2025-10-08T09:15:14.552Z" },
+    { url = "https://files.pythonhosted.org/packages/92/dc/c385f38f2c2433333345a82926c6bfa5ecfff3ef787201614317b58dd8be/msgpack-1.1.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:42eefe2c3e2af97ed470eec850facbe1b5ad1d6eacdbadc42ec98e7dcf68b4b7", size = 84315, upload-time = "2025-10-08T09:15:15.543Z" },
+    { url = "https://files.pythonhosted.org/packages/d3/68/93180dce57f684a61a88a45ed13047558ded2be46f03acb8dec6d7c513af/msgpack-1.1.2-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:1fdf7d83102bf09e7ce3357de96c59b627395352a4024f6e2458501f158bf999", size = 412721, upload-time = "2025-10-08T09:15:16.567Z" },
+    { url = "https://files.pythonhosted.org/packages/5d/ba/459f18c16f2b3fc1a1ca871f72f07d70c07bf768ad0a507a698b8052ac58/msgpack-1.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:fac4be746328f90caa3cd4bc67e6fe36ca2bf61d5c6eb6d895b6527e3f05071e", size = 424657, upload-time = "2025-10-08T09:15:17.825Z" },
+    { url = "https://files.pythonhosted.org/packages/38/f8/4398c46863b093252fe67368b44edc6c13b17f4e6b0e4929dbf0bdb13f23/msgpack-1.1.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:fffee09044073e69f2bad787071aeec727183e7580443dfeb8556cbf1978d162", size = 402668, upload-time = "2025-10-08T09:15:19.003Z" },
+    { url = "https://files.pythonhosted.org/packages/28/ce/698c1eff75626e4124b4d78e21cca0b4cc90043afb80a507626ea354ab52/msgpack-1.1.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:5928604de9b032bc17f5099496417f113c45bc6bc21b5c6920caf34b3c428794", size = 419040, upload-time = "2025-10-08T09:15:20.183Z" },
+    { url = "https://files.pythonhosted.org/packages/67/32/f3cd1667028424fa7001d82e10ee35386eea1408b93d399b09fb0aa7875f/msgpack-1.1.2-cp313-cp313-win32.whl", hash = "sha256:a7787d353595c7c7e145e2331abf8b7ff1e6673a6b974ded96e6d4ec09f00c8c", size = 65037, upload-time = "2025-10-08T09:15:21.416Z" },
+    { url = "https://files.pythonhosted.org/packages/74/07/1ed8277f8653c40ebc65985180b007879f6a836c525b3885dcc6448ae6cb/msgpack-1.1.2-cp313-cp313-win_amd64.whl", hash = "sha256:a465f0dceb8e13a487e54c07d04ae3ba131c7c5b95e2612596eafde1dccf64a9", size = 72631, upload-time = "2025-10-08T09:15:22.431Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/db/0314e4e2db56ebcf450f277904ffd84a7988b9e5da8d0d61ab2d057df2b6/msgpack-1.1.2-cp313-cp313-win_arm64.whl", hash = "sha256:e69b39f8c0aa5ec24b57737ebee40be647035158f14ed4b40e6f150077e21a84", size = 64118, upload-time = "2025-10-08T09:15:23.402Z" },
+    { url = "https://files.pythonhosted.org/packages/22/71/201105712d0a2ff07b7873ed3c220292fb2ea5120603c00c4b634bcdafb3/msgpack-1.1.2-cp314-cp314-macosx_10_13_x86_64.whl", hash = "sha256:e23ce8d5f7aa6ea6d2a2b326b4ba46c985dbb204523759984430db7114f8aa00", size = 81127, upload-time = "2025-10-08T09:15:24.408Z" },
+    { url = "https://files.pythonhosted.org/packages/1b/9f/38ff9e57a2eade7bf9dfee5eae17f39fc0e998658050279cbb14d97d36d9/msgpack-1.1.2-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:6c15b7d74c939ebe620dd8e559384be806204d73b4f9356320632d783d1f7939", size = 84981, upload-time = "2025-10-08T09:15:25.812Z" },
+    { url = "https://files.pythonhosted.org/packages/8e/a9/3536e385167b88c2cc8f4424c49e28d49a6fc35206d4a8060f136e71f94c/msgpack-1.1.2-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:99e2cb7b9031568a2a5c73aa077180f93dd2e95b4f8d3b8e14a73ae94a9e667e", size = 411885, upload-time = "2025-10-08T09:15:27.22Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/40/dc34d1a8d5f1e51fc64640b62b191684da52ca469da9cd74e84936ffa4a6/msgpack-1.1.2-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:180759d89a057eab503cf62eeec0aa61c4ea1200dee709f3a8e9397dbb3b6931", size = 419658, upload-time = "2025-10-08T09:15:28.4Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/ef/2b92e286366500a09a67e03496ee8b8ba00562797a52f3c117aa2b29514b/msgpack-1.1.2-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:04fb995247a6e83830b62f0b07bf36540c213f6eac8e851166d8d86d83cbd014", size = 403290, upload-time = "2025-10-08T09:15:29.764Z" },
+    { url = "https://files.pythonhosted.org/packages/78/90/e0ea7990abea5764e4655b8177aa7c63cdfa89945b6e7641055800f6c16b/msgpack-1.1.2-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:8e22ab046fa7ede9e36eeb4cfad44d46450f37bb05d5ec482b02868f451c95e2", size = 415234, upload-time = "2025-10-08T09:15:31.022Z" },
+    { url = "https://files.pythonhosted.org/packages/72/4e/9390aed5db983a2310818cd7d3ec0aecad45e1f7007e0cda79c79507bb0d/msgpack-1.1.2-cp314-cp314-win32.whl", hash = "sha256:80a0ff7d4abf5fecb995fcf235d4064b9a9a8a40a3ab80999e6ac1e30b702717", size = 66391, upload-time = "2025-10-08T09:15:32.265Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/f1/abd09c2ae91228c5f3998dbd7f41353def9eac64253de3c8105efa2082f7/msgpack-1.1.2-cp314-cp314-win_amd64.whl", hash = "sha256:9ade919fac6a3e7260b7f64cea89df6bec59104987cbea34d34a2fa15d74310b", size = 73787, upload-time = "2025-10-08T09:15:33.219Z" },
+    { url = "https://files.pythonhosted.org/packages/6a/b0/9d9f667ab48b16ad4115c1935d94023b82b3198064cb84a123e97f7466c1/msgpack-1.1.2-cp314-cp314-win_arm64.whl", hash = "sha256:59415c6076b1e30e563eb732e23b994a61c159cec44deaf584e5cc1dd662f2af", size = 66453, upload-time = "2025-10-08T09:15:34.225Z" },
+    { url = "https://files.pythonhosted.org/packages/16/67/93f80545eb1792b61a217fa7f06d5e5cb9e0055bed867f43e2b8e012e137/msgpack-1.1.2-cp314-cp314t-macosx_10_13_x86_64.whl", hash = "sha256:897c478140877e5307760b0ea66e0932738879e7aa68144d9b78ea4c8302a84a", size = 85264, upload-time = "2025-10-08T09:15:35.61Z" },
+    { url = "https://files.pythonhosted.org/packages/87/1c/33c8a24959cf193966ef11a6f6a2995a65eb066bd681fd085afd519a57ce/msgpack-1.1.2-cp314-cp314t-macosx_11_0_arm64.whl", hash = "sha256:a668204fa43e6d02f89dbe79a30b0d67238d9ec4c5bd8a940fc3a004a47b721b", size = 89076, upload-time = "2025-10-08T09:15:36.619Z" },
+    { url = "https://files.pythonhosted.org/packages/fc/6b/62e85ff7193663fbea5c0254ef32f0c77134b4059f8da89b958beb7696f3/msgpack-1.1.2-cp314-cp314t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:5559d03930d3aa0f3aacb4c42c776af1a2ace2611871c84a75afe436695e6245", size = 435242, upload-time = "2025-10-08T09:15:37.647Z" },
+    { url = "https://files.pythonhosted.org/packages/c1/47/5c74ecb4cc277cf09f64e913947871682ffa82b3b93c8dad68083112f412/msgpack-1.1.2-cp314-cp314t-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:70c5a7a9fea7f036b716191c29047374c10721c389c21e9ffafad04df8c52c90", size = 432509, upload-time = "2025-10-08T09:15:38.794Z" },
+    { url = "https://files.pythonhosted.org/packages/24/a4/e98ccdb56dc4e98c929a3f150de1799831c0a800583cde9fa022fa90602d/msgpack-1.1.2-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:f2cb069d8b981abc72b41aea1c580ce92d57c673ec61af4c500153a626cb9e20", size = 415957, upload-time = "2025-10-08T09:15:40.238Z" },
+    { url = "https://files.pythonhosted.org/packages/da/28/6951f7fb67bc0a4e184a6b38ab71a92d9ba58080b27a77d3e2fb0be5998f/msgpack-1.1.2-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:d62ce1f483f355f61adb5433ebfd8868c5f078d1a52d042b0a998682b4fa8c27", size = 422910, upload-time = "2025-10-08T09:15:41.505Z" },
+    { url = "https://files.pythonhosted.org/packages/f0/03/42106dcded51f0a0b5284d3ce30a671e7bd3f7318d122b2ead66ad289fed/msgpack-1.1.2-cp314-cp314t-win32.whl", hash = "sha256:1d1418482b1ee984625d88aa9585db570180c286d942da463533b238b98b812b", size = 75197, upload-time = "2025-10-08T09:15:42.954Z" },
+    { url = "https://files.pythonhosted.org/packages/15/86/d0071e94987f8db59d4eeb386ddc64d0bb9b10820a8d82bcd3e53eeb2da6/msgpack-1.1.2-cp314-cp314t-win_amd64.whl", hash = "sha256:5a46bf7e831d09470ad92dff02b8b1ac92175ca36b087f904a0519857c6be3ff", size = 85772, upload-time = "2025-10-08T09:15:43.954Z" },
+    { url = "https://files.pythonhosted.org/packages/81/f2/08ace4142eb281c12701fc3b93a10795e4d4dc7f753911d836675050f886/msgpack-1.1.2-cp314-cp314t-win_arm64.whl", hash = "sha256:d99ef64f349d5ec3293688e91486c5fdb925ed03807f64d98d205d2713c60b46", size = 70868, upload-time = "2025-10-08T09:15:44.959Z" },
+    { url = "https://files.pythonhosted.org/packages/46/73/85469b4aa71d25e5949fee50d3c2cf46f69cea619fe97cfe309058080f75/msgpack-1.1.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:ea5405c46e690122a76531ab97a079e184c0daf491e588592d6a23d3e32af99e", size = 81529, upload-time = "2025-10-08T09:15:46.069Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/3a/7d4077e8ae720b29d2b299a9591969f0d105146960681ea6f4121e6d0f8d/msgpack-1.1.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:9fba231af7a933400238cb357ecccf8ab5d51535ea95d94fc35b7806218ff844", size = 84106, upload-time = "2025-10-08T09:15:47.064Z" },
+    { url = "https://files.pythonhosted.org/packages/df/c0/da451c74746ed9388dca1b4ec647c82945f4e2f8ce242c25fb7c0e12181f/msgpack-1.1.2-cp39-cp39-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:a8f6e7d30253714751aa0b0c84ae28948e852ee7fb0524082e6716769124bc23", size = 396656, upload-time = "2025-10-08T09:15:48.118Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/a1/20486c29a31ec9f0f88377fdf7eb7a67f30bcb5e0f89b7550f6f16d9373b/msgpack-1.1.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:94fd7dc7d8cb0a54432f296f2246bc39474e017204ca6f4ff345941d4ed285a7", size = 404722, upload-time = "2025-10-08T09:15:49.328Z" },
+    { url = "https://files.pythonhosted.org/packages/ad/ae/e613b0a526d54ce85447d9665c2ff8c3210a784378d50573321d43d324b8/msgpack-1.1.2-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:350ad5353a467d9e3b126d8d1b90fe05ad081e2e1cef5753f8c345217c37e7b8", size = 391838, upload-time = "2025-10-08T09:15:50.517Z" },
+    { url = "https://files.pythonhosted.org/packages/49/6a/07f3e10ed4503045b882ef7bf8512d01d8a9e25056950a977bd5f50df1c2/msgpack-1.1.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:6bde749afe671dc44893f8d08e83bf475a1a14570d67c4bb5cec5573463c8833", size = 397516, upload-time = "2025-10-08T09:15:51.646Z" },
+    { url = "https://files.pythonhosted.org/packages/76/9b/a86828e75986c12a3809c1e5062f5eba8e0cae3dfa2bf724ed2b1bb72b4c/msgpack-1.1.2-cp39-cp39-win32.whl", hash = "sha256:ad09b984828d6b7bb52d1d1d0c9be68ad781fa004ca39216c8a1e63c0f34ba3c", size = 64863, upload-time = "2025-10-08T09:15:53.118Z" },
+    { url = "https://files.pythonhosted.org/packages/14/a7/b1992b4fb3da3b413f5fb78a63bad42f256c3be2352eb69273c3789c2c96/msgpack-1.1.2-cp39-cp39-win_amd64.whl", hash = "sha256:67016ae8c8965124fdede9d3769528ad8284f14d635337ffa6a713a580f6c030", size = 71540, upload-time = "2025-10-08T09:15:55.573Z" },
+]
+
 [[package]]
 name = "nest-asyncio"
 version = "1.6.0"
@@ -833,6 +1578,46 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl", hash = "sha256:87af6efd6b5e897c81050477ef65c62e2b2f35d51703cae01aff2905b1852e1c", size = 5195, upload-time = "2024-01-21T14:25:17.223Z" },
 ]
 
+[[package]]
+name = "networkx"
+version = "3.2.1"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/c4/80/a84676339aaae2f1cfdf9f418701dd634aef9cc76f708ef55c36ff39c3ca/networkx-3.2.1.tar.gz", hash = "sha256:9f1bb5cf3409bf324e0a722c20bdb4c20ee39bf1c30ce8ae499c8502b0b5e0c6", size = 2073928, upload-time = "2023-10-28T08:41:39.364Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl", hash = "sha256:f18c69adc97877c42332c170849c96cefa91881c99a7cb3e95b7c659ebdc1ec2", size = 1647772, upload-time = "2023-10-28T08:41:36.945Z" },
+]
+
+[[package]]
+name = "networkx"
+version = "3.4.2"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version == '3.10.*'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/fd/1d/06475e1cd5264c0b870ea2cc6fdb3e37177c1e565c43f56ff17a10e3937f/networkx-3.4.2.tar.gz", hash = "sha256:307c3669428c5362aab27c8a1260aa8f47c4e91d3891f48be0141738d8d053e1", size = 2151368, upload-time = "2024-10-21T12:39:38.695Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl", hash = "sha256:df5d4365b724cf81b8c6a7312509d0c22386097011ad1abe274afd5e9d3bbc5f", size = 1723263, upload-time = "2024-10-21T12:39:36.247Z" },
+]
+
+[[package]]
+name = "networkx"
+version = "3.5"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/6c/4f/ccdb8ad3a38e583f214547fd2f7ff1fc160c43a75af88e6aec213404b96a/networkx-3.5.tar.gz", hash = "sha256:d4c6f9cf81f52d69230866796b82afbccdec3db7ae4fbd1b65ea750feed50037", size = 2471065, upload-time = "2025-05-29T11:35:07.804Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl", hash = "sha256:0030d386a9a06dee3565298b4a734b68589749a544acbb6c412dc9e2489ec6ec", size = 2034406, upload-time = "2025-05-29T11:35:04.961Z" },
+]
+
 [[package]]
 name = "numpy"
 version = "2.0.2"
@@ -958,7 +1743,10 @@ name = "numpy"
 version = "2.3.5"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
 ]
 sdist = { url = "https://files.pythonhosted.org/packages/76/65/21b3bc86aac7b8f2862db1e808f1ea22b028e30a225a34a5ede9bf8678f2/numpy-2.3.5.tar.gz", hash = "sha256:784db1dcdab56bf0517743e746dfb0f885fc68d948aba86eeec2cba234bdf1c0", size = 20584950, upload-time = "2025-11-16T22:52:42.067Z" }
@@ -1038,6 +1826,27 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/2d/ee/346fa473e666fe14c52fcdd19ec2424157290a032d4c41f98127bfb31ac7/numpy-2.3.5-pp311-pypy311_pp73-win_amd64.whl", hash = "sha256:f16417ec91f12f814b10bafe79ef77e70113a2f5f7018640e7425ff979253425", size = 12967213, upload-time = "2025-11-16T22:52:39.38Z" },
 ]
 
+[[package]]
+name = "oauthlib"
+version = "3.3.1"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/0b/5f/19930f824ffeb0ad4372da4812c50edbd1434f678c90c2733e1188edfc63/oauthlib-3.3.1.tar.gz", hash = "sha256:0f0f8aa759826a193cf66c12ea1af1637f87b9b4622d46e866952bb022e538c9", size = 185918, upload-time = "2025-06-19T22:48:08.269Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl", hash = "sha256:88119c938d2b8fb88561af5f6ee0eec8cc8d552b7bb1f712743136eb7523b7a1", size = 160065, upload-time = "2025-06-19T22:48:06.508Z" },
+]
+
+[[package]]
+name = "openpyxl"
+version = "3.1.5"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "et-xmlfile" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/3d/f9/88d94a75de065ea32619465d2f77b29a0469500e99012523b91cc4141cd1/openpyxl-3.1.5.tar.gz", hash = "sha256:cf0e3cf56142039133628b5acffe8ef0c12bc902d2aadd3e0fe5878dc08d1050", size = 186464, upload-time = "2024-06-28T14:03:44.161Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl", hash = "sha256:5282c12b107bffeef825f4617dc029afaf41d0ea60823bbb665ef3079dc79de2", size = 250910, upload-time = "2024-06-28T14:03:41.161Z" },
+]
+
 [[package]]
 name = "packaging"
 version = "25.0"
@@ -1117,6 +1926,15 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/98/af/7be05277859a7bc399da8ba68b88c96b27b48740b6cf49688899c6eb4176/pandas-2.3.3-cp39-cp39-win_amd64.whl", hash = "sha256:d3e28b3e83862ccf4d85ff19cf8c20b2ae7e503881711ff2d534dc8f761131aa", size = 11359119, upload-time = "2025-09-29T23:34:46.339Z" },
 ]
 
+[[package]]
+name = "parsedatetime"
+version = "2.6"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/a8/20/cb587f6672dbe585d101f590c3871d16e7aec5a576a1694997a3777312ac/parsedatetime-2.6.tar.gz", hash = "sha256:4cb368fbb18a0b7231f4d76119165451c8d2e35951455dfee97c62a87b04d455", size = 60114, upload-time = "2020-05-31T23:50:57.443Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/9d/a4/3dd804926a42537bf69fb3ebb9fd72a50ba84f807d95df5ae016606c976c/parsedatetime-2.6-py3-none-any.whl", hash = "sha256:cb96edd7016872f58479e35879294258c71437195760746faffedb692aef000b", size = 42548, upload-time = "2020-05-31T23:50:56.315Z" },
+]
+
 [[package]]
 name = "parso"
 version = "0.8.5"
@@ -1128,11 +1946,11 @@ wheels = [
 
 [[package]]
 name = "pathspec"
-version = "0.12.1"
+version = "0.11.2"
 source = { registry = "https://pypi.org/simple" }
-sdist = { url = "https://files.pythonhosted.org/packages/ca/bc/f35b8446f4531a7cb215605d100cd88b7ac6f44ab3fc94870c120ab3adbf/pathspec-0.12.1.tar.gz", hash = "sha256:a482d51503a1ab33b1c67a6c3813a26953dbdc71c31dacaef9a838c4e29f5712", size = 51043, upload-time = "2023-12-10T22:30:45Z" }
+sdist = { url = "https://files.pythonhosted.org/packages/a0/2a/bd167cdf116d4f3539caaa4c332752aac0b3a0cc0174cdb302ee68933e81/pathspec-0.11.2.tar.gz", hash = "sha256:e0d8d0ac2f12da61956eb2306b69f9469b42f4deb0f3cb6ed47b9cce9996ced3", size = 47032, upload-time = "2023-07-29T01:05:04.481Z" }
 wheels = [
-    { url = "https://files.pythonhosted.org/packages/cc/20/ff623b09d963f88bfde16306a54e12ee5ea43e9b597108672ff3a408aad6/pathspec-0.12.1-py3-none-any.whl", hash = "sha256:a0d503e138a4c123b27490a4f7beda6a01c6f288df0e4a8b79c7eb0dc7b4cc08", size = 31191, upload-time = "2023-12-10T22:30:43.14Z" },
+    { url = "https://files.pythonhosted.org/packages/b4/2a/9b1be29146139ef459188f5e420a66e835dda921208db600b7037093891f/pathspec-0.11.2-py3-none-any.whl", hash = "sha256:1d6ed233af05e679efb96b1851550ea95bbb64b7c490b0f5aa52996c11e92a20", size = 29603, upload-time = "2023-07-29T01:05:02.656Z" },
 ]
 
 [[package]]
@@ -1164,7 +1982,10 @@ name = "platformdirs"
 version = "4.5.0"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -1194,6 +2015,22 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/84/03/0d3ce49e2505ae70cf43bc5bb3033955d2fc9f932163e84dc0779cc47f48/prompt_toolkit-3.0.52-py3-none-any.whl", hash = "sha256:9aac639a3bbd33284347de5ad8d68ecc044b91a762dc39b7c21095fcd6a19955", size = 391431, upload-time = "2025-08-27T15:23:59.498Z" },
 ]
 
+[[package]]
+name = "protobuf"
+version = "4.25.8"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/df/01/34c8d2b6354906d728703cb9d546a0e534de479e25f1b581e4094c4a85cc/protobuf-4.25.8.tar.gz", hash = "sha256:6135cf8affe1fc6f76cced2641e4ea8d3e59518d1f24ae41ba97bcad82d397cd", size = 380920, upload-time = "2025-05-28T14:22:25.153Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/45/ff/05f34305fe6b85bbfbecbc559d423a5985605cad5eda4f47eae9e9c9c5c5/protobuf-4.25.8-cp310-abi3-win32.whl", hash = "sha256:504435d831565f7cfac9f0714440028907f1975e4bed228e58e72ecfff58a1e0", size = 392745, upload-time = "2025-05-28T14:22:10.524Z" },
+    { url = "https://files.pythonhosted.org/packages/08/35/8b8a8405c564caf4ba835b1fdf554da869954712b26d8f2a98c0e434469b/protobuf-4.25.8-cp310-abi3-win_amd64.whl", hash = "sha256:bd551eb1fe1d7e92c1af1d75bdfa572eff1ab0e5bf1736716814cdccdb2360f9", size = 413736, upload-time = "2025-05-28T14:22:13.156Z" },
+    { url = "https://files.pythonhosted.org/packages/28/d7/ab27049a035b258dab43445eb6ec84a26277b16105b277cbe0a7698bdc6c/protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl", hash = "sha256:ca809b42f4444f144f2115c4c1a747b9a404d590f18f37e9402422033e464e0f", size = 394537, upload-time = "2025-05-28T14:22:14.768Z" },
+    { url = "https://files.pythonhosted.org/packages/bd/6d/a4a198b61808dd3d1ee187082ccc21499bc949d639feb948961b48be9a7e/protobuf-4.25.8-cp37-abi3-manylinux2014_aarch64.whl", hash = "sha256:9ad7ef62d92baf5a8654fbb88dac7fa5594cfa70fd3440488a5ca3bfc6d795a7", size = 294005, upload-time = "2025-05-28T14:22:16.052Z" },
+    { url = "https://files.pythonhosted.org/packages/d6/c6/c9deaa6e789b6fc41b88ccbdfe7a42d2b82663248b715f55aa77fbc00724/protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl", hash = "sha256:83e6e54e93d2b696a92cad6e6efc924f3850f82b52e1563778dfab8b355101b0", size = 294924, upload-time = "2025-05-28T14:22:17.105Z" },
+    { url = "https://files.pythonhosted.org/packages/f3/d5/31cc45286413746927cf46251f87b0120e304e6f233f5e89019b1bc00de8/protobuf-4.25.8-cp39-cp39-win32.whl", hash = "sha256:077ff8badf2acf8bc474406706ad890466274191a48d0abd3bd6987107c9cde5", size = 392789, upload-time = "2025-05-28T14:22:21.249Z" },
+    { url = "https://files.pythonhosted.org/packages/de/3f/2e1812771b4e28b2a70b566527963e40670d1ec90d3639b6b5f7206ac287/protobuf-4.25.8-cp39-cp39-win_amd64.whl", hash = "sha256:f4510b93a3bec6eba8fd8f1093e9d7fb0d4a24d1a81377c10c0e5bbfe9e4ed24", size = 413684, upload-time = "2025-05-28T14:22:22.72Z" },
+    { url = "https://files.pythonhosted.org/packages/0c/c1/6aece0ab5209981a70cd186f164c133fdba2f51e124ff92b73de7fd24d78/protobuf-4.25.8-py3-none-any.whl", hash = "sha256:15a0af558aa3b13efef102ae6e4f3efac06f1eea11afb3a57db2901447d9fb59", size = 156757, upload-time = "2025-05-28T14:22:24.135Z" },
+]
+
 [[package]]
 name = "psutil"
 version = "7.1.3"
@@ -1238,6 +2075,145 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/8e/37/efad0257dc6e593a18957422533ff0f87ede7c9c6ea010a2177d738fb82f/pure_eval-0.2.3-py3-none-any.whl", hash = "sha256:1db8e35b67b3d218d818ae653e27f06c3aa420901fa7b081ca98cbedc874e0d0", size = 11842, upload-time = "2024-07-21T12:58:20.04Z" },
 ]
 
+[[package]]
+name = "pyarrow"
+version = "21.0.0"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/ef/c2/ea068b8f00905c06329a3dfcd40d0fcc2b7d0f2e355bdb25b65e0a0e4cd4/pyarrow-21.0.0.tar.gz", hash = "sha256:5051f2dccf0e283ff56335760cbc8622cf52264d67e359d5569541ac11b6d5bc", size = 1133487, upload-time = "2025-07-18T00:57:31.761Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/17/d9/110de31880016e2afc52d8580b397dbe47615defbf09ca8cf55f56c62165/pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl", hash = "sha256:e563271e2c5ff4d4a4cbeb2c83d5cf0d4938b891518e676025f7268c6fe5fe26", size = 31196837, upload-time = "2025-07-18T00:54:34.755Z" },
+    { url = "https://files.pythonhosted.org/packages/df/5f/c1c1997613abf24fceb087e79432d24c19bc6f7259cab57c2c8e5e545fab/pyarrow-21.0.0-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:fee33b0ca46f4c85443d6c450357101e47d53e6c3f008d658c27a2d020d44c79", size = 32659470, upload-time = "2025-07-18T00:54:38.329Z" },
+    { url = "https://files.pythonhosted.org/packages/3e/ed/b1589a777816ee33ba123ba1e4f8f02243a844fed0deec97bde9fb21a5cf/pyarrow-21.0.0-cp310-cp310-manylinux_2_28_aarch64.whl", hash = "sha256:7be45519b830f7c24b21d630a31d48bcebfd5d4d7f9d3bdb49da9cdf6d764edb", size = 41055619, upload-time = "2025-07-18T00:54:42.172Z" },
+    { url = "https://files.pythonhosted.org/packages/44/28/b6672962639e85dc0ac36f71ab3a8f5f38e01b51343d7aa372a6b56fa3f3/pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl", hash = "sha256:26bfd95f6bff443ceae63c65dc7e048670b7e98bc892210acba7e4995d3d4b51", size = 42733488, upload-time = "2025-07-18T00:54:47.132Z" },
+    { url = "https://files.pythonhosted.org/packages/f8/cc/de02c3614874b9089c94eac093f90ca5dfa6d5afe45de3ba847fd950fdf1/pyarrow-21.0.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:bd04ec08f7f8bd113c55868bd3fc442a9db67c27af098c5f814a3091e71cc61a", size = 43329159, upload-time = "2025-07-18T00:54:51.686Z" },
+    { url = "https://files.pythonhosted.org/packages/a6/3e/99473332ac40278f196e105ce30b79ab8affab12f6194802f2593d6b0be2/pyarrow-21.0.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:9b0b14b49ac10654332a805aedfc0147fb3469cbf8ea951b3d040dab12372594", size = 45050567, upload-time = "2025-07-18T00:54:56.679Z" },
+    { url = "https://files.pythonhosted.org/packages/7b/f5/c372ef60593d713e8bfbb7e0c743501605f0ad00719146dc075faf11172b/pyarrow-21.0.0-cp310-cp310-win_amd64.whl", hash = "sha256:9d9f8bcb4c3be7738add259738abdeddc363de1b80e3310e04067aa1ca596634", size = 26217959, upload-time = "2025-07-18T00:55:00.482Z" },
+    { url = "https://files.pythonhosted.org/packages/94/dc/80564a3071a57c20b7c32575e4a0120e8a330ef487c319b122942d665960/pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl", hash = "sha256:c077f48aab61738c237802836fc3844f85409a46015635198761b0d6a688f87b", size = 31243234, upload-time = "2025-07-18T00:55:03.812Z" },
+    { url = "https://files.pythonhosted.org/packages/ea/cc/3b51cb2db26fe535d14f74cab4c79b191ed9a8cd4cbba45e2379b5ca2746/pyarrow-21.0.0-cp311-cp311-macosx_12_0_x86_64.whl", hash = "sha256:689f448066781856237eca8d1975b98cace19b8dd2ab6145bf49475478bcaa10", size = 32714370, upload-time = "2025-07-18T00:55:07.495Z" },
+    { url = "https://files.pythonhosted.org/packages/24/11/a4431f36d5ad7d83b87146f515c063e4d07ef0b7240876ddb885e6b44f2e/pyarrow-21.0.0-cp311-cp311-manylinux_2_28_aarch64.whl", hash = "sha256:479ee41399fcddc46159a551705b89c05f11e8b8cb8e968f7fec64f62d91985e", size = 41135424, upload-time = "2025-07-18T00:55:11.461Z" },
+    { url = "https://files.pythonhosted.org/packages/74/dc/035d54638fc5d2971cbf1e987ccd45f1091c83bcf747281cf6cc25e72c88/pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl", hash = "sha256:40ebfcb54a4f11bcde86bc586cbd0272bac0d516cfa539c799c2453768477569", size = 42823810, upload-time = "2025-07-18T00:55:16.301Z" },
+    { url = "https://files.pythonhosted.org/packages/2e/3b/89fced102448a9e3e0d4dded1f37fa3ce4700f02cdb8665457fcc8015f5b/pyarrow-21.0.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:8d58d8497814274d3d20214fbb24abcad2f7e351474357d552a8d53bce70c70e", size = 43391538, upload-time = "2025-07-18T00:55:23.82Z" },
+    { url = "https://files.pythonhosted.org/packages/fb/bb/ea7f1bd08978d39debd3b23611c293f64a642557e8141c80635d501e6d53/pyarrow-21.0.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:585e7224f21124dd57836b1530ac8f2df2afc43c861d7bf3d58a4870c42ae36c", size = 45120056, upload-time = "2025-07-18T00:55:28.231Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/0b/77ea0600009842b30ceebc3337639a7380cd946061b620ac1a2f3cb541e2/pyarrow-21.0.0-cp311-cp311-win_amd64.whl", hash = "sha256:555ca6935b2cbca2c0e932bedd853e9bc523098c39636de9ad4693b5b1df86d6", size = 26220568, upload-time = "2025-07-18T00:55:32.122Z" },
+    { url = "https://files.pythonhosted.org/packages/ca/d4/d4f817b21aacc30195cf6a46ba041dd1be827efa4a623cc8bf39a1c2a0c0/pyarrow-21.0.0-cp312-cp312-macosx_12_0_arm64.whl", hash = "sha256:3a302f0e0963db37e0a24a70c56cf91a4faa0bca51c23812279ca2e23481fccd", size = 31160305, upload-time = "2025-07-18T00:55:35.373Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/9c/dcd38ce6e4b4d9a19e1d36914cb8e2b1da4e6003dd075474c4cfcdfe0601/pyarrow-21.0.0-cp312-cp312-macosx_12_0_x86_64.whl", hash = "sha256:b6b27cf01e243871390474a211a7922bfbe3bda21e39bc9160daf0da3fe48876", size = 32684264, upload-time = "2025-07-18T00:55:39.303Z" },
+    { url = "https://files.pythonhosted.org/packages/4f/74/2a2d9f8d7a59b639523454bec12dba35ae3d0a07d8ab529dc0809f74b23c/pyarrow-21.0.0-cp312-cp312-manylinux_2_28_aarch64.whl", hash = "sha256:e72a8ec6b868e258a2cd2672d91f2860ad532d590ce94cdf7d5e7ec674ccf03d", size = 41108099, upload-time = "2025-07-18T00:55:42.889Z" },
+    { url = "https://files.pythonhosted.org/packages/ad/90/2660332eeb31303c13b653ea566a9918484b6e4d6b9d2d46879a33ab0622/pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl", hash = "sha256:b7ae0bbdc8c6674259b25bef5d2a1d6af5d39d7200c819cf99e07f7dfef1c51e", size = 42829529, upload-time = "2025-07-18T00:55:47.069Z" },
+    { url = "https://files.pythonhosted.org/packages/33/27/1a93a25c92717f6aa0fca06eb4700860577d016cd3ae51aad0e0488ac899/pyarrow-21.0.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:58c30a1729f82d201627c173d91bd431db88ea74dcaa3885855bc6203e433b82", size = 43367883, upload-time = "2025-07-18T00:55:53.069Z" },
+    { url = "https://files.pythonhosted.org/packages/05/d9/4d09d919f35d599bc05c6950095e358c3e15148ead26292dfca1fb659b0c/pyarrow-21.0.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:072116f65604b822a7f22945a7a6e581cfa28e3454fdcc6939d4ff6090126623", size = 45133802, upload-time = "2025-07-18T00:55:57.714Z" },
+    { url = "https://files.pythonhosted.org/packages/71/30/f3795b6e192c3ab881325ffe172e526499eb3780e306a15103a2764916a2/pyarrow-21.0.0-cp312-cp312-win_amd64.whl", hash = "sha256:cf56ec8b0a5c8c9d7021d6fd754e688104f9ebebf1bf4449613c9531f5346a18", size = 26203175, upload-time = "2025-07-18T00:56:01.364Z" },
+    { url = "https://files.pythonhosted.org/packages/16/ca/c7eaa8e62db8fb37ce942b1ea0c6d7abfe3786ca193957afa25e71b81b66/pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl", hash = "sha256:e99310a4ebd4479bcd1964dff9e14af33746300cb014aa4a3781738ac63baf4a", size = 31154306, upload-time = "2025-07-18T00:56:04.42Z" },
+    { url = "https://files.pythonhosted.org/packages/ce/e8/e87d9e3b2489302b3a1aea709aaca4b781c5252fcb812a17ab6275a9a484/pyarrow-21.0.0-cp313-cp313-macosx_12_0_x86_64.whl", hash = "sha256:d2fe8e7f3ce329a71b7ddd7498b3cfac0eeb200c2789bd840234f0dc271a8efe", size = 32680622, upload-time = "2025-07-18T00:56:07.505Z" },
+    { url = "https://files.pythonhosted.org/packages/84/52/79095d73a742aa0aba370c7942b1b655f598069489ab387fe47261a849e1/pyarrow-21.0.0-cp313-cp313-manylinux_2_28_aarch64.whl", hash = "sha256:f522e5709379d72fb3da7785aa489ff0bb87448a9dc5a75f45763a795a089ebd", size = 41104094, upload-time = "2025-07-18T00:56:10.994Z" },
+    { url = "https://files.pythonhosted.org/packages/89/4b/7782438b551dbb0468892a276b8c789b8bbdb25ea5c5eb27faadd753e037/pyarrow-21.0.0-cp313-cp313-manylinux_2_28_x86_64.whl", hash = "sha256:69cbbdf0631396e9925e048cfa5bce4e8c3d3b41562bbd70c685a8eb53a91e61", size = 42825576, upload-time = "2025-07-18T00:56:15.569Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/62/0f29de6e0a1e33518dec92c65be0351d32d7ca351e51ec5f4f837a9aab91/pyarrow-21.0.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:731c7022587006b755d0bdb27626a1a3bb004bb56b11fb30d98b6c1b4718579d", size = 43368342, upload-time = "2025-07-18T00:56:19.531Z" },
+    { url = "https://files.pythonhosted.org/packages/90/c7/0fa1f3f29cf75f339768cc698c8ad4ddd2481c1742e9741459911c9ac477/pyarrow-21.0.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:dc56bc708f2d8ac71bd1dcb927e458c93cec10b98eb4120206a4091db7b67b99", size = 45131218, upload-time = "2025-07-18T00:56:23.347Z" },
+    { url = "https://files.pythonhosted.org/packages/01/63/581f2076465e67b23bc5a37d4a2abff8362d389d29d8105832e82c9c811c/pyarrow-21.0.0-cp313-cp313-win_amd64.whl", hash = "sha256:186aa00bca62139f75b7de8420f745f2af12941595bbbfa7ed3870ff63e25636", size = 26087551, upload-time = "2025-07-18T00:56:26.758Z" },
+    { url = "https://files.pythonhosted.org/packages/c9/ab/357d0d9648bb8241ee7348e564f2479d206ebe6e1c47ac5027c2e31ecd39/pyarrow-21.0.0-cp313-cp313t-macosx_12_0_arm64.whl", hash = "sha256:a7a102574faa3f421141a64c10216e078df467ab9576684d5cd696952546e2da", size = 31290064, upload-time = "2025-07-18T00:56:30.214Z" },
+    { url = "https://files.pythonhosted.org/packages/3f/8a/5685d62a990e4cac2043fc76b4661bf38d06efed55cf45a334b455bd2759/pyarrow-21.0.0-cp313-cp313t-macosx_12_0_x86_64.whl", hash = "sha256:1e005378c4a2c6db3ada3ad4c217b381f6c886f0a80d6a316fe586b90f77efd7", size = 32727837, upload-time = "2025-07-18T00:56:33.935Z" },
+    { url = "https://files.pythonhosted.org/packages/fc/de/c0828ee09525c2bafefd3e736a248ebe764d07d0fd762d4f0929dbc516c9/pyarrow-21.0.0-cp313-cp313t-manylinux_2_28_aarch64.whl", hash = "sha256:65f8e85f79031449ec8706b74504a316805217b35b6099155dd7e227eef0d4b6", size = 41014158, upload-time = "2025-07-18T00:56:37.528Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/26/a2865c420c50b7a3748320b614f3484bfcde8347b2639b2b903b21ce6a72/pyarrow-21.0.0-cp313-cp313t-manylinux_2_28_x86_64.whl", hash = "sha256:3a81486adc665c7eb1a2bde0224cfca6ceaba344a82a971ef059678417880eb8", size = 42667885, upload-time = "2025-07-18T00:56:41.483Z" },
+    { url = "https://files.pythonhosted.org/packages/0a/f9/4ee798dc902533159250fb4321267730bc0a107d8c6889e07c3add4fe3a5/pyarrow-21.0.0-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:fc0d2f88b81dcf3ccf9a6ae17f89183762c8a94a5bdcfa09e05cfe413acf0503", size = 43276625, upload-time = "2025-07-18T00:56:48.002Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/da/e02544d6997037a4b0d22d8e5f66bc9315c3671371a8b18c79ade1cefe14/pyarrow-21.0.0-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:6299449adf89df38537837487a4f8d3bd91ec94354fdd2a7d30bc11c48ef6e79", size = 44951890, upload-time = "2025-07-18T00:56:52.568Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/4e/519c1bc1876625fe6b71e9a28287c43ec2f20f73c658b9ae1d485c0c206e/pyarrow-21.0.0-cp313-cp313t-win_amd64.whl", hash = "sha256:222c39e2c70113543982c6b34f3077962b44fca38c0bd9e68bb6781534425c10", size = 26371006, upload-time = "2025-07-18T00:56:56.379Z" },
+    { url = "https://files.pythonhosted.org/packages/3e/cc/ce4939f4b316457a083dc5718b3982801e8c33f921b3c98e7a93b7c7491f/pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl", hash = "sha256:a7f6524e3747e35f80744537c78e7302cd41deee8baa668d56d55f77d9c464b3", size = 31211248, upload-time = "2025-07-18T00:56:59.7Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/c2/7a860931420d73985e2f340f06516b21740c15b28d24a0e99a900bb27d2b/pyarrow-21.0.0-cp39-cp39-macosx_12_0_x86_64.whl", hash = "sha256:203003786c9fd253ebcafa44b03c06983c9c8d06c3145e37f1b76a1f317aeae1", size = 32676896, upload-time = "2025-07-18T00:57:03.884Z" },
+    { url = "https://files.pythonhosted.org/packages/68/a8/197f989b9a75e59b4ca0db6a13c56f19a0ad8a298c68da9cc28145e0bb97/pyarrow-21.0.0-cp39-cp39-manylinux_2_28_aarch64.whl", hash = "sha256:3b4d97e297741796fead24867a8dabf86c87e4584ccc03167e4a811f50fdf74d", size = 41067862, upload-time = "2025-07-18T00:57:07.587Z" },
+    { url = "https://files.pythonhosted.org/packages/fa/82/6ecfa89487b35aa21accb014b64e0a6b814cc860d5e3170287bf5135c7d8/pyarrow-21.0.0-cp39-cp39-manylinux_2_28_x86_64.whl", hash = "sha256:898afce396b80fdda05e3086b4256f8677c671f7b1d27a6976fa011d3fd0a86e", size = 42747508, upload-time = "2025-07-18T00:57:13.917Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/b7/ba252f399bbf3addc731e8643c05532cf32e74cebb5e32f8f7409bc243cf/pyarrow-21.0.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:067c66ca29aaedae08218569a114e413b26e742171f526e828e1064fcdec13f4", size = 43345293, upload-time = "2025-07-18T00:57:19.828Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/0a/a20819795bd702b9486f536a8eeb70a6aa64046fce32071c19ec8230dbaa/pyarrow-21.0.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:0c4e75d13eb76295a49e0ea056eb18dbd87d81450bfeb8afa19a7e5a75ae2ad7", size = 45060670, upload-time = "2025-07-18T00:57:24.477Z" },
+    { url = "https://files.pythonhosted.org/packages/10/15/6b30e77872012bbfe8265d42a01d5b3c17ef0ac0f2fae531ad91b6a6c02e/pyarrow-21.0.0-cp39-cp39-win_amd64.whl", hash = "sha256:cdc4c17afda4dab2a9c0b79148a43a7f4e1094916b3e18d8975bfd6d6d52241f", size = 26227521, upload-time = "2025-07-18T00:57:29.119Z" },
+]
+
+[[package]]
+name = "pyarrow"
+version = "22.0.0"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/30/53/04a7fdc63e6056116c9ddc8b43bc28c12cdd181b85cbeadb79278475f3ae/pyarrow-22.0.0.tar.gz", hash = "sha256:3d600dc583260d845c7d8a6db540339dd883081925da2bd1c5cb808f720b3cd9", size = 1151151, upload-time = "2025-10-24T12:30:00.762Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/d9/9b/cb3f7e0a345353def531ca879053e9ef6b9f38ed91aebcf68b09ba54dec0/pyarrow-22.0.0-cp310-cp310-macosx_12_0_arm64.whl", hash = "sha256:77718810bd3066158db1e95a63c160ad7ce08c6b0710bc656055033e39cdad88", size = 34223968, upload-time = "2025-10-24T10:03:31.21Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/41/3184b8192a120306270c5307f105b70320fdaa592c99843c5ef78aaefdcf/pyarrow-22.0.0-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:44d2d26cda26d18f7af7db71453b7b783788322d756e81730acb98f24eb90ace", size = 35942085, upload-time = "2025-10-24T10:03:38.146Z" },
+    { url = "https://files.pythonhosted.org/packages/d9/3d/a1eab2f6f08001f9fb714b8ed5cfb045e2fe3e3e3c0c221f2c9ed1e6d67d/pyarrow-22.0.0-cp310-cp310-manylinux_2_28_aarch64.whl", hash = "sha256:b9d71701ce97c95480fecb0039ec5bb889e75f110da72005743451339262f4ce", size = 44964613, upload-time = "2025-10-24T10:03:46.516Z" },
+    { url = "https://files.pythonhosted.org/packages/46/46/a1d9c24baf21cfd9ce994ac820a24608decf2710521b29223d4334985127/pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl", hash = "sha256:710624ab925dc2b05a6229d47f6f0dac1c1155e6ed559be7109f684eba048a48", size = 47627059, upload-time = "2025-10-24T10:03:55.353Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/4c/f711acb13075c1391fd54bc17e078587672c575f8de2a6e62509af026dcf/pyarrow-22.0.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:f963ba8c3b0199f9d6b794c90ec77545e05eadc83973897a4523c9e8d84e9340", size = 47947043, upload-time = "2025-10-24T10:04:05.408Z" },
+    { url = "https://files.pythonhosted.org/packages/4e/70/1f3180dd7c2eab35c2aca2b29ace6c519f827dcd4cfeb8e0dca41612cf7a/pyarrow-22.0.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:bd0d42297ace400d8febe55f13fdf46e86754842b860c978dfec16f081e5c653", size = 50206505, upload-time = "2025-10-24T10:04:15.786Z" },
+    { url = "https://files.pythonhosted.org/packages/80/07/fea6578112c8c60ffde55883a571e4c4c6bc7049f119d6b09333b5cc6f73/pyarrow-22.0.0-cp310-cp310-win_amd64.whl", hash = "sha256:00626d9dc0f5ef3a75fe63fd68b9c7c8302d2b5bbc7f74ecaedba83447a24f84", size = 28101641, upload-time = "2025-10-24T10:04:22.57Z" },
+    { url = "https://files.pythonhosted.org/packages/2e/b7/18f611a8cdc43417f9394a3ccd3eace2f32183c08b9eddc3d17681819f37/pyarrow-22.0.0-cp311-cp311-macosx_12_0_arm64.whl", hash = "sha256:3e294c5eadfb93d78b0763e859a0c16d4051fc1c5231ae8956d61cb0b5666f5a", size = 34272022, upload-time = "2025-10-24T10:04:28.973Z" },
+    { url = "https://files.pythonhosted.org/packages/26/5c/f259e2526c67eb4b9e511741b19870a02363a47a35edbebc55c3178db22d/pyarrow-22.0.0-cp311-cp311-macosx_12_0_x86_64.whl", hash = "sha256:69763ab2445f632d90b504a815a2a033f74332997052b721002298ed6de40f2e", size = 35995834, upload-time = "2025-10-24T10:04:35.467Z" },
+    { url = "https://files.pythonhosted.org/packages/50/8d/281f0f9b9376d4b7f146913b26fac0aa2829cd1ee7e997f53a27411bbb92/pyarrow-22.0.0-cp311-cp311-manylinux_2_28_aarch64.whl", hash = "sha256:b41f37cabfe2463232684de44bad753d6be08a7a072f6a83447eeaf0e4d2a215", size = 45030348, upload-time = "2025-10-24T10:04:43.366Z" },
+    { url = "https://files.pythonhosted.org/packages/f5/e5/53c0a1c428f0976bf22f513d79c73000926cb00b9c138d8e02daf2102e18/pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl", hash = "sha256:35ad0f0378c9359b3f297299c3309778bb03b8612f987399a0333a560b43862d", size = 47699480, upload-time = "2025-10-24T10:04:51.486Z" },
+    { url = "https://files.pythonhosted.org/packages/95/e1/9dbe4c465c3365959d183e6345d0a8d1dc5b02ca3f8db4760b3bc834cf25/pyarrow-22.0.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:8382ad21458075c2e66a82a29d650f963ce51c7708c7c0ff313a8c206c4fd5e8", size = 48011148, upload-time = "2025-10-24T10:04:59.585Z" },
+    { url = "https://files.pythonhosted.org/packages/c5/b4/7caf5d21930061444c3cf4fa7535c82faf5263e22ce43af7c2759ceb5b8b/pyarrow-22.0.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:1a812a5b727bc09c3d7ea072c4eebf657c2f7066155506ba31ebf4792f88f016", size = 50276964, upload-time = "2025-10-24T10:05:08.175Z" },
+    { url = "https://files.pythonhosted.org/packages/ae/f3/cec89bd99fa3abf826f14d4e53d3d11340ce6f6af4d14bdcd54cd83b6576/pyarrow-22.0.0-cp311-cp311-win_amd64.whl", hash = "sha256:ec5d40dd494882704fb876c16fa7261a69791e784ae34e6b5992e977bd2e238c", size = 28106517, upload-time = "2025-10-24T10:05:14.314Z" },
+    { url = "https://files.pythonhosted.org/packages/af/63/ba23862d69652f85b615ca14ad14f3bcfc5bf1b99ef3f0cd04ff93fdad5a/pyarrow-22.0.0-cp312-cp312-macosx_12_0_arm64.whl", hash = "sha256:bea79263d55c24a32b0d79c00a1c58bb2ee5f0757ed95656b01c0fb310c5af3d", size = 34211578, upload-time = "2025-10-24T10:05:21.583Z" },
+    { url = "https://files.pythonhosted.org/packages/b1/d0/f9ad86fe809efd2bcc8be32032fa72e8b0d112b01ae56a053006376c5930/pyarrow-22.0.0-cp312-cp312-macosx_12_0_x86_64.whl", hash = "sha256:12fe549c9b10ac98c91cf791d2945e878875d95508e1a5d14091a7aaa66d9cf8", size = 35989906, upload-time = "2025-10-24T10:05:29.485Z" },
+    { url = "https://files.pythonhosted.org/packages/b4/a8/f910afcb14630e64d673f15904ec27dd31f1e009b77033c365c84e8c1e1d/pyarrow-22.0.0-cp312-cp312-manylinux_2_28_aarch64.whl", hash = "sha256:334f900ff08ce0423407af97e6c26ad5d4e3b0763645559ece6fbf3747d6a8f5", size = 45021677, upload-time = "2025-10-24T10:05:38.274Z" },
+    { url = "https://files.pythonhosted.org/packages/13/95/aec81f781c75cd10554dc17a25849c720d54feafb6f7847690478dcf5ef8/pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl", hash = "sha256:c6c791b09c57ed76a18b03f2631753a4960eefbbca80f846da8baefc6491fcfe", size = 47726315, upload-time = "2025-10-24T10:05:47.314Z" },
+    { url = "https://files.pythonhosted.org/packages/bb/d4/74ac9f7a54cfde12ee42734ea25d5a3c9a45db78f9def949307a92720d37/pyarrow-22.0.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:c3200cb41cdbc65156e5f8c908d739b0dfed57e890329413da2748d1a2cd1a4e", size = 47990906, upload-time = "2025-10-24T10:05:58.254Z" },
+    { url = "https://files.pythonhosted.org/packages/2e/71/fedf2499bf7a95062eafc989ace56572f3343432570e1c54e6599d5b88da/pyarrow-22.0.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:ac93252226cf288753d8b46280f4edf3433bf9508b6977f8dd8526b521a1bbb9", size = 50306783, upload-time = "2025-10-24T10:06:08.08Z" },
+    { url = "https://files.pythonhosted.org/packages/68/ed/b202abd5a5b78f519722f3d29063dda03c114711093c1995a33b8e2e0f4b/pyarrow-22.0.0-cp312-cp312-win_amd64.whl", hash = "sha256:44729980b6c50a5f2bfcc2668d36c569ce17f8b17bccaf470c4313dcbbf13c9d", size = 27972883, upload-time = "2025-10-24T10:06:14.204Z" },
+    { url = "https://files.pythonhosted.org/packages/a6/d6/d0fac16a2963002fc22c8fa75180a838737203d558f0ed3b564c4a54eef5/pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl", hash = "sha256:e6e95176209257803a8b3d0394f21604e796dadb643d2f7ca21b66c9c0b30c9a", size = 34204629, upload-time = "2025-10-24T10:06:20.274Z" },
+    { url = "https://files.pythonhosted.org/packages/c6/9c/1d6357347fbae062ad3f17082f9ebc29cc733321e892c0d2085f42a2212b/pyarrow-22.0.0-cp313-cp313-macosx_12_0_x86_64.whl", hash = "sha256:001ea83a58024818826a9e3f89bf9310a114f7e26dfe404a4c32686f97bd7901", size = 35985783, upload-time = "2025-10-24T10:06:27.301Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/c0/782344c2ce58afbea010150df07e3a2f5fdad299cd631697ae7bd3bac6e3/pyarrow-22.0.0-cp313-cp313-manylinux_2_28_aarch64.whl", hash = "sha256:ce20fe000754f477c8a9125543f1936ea5b8867c5406757c224d745ed033e691", size = 45020999, upload-time = "2025-10-24T10:06:35.387Z" },
+    { url = "https://files.pythonhosted.org/packages/1b/8b/5362443737a5307a7b67c1017c42cd104213189b4970bf607e05faf9c525/pyarrow-22.0.0-cp313-cp313-manylinux_2_28_x86_64.whl", hash = "sha256:e0a15757fccb38c410947df156f9749ae4a3c89b2393741a50521f39a8cf202a", size = 47724601, upload-time = "2025-10-24T10:06:43.551Z" },
+    { url = "https://files.pythonhosted.org/packages/69/4d/76e567a4fc2e190ee6072967cb4672b7d9249ac59ae65af2d7e3047afa3b/pyarrow-22.0.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:cedb9dd9358e4ea1d9bce3665ce0797f6adf97ff142c8e25b46ba9cdd508e9b6", size = 48001050, upload-time = "2025-10-24T10:06:52.284Z" },
+    { url = "https://files.pythonhosted.org/packages/01/5e/5653f0535d2a1aef8223cee9d92944cb6bccfee5cf1cd3f462d7cb022790/pyarrow-22.0.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:252be4a05f9d9185bb8c18e83764ebcfea7185076c07a7a662253af3a8c07941", size = 50307877, upload-time = "2025-10-24T10:07:02.405Z" },
+    { url = "https://files.pythonhosted.org/packages/2d/f8/1d0bd75bf9328a3b826e24a16e5517cd7f9fbf8d34a3184a4566ef5a7f29/pyarrow-22.0.0-cp313-cp313-win_amd64.whl", hash = "sha256:a4893d31e5ef780b6edcaf63122df0f8d321088bb0dee4c8c06eccb1ca28d145", size = 27977099, upload-time = "2025-10-24T10:08:07.259Z" },
+    { url = "https://files.pythonhosted.org/packages/90/81/db56870c997805bf2b0f6eeeb2d68458bf4654652dccdcf1bf7a42d80903/pyarrow-22.0.0-cp313-cp313t-macosx_12_0_arm64.whl", hash = "sha256:f7fe3dbe871294ba70d789be16b6e7e52b418311e166e0e3cba9522f0f437fb1", size = 34336685, upload-time = "2025-10-24T10:07:11.47Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/98/0727947f199aba8a120f47dfc229eeb05df15bcd7a6f1b669e9f882afc58/pyarrow-22.0.0-cp313-cp313t-macosx_12_0_x86_64.whl", hash = "sha256:ba95112d15fd4f1105fb2402c4eab9068f0554435e9b7085924bcfaac2cc306f", size = 36032158, upload-time = "2025-10-24T10:07:18.626Z" },
+    { url = "https://files.pythonhosted.org/packages/96/b4/9babdef9c01720a0785945c7cf550e4acd0ebcd7bdd2e6f0aa7981fa85e2/pyarrow-22.0.0-cp313-cp313t-manylinux_2_28_aarch64.whl", hash = "sha256:c064e28361c05d72eed8e744c9605cbd6d2bb7481a511c74071fd9b24bc65d7d", size = 44892060, upload-time = "2025-10-24T10:07:26.002Z" },
+    { url = "https://files.pythonhosted.org/packages/f8/ca/2f8804edd6279f78a37062d813de3f16f29183874447ef6d1aadbb4efa0f/pyarrow-22.0.0-cp313-cp313t-manylinux_2_28_x86_64.whl", hash = "sha256:6f9762274496c244d951c819348afbcf212714902742225f649cf02823a6a10f", size = 47504395, upload-time = "2025-10-24T10:07:34.09Z" },
+    { url = "https://files.pythonhosted.org/packages/b9/f0/77aa5198fd3943682b2e4faaf179a674f0edea0d55d326d83cb2277d9363/pyarrow-22.0.0-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:a9d9ffdc2ab696f6b15b4d1f7cec6658e1d788124418cb30030afbae31c64746", size = 48066216, upload-time = "2025-10-24T10:07:43.528Z" },
+    { url = "https://files.pythonhosted.org/packages/79/87/a1937b6e78b2aff18b706d738c9e46ade5bfcf11b294e39c87706a0089ac/pyarrow-22.0.0-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:ec1a15968a9d80da01e1d30349b2b0d7cc91e96588ee324ce1b5228175043e95", size = 50288552, upload-time = "2025-10-24T10:07:53.519Z" },
+    { url = "https://files.pythonhosted.org/packages/60/ae/b5a5811e11f25788ccfdaa8f26b6791c9807119dffcf80514505527c384c/pyarrow-22.0.0-cp313-cp313t-win_amd64.whl", hash = "sha256:bba208d9c7decf9961998edf5c65e3ea4355d5818dd6cd0f6809bec1afb951cc", size = 28262504, upload-time = "2025-10-24T10:08:00.932Z" },
+    { url = "https://files.pythonhosted.org/packages/bd/b0/0fa4d28a8edb42b0a7144edd20befd04173ac79819547216f8a9f36f9e50/pyarrow-22.0.0-cp314-cp314-macosx_12_0_arm64.whl", hash = "sha256:9bddc2cade6561f6820d4cd73f99a0243532ad506bc510a75a5a65a522b2d74d", size = 34224062, upload-time = "2025-10-24T10:08:14.101Z" },
+    { url = "https://files.pythonhosted.org/packages/0f/a8/7a719076b3c1be0acef56a07220c586f25cd24de0e3f3102b438d18ae5df/pyarrow-22.0.0-cp314-cp314-macosx_12_0_x86_64.whl", hash = "sha256:e70ff90c64419709d38c8932ea9fe1cc98415c4f87ea8da81719e43f02534bc9", size = 35990057, upload-time = "2025-10-24T10:08:21.842Z" },
+    { url = "https://files.pythonhosted.org/packages/89/3c/359ed54c93b47fb6fe30ed16cdf50e3f0e8b9ccfb11b86218c3619ae50a8/pyarrow-22.0.0-cp314-cp314-manylinux_2_28_aarch64.whl", hash = "sha256:92843c305330aa94a36e706c16209cd4df274693e777ca47112617db7d0ef3d7", size = 45068002, upload-time = "2025-10-24T10:08:29.034Z" },
+    { url = "https://files.pythonhosted.org/packages/55/fc/4945896cc8638536ee787a3bd6ce7cec8ec9acf452d78ec39ab328efa0a1/pyarrow-22.0.0-cp314-cp314-manylinux_2_28_x86_64.whl", hash = "sha256:6dda1ddac033d27421c20d7a7943eec60be44e0db4e079f33cc5af3b8280ccde", size = 47737765, upload-time = "2025-10-24T10:08:38.559Z" },
+    { url = "https://files.pythonhosted.org/packages/cd/5e/7cb7edeb2abfaa1f79b5d5eb89432356155c8426f75d3753cbcb9592c0fd/pyarrow-22.0.0-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:84378110dd9a6c06323b41b56e129c504d157d1a983ce8f5443761eb5256bafc", size = 48048139, upload-time = "2025-10-24T10:08:46.784Z" },
+    { url = "https://files.pythonhosted.org/packages/88/c6/546baa7c48185f5e9d6e59277c4b19f30f48c94d9dd938c2a80d4d6b067c/pyarrow-22.0.0-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:854794239111d2b88b40b6ef92aa478024d1e5074f364033e73e21e3f76b25e0", size = 50314244, upload-time = "2025-10-24T10:08:55.771Z" },
+    { url = "https://files.pythonhosted.org/packages/3c/79/755ff2d145aafec8d347bf18f95e4e81c00127f06d080135dfc86aea417c/pyarrow-22.0.0-cp314-cp314-win_amd64.whl", hash = "sha256:b883fe6fd85adad7932b3271c38ac289c65b7337c2c132e9569f9d3940620730", size = 28757501, upload-time = "2025-10-24T10:09:59.891Z" },
+    { url = "https://files.pythonhosted.org/packages/0e/d2/237d75ac28ced3147912954e3c1a174df43a95f4f88e467809118a8165e0/pyarrow-22.0.0-cp314-cp314t-macosx_12_0_arm64.whl", hash = "sha256:7a820d8ae11facf32585507c11f04e3f38343c1e784c9b5a8b1da5c930547fe2", size = 34355506, upload-time = "2025-10-24T10:09:02.953Z" },
+    { url = "https://files.pythonhosted.org/packages/1e/2c/733dfffe6d3069740f98e57ff81007809067d68626c5faef293434d11bd6/pyarrow-22.0.0-cp314-cp314t-macosx_12_0_x86_64.whl", hash = "sha256:c6ec3675d98915bf1ec8b3c7986422682f7232ea76cad276f4c8abd5b7319b70", size = 36047312, upload-time = "2025-10-24T10:09:10.334Z" },
+    { url = "https://files.pythonhosted.org/packages/7c/2b/29d6e3782dc1f299727462c1543af357a0f2c1d3c160ce199950d9ca51eb/pyarrow-22.0.0-cp314-cp314t-manylinux_2_28_aarch64.whl", hash = "sha256:3e739edd001b04f654b166204fc7a9de896cf6007eaff33409ee9e50ceaff754", size = 45081609, upload-time = "2025-10-24T10:09:18.61Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/42/aa9355ecc05997915af1b7b947a7f66c02dcaa927f3203b87871c114ba10/pyarrow-22.0.0-cp314-cp314t-manylinux_2_28_x86_64.whl", hash = "sha256:7388ac685cab5b279a41dfe0a6ccd99e4dbf322edfb63e02fc0443bf24134e91", size = 47703663, upload-time = "2025-10-24T10:09:27.369Z" },
+    { url = "https://files.pythonhosted.org/packages/ee/62/45abedde480168e83a1de005b7b7043fd553321c1e8c5a9a114425f64842/pyarrow-22.0.0-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:f633074f36dbc33d5c05b5dc75371e5660f1dbf9c8b1d95669def05e5425989c", size = 48066543, upload-time = "2025-10-24T10:09:34.908Z" },
+    { url = "https://files.pythonhosted.org/packages/84/e9/7878940a5b072e4f3bf998770acafeae13b267f9893af5f6d4ab3904b67e/pyarrow-22.0.0-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:4c19236ae2402a8663a2c8f21f1870a03cc57f0bef7e4b6eb3238cc82944de80", size = 50288838, upload-time = "2025-10-24T10:09:44.394Z" },
+    { url = "https://files.pythonhosted.org/packages/7b/03/f335d6c52b4a4761bcc83499789a1e2e16d9d201a58c327a9b5cc9a41bd9/pyarrow-22.0.0-cp314-cp314t-win_amd64.whl", hash = "sha256:0c34fe18094686194f204a3b1787a27456897d8a2d62caf84b61e8dfbc0252ae", size = 29185594, upload-time = "2025-10-24T10:09:53.111Z" },
+]
+
+[[package]]
+name = "pyasn1"
+version = "0.6.1"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/ba/e9/01f1a64245b89f039897cb0130016d79f77d52669aae6ee7b159a6c4c018/pyasn1-0.6.1.tar.gz", hash = "sha256:6f580d2bdd84365380830acf45550f2511469f673cb4a5ae3857a3170128b034", size = 145322, upload-time = "2024-09-10T22:41:42.55Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl", hash = "sha256:0d632f46f2ba09143da3a8afe9e33fb6f92fa2320ab7e886e2d0f7672af84629", size = 83135, upload-time = "2024-09-11T16:00:36.122Z" },
+]
+
+[[package]]
+name = "pyasn1-modules"
+version = "0.4.2"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "pyasn1" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/e9/e6/78ebbb10a8c8e4b61a59249394a4a594c1a7af95593dc933a349c8d00964/pyasn1_modules-0.4.2.tar.gz", hash = "sha256:677091de870a80aae844b1ca6134f54652fa2c8c5a52aa396440ac3106e941e6", size = 307892, upload-time = "2025-03-28T02:41:22.17Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl", hash = "sha256:29253a9207ce32b64c3ac6600edc75368f98473906e8fd1043bd6b5b1de2c14a", size = 181259, upload-time = "2025-03-28T02:41:19.028Z" },
+]
+
 [[package]]
 name = "pycparser"
 version = "2.23"
@@ -1247,6 +2223,152 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/a0/e3/59cd50310fc9b59512193629e1984c1f95e5c8ae6e5d8c69532ccc65a7fe/pycparser-2.23-py3-none-any.whl", hash = "sha256:e5c6e8d3fbad53479cab09ac03729e0a9faf2bee3db8208a550daf5af81a5934", size = 118140, upload-time = "2025-09-09T13:23:46.651Z" },
 ]
 
+[[package]]
+name = "pydantic"
+version = "2.12.4"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "annotated-types" },
+    { name = "pydantic-core" },
+    { name = "typing-extensions" },
+    { name = "typing-inspection" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/96/ad/a17bc283d7d81837c061c49e3eaa27a45991759a1b7eae1031921c6bd924/pydantic-2.12.4.tar.gz", hash = "sha256:0f8cb9555000a4b5b617f66bfd2566264c4984b27589d3b845685983e8ea85ac", size = 821038, upload-time = "2025-11-05T10:50:08.59Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/82/2f/e68750da9b04856e2a7ec56fc6f034a5a79775e9b9a81882252789873798/pydantic-2.12.4-py3-none-any.whl", hash = "sha256:92d3d202a745d46f9be6df459ac5a064fdaa3c1c4cd8adcfa332ccf3c05f871e", size = 463400, upload-time = "2025-11-05T10:50:06.732Z" },
+]
+
+[[package]]
+name = "pydantic-core"
+version = "2.41.5"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "typing-extensions" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/71/70/23b021c950c2addd24ec408e9ab05d59b035b39d97cdc1130e1bce647bb6/pydantic_core-2.41.5.tar.gz", hash = "sha256:08daa51ea16ad373ffd5e7606252cc32f07bc72b28284b6bc9c6df804816476e", size = 460952, upload-time = "2025-11-04T13:43:49.098Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c6/90/32c9941e728d564b411d574d8ee0cf09b12ec978cb22b294995bae5549a5/pydantic_core-2.41.5-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:77b63866ca88d804225eaa4af3e664c5faf3568cea95360d21f4725ab6e07146", size = 2107298, upload-time = "2025-11-04T13:39:04.116Z" },
+    { url = "https://files.pythonhosted.org/packages/fb/a8/61c96a77fe28993d9a6fb0f4127e05430a267b235a124545d79fea46dd65/pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:dfa8a0c812ac681395907e71e1274819dec685fec28273a28905df579ef137e2", size = 1901475, upload-time = "2025-11-04T13:39:06.055Z" },
+    { url = "https://files.pythonhosted.org/packages/5d/b6/338abf60225acc18cdc08b4faef592d0310923d19a87fba1faf05af5346e/pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5921a4d3ca3aee735d9fd163808f5e8dd6c6972101e4adbda9a4667908849b97", size = 1918815, upload-time = "2025-11-04T13:39:10.41Z" },
+    { url = "https://files.pythonhosted.org/packages/d1/1c/2ed0433e682983d8e8cba9c8d8ef274d4791ec6a6f24c58935b90e780e0a/pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:e25c479382d26a2a41b7ebea1043564a937db462816ea07afa8a44c0866d52f9", size = 2065567, upload-time = "2025-11-04T13:39:12.244Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/24/cf84974ee7d6eae06b9e63289b7b8f6549d416b5c199ca2d7ce13bbcf619/pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f547144f2966e1e16ae626d8ce72b4cfa0caedc7fa28052001c94fb2fcaa1c52", size = 2230442, upload-time = "2025-11-04T13:39:13.962Z" },
+    { url = "https://files.pythonhosted.org/packages/fd/21/4e287865504b3edc0136c89c9c09431be326168b1eb7841911cbc877a995/pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6f52298fbd394f9ed112d56f3d11aabd0d5bd27beb3084cc3d8ad069483b8941", size = 2350956, upload-time = "2025-11-04T13:39:15.889Z" },
+    { url = "https://files.pythonhosted.org/packages/a8/76/7727ef2ffa4b62fcab916686a68a0426b9b790139720e1934e8ba797e238/pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:100baa204bb412b74fe285fb0f3a385256dad1d1879f0a5cb1499ed2e83d132a", size = 2068253, upload-time = "2025-11-04T13:39:17.403Z" },
+    { url = "https://files.pythonhosted.org/packages/d5/8c/a4abfc79604bcb4c748e18975c44f94f756f08fb04218d5cb87eb0d3a63e/pydantic_core-2.41.5-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:05a2c8852530ad2812cb7914dc61a1125dc4e06252ee98e5638a12da6cc6fb6c", size = 2177050, upload-time = "2025-11-04T13:39:19.351Z" },
+    { url = "https://files.pythonhosted.org/packages/67/b1/de2e9a9a79b480f9cb0b6e8b6ba4c50b18d4e89852426364c66aa82bb7b3/pydantic_core-2.41.5-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:29452c56df2ed968d18d7e21f4ab0ac55e71dc59524872f6fc57dcf4a3249ed2", size = 2147178, upload-time = "2025-11-04T13:39:21Z" },
+    { url = "https://files.pythonhosted.org/packages/16/c1/dfb33f837a47b20417500efaa0378adc6635b3c79e8369ff7a03c494b4ac/pydantic_core-2.41.5-cp310-cp310-musllinux_1_1_armv7l.whl", hash = "sha256:d5160812ea7a8a2ffbe233d8da666880cad0cbaf5d4de74ae15c313213d62556", size = 2341833, upload-time = "2025-11-04T13:39:22.606Z" },
+    { url = "https://files.pythonhosted.org/packages/47/36/00f398642a0f4b815a9a558c4f1dca1b4020a7d49562807d7bc9ff279a6c/pydantic_core-2.41.5-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:df3959765b553b9440adfd3c795617c352154e497a4eaf3752555cfb5da8fc49", size = 2321156, upload-time = "2025-11-04T13:39:25.843Z" },
+    { url = "https://files.pythonhosted.org/packages/7e/70/cad3acd89fde2010807354d978725ae111ddf6d0ea46d1ea1775b5c1bd0c/pydantic_core-2.41.5-cp310-cp310-win32.whl", hash = "sha256:1f8d33a7f4d5a7889e60dc39856d76d09333d8a6ed0f5f1190635cbec70ec4ba", size = 1989378, upload-time = "2025-11-04T13:39:27.92Z" },
+    { url = "https://files.pythonhosted.org/packages/76/92/d338652464c6c367e5608e4488201702cd1cbb0f33f7b6a85a60fe5f3720/pydantic_core-2.41.5-cp310-cp310-win_amd64.whl", hash = "sha256:62de39db01b8d593e45871af2af9e497295db8d73b085f6bfd0b18c83c70a8f9", size = 2013622, upload-time = "2025-11-04T13:39:29.848Z" },
+    { url = "https://files.pythonhosted.org/packages/e8/72/74a989dd9f2084b3d9530b0915fdda64ac48831c30dbf7c72a41a5232db8/pydantic_core-2.41.5-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:a3a52f6156e73e7ccb0f8cced536adccb7042be67cb45f9562e12b319c119da6", size = 2105873, upload-time = "2025-11-04T13:39:31.373Z" },
+    { url = "https://files.pythonhosted.org/packages/12/44/37e403fd9455708b3b942949e1d7febc02167662bf1a7da5b78ee1ea2842/pydantic_core-2.41.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:7f3bf998340c6d4b0c9a2f02d6a400e51f123b59565d74dc60d252ce888c260b", size = 1899826, upload-time = "2025-11-04T13:39:32.897Z" },
+    { url = "https://files.pythonhosted.org/packages/33/7f/1d5cab3ccf44c1935a359d51a8a2a9e1a654b744b5e7f80d41b88d501eec/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:378bec5c66998815d224c9ca994f1e14c0c21cb95d2f52b6021cc0b2a58f2a5a", size = 1917869, upload-time = "2025-11-04T13:39:34.469Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/6a/30d94a9674a7fe4f4744052ed6c5e083424510be1e93da5bc47569d11810/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:e7b576130c69225432866fe2f4a469a85a54ade141d96fd396dffcf607b558f8", size = 2063890, upload-time = "2025-11-04T13:39:36.053Z" },
+    { url = "https://files.pythonhosted.org/packages/50/be/76e5d46203fcb2750e542f32e6c371ffa9b8ad17364cf94bb0818dbfb50c/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:6cb58b9c66f7e4179a2d5e0f849c48eff5c1fca560994d6eb6543abf955a149e", size = 2229740, upload-time = "2025-11-04T13:39:37.753Z" },
+    { url = "https://files.pythonhosted.org/packages/d3/ee/fed784df0144793489f87db310a6bbf8118d7b630ed07aa180d6067e653a/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:88942d3a3dff3afc8288c21e565e476fc278902ae4d6d134f1eeda118cc830b1", size = 2350021, upload-time = "2025-11-04T13:39:40.94Z" },
+    { url = "https://files.pythonhosted.org/packages/c8/be/8fed28dd0a180dca19e72c233cbf58efa36df055e5b9d90d64fd1740b828/pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f31d95a179f8d64d90f6831d71fa93290893a33148d890ba15de25642c5d075b", size = 2066378, upload-time = "2025-11-04T13:39:42.523Z" },
+    { url = "https://files.pythonhosted.org/packages/b0/3b/698cf8ae1d536a010e05121b4958b1257f0b5522085e335360e53a6b1c8b/pydantic_core-2.41.5-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:c1df3d34aced70add6f867a8cf413e299177e0c22660cc767218373d0779487b", size = 2175761, upload-time = "2025-11-04T13:39:44.553Z" },
+    { url = "https://files.pythonhosted.org/packages/b8/ba/15d537423939553116dea94ce02f9c31be0fa9d0b806d427e0308ec17145/pydantic_core-2.41.5-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:4009935984bd36bd2c774e13f9a09563ce8de4abaa7226f5108262fa3e637284", size = 2146303, upload-time = "2025-11-04T13:39:46.238Z" },
+    { url = "https://files.pythonhosted.org/packages/58/7f/0de669bf37d206723795f9c90c82966726a2ab06c336deba4735b55af431/pydantic_core-2.41.5-cp311-cp311-musllinux_1_1_armv7l.whl", hash = "sha256:34a64bc3441dc1213096a20fe27e8e128bd3ff89921706e83c0b1ac971276594", size = 2340355, upload-time = "2025-11-04T13:39:48.002Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/de/e7482c435b83d7e3c3ee5ee4451f6e8973cff0eb6007d2872ce6383f6398/pydantic_core-2.41.5-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:c9e19dd6e28fdcaa5a1de679aec4141f691023916427ef9bae8584f9c2fb3b0e", size = 2319875, upload-time = "2025-11-04T13:39:49.705Z" },
+    { url = "https://files.pythonhosted.org/packages/fe/e6/8c9e81bb6dd7560e33b9053351c29f30c8194b72f2d6932888581f503482/pydantic_core-2.41.5-cp311-cp311-win32.whl", hash = "sha256:2c010c6ded393148374c0f6f0bf89d206bf3217f201faa0635dcd56bd1520f6b", size = 1987549, upload-time = "2025-11-04T13:39:51.842Z" },
+    { url = "https://files.pythonhosted.org/packages/11/66/f14d1d978ea94d1bc21fc98fcf570f9542fe55bfcc40269d4e1a21c19bf7/pydantic_core-2.41.5-cp311-cp311-win_amd64.whl", hash = "sha256:76ee27c6e9c7f16f47db7a94157112a2f3a00e958bc626e2f4ee8bec5c328fbe", size = 2011305, upload-time = "2025-11-04T13:39:53.485Z" },
+    { url = "https://files.pythonhosted.org/packages/56/d8/0e271434e8efd03186c5386671328154ee349ff0354d83c74f5caaf096ed/pydantic_core-2.41.5-cp311-cp311-win_arm64.whl", hash = "sha256:4bc36bbc0b7584de96561184ad7f012478987882ebf9f9c389b23f432ea3d90f", size = 1972902, upload-time = "2025-11-04T13:39:56.488Z" },
+    { url = "https://files.pythonhosted.org/packages/5f/5d/5f6c63eebb5afee93bcaae4ce9a898f3373ca23df3ccaef086d0233a35a7/pydantic_core-2.41.5-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:f41a7489d32336dbf2199c8c0a215390a751c5b014c2c1c5366e817202e9cdf7", size = 2110990, upload-time = "2025-11-04T13:39:58.079Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/32/9c2e8ccb57c01111e0fd091f236c7b371c1bccea0fa85247ac55b1e2b6b6/pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:070259a8818988b9a84a449a2a7337c7f430a22acc0859c6b110aa7212a6d9c0", size = 1896003, upload-time = "2025-11-04T13:39:59.956Z" },
+    { url = "https://files.pythonhosted.org/packages/68/b8/a01b53cb0e59139fbc9e4fda3e9724ede8de279097179be4ff31f1abb65a/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e96cea19e34778f8d59fe40775a7a574d95816eb150850a85a7a4c8f4b94ac69", size = 1919200, upload-time = "2025-11-04T13:40:02.241Z" },
+    { url = "https://files.pythonhosted.org/packages/38/de/8c36b5198a29bdaade07b5985e80a233a5ac27137846f3bc2d3b40a47360/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:ed2e99c456e3fadd05c991f8f437ef902e00eedf34320ba2b0842bd1c3ca3a75", size = 2052578, upload-time = "2025-11-04T13:40:04.401Z" },
+    { url = "https://files.pythonhosted.org/packages/00/b5/0e8e4b5b081eac6cb3dbb7e60a65907549a1ce035a724368c330112adfdd/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:65840751b72fbfd82c3c640cff9284545342a4f1eb1586ad0636955b261b0b05", size = 2208504, upload-time = "2025-11-04T13:40:06.072Z" },
+    { url = "https://files.pythonhosted.org/packages/77/56/87a61aad59c7c5b9dc8caad5a41a5545cba3810c3e828708b3d7404f6cef/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e536c98a7626a98feb2d3eaf75944ef6f3dbee447e1f841eae16f2f0a72d8ddc", size = 2335816, upload-time = "2025-11-04T13:40:07.835Z" },
+    { url = "https://files.pythonhosted.org/packages/0d/76/941cc9f73529988688a665a5c0ecff1112b3d95ab48f81db5f7606f522d3/pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:eceb81a8d74f9267ef4081e246ffd6d129da5d87e37a77c9bde550cb04870c1c", size = 2075366, upload-time = "2025-11-04T13:40:09.804Z" },
+    { url = "https://files.pythonhosted.org/packages/d3/43/ebef01f69baa07a482844faaa0a591bad1ef129253ffd0cdaa9d8a7f72d3/pydantic_core-2.41.5-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d38548150c39b74aeeb0ce8ee1d8e82696f4a4e16ddc6de7b1d8823f7de4b9b5", size = 2171698, upload-time = "2025-11-04T13:40:12.004Z" },
+    { url = "https://files.pythonhosted.org/packages/b1/87/41f3202e4193e3bacfc2c065fab7706ebe81af46a83d3e27605029c1f5a6/pydantic_core-2.41.5-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:c23e27686783f60290e36827f9c626e63154b82b116d7fe9adba1fda36da706c", size = 2132603, upload-time = "2025-11-04T13:40:13.868Z" },
+    { url = "https://files.pythonhosted.org/packages/49/7d/4c00df99cb12070b6bccdef4a195255e6020a550d572768d92cc54dba91a/pydantic_core-2.41.5-cp312-cp312-musllinux_1_1_armv7l.whl", hash = "sha256:482c982f814460eabe1d3bb0adfdc583387bd4691ef00b90575ca0d2b6fe2294", size = 2329591, upload-time = "2025-11-04T13:40:15.672Z" },
+    { url = "https://files.pythonhosted.org/packages/cc/6a/ebf4b1d65d458f3cda6a7335d141305dfa19bdc61140a884d165a8a1bbc7/pydantic_core-2.41.5-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:bfea2a5f0b4d8d43adf9d7b8bf019fb46fdd10a2e5cde477fbcb9d1fa08c68e1", size = 2319068, upload-time = "2025-11-04T13:40:17.532Z" },
+    { url = "https://files.pythonhosted.org/packages/49/3b/774f2b5cd4192d5ab75870ce4381fd89cf218af999515baf07e7206753f0/pydantic_core-2.41.5-cp312-cp312-win32.whl", hash = "sha256:b74557b16e390ec12dca509bce9264c3bbd128f8a2c376eaa68003d7f327276d", size = 1985908, upload-time = "2025-11-04T13:40:19.309Z" },
+    { url = "https://files.pythonhosted.org/packages/86/45/00173a033c801cacf67c190fef088789394feaf88a98a7035b0e40d53dc9/pydantic_core-2.41.5-cp312-cp312-win_amd64.whl", hash = "sha256:1962293292865bca8e54702b08a4f26da73adc83dd1fcf26fbc875b35d81c815", size = 2020145, upload-time = "2025-11-04T13:40:21.548Z" },
+    { url = "https://files.pythonhosted.org/packages/f9/22/91fbc821fa6d261b376a3f73809f907cec5ca6025642c463d3488aad22fb/pydantic_core-2.41.5-cp312-cp312-win_arm64.whl", hash = "sha256:1746d4a3d9a794cacae06a5eaaccb4b8643a131d45fbc9af23e353dc0a5ba5c3", size = 1976179, upload-time = "2025-11-04T13:40:23.393Z" },
+    { url = "https://files.pythonhosted.org/packages/87/06/8806241ff1f70d9939f9af039c6c35f2360cf16e93c2ca76f184e76b1564/pydantic_core-2.41.5-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:941103c9be18ac8daf7b7adca8228f8ed6bb7a1849020f643b3a14d15b1924d9", size = 2120403, upload-time = "2025-11-04T13:40:25.248Z" },
+    { url = "https://files.pythonhosted.org/packages/94/02/abfa0e0bda67faa65fef1c84971c7e45928e108fe24333c81f3bfe35d5f5/pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:112e305c3314f40c93998e567879e887a3160bb8689ef3d2c04b6cc62c33ac34", size = 1896206, upload-time = "2025-11-04T13:40:27.099Z" },
+    { url = "https://files.pythonhosted.org/packages/15/df/a4c740c0943e93e6500f9eb23f4ca7ec9bf71b19e608ae5b579678c8d02f/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0cbaad15cb0c90aa221d43c00e77bb33c93e8d36e0bf74760cd00e732d10a6a0", size = 1919307, upload-time = "2025-11-04T13:40:29.806Z" },
+    { url = "https://files.pythonhosted.org/packages/9a/e3/6324802931ae1d123528988e0e86587c2072ac2e5394b4bc2bc34b61ff6e/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:03ca43e12fab6023fc79d28ca6b39b05f794ad08ec2feccc59a339b02f2b3d33", size = 2063258, upload-time = "2025-11-04T13:40:33.544Z" },
+    { url = "https://files.pythonhosted.org/packages/c9/d4/2230d7151d4957dd79c3044ea26346c148c98fbf0ee6ebd41056f2d62ab5/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:dc799088c08fa04e43144b164feb0c13f9a0bc40503f8df3e9fde58a3c0c101e", size = 2214917, upload-time = "2025-11-04T13:40:35.479Z" },
+    { url = "https://files.pythonhosted.org/packages/e6/9f/eaac5df17a3672fef0081b6c1bb0b82b33ee89aa5cec0d7b05f52fd4a1fa/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:97aeba56665b4c3235a0e52b2c2f5ae9cd071b8a8310ad27bddb3f7fb30e9aa2", size = 2332186, upload-time = "2025-11-04T13:40:37.436Z" },
+    { url = "https://files.pythonhosted.org/packages/cf/4e/35a80cae583a37cf15604b44240e45c05e04e86f9cfd766623149297e971/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:406bf18d345822d6c21366031003612b9c77b3e29ffdb0f612367352aab7d586", size = 2073164, upload-time = "2025-11-04T13:40:40.289Z" },
+    { url = "https://files.pythonhosted.org/packages/bf/e3/f6e262673c6140dd3305d144d032f7bd5f7497d3871c1428521f19f9efa2/pydantic_core-2.41.5-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:b93590ae81f7010dbe380cdeab6f515902ebcbefe0b9327cc4804d74e93ae69d", size = 2179146, upload-time = "2025-11-04T13:40:42.809Z" },
+    { url = "https://files.pythonhosted.org/packages/75/c7/20bd7fc05f0c6ea2056a4565c6f36f8968c0924f19b7d97bbfea55780e73/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:01a3d0ab748ee531f4ea6c3e48ad9dac84ddba4b0d82291f87248f2f9de8d740", size = 2137788, upload-time = "2025-11-04T13:40:44.752Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/8d/34318ef985c45196e004bc46c6eab2eda437e744c124ef0dbe1ff2c9d06b/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:6561e94ba9dacc9c61bce40e2d6bdc3bfaa0259d3ff36ace3b1e6901936d2e3e", size = 2340133, upload-time = "2025-11-04T13:40:46.66Z" },
+    { url = "https://files.pythonhosted.org/packages/9c/59/013626bf8c78a5a5d9350d12e7697d3d4de951a75565496abd40ccd46bee/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:915c3d10f81bec3a74fbd4faebe8391013ba61e5a1a8d48c4455b923bdda7858", size = 2324852, upload-time = "2025-11-04T13:40:48.575Z" },
+    { url = "https://files.pythonhosted.org/packages/1a/d9/c248c103856f807ef70c18a4f986693a46a8ffe1602e5d361485da502d20/pydantic_core-2.41.5-cp313-cp313-win32.whl", hash = "sha256:650ae77860b45cfa6e2cdafc42618ceafab3a2d9a3811fcfbd3bbf8ac3c40d36", size = 1994679, upload-time = "2025-11-04T13:40:50.619Z" },
+    { url = "https://files.pythonhosted.org/packages/9e/8b/341991b158ddab181cff136acd2552c9f35bd30380422a639c0671e99a91/pydantic_core-2.41.5-cp313-cp313-win_amd64.whl", hash = "sha256:79ec52ec461e99e13791ec6508c722742ad745571f234ea6255bed38c6480f11", size = 2019766, upload-time = "2025-11-04T13:40:52.631Z" },
+    { url = "https://files.pythonhosted.org/packages/73/7d/f2f9db34af103bea3e09735bb40b021788a5e834c81eedb541991badf8f5/pydantic_core-2.41.5-cp313-cp313-win_arm64.whl", hash = "sha256:3f84d5c1b4ab906093bdc1ff10484838aca54ef08de4afa9de0f5f14d69639cd", size = 1981005, upload-time = "2025-11-04T13:40:54.734Z" },
+    { url = "https://files.pythonhosted.org/packages/ea/28/46b7c5c9635ae96ea0fbb779e271a38129df2550f763937659ee6c5dbc65/pydantic_core-2.41.5-cp314-cp314-macosx_10_12_x86_64.whl", hash = "sha256:3f37a19d7ebcdd20b96485056ba9e8b304e27d9904d233d7b1015db320e51f0a", size = 2119622, upload-time = "2025-11-04T13:40:56.68Z" },
+    { url = "https://files.pythonhosted.org/packages/74/1a/145646e5687e8d9a1e8d09acb278c8535ebe9e972e1f162ed338a622f193/pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:1d1d9764366c73f996edd17abb6d9d7649a7eb690006ab6adbda117717099b14", size = 1891725, upload-time = "2025-11-04T13:40:58.807Z" },
+    { url = "https://files.pythonhosted.org/packages/23/04/e89c29e267b8060b40dca97bfc64a19b2a3cf99018167ea1677d96368273/pydantic_core-2.41.5-cp314-cp314-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:25e1c2af0fce638d5f1988b686f3b3ea8cd7de5f244ca147c777769e798a9cd1", size = 1915040, upload-time = "2025-11-04T13:41:00.853Z" },
+    { url = "https://files.pythonhosted.org/packages/84/a3/15a82ac7bd97992a82257f777b3583d3e84bdb06ba6858f745daa2ec8a85/pydantic_core-2.41.5-cp314-cp314-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:506d766a8727beef16b7adaeb8ee6217c64fc813646b424d0804d67c16eddb66", size = 2063691, upload-time = "2025-11-04T13:41:03.504Z" },
+    { url = "https://files.pythonhosted.org/packages/74/9b/0046701313c6ef08c0c1cf0e028c67c770a4e1275ca73131563c5f2a310a/pydantic_core-2.41.5-cp314-cp314-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4819fa52133c9aa3c387b3328f25c1facc356491e6135b459f1de698ff64d869", size = 2213897, upload-time = "2025-11-04T13:41:05.804Z" },
+    { url = "https://files.pythonhosted.org/packages/8a/cd/6bac76ecd1b27e75a95ca3a9a559c643b3afcd2dd62086d4b7a32a18b169/pydantic_core-2.41.5-cp314-cp314-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2b761d210c9ea91feda40d25b4efe82a1707da2ef62901466a42492c028553a2", size = 2333302, upload-time = "2025-11-04T13:41:07.809Z" },
+    { url = "https://files.pythonhosted.org/packages/4c/d2/ef2074dc020dd6e109611a8be4449b98cd25e1b9b8a303c2f0fca2f2bcf7/pydantic_core-2.41.5-cp314-cp314-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:22f0fb8c1c583a3b6f24df2470833b40207e907b90c928cc8d3594b76f874375", size = 2064877, upload-time = "2025-11-04T13:41:09.827Z" },
+    { url = "https://files.pythonhosted.org/packages/18/66/e9db17a9a763d72f03de903883c057b2592c09509ccfe468187f2a2eef29/pydantic_core-2.41.5-cp314-cp314-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:2782c870e99878c634505236d81e5443092fba820f0373997ff75f90f68cd553", size = 2180680, upload-time = "2025-11-04T13:41:12.379Z" },
+    { url = "https://files.pythonhosted.org/packages/d3/9e/3ce66cebb929f3ced22be85d4c2399b8e85b622db77dad36b73c5387f8f8/pydantic_core-2.41.5-cp314-cp314-musllinux_1_1_aarch64.whl", hash = "sha256:0177272f88ab8312479336e1d777f6b124537d47f2123f89cb37e0accea97f90", size = 2138960, upload-time = "2025-11-04T13:41:14.627Z" },
+    { url = "https://files.pythonhosted.org/packages/a6/62/205a998f4327d2079326b01abee48e502ea739d174f0a89295c481a2272e/pydantic_core-2.41.5-cp314-cp314-musllinux_1_1_armv7l.whl", hash = "sha256:63510af5e38f8955b8ee5687740d6ebf7c2a0886d15a6d65c32814613681bc07", size = 2339102, upload-time = "2025-11-04T13:41:16.868Z" },
+    { url = "https://files.pythonhosted.org/packages/3c/0d/f05e79471e889d74d3d88f5bd20d0ed189ad94c2423d81ff8d0000aab4ff/pydantic_core-2.41.5-cp314-cp314-musllinux_1_1_x86_64.whl", hash = "sha256:e56ba91f47764cc14f1daacd723e3e82d1a89d783f0f5afe9c364b8bb491ccdb", size = 2326039, upload-time = "2025-11-04T13:41:18.934Z" },
+    { url = "https://files.pythonhosted.org/packages/ec/e1/e08a6208bb100da7e0c4b288eed624a703f4d129bde2da475721a80cab32/pydantic_core-2.41.5-cp314-cp314-win32.whl", hash = "sha256:aec5cf2fd867b4ff45b9959f8b20ea3993fc93e63c7363fe6851424c8a7e7c23", size = 1995126, upload-time = "2025-11-04T13:41:21.418Z" },
+    { url = "https://files.pythonhosted.org/packages/48/5d/56ba7b24e9557f99c9237e29f5c09913c81eeb2f3217e40e922353668092/pydantic_core-2.41.5-cp314-cp314-win_amd64.whl", hash = "sha256:8e7c86f27c585ef37c35e56a96363ab8de4e549a95512445b85c96d3e2f7c1bf", size = 2015489, upload-time = "2025-11-04T13:41:24.076Z" },
+    { url = "https://files.pythonhosted.org/packages/4e/bb/f7a190991ec9e3e0ba22e4993d8755bbc4a32925c0b5b42775c03e8148f9/pydantic_core-2.41.5-cp314-cp314-win_arm64.whl", hash = "sha256:e672ba74fbc2dc8eea59fb6d4aed6845e6905fc2a8afe93175d94a83ba2a01a0", size = 1977288, upload-time = "2025-11-04T13:41:26.33Z" },
+    { url = "https://files.pythonhosted.org/packages/92/ed/77542d0c51538e32e15afe7899d79efce4b81eee631d99850edc2f5e9349/pydantic_core-2.41.5-cp314-cp314t-macosx_10_12_x86_64.whl", hash = "sha256:8566def80554c3faa0e65ac30ab0932b9e3a5cd7f8323764303d468e5c37595a", size = 2120255, upload-time = "2025-11-04T13:41:28.569Z" },
+    { url = "https://files.pythonhosted.org/packages/bb/3d/6913dde84d5be21e284439676168b28d8bbba5600d838b9dca99de0fad71/pydantic_core-2.41.5-cp314-cp314t-macosx_11_0_arm64.whl", hash = "sha256:b80aa5095cd3109962a298ce14110ae16b8c1aece8b72f9dafe81cf597ad80b3", size = 1863760, upload-time = "2025-11-04T13:41:31.055Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/f0/e5e6b99d4191da102f2b0eb9687aaa7f5bea5d9964071a84effc3e40f997/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3006c3dd9ba34b0c094c544c6006cc79e87d8612999f1a5d43b769b89181f23c", size = 1878092, upload-time = "2025-11-04T13:41:33.21Z" },
+    { url = "https://files.pythonhosted.org/packages/71/48/36fb760642d568925953bcc8116455513d6e34c4beaa37544118c36aba6d/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:72f6c8b11857a856bcfa48c86f5368439f74453563f951e473514579d44aa612", size = 2053385, upload-time = "2025-11-04T13:41:35.508Z" },
+    { url = "https://files.pythonhosted.org/packages/20/25/92dc684dd8eb75a234bc1c764b4210cf2646479d54b47bf46061657292a8/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5cb1b2f9742240e4bb26b652a5aeb840aa4b417c7748b6f8387927bc6e45e40d", size = 2218832, upload-time = "2025-11-04T13:41:37.732Z" },
+    { url = "https://files.pythonhosted.org/packages/e2/09/f53e0b05023d3e30357d82eb35835d0f6340ca344720a4599cd663dca599/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:bd3d54f38609ff308209bd43acea66061494157703364ae40c951f83ba99a1a9", size = 2327585, upload-time = "2025-11-04T13:41:40Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/4e/2ae1aa85d6af35a39b236b1b1641de73f5a6ac4d5a7509f77b814885760c/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2ff4321e56e879ee8d2a879501c8e469414d948f4aba74a2d4593184eb326660", size = 2041078, upload-time = "2025-11-04T13:41:42.323Z" },
+    { url = "https://files.pythonhosted.org/packages/cd/13/2e215f17f0ef326fc72afe94776edb77525142c693767fc347ed6288728d/pydantic_core-2.41.5-cp314-cp314t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d0d2568a8c11bf8225044aa94409e21da0cb09dcdafe9ecd10250b2baad531a9", size = 2173914, upload-time = "2025-11-04T13:41:45.221Z" },
+    { url = "https://files.pythonhosted.org/packages/02/7a/f999a6dcbcd0e5660bc348a3991c8915ce6599f4f2c6ac22f01d7a10816c/pydantic_core-2.41.5-cp314-cp314t-musllinux_1_1_aarch64.whl", hash = "sha256:a39455728aabd58ceabb03c90e12f71fd30fa69615760a075b9fec596456ccc3", size = 2129560, upload-time = "2025-11-04T13:41:47.474Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/b1/6c990ac65e3b4c079a4fb9f5b05f5b013afa0f4ed6780a3dd236d2cbdc64/pydantic_core-2.41.5-cp314-cp314t-musllinux_1_1_armv7l.whl", hash = "sha256:239edca560d05757817c13dc17c50766136d21f7cd0fac50295499ae24f90fdf", size = 2329244, upload-time = "2025-11-04T13:41:49.992Z" },
+    { url = "https://files.pythonhosted.org/packages/d9/02/3c562f3a51afd4d88fff8dffb1771b30cfdfd79befd9883ee094f5b6c0d8/pydantic_core-2.41.5-cp314-cp314t-musllinux_1_1_x86_64.whl", hash = "sha256:2a5e06546e19f24c6a96a129142a75cee553cc018ffee48a460059b1185f4470", size = 2331955, upload-time = "2025-11-04T13:41:54.079Z" },
+    { url = "https://files.pythonhosted.org/packages/5c/96/5fb7d8c3c17bc8c62fdb031c47d77a1af698f1d7a406b0f79aaa1338f9ad/pydantic_core-2.41.5-cp314-cp314t-win32.whl", hash = "sha256:b4ececa40ac28afa90871c2cc2b9ffd2ff0bf749380fbdf57d165fd23da353aa", size = 1988906, upload-time = "2025-11-04T13:41:56.606Z" },
+    { url = "https://files.pythonhosted.org/packages/22/ed/182129d83032702912c2e2d8bbe33c036f342cc735737064668585dac28f/pydantic_core-2.41.5-cp314-cp314t-win_amd64.whl", hash = "sha256:80aa89cad80b32a912a65332f64a4450ed00966111b6615ca6816153d3585a8c", size = 1981607, upload-time = "2025-11-04T13:41:58.889Z" },
+    { url = "https://files.pythonhosted.org/packages/9f/ed/068e41660b832bb0b1aa5b58011dea2a3fe0ba7861ff38c4d4904c1c1a99/pydantic_core-2.41.5-cp314-cp314t-win_arm64.whl", hash = "sha256:35b44f37a3199f771c3eaa53051bc8a70cd7b54f333531c59e29fd4db5d15008", size = 1974769, upload-time = "2025-11-04T13:42:01.186Z" },
+    { url = "https://files.pythonhosted.org/packages/54/db/160dffb57ed9a3705c4cbcbff0ac03bdae45f1ca7d58ab74645550df3fbd/pydantic_core-2.41.5-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:8bfeaf8735be79f225f3fefab7f941c712aaca36f1128c9d7e2352ee1aa87bdf", size = 2107999, upload-time = "2025-11-04T13:42:03.885Z" },
+    { url = "https://files.pythonhosted.org/packages/a3/7d/88e7de946f60d9263cc84819f32513520b85c0f8322f9b8f6e4afc938383/pydantic_core-2.41.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:346285d28e4c8017da95144c7f3acd42740d637ff41946af5ce6e5e420502dd5", size = 1929745, upload-time = "2025-11-04T13:42:06.075Z" },
+    { url = "https://files.pythonhosted.org/packages/d5/c2/aef51e5b283780e85e99ff19db0f05842d2d4a8a8cd15e63b0280029b08f/pydantic_core-2.41.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a75dafbf87d6276ddc5b2bf6fae5254e3d0876b626eb24969a574fff9149ee5d", size = 1920220, upload-time = "2025-11-04T13:42:08.457Z" },
+    { url = "https://files.pythonhosted.org/packages/c7/97/492ab10f9ac8695cd76b2fdb24e9e61f394051df71594e9bcc891c9f586e/pydantic_core-2.41.5-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:7b93a4d08587e2b7e7882de461e82b6ed76d9026ce91ca7915e740ecc7855f60", size = 2067296, upload-time = "2025-11-04T13:42:10.817Z" },
+    { url = "https://files.pythonhosted.org/packages/ec/23/984149650e5269c59a2a4c41d234a9570adc68ab29981825cfaf4cfad8f4/pydantic_core-2.41.5-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e8465ab91a4bd96d36dde3263f06caa6a8a6019e4113f24dc753d79a8b3a3f82", size = 2231548, upload-time = "2025-11-04T13:42:13.843Z" },
+    { url = "https://files.pythonhosted.org/packages/71/0c/85bcbb885b9732c28bec67a222dbed5ed2d77baee1f8bba2002e8cd00c5c/pydantic_core-2.41.5-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:299e0a22e7ae2b85c1a57f104538b2656e8ab1873511fd718a1c1c6f149b77b5", size = 2362571, upload-time = "2025-11-04T13:42:16.208Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/4a/412d2048be12c334003e9b823a3fa3d038e46cc2d64dd8aab50b31b65499/pydantic_core-2.41.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:707625ef0983fcfb461acfaf14de2067c5942c6bb0f3b4c99158bed6fedd3cf3", size = 2068175, upload-time = "2025-11-04T13:42:18.911Z" },
+    { url = "https://files.pythonhosted.org/packages/73/f4/c58b6a776b502d0a5540ad02e232514285513572060f0d78f7832ca3c98b/pydantic_core-2.41.5-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:f41eb9797986d6ebac5e8edff36d5cef9de40def462311b3eb3eeded1431e425", size = 2177203, upload-time = "2025-11-04T13:42:22.578Z" },
+    { url = "https://files.pythonhosted.org/packages/ed/ae/f06ea4c7e7a9eead3d165e7623cd2ea0cb788e277e4f935af63fc98fa4e6/pydantic_core-2.41.5-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:0384e2e1021894b1ff5a786dbf94771e2986ebe2869533874d7e43bc79c6f504", size = 2148191, upload-time = "2025-11-04T13:42:24.89Z" },
+    { url = "https://files.pythonhosted.org/packages/c1/57/25a11dcdc656bf5f8b05902c3c2934ac3ea296257cc4a3f79a6319e61856/pydantic_core-2.41.5-cp39-cp39-musllinux_1_1_armv7l.whl", hash = "sha256:f0cd744688278965817fd0839c4a4116add48d23890d468bc436f78beb28abf5", size = 2343907, upload-time = "2025-11-04T13:42:27.683Z" },
+    { url = "https://files.pythonhosted.org/packages/96/82/e33d5f4933d7a03327c0c43c65d575e5919d4974ffc026bc917a5f7b9f61/pydantic_core-2.41.5-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:753e230374206729bf0a807954bcc6c150d3743928a73faffee51ac6557a03c3", size = 2322174, upload-time = "2025-11-04T13:42:30.776Z" },
+    { url = "https://files.pythonhosted.org/packages/81/45/4091be67ce9f469e81656f880f3506f6a5624121ec5eb3eab37d7581897d/pydantic_core-2.41.5-cp39-cp39-win32.whl", hash = "sha256:873e0d5b4fb9b89ef7c2d2a963ea7d02879d9da0da8d9d4933dee8ee86a8b460", size = 1990353, upload-time = "2025-11-04T13:42:33.111Z" },
+    { url = "https://files.pythonhosted.org/packages/44/8a/a98aede18db6e9cd5d66bcacd8a409fcf8134204cdede2e7de35c5a2c5ef/pydantic_core-2.41.5-cp39-cp39-win_amd64.whl", hash = "sha256:e4f4a984405e91527a0d62649ee21138f8e3d0ef103be488c1dc11a80d7f184b", size = 2015698, upload-time = "2025-11-04T13:42:35.484Z" },
+    { url = "https://files.pythonhosted.org/packages/11/72/90fda5ee3b97e51c494938a4a44c3a35a9c96c19bba12372fb9c634d6f57/pydantic_core-2.41.5-graalpy311-graalpy242_311_native-macosx_10_12_x86_64.whl", hash = "sha256:b96d5f26b05d03cc60f11a7761a5ded1741da411e7fe0909e27a5e6a0cb7b034", size = 2115441, upload-time = "2025-11-04T13:42:39.557Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/53/8942f884fa33f50794f119012dc6a1a02ac43a56407adaac20463df8e98f/pydantic_core-2.41.5-graalpy311-graalpy242_311_native-macosx_11_0_arm64.whl", hash = "sha256:634e8609e89ceecea15e2d61bc9ac3718caaaa71963717bf3c8f38bfde64242c", size = 1930291, upload-time = "2025-11-04T13:42:42.169Z" },
+    { url = "https://files.pythonhosted.org/packages/79/c8/ecb9ed9cd942bce09fc888ee960b52654fbdbede4ba6c2d6e0d3b1d8b49c/pydantic_core-2.41.5-graalpy311-graalpy242_311_native-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:93e8740d7503eb008aa2df04d3b9735f845d43ae845e6dcd2be0b55a2da43cd2", size = 1948632, upload-time = "2025-11-04T13:42:44.564Z" },
+    { url = "https://files.pythonhosted.org/packages/2e/1b/687711069de7efa6af934e74f601e2a4307365e8fdc404703afc453eab26/pydantic_core-2.41.5-graalpy311-graalpy242_311_native-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f15489ba13d61f670dcc96772e733aad1a6f9c429cc27574c6cdaed82d0146ad", size = 2138905, upload-time = "2025-11-04T13:42:47.156Z" },
+    { url = "https://files.pythonhosted.org/packages/09/32/59b0c7e63e277fa7911c2fc70ccfb45ce4b98991e7ef37110663437005af/pydantic_core-2.41.5-graalpy312-graalpy250_312_native-macosx_10_12_x86_64.whl", hash = "sha256:7da7087d756b19037bc2c06edc6c170eeef3c3bafcb8f532ff17d64dc427adfd", size = 2110495, upload-time = "2025-11-04T13:42:49.689Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/81/05e400037eaf55ad400bcd318c05bb345b57e708887f07ddb2d20e3f0e98/pydantic_core-2.41.5-graalpy312-graalpy250_312_native-macosx_11_0_arm64.whl", hash = "sha256:aabf5777b5c8ca26f7824cb4a120a740c9588ed58df9b2d196ce92fba42ff8dc", size = 1915388, upload-time = "2025-11-04T13:42:52.215Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/0d/e3549b2399f71d56476b77dbf3cf8937cec5cd70536bdc0e374a421d0599/pydantic_core-2.41.5-graalpy312-graalpy250_312_native-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c007fe8a43d43b3969e8469004e9845944f1a80e6acd47c150856bb87f230c56", size = 1942879, upload-time = "2025-11-04T13:42:56.483Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/07/34573da085946b6a313d7c42f82f16e8920bfd730665de2d11c0c37a74b5/pydantic_core-2.41.5-graalpy312-graalpy250_312_native-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:76d0819de158cd855d1cbb8fcafdf6f5cf1eb8e470abe056d5d161106e38062b", size = 2139017, upload-time = "2025-11-04T13:42:59.471Z" },
+    { url = "https://files.pythonhosted.org/packages/e6/b0/1a2aa41e3b5a4ba11420aba2d091b2d17959c8d1519ece3627c371951e73/pydantic_core-2.41.5-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:b5819cd790dbf0c5eb9f82c73c16b39a65dd6dd4d1439dcdea7816ec9adddab8", size = 2103351, upload-time = "2025-11-04T13:43:02.058Z" },
+    { url = "https://files.pythonhosted.org/packages/a4/ee/31b1f0020baaf6d091c87900ae05c6aeae101fa4e188e1613c80e4f1ea31/pydantic_core-2.41.5-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:5a4e67afbc95fa5c34cf27d9089bca7fcab4e51e57278d710320a70b956d1b9a", size = 1925363, upload-time = "2025-11-04T13:43:05.159Z" },
+    { url = "https://files.pythonhosted.org/packages/e1/89/ab8e86208467e467a80deaca4e434adac37b10a9d134cd2f99b28a01e483/pydantic_core-2.41.5-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ece5c59f0ce7d001e017643d8d24da587ea1f74f6993467d85ae8a5ef9d4f42b", size = 2135615, upload-time = "2025-11-04T13:43:08.116Z" },
+    { url = "https://files.pythonhosted.org/packages/99/0a/99a53d06dd0348b2008f2f30884b34719c323f16c3be4e6cc1203b74a91d/pydantic_core-2.41.5-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:16f80f7abe3351f8ea6858914ddc8c77e02578544a0ebc15b4c2e1a0e813b0b2", size = 2175369, upload-time = "2025-11-04T13:43:12.49Z" },
+    { url = "https://files.pythonhosted.org/packages/6d/94/30ca3b73c6d485b9bb0bc66e611cff4a7138ff9736b7e66bcf0852151636/pydantic_core-2.41.5-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:33cb885e759a705b426baada1fe68cbb0a2e68e34c5d0d0289a364cf01709093", size = 2144218, upload-time = "2025-11-04T13:43:15.431Z" },
+    { url = "https://files.pythonhosted.org/packages/87/57/31b4f8e12680b739a91f472b5671294236b82586889ef764b5fbc6669238/pydantic_core-2.41.5-pp310-pypy310_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:c8d8b4eb992936023be7dee581270af5c6e0697a8559895f527f5b7105ecd36a", size = 2329951, upload-time = "2025-11-04T13:43:18.062Z" },
+    { url = "https://files.pythonhosted.org/packages/7d/73/3c2c8edef77b8f7310e6fb012dbc4b8551386ed575b9eb6fb2506e28a7eb/pydantic_core-2.41.5-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:242a206cd0318f95cd21bdacff3fcc3aab23e79bba5cac3db5a841c9ef9c6963", size = 2318428, upload-time = "2025-11-04T13:43:20.679Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/02/8559b1f26ee0d502c74f9cca5c0d2fd97e967e083e006bbbb4e97f3a043a/pydantic_core-2.41.5-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:d3a978c4f57a597908b7e697229d996d77a6d3c94901e9edee593adada95ce1a", size = 2147009, upload-time = "2025-11-04T13:43:23.286Z" },
+    { url = "https://files.pythonhosted.org/packages/5f/9b/1b3f0e9f9305839d7e84912f9e8bfbd191ed1b1ef48083609f0dabde978c/pydantic_core-2.41.5-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:b2379fa7ed44ddecb5bfe4e48577d752db9fc10be00a6b7446e9663ba143de26", size = 2101980, upload-time = "2025-11-04T13:43:25.97Z" },
+    { url = "https://files.pythonhosted.org/packages/a4/ed/d71fefcb4263df0da6a85b5d8a7508360f2f2e9b3bf5814be9c8bccdccc1/pydantic_core-2.41.5-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:266fb4cbf5e3cbd0b53669a6d1b039c45e3ce651fd5442eff4d07c2cc8d66808", size = 1923865, upload-time = "2025-11-04T13:43:28.763Z" },
+    { url = "https://files.pythonhosted.org/packages/ce/3a/626b38db460d675f873e4444b4bb030453bbe7b4ba55df821d026a0493c4/pydantic_core-2.41.5-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:58133647260ea01e4d0500089a8c4f07bd7aa6ce109682b1426394988d8aaacc", size = 2134256, upload-time = "2025-11-04T13:43:31.71Z" },
+    { url = "https://files.pythonhosted.org/packages/83/d9/8412d7f06f616bbc053d30cb4e5f76786af3221462ad5eee1f202021eb4e/pydantic_core-2.41.5-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:287dad91cfb551c363dc62899a80e9e14da1f0e2b6ebde82c806612ca2a13ef1", size = 2174762, upload-time = "2025-11-04T13:43:34.744Z" },
+    { url = "https://files.pythonhosted.org/packages/55/4c/162d906b8e3ba3a99354e20faa1b49a85206c47de97a639510a0e673f5da/pydantic_core-2.41.5-pp311-pypy311_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:03b77d184b9eb40240ae9fd676ca364ce1085f203e1b1256f8ab9984dca80a84", size = 2143141, upload-time = "2025-11-04T13:43:37.701Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/f2/f11dd73284122713f5f89fc940f370d035fa8e1e078d446b3313955157fe/pydantic_core-2.41.5-pp311-pypy311_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:a668ce24de96165bb239160b3d854943128f4334822900534f2fe947930e5770", size = 2330317, upload-time = "2025-11-04T13:43:40.406Z" },
+    { url = "https://files.pythonhosted.org/packages/88/9d/b06ca6acfe4abb296110fb1273a4d848a0bfb2ff65f3ee92127b3244e16b/pydantic_core-2.41.5-pp311-pypy311_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:f14f8f046c14563f8eb3f45f499cc658ab8d10072961e07225e507adb700e93f", size = 2316992, upload-time = "2025-11-04T13:43:43.602Z" },
+    { url = "https://files.pythonhosted.org/packages/36/c7/cfc8e811f061c841d7990b0201912c3556bfeb99cdcb7ed24adc8d6f8704/pydantic_core-2.41.5-pp311-pypy311_pp73-win_amd64.whl", hash = "sha256:56121965f7a4dc965bff783d70b907ddf3d57f6eba29b6d2e5dabfaf07799c51", size = 2145302, upload-time = "2025-11-04T13:43:46.64Z" },
+]
+
 [[package]]
 name = "pygments"
 version = "2.19.2"
@@ -1282,7 +2404,10 @@ name = "pytest"
 version = "9.0.1"
 source = { registry = "https://pypi.org/simple" }
 resolution-markers = [
-    "python_full_version >= '3.12'",
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
     "python_full_version == '3.11.*'",
     "python_full_version == '3.10.*'",
 ]
@@ -1312,6 +2437,27 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl", hash = "sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427", size = 229892, upload-time = "2024-03-01T18:36:18.57Z" },
 ]
 
+[[package]]
+name = "python-slugify"
+version = "8.0.4"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "text-unidecode" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/87/c7/5e1547c44e31da50a460df93af11a535ace568ef89d7a811069ead340c4a/python-slugify-8.0.4.tar.gz", hash = "sha256:59202371d1d05b54a9e7720c5e038f928f45daaffe41dd10822f3907b937c856", size = 10921, upload-time = "2024-02-08T18:32:45.488Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a4/62/02da182e544a51a5c3ccf4b03ab79df279f9c60c5e82d5e8bec7ca26ac11/python_slugify-8.0.4-py2.py3-none-any.whl", hash = "sha256:276540b79961052b66b7d116620b36518847f52d5fd9e3a70164fc8c50faa6b8", size = 10051, upload-time = "2024-02-08T18:32:43.911Z" },
+]
+
+[[package]]
+name = "pytimeparse"
+version = "1.1.8"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/37/5d/231f5f33c81e09682708fb323f9e4041408d8223e2f0fb9742843328778f/pytimeparse-1.1.8.tar.gz", hash = "sha256:e86136477be924d7e670646a98561957e8ca7308d44841e21f5ddea757556a0a", size = 9403, upload-time = "2018-05-18T17:40:42.76Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/1b/b4/afd75551a3b910abd1d922dbd45e49e5deeb4d47dc50209ce489ba9844dd/pytimeparse-1.1.8-py2.py3-none-any.whl", hash = "sha256:04b7be6cc8bd9f5647a6325444926c3ac34ee6bc7e69da4367ba282f076036bd", size = 9969, upload-time = "2018-05-18T17:40:41.28Z" },
+]
+
 [[package]]
 name = "pytz"
 version = "2025.2"
@@ -1346,6 +2492,15 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/60/22/e0e8d802f124772cec9c75430b01a212f86f9de7546bda715e54140d5aeb/pywin32-311-cp39-cp39-win_arm64.whl", hash = "sha256:62ea666235135fee79bb154e695f3ff67370afefd71bd7fea7512fc70ef31e3d", size = 8778162, upload-time = "2025-07-14T20:13:03.544Z" },
 ]
 
+[[package]]
+name = "pywin32-ctypes"
+version = "0.2.3"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/85/9f/01a1a99704853cb63f253eea009390c88e7131c67e66a0a02099a8c917cb/pywin32-ctypes-0.2.3.tar.gz", hash = "sha256:d162dc04946d704503b2edc4d55f3dba5c1d539ead017afa00142c38b9885755", size = 29471, upload-time = "2024-08-14T10:15:34.626Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/de/3d/8161f7711c017e01ac9f008dfddd9410dff3674334c233bde66e7ba65bbf/pywin32_ctypes-0.2.3-py3-none-any.whl", hash = "sha256:8a1513379d709975552d202d942d9837758905c8d01eb82b8bcc30918929e7b8", size = 30756, upload-time = "2024-08-14T10:15:33.187Z" },
+]
+
 [[package]]
 name = "pyyaml"
 version = "6.0.3"
@@ -1507,6 +2662,45 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/92/aa/ee86edad943438cd0316964020c4b6d09854414f9f945f8e289ea6fcc019/pyzmq-27.1.0-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:ff8d114d14ac671d88c89b9224c63d6c4e5a613fe8acd5594ce53d752a3aafe9", size = 544857, upload-time = "2025-09-08T23:10:16.431Z" },
 ]
 
+[[package]]
+name = "referencing"
+version = "0.36.2"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+dependencies = [
+    { name = "attrs", marker = "python_full_version < '3.10'" },
+    { name = "rpds-py", version = "0.27.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "typing-extensions", marker = "python_full_version < '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/2f/db/98b5c277be99dd18bfd91dd04e1b759cad18d1a338188c936e92f921c7e2/referencing-0.36.2.tar.gz", hash = "sha256:df2e89862cd09deabbdba16944cc3f10feb6b3e6f18e902f7cc25609a34775aa", size = 74744, upload-time = "2025-01-25T08:48:16.138Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl", hash = "sha256:e8699adbbf8b5c7de96d8ffa0eb5c158b3beafce084968e2ea8bb08c6794dcd0", size = 26775, upload-time = "2025-01-25T08:48:14.241Z" },
+]
+
+[[package]]
+name = "referencing"
+version = "0.37.0"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+]
+dependencies = [
+    { name = "attrs", marker = "python_full_version >= '3.10'" },
+    { name = "rpds-py", version = "0.29.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.10'" },
+    { name = "typing-extensions", marker = "python_full_version >= '3.10' and python_full_version < '3.13'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/22/f5/df4e9027acead3ecc63e50fe1e36aca1523e1719559c499951bb4b53188f/referencing-0.37.0.tar.gz", hash = "sha256:44aefc3142c5b842538163acb373e24cce6632bd54bdb01b21ad5863489f50d8", size = 78036, upload-time = "2025-10-13T15:30:48.871Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/2c/58/ca301544e1fa93ed4f80d724bf5b194f6e4b945841c5bfd555878eea9fcb/referencing-0.37.0-py3-none-any.whl", hash = "sha256:381329a9f99628c9069361716891d34ad94af76e461dcb0335825aecc7692231", size = 26766, upload-time = "2025-10-13T15:30:47.625Z" },
+]
+
 [[package]]
 name = "regex"
 version = "2025.11.3"
@@ -1644,6 +2838,313 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl", hash = "sha256:2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6", size = 64738, upload-time = "2025-08-18T20:46:00.542Z" },
 ]
 
+[[package]]
+name = "rpds-py"
+version = "0.27.1"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/e9/dd/2c0cbe774744272b0ae725f44032c77bdcab6e8bcf544bffa3b6e70c8dba/rpds_py-0.27.1.tar.gz", hash = "sha256:26a1c73171d10b7acccbded82bf6a586ab8203601e565badc74bbbf8bc5a10f8", size = 27479, upload-time = "2025-08-27T12:16:36.024Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a5/ed/3aef893e2dd30e77e35d20d4ddb45ca459db59cead748cad9796ad479411/rpds_py-0.27.1-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:68afeec26d42ab3b47e541b272166a0b4400313946871cba3ed3a4fc0cab1cef", size = 371606, upload-time = "2025-08-27T12:12:25.189Z" },
+    { url = "https://files.pythonhosted.org/packages/6d/82/9818b443e5d3eb4c83c3994561387f116aae9833b35c484474769c4a8faf/rpds_py-0.27.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:74e5b2f7bb6fa38b1b10546d27acbacf2a022a8b5543efb06cfebc72a59c85be", size = 353452, upload-time = "2025-08-27T12:12:27.433Z" },
+    { url = "https://files.pythonhosted.org/packages/99/c7/d2a110ffaaa397fc6793a83c7bd3545d9ab22658b7cdff05a24a4535cc45/rpds_py-0.27.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9024de74731df54546fab0bfbcdb49fae19159ecaecfc8f37c18d2c7e2c0bd61", size = 381519, upload-time = "2025-08-27T12:12:28.719Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/bc/e89581d1f9d1be7d0247eaef602566869fdc0d084008ba139e27e775366c/rpds_py-0.27.1-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:31d3ebadefcd73b73928ed0b2fd696f7fefda8629229f81929ac9c1854d0cffb", size = 394424, upload-time = "2025-08-27T12:12:30.207Z" },
+    { url = "https://files.pythonhosted.org/packages/ac/2e/36a6861f797530e74bb6ed53495f8741f1ef95939eed01d761e73d559067/rpds_py-0.27.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b2e7f8f169d775dd9092a1743768d771f1d1300453ddfe6325ae3ab5332b4657", size = 523467, upload-time = "2025-08-27T12:12:31.808Z" },
+    { url = "https://files.pythonhosted.org/packages/c4/59/c1bc2be32564fa499f988f0a5c6505c2f4746ef96e58e4d7de5cf923d77e/rpds_py-0.27.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3d905d16f77eb6ab2e324e09bfa277b4c8e5e6b8a78a3e7ff8f3cdf773b4c013", size = 402660, upload-time = "2025-08-27T12:12:33.444Z" },
+    { url = "https://files.pythonhosted.org/packages/0a/ec/ef8bf895f0628dd0a59e54d81caed6891663cb9c54a0f4bb7da918cb88cf/rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:50c946f048209e6362e22576baea09193809f87687a95a8db24e5fbdb307b93a", size = 384062, upload-time = "2025-08-27T12:12:34.857Z" },
+    { url = "https://files.pythonhosted.org/packages/69/f7/f47ff154be8d9a5e691c083a920bba89cef88d5247c241c10b9898f595a1/rpds_py-0.27.1-cp310-cp310-manylinux_2_31_riscv64.whl", hash = "sha256:3deab27804d65cd8289eb814c2c0e807c4b9d9916c9225e363cb0cf875eb67c1", size = 401289, upload-time = "2025-08-27T12:12:36.085Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/d9/ca410363efd0615814ae579f6829cafb39225cd63e5ea5ed1404cb345293/rpds_py-0.27.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:8b61097f7488de4be8244c89915da8ed212832ccf1e7c7753a25a394bf9b1f10", size = 417718, upload-time = "2025-08-27T12:12:37.401Z" },
+    { url = "https://files.pythonhosted.org/packages/e3/a0/8cb5c2ff38340f221cc067cc093d1270e10658ba4e8d263df923daa18e86/rpds_py-0.27.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:8a3f29aba6e2d7d90528d3c792555a93497fe6538aa65eb675b44505be747808", size = 558333, upload-time = "2025-08-27T12:12:38.672Z" },
+    { url = "https://files.pythonhosted.org/packages/6f/8c/1b0de79177c5d5103843774ce12b84caa7164dfc6cd66378768d37db11bf/rpds_py-0.27.1-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:dd6cd0485b7d347304067153a6dc1d73f7d4fd995a396ef32a24d24b8ac63ac8", size = 589127, upload-time = "2025-08-27T12:12:41.48Z" },
+    { url = "https://files.pythonhosted.org/packages/c8/5e/26abb098d5e01266b0f3a2488d299d19ccc26849735d9d2b95c39397e945/rpds_py-0.27.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:6f4461bf931108c9fa226ffb0e257c1b18dc2d44cd72b125bec50ee0ab1248a9", size = 554899, upload-time = "2025-08-27T12:12:42.925Z" },
+    { url = "https://files.pythonhosted.org/packages/de/41/905cc90ced13550db017f8f20c6d8e8470066c5738ba480d7ba63e3d136b/rpds_py-0.27.1-cp310-cp310-win32.whl", hash = "sha256:ee5422d7fb21f6a00c1901bf6559c49fee13a5159d0288320737bbf6585bd3e4", size = 217450, upload-time = "2025-08-27T12:12:44.813Z" },
+    { url = "https://files.pythonhosted.org/packages/75/3d/6bef47b0e253616ccdf67c283e25f2d16e18ccddd38f92af81d5a3420206/rpds_py-0.27.1-cp310-cp310-win_amd64.whl", hash = "sha256:3e039aabf6d5f83c745d5f9a0a381d031e9ed871967c0a5c38d201aca41f3ba1", size = 228447, upload-time = "2025-08-27T12:12:46.204Z" },
+    { url = "https://files.pythonhosted.org/packages/b5/c1/7907329fbef97cbd49db6f7303893bd1dd5a4a3eae415839ffdfb0762cae/rpds_py-0.27.1-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:be898f271f851f68b318872ce6ebebbc62f303b654e43bf72683dbdc25b7c881", size = 371063, upload-time = "2025-08-27T12:12:47.856Z" },
+    { url = "https://files.pythonhosted.org/packages/11/94/2aab4bc86228bcf7c48760990273653a4900de89c7537ffe1b0d6097ed39/rpds_py-0.27.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:62ac3d4e3e07b58ee0ddecd71d6ce3b1637de2d373501412df395a0ec5f9beb5", size = 353210, upload-time = "2025-08-27T12:12:49.187Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/57/f5eb3ecf434342f4f1a46009530e93fd201a0b5b83379034ebdb1d7c1a58/rpds_py-0.27.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4708c5c0ceb2d034f9991623631d3d23cb16e65c83736ea020cdbe28d57c0a0e", size = 381636, upload-time = "2025-08-27T12:12:50.492Z" },
+    { url = "https://files.pythonhosted.org/packages/ae/f4/ef95c5945e2ceb5119571b184dd5a1cc4b8541bbdf67461998cfeac9cb1e/rpds_py-0.27.1-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:abfa1171a9952d2e0002aba2ad3780820b00cc3d9c98c6630f2e93271501f66c", size = 394341, upload-time = "2025-08-27T12:12:52.024Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/7e/4bd610754bf492d398b61725eb9598ddd5eb86b07d7d9483dbcd810e20bc/rpds_py-0.27.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4b507d19f817ebaca79574b16eb2ae412e5c0835542c93fe9983f1e432aca195", size = 523428, upload-time = "2025-08-27T12:12:53.779Z" },
+    { url = "https://files.pythonhosted.org/packages/9f/e5/059b9f65a8c9149361a8b75094864ab83b94718344db511fd6117936ed2a/rpds_py-0.27.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:168b025f8fd8d8d10957405f3fdcef3dc20f5982d398f90851f4abc58c566c52", size = 402923, upload-time = "2025-08-27T12:12:55.15Z" },
+    { url = "https://files.pythonhosted.org/packages/f5/48/64cabb7daced2968dd08e8a1b7988bf358d7bd5bcd5dc89a652f4668543c/rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cb56c6210ef77caa58e16e8c17d35c63fe3f5b60fd9ba9d424470c3400bcf9ed", size = 384094, upload-time = "2025-08-27T12:12:57.194Z" },
+    { url = "https://files.pythonhosted.org/packages/ae/e1/dc9094d6ff566bff87add8a510c89b9e158ad2ecd97ee26e677da29a9e1b/rpds_py-0.27.1-cp311-cp311-manylinux_2_31_riscv64.whl", hash = "sha256:d252f2d8ca0195faa707f8eb9368955760880b2b42a8ee16d382bf5dd807f89a", size = 401093, upload-time = "2025-08-27T12:12:58.985Z" },
+    { url = "https://files.pythonhosted.org/packages/37/8e/ac8577e3ecdd5593e283d46907d7011618994e1d7ab992711ae0f78b9937/rpds_py-0.27.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:6e5e54da1e74b91dbc7996b56640f79b195d5925c2b78efaa8c5d53e1d88edde", size = 417969, upload-time = "2025-08-27T12:13:00.367Z" },
+    { url = "https://files.pythonhosted.org/packages/66/6d/87507430a8f74a93556fe55c6485ba9c259949a853ce407b1e23fea5ba31/rpds_py-0.27.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:ffce0481cc6e95e5b3f0a47ee17ffbd234399e6d532f394c8dce320c3b089c21", size = 558302, upload-time = "2025-08-27T12:13:01.737Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/bb/1db4781ce1dda3eecc735e3152659a27b90a02ca62bfeea17aee45cc0fbc/rpds_py-0.27.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:a205fdfe55c90c2cd8e540ca9ceba65cbe6629b443bc05db1f590a3db8189ff9", size = 589259, upload-time = "2025-08-27T12:13:03.127Z" },
+    { url = "https://files.pythonhosted.org/packages/7b/0e/ae1c8943d11a814d01b482e1f8da903f88047a962dff9bbdadf3bd6e6fd1/rpds_py-0.27.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:689fb5200a749db0415b092972e8eba85847c23885c8543a8b0f5c009b1a5948", size = 554983, upload-time = "2025-08-27T12:13:04.516Z" },
+    { url = "https://files.pythonhosted.org/packages/b2/d5/0b2a55415931db4f112bdab072443ff76131b5ac4f4dc98d10d2d357eb03/rpds_py-0.27.1-cp311-cp311-win32.whl", hash = "sha256:3182af66048c00a075010bc7f4860f33913528a4b6fc09094a6e7598e462fe39", size = 217154, upload-time = "2025-08-27T12:13:06.278Z" },
+    { url = "https://files.pythonhosted.org/packages/24/75/3b7ffe0d50dc86a6a964af0d1cc3a4a2cdf437cb7b099a4747bbb96d1819/rpds_py-0.27.1-cp311-cp311-win_amd64.whl", hash = "sha256:b4938466c6b257b2f5c4ff98acd8128ec36b5059e5c8f8372d79316b1c36bb15", size = 228627, upload-time = "2025-08-27T12:13:07.625Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/3f/4fd04c32abc02c710f09a72a30c9a55ea3cc154ef8099078fd50a0596f8e/rpds_py-0.27.1-cp311-cp311-win_arm64.whl", hash = "sha256:2f57af9b4d0793e53266ee4325535a31ba48e2f875da81a9177c9926dfa60746", size = 220998, upload-time = "2025-08-27T12:13:08.972Z" },
+    { url = "https://files.pythonhosted.org/packages/bd/fe/38de28dee5df58b8198c743fe2bea0c785c6d40941b9950bac4cdb71a014/rpds_py-0.27.1-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:ae2775c1973e3c30316892737b91f9283f9908e3cc7625b9331271eaaed7dc90", size = 361887, upload-time = "2025-08-27T12:13:10.233Z" },
+    { url = "https://files.pythonhosted.org/packages/7c/9a/4b6c7eedc7dd90986bf0fab6ea2a091ec11c01b15f8ba0a14d3f80450468/rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:2643400120f55c8a96f7c9d858f7be0c88d383cd4653ae2cf0d0c88f668073e5", size = 345795, upload-time = "2025-08-27T12:13:11.65Z" },
+    { url = "https://files.pythonhosted.org/packages/6f/0e/e650e1b81922847a09cca820237b0edee69416a01268b7754d506ade11ad/rpds_py-0.27.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:16323f674c089b0360674a4abd28d5042947d54ba620f72514d69be4ff64845e", size = 385121, upload-time = "2025-08-27T12:13:13.008Z" },
+    { url = "https://files.pythonhosted.org/packages/1b/ea/b306067a712988e2bff00dcc7c8f31d26c29b6d5931b461aa4b60a013e33/rpds_py-0.27.1-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:9a1f4814b65eacac94a00fc9a526e3fdafd78e439469644032032d0d63de4881", size = 398976, upload-time = "2025-08-27T12:13:14.368Z" },
+    { url = "https://files.pythonhosted.org/packages/2c/0a/26dc43c8840cb8fe239fe12dbc8d8de40f2365e838f3d395835dde72f0e5/rpds_py-0.27.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:7ba32c16b064267b22f1850a34051121d423b6f7338a12b9459550eb2096e7ec", size = 525953, upload-time = "2025-08-27T12:13:15.774Z" },
+    { url = "https://files.pythonhosted.org/packages/22/14/c85e8127b573aaf3a0cbd7fbb8c9c99e735a4a02180c84da2a463b766e9e/rpds_py-0.27.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e5c20f33fd10485b80f65e800bbe5f6785af510b9f4056c5a3c612ebc83ba6cb", size = 407915, upload-time = "2025-08-27T12:13:17.379Z" },
+    { url = "https://files.pythonhosted.org/packages/ed/7b/8f4fee9ba1fb5ec856eb22d725a4efa3deb47f769597c809e03578b0f9d9/rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:466bfe65bd932da36ff279ddd92de56b042f2266d752719beb97b08526268ec5", size = 386883, upload-time = "2025-08-27T12:13:18.704Z" },
+    { url = "https://files.pythonhosted.org/packages/86/47/28fa6d60f8b74fcdceba81b272f8d9836ac0340570f68f5df6b41838547b/rpds_py-0.27.1-cp312-cp312-manylinux_2_31_riscv64.whl", hash = "sha256:41e532bbdcb57c92ba3be62c42e9f096431b4cf478da9bc3bc6ce5c38ab7ba7a", size = 405699, upload-time = "2025-08-27T12:13:20.089Z" },
+    { url = "https://files.pythonhosted.org/packages/d0/fd/c5987b5e054548df56953a21fe2ebed51fc1ec7c8f24fd41c067b68c4a0a/rpds_py-0.27.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:f149826d742b406579466283769a8ea448eed82a789af0ed17b0cd5770433444", size = 423713, upload-time = "2025-08-27T12:13:21.436Z" },
+    { url = "https://files.pythonhosted.org/packages/ac/ba/3c4978b54a73ed19a7d74531be37a8bcc542d917c770e14d372b8daea186/rpds_py-0.27.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:80c60cfb5310677bd67cb1e85a1e8eb52e12529545441b43e6f14d90b878775a", size = 562324, upload-time = "2025-08-27T12:13:22.789Z" },
+    { url = "https://files.pythonhosted.org/packages/b5/6c/6943a91768fec16db09a42b08644b960cff540c66aab89b74be6d4a144ba/rpds_py-0.27.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:7ee6521b9baf06085f62ba9c7a3e5becffbc32480d2f1b351559c001c38ce4c1", size = 593646, upload-time = "2025-08-27T12:13:24.122Z" },
+    { url = "https://files.pythonhosted.org/packages/11/73/9d7a8f4be5f4396f011a6bb7a19fe26303a0dac9064462f5651ced2f572f/rpds_py-0.27.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:a512c8263249a9d68cac08b05dd59d2b3f2061d99b322813cbcc14c3c7421998", size = 558137, upload-time = "2025-08-27T12:13:25.557Z" },
+    { url = "https://files.pythonhosted.org/packages/6e/96/6772cbfa0e2485bcceef8071de7821f81aeac8bb45fbfd5542a3e8108165/rpds_py-0.27.1-cp312-cp312-win32.whl", hash = "sha256:819064fa048ba01b6dadc5116f3ac48610435ac9a0058bbde98e569f9e785c39", size = 221343, upload-time = "2025-08-27T12:13:26.967Z" },
+    { url = "https://files.pythonhosted.org/packages/67/b6/c82f0faa9af1c6a64669f73a17ee0eeef25aff30bb9a1c318509efe45d84/rpds_py-0.27.1-cp312-cp312-win_amd64.whl", hash = "sha256:d9199717881f13c32c4046a15f024971a3b78ad4ea029e8da6b86e5aa9cf4594", size = 232497, upload-time = "2025-08-27T12:13:28.326Z" },
+    { url = "https://files.pythonhosted.org/packages/e1/96/2817b44bd2ed11aebacc9251da03689d56109b9aba5e311297b6902136e2/rpds_py-0.27.1-cp312-cp312-win_arm64.whl", hash = "sha256:33aa65b97826a0e885ef6e278fbd934e98cdcfed80b63946025f01e2f5b29502", size = 222790, upload-time = "2025-08-27T12:13:29.71Z" },
+    { url = "https://files.pythonhosted.org/packages/cc/77/610aeee8d41e39080c7e14afa5387138e3c9fa9756ab893d09d99e7d8e98/rpds_py-0.27.1-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:e4b9fcfbc021633863a37e92571d6f91851fa656f0180246e84cbd8b3f6b329b", size = 361741, upload-time = "2025-08-27T12:13:31.039Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/fc/c43765f201c6a1c60be2043cbdb664013def52460a4c7adace89d6682bf4/rpds_py-0.27.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:1441811a96eadca93c517d08df75de45e5ffe68aa3089924f963c782c4b898cf", size = 345574, upload-time = "2025-08-27T12:13:32.902Z" },
+    { url = "https://files.pythonhosted.org/packages/20/42/ee2b2ca114294cd9847d0ef9c26d2b0851b2e7e00bf14cc4c0b581df0fc3/rpds_py-0.27.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:55266dafa22e672f5a4f65019015f90336ed31c6383bd53f5e7826d21a0e0b83", size = 385051, upload-time = "2025-08-27T12:13:34.228Z" },
+    { url = "https://files.pythonhosted.org/packages/fd/e8/1e430fe311e4799e02e2d1af7c765f024e95e17d651612425b226705f910/rpds_py-0.27.1-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:d78827d7ac08627ea2c8e02c9e5b41180ea5ea1f747e9db0915e3adf36b62dcf", size = 398395, upload-time = "2025-08-27T12:13:36.132Z" },
+    { url = "https://files.pythonhosted.org/packages/82/95/9dc227d441ff2670651c27a739acb2535ccaf8b351a88d78c088965e5996/rpds_py-0.27.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ae92443798a40a92dc5f0b01d8a7c93adde0c4dc965310a29ae7c64d72b9fad2", size = 524334, upload-time = "2025-08-27T12:13:37.562Z" },
+    { url = "https://files.pythonhosted.org/packages/87/01/a670c232f401d9ad461d9a332aa4080cd3cb1d1df18213dbd0d2a6a7ab51/rpds_py-0.27.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c46c9dd2403b66a2a3b9720ec4b74d4ab49d4fabf9f03dfdce2d42af913fe8d0", size = 407691, upload-time = "2025-08-27T12:13:38.94Z" },
+    { url = "https://files.pythonhosted.org/packages/03/36/0a14aebbaa26fe7fab4780c76f2239e76cc95a0090bdb25e31d95c492fcd/rpds_py-0.27.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2efe4eb1d01b7f5f1939f4ef30ecea6c6b3521eec451fb93191bf84b2a522418", size = 386868, upload-time = "2025-08-27T12:13:40.192Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/03/8c897fb8b5347ff6c1cc31239b9611c5bf79d78c984430887a353e1409a1/rpds_py-0.27.1-cp313-cp313-manylinux_2_31_riscv64.whl", hash = "sha256:15d3b4d83582d10c601f481eca29c3f138d44c92187d197aff663a269197c02d", size = 405469, upload-time = "2025-08-27T12:13:41.496Z" },
+    { url = "https://files.pythonhosted.org/packages/da/07/88c60edc2df74850d496d78a1fdcdc7b54360a7f610a4d50008309d41b94/rpds_py-0.27.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:4ed2e16abbc982a169d30d1a420274a709949e2cbdef119fe2ec9d870b42f274", size = 422125, upload-time = "2025-08-27T12:13:42.802Z" },
+    { url = "https://files.pythonhosted.org/packages/6b/86/5f4c707603e41b05f191a749984f390dabcbc467cf833769b47bf14ba04f/rpds_py-0.27.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:a75f305c9b013289121ec0f1181931975df78738cdf650093e6b86d74aa7d8dd", size = 562341, upload-time = "2025-08-27T12:13:44.472Z" },
+    { url = "https://files.pythonhosted.org/packages/b2/92/3c0cb2492094e3cd9baf9e49bbb7befeceb584ea0c1a8b5939dca4da12e5/rpds_py-0.27.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:67ce7620704745881a3d4b0ada80ab4d99df390838839921f99e63c474f82cf2", size = 592511, upload-time = "2025-08-27T12:13:45.898Z" },
+    { url = "https://files.pythonhosted.org/packages/10/bb/82e64fbb0047c46a168faa28d0d45a7851cd0582f850b966811d30f67ad8/rpds_py-0.27.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:9d992ac10eb86d9b6f369647b6a3f412fc0075cfd5d799530e84d335e440a002", size = 557736, upload-time = "2025-08-27T12:13:47.408Z" },
+    { url = "https://files.pythonhosted.org/packages/00/95/3c863973d409210da7fb41958172c6b7dbe7fc34e04d3cc1f10bb85e979f/rpds_py-0.27.1-cp313-cp313-win32.whl", hash = "sha256:4f75e4bd8ab8db624e02c8e2fc4063021b58becdbe6df793a8111d9343aec1e3", size = 221462, upload-time = "2025-08-27T12:13:48.742Z" },
+    { url = "https://files.pythonhosted.org/packages/ce/2c/5867b14a81dc217b56d95a9f2a40fdbc56a1ab0181b80132beeecbd4b2d6/rpds_py-0.27.1-cp313-cp313-win_amd64.whl", hash = "sha256:f9025faafc62ed0b75a53e541895ca272815bec18abe2249ff6501c8f2e12b83", size = 232034, upload-time = "2025-08-27T12:13:50.11Z" },
+    { url = "https://files.pythonhosted.org/packages/c7/78/3958f3f018c01923823f1e47f1cc338e398814b92d83cd278364446fac66/rpds_py-0.27.1-cp313-cp313-win_arm64.whl", hash = "sha256:ed10dc32829e7d222b7d3b93136d25a406ba9788f6a7ebf6809092da1f4d279d", size = 222392, upload-time = "2025-08-27T12:13:52.587Z" },
+    { url = "https://files.pythonhosted.org/packages/01/76/1cdf1f91aed5c3a7bf2eba1f1c4e4d6f57832d73003919a20118870ea659/rpds_py-0.27.1-cp313-cp313t-macosx_10_12_x86_64.whl", hash = "sha256:92022bbbad0d4426e616815b16bc4127f83c9a74940e1ccf3cfe0b387aba0228", size = 358355, upload-time = "2025-08-27T12:13:54.012Z" },
+    { url = "https://files.pythonhosted.org/packages/c3/6f/bf142541229374287604caf3bb2a4ae17f0a580798fd72d3b009b532db4e/rpds_py-0.27.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:47162fdab9407ec3f160805ac3e154df042e577dd53341745fc7fb3f625e6d92", size = 342138, upload-time = "2025-08-27T12:13:55.791Z" },
+    { url = "https://files.pythonhosted.org/packages/1a/77/355b1c041d6be40886c44ff5e798b4e2769e497b790f0f7fd1e78d17e9a8/rpds_py-0.27.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fb89bec23fddc489e5d78b550a7b773557c9ab58b7946154a10a6f7a214a48b2", size = 380247, upload-time = "2025-08-27T12:13:57.683Z" },
+    { url = "https://files.pythonhosted.org/packages/d6/a4/d9cef5c3946ea271ce2243c51481971cd6e34f21925af2783dd17b26e815/rpds_py-0.27.1-cp313-cp313t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:e48af21883ded2b3e9eb48cb7880ad8598b31ab752ff3be6457001d78f416723", size = 390699, upload-time = "2025-08-27T12:13:59.137Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/06/005106a7b8c6c1a7e91b73169e49870f4af5256119d34a361ae5240a0c1d/rpds_py-0.27.1-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:6f5b7bd8e219ed50299e58551a410b64daafb5017d54bbe822e003856f06a802", size = 521852, upload-time = "2025-08-27T12:14:00.583Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/3e/50fb1dac0948e17a02eb05c24510a8fe12d5ce8561c6b7b7d1339ab7ab9c/rpds_py-0.27.1-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:08f1e20bccf73b08d12d804d6e1c22ca5530e71659e6673bce31a6bb71c1e73f", size = 402582, upload-time = "2025-08-27T12:14:02.034Z" },
+    { url = "https://files.pythonhosted.org/packages/cb/b0/f4e224090dc5b0ec15f31a02d746ab24101dd430847c4d99123798661bfc/rpds_py-0.27.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0dc5dceeaefcc96dc192e3a80bbe1d6c410c469e97bdd47494a7d930987f18b2", size = 384126, upload-time = "2025-08-27T12:14:03.437Z" },
+    { url = "https://files.pythonhosted.org/packages/54/77/ac339d5f82b6afff1df8f0fe0d2145cc827992cb5f8eeb90fc9f31ef7a63/rpds_py-0.27.1-cp313-cp313t-manylinux_2_31_riscv64.whl", hash = "sha256:d76f9cc8665acdc0c9177043746775aa7babbf479b5520b78ae4002d889f5c21", size = 399486, upload-time = "2025-08-27T12:14:05.443Z" },
+    { url = "https://files.pythonhosted.org/packages/d6/29/3e1c255eee6ac358c056a57d6d6869baa00a62fa32eea5ee0632039c50a3/rpds_py-0.27.1-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:134fae0e36022edad8290a6661edf40c023562964efea0cc0ec7f5d392d2aaef", size = 414832, upload-time = "2025-08-27T12:14:06.902Z" },
+    { url = "https://files.pythonhosted.org/packages/3f/db/6d498b844342deb3fa1d030598db93937a9964fcf5cb4da4feb5f17be34b/rpds_py-0.27.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:eb11a4f1b2b63337cfd3b4d110af778a59aae51c81d195768e353d8b52f88081", size = 557249, upload-time = "2025-08-27T12:14:08.37Z" },
+    { url = "https://files.pythonhosted.org/packages/60/f3/690dd38e2310b6f68858a331399b4d6dbb9132c3e8ef8b4333b96caf403d/rpds_py-0.27.1-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:13e608ac9f50a0ed4faec0e90ece76ae33b34c0e8656e3dceb9a7db994c692cd", size = 587356, upload-time = "2025-08-27T12:14:10.034Z" },
+    { url = "https://files.pythonhosted.org/packages/86/e3/84507781cccd0145f35b1dc32c72675200c5ce8d5b30f813e49424ef68fc/rpds_py-0.27.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:dd2135527aa40f061350c3f8f89da2644de26cd73e4de458e79606384f4f68e7", size = 555300, upload-time = "2025-08-27T12:14:11.783Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/ee/375469849e6b429b3516206b4580a79e9ef3eb12920ddbd4492b56eaacbe/rpds_py-0.27.1-cp313-cp313t-win32.whl", hash = "sha256:3020724ade63fe320a972e2ffd93b5623227e684315adce194941167fee02688", size = 216714, upload-time = "2025-08-27T12:14:13.629Z" },
+    { url = "https://files.pythonhosted.org/packages/21/87/3fc94e47c9bd0742660e84706c311a860dcae4374cf4a03c477e23ce605a/rpds_py-0.27.1-cp313-cp313t-win_amd64.whl", hash = "sha256:8ee50c3e41739886606388ba3ab3ee2aae9f35fb23f833091833255a31740797", size = 228943, upload-time = "2025-08-27T12:14:14.937Z" },
+    { url = "https://files.pythonhosted.org/packages/70/36/b6e6066520a07cf029d385de869729a895917b411e777ab1cde878100a1d/rpds_py-0.27.1-cp314-cp314-macosx_10_12_x86_64.whl", hash = "sha256:acb9aafccaae278f449d9c713b64a9e68662e7799dbd5859e2c6b3c67b56d334", size = 362472, upload-time = "2025-08-27T12:14:16.333Z" },
+    { url = "https://files.pythonhosted.org/packages/af/07/b4646032e0dcec0df9c73a3bd52f63bc6c5f9cda992f06bd0e73fe3fbebd/rpds_py-0.27.1-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:b7fb801aa7f845ddf601c49630deeeccde7ce10065561d92729bfe81bd21fb33", size = 345676, upload-time = "2025-08-27T12:14:17.764Z" },
+    { url = "https://files.pythonhosted.org/packages/b0/16/2f1003ee5d0af4bcb13c0cf894957984c32a6751ed7206db2aee7379a55e/rpds_py-0.27.1-cp314-cp314-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fe0dd05afb46597b9a2e11c351e5e4283c741237e7f617ffb3252780cca9336a", size = 385313, upload-time = "2025-08-27T12:14:19.829Z" },
+    { url = "https://files.pythonhosted.org/packages/05/cd/7eb6dd7b232e7f2654d03fa07f1414d7dfc980e82ba71e40a7c46fd95484/rpds_py-0.27.1-cp314-cp314-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:b6dfb0e058adb12d8b1d1b25f686e94ffa65d9995a5157afe99743bf7369d62b", size = 399080, upload-time = "2025-08-27T12:14:21.531Z" },
+    { url = "https://files.pythonhosted.org/packages/20/51/5829afd5000ec1cb60f304711f02572d619040aa3ec033d8226817d1e571/rpds_py-0.27.1-cp314-cp314-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ed090ccd235f6fa8bb5861684567f0a83e04f52dfc2e5c05f2e4b1309fcf85e7", size = 523868, upload-time = "2025-08-27T12:14:23.485Z" },
+    { url = "https://files.pythonhosted.org/packages/05/2c/30eebca20d5db95720ab4d2faec1b5e4c1025c473f703738c371241476a2/rpds_py-0.27.1-cp314-cp314-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:bf876e79763eecf3e7356f157540d6a093cef395b65514f17a356f62af6cc136", size = 408750, upload-time = "2025-08-27T12:14:24.924Z" },
+    { url = "https://files.pythonhosted.org/packages/90/1a/cdb5083f043597c4d4276eae4e4c70c55ab5accec078da8611f24575a367/rpds_py-0.27.1-cp314-cp314-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:12ed005216a51b1d6e2b02a7bd31885fe317e45897de81d86dcce7d74618ffff", size = 387688, upload-time = "2025-08-27T12:14:27.537Z" },
+    { url = "https://files.pythonhosted.org/packages/7c/92/cf786a15320e173f945d205ab31585cc43969743bb1a48b6888f7a2b0a2d/rpds_py-0.27.1-cp314-cp314-manylinux_2_31_riscv64.whl", hash = "sha256:ee4308f409a40e50593c7e3bb8cbe0b4d4c66d1674a316324f0c2f5383b486f9", size = 407225, upload-time = "2025-08-27T12:14:28.981Z" },
+    { url = "https://files.pythonhosted.org/packages/33/5c/85ee16df5b65063ef26017bef33096557a4c83fbe56218ac7cd8c235f16d/rpds_py-0.27.1-cp314-cp314-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:0b08d152555acf1f455154d498ca855618c1378ec810646fcd7c76416ac6dc60", size = 423361, upload-time = "2025-08-27T12:14:30.469Z" },
+    { url = "https://files.pythonhosted.org/packages/4b/8e/1c2741307fcabd1a334ecf008e92c4f47bb6f848712cf15c923becfe82bb/rpds_py-0.27.1-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:dce51c828941973a5684d458214d3a36fcd28da3e1875d659388f4f9f12cc33e", size = 562493, upload-time = "2025-08-27T12:14:31.987Z" },
+    { url = "https://files.pythonhosted.org/packages/04/03/5159321baae9b2222442a70c1f988cbbd66b9be0675dd3936461269be360/rpds_py-0.27.1-cp314-cp314-musllinux_1_2_i686.whl", hash = "sha256:c1476d6f29eb81aa4151c9a31219b03f1f798dc43d8af1250a870735516a1212", size = 592623, upload-time = "2025-08-27T12:14:33.543Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/39/c09fd1ad28b85bc1d4554a8710233c9f4cefd03d7717a1b8fbfd171d1167/rpds_py-0.27.1-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:3ce0cac322b0d69b63c9cdb895ee1b65805ec9ffad37639f291dd79467bee675", size = 558800, upload-time = "2025-08-27T12:14:35.436Z" },
+    { url = "https://files.pythonhosted.org/packages/c5/d6/99228e6bbcf4baa764b18258f519a9035131d91b538d4e0e294313462a98/rpds_py-0.27.1-cp314-cp314-win32.whl", hash = "sha256:dfbfac137d2a3d0725758cd141f878bf4329ba25e34979797c89474a89a8a3a3", size = 221943, upload-time = "2025-08-27T12:14:36.898Z" },
+    { url = "https://files.pythonhosted.org/packages/be/07/c802bc6b8e95be83b79bdf23d1aa61d68324cb1006e245d6c58e959e314d/rpds_py-0.27.1-cp314-cp314-win_amd64.whl", hash = "sha256:a6e57b0abfe7cc513450fcf529eb486b6e4d3f8aee83e92eb5f1ef848218d456", size = 233739, upload-time = "2025-08-27T12:14:38.386Z" },
+    { url = "https://files.pythonhosted.org/packages/c8/89/3e1b1c16d4c2d547c5717377a8df99aee8099ff050f87c45cb4d5fa70891/rpds_py-0.27.1-cp314-cp314-win_arm64.whl", hash = "sha256:faf8d146f3d476abfee026c4ae3bdd9ca14236ae4e4c310cbd1cf75ba33d24a3", size = 223120, upload-time = "2025-08-27T12:14:39.82Z" },
+    { url = "https://files.pythonhosted.org/packages/62/7e/dc7931dc2fa4a6e46b2a4fa744a9fe5c548efd70e0ba74f40b39fa4a8c10/rpds_py-0.27.1-cp314-cp314t-macosx_10_12_x86_64.whl", hash = "sha256:ba81d2b56b6d4911ce735aad0a1d4495e808b8ee4dc58715998741a26874e7c2", size = 358944, upload-time = "2025-08-27T12:14:41.199Z" },
+    { url = "https://files.pythonhosted.org/packages/e6/22/4af76ac4e9f336bfb1a5f240d18a33c6b2fcaadb7472ac7680576512b49a/rpds_py-0.27.1-cp314-cp314t-macosx_11_0_arm64.whl", hash = "sha256:84f7d509870098de0e864cad0102711c1e24e9b1a50ee713b65928adb22269e4", size = 342283, upload-time = "2025-08-27T12:14:42.699Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/15/2a7c619b3c2272ea9feb9ade67a45c40b3eeb500d503ad4c28c395dc51b4/rpds_py-0.27.1-cp314-cp314t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a9e960fc78fecd1100539f14132425e1d5fe44ecb9239f8f27f079962021523e", size = 380320, upload-time = "2025-08-27T12:14:44.157Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/7d/4c6d243ba4a3057e994bb5bedd01b5c963c12fe38dde707a52acdb3849e7/rpds_py-0.27.1-cp314-cp314t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:62f85b665cedab1a503747617393573995dac4600ff51869d69ad2f39eb5e817", size = 391760, upload-time = "2025-08-27T12:14:45.845Z" },
+    { url = "https://files.pythonhosted.org/packages/b4/71/b19401a909b83bcd67f90221330bc1ef11bc486fe4e04c24388d28a618ae/rpds_py-0.27.1-cp314-cp314t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:fed467af29776f6556250c9ed85ea5a4dd121ab56a5f8b206e3e7a4c551e48ec", size = 522476, upload-time = "2025-08-27T12:14:47.364Z" },
+    { url = "https://files.pythonhosted.org/packages/e4/44/1a3b9715c0455d2e2f0f6df5ee6d6f5afdc423d0773a8a682ed2b43c566c/rpds_py-0.27.1-cp314-cp314t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f2729615f9d430af0ae6b36cf042cb55c0936408d543fb691e1a9e36648fd35a", size = 403418, upload-time = "2025-08-27T12:14:49.991Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/4b/fb6c4f14984eb56673bc868a66536f53417ddb13ed44b391998100a06a96/rpds_py-0.27.1-cp314-cp314t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1b207d881a9aef7ba753d69c123a35d96ca7cb808056998f6b9e8747321f03b8", size = 384771, upload-time = "2025-08-27T12:14:52.159Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/56/d5265d2d28b7420d7b4d4d85cad8ef891760f5135102e60d5c970b976e41/rpds_py-0.27.1-cp314-cp314t-manylinux_2_31_riscv64.whl", hash = "sha256:639fd5efec029f99b79ae47e5d7e00ad8a773da899b6309f6786ecaf22948c48", size = 400022, upload-time = "2025-08-27T12:14:53.859Z" },
+    { url = "https://files.pythonhosted.org/packages/8f/e9/9f5fc70164a569bdd6ed9046486c3568d6926e3a49bdefeeccfb18655875/rpds_py-0.27.1-cp314-cp314t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:fecc80cb2a90e28af8a9b366edacf33d7a91cbfe4c2c4544ea1246e949cfebeb", size = 416787, upload-time = "2025-08-27T12:14:55.673Z" },
+    { url = "https://files.pythonhosted.org/packages/d4/64/56dd03430ba491db943a81dcdef115a985aac5f44f565cd39a00c766d45c/rpds_py-0.27.1-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:42a89282d711711d0a62d6f57d81aa43a1368686c45bc1c46b7f079d55692734", size = 557538, upload-time = "2025-08-27T12:14:57.245Z" },
+    { url = "https://files.pythonhosted.org/packages/3f/36/92cc885a3129993b1d963a2a42ecf64e6a8e129d2c7cc980dbeba84e55fb/rpds_py-0.27.1-cp314-cp314t-musllinux_1_2_i686.whl", hash = "sha256:cf9931f14223de59551ab9d38ed18d92f14f055a5f78c1d8ad6493f735021bbb", size = 588512, upload-time = "2025-08-27T12:14:58.728Z" },
+    { url = "https://files.pythonhosted.org/packages/dd/10/6b283707780a81919f71625351182b4f98932ac89a09023cb61865136244/rpds_py-0.27.1-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:f39f58a27cc6e59f432b568ed8429c7e1641324fbe38131de852cd77b2d534b0", size = 555813, upload-time = "2025-08-27T12:15:00.334Z" },
+    { url = "https://files.pythonhosted.org/packages/04/2e/30b5ea18c01379da6272a92825dd7e53dc9d15c88a19e97932d35d430ef7/rpds_py-0.27.1-cp314-cp314t-win32.whl", hash = "sha256:d5fa0ee122dc09e23607a28e6d7b150da16c662e66409bbe85230e4c85bb528a", size = 217385, upload-time = "2025-08-27T12:15:01.937Z" },
+    { url = "https://files.pythonhosted.org/packages/32/7d/97119da51cb1dd3f2f3c0805f155a3aa4a95fa44fe7d78ae15e69edf4f34/rpds_py-0.27.1-cp314-cp314t-win_amd64.whl", hash = "sha256:6567d2bb951e21232c2f660c24cf3470bb96de56cdcb3f071a83feeaff8a2772", size = 230097, upload-time = "2025-08-27T12:15:03.961Z" },
+    { url = "https://files.pythonhosted.org/packages/7f/6c/252e83e1ce7583c81f26d1d884b2074d40a13977e1b6c9c50bbf9a7f1f5a/rpds_py-0.27.1-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:c918c65ec2e42c2a78d19f18c553d77319119bf43aa9e2edf7fb78d624355527", size = 372140, upload-time = "2025-08-27T12:15:05.441Z" },
+    { url = "https://files.pythonhosted.org/packages/9d/71/949c195d927c5aeb0d0629d329a20de43a64c423a6aa53836290609ef7ec/rpds_py-0.27.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:1fea2b1a922c47c51fd07d656324531adc787e415c8b116530a1d29c0516c62d", size = 354086, upload-time = "2025-08-27T12:15:07.404Z" },
+    { url = "https://files.pythonhosted.org/packages/9f/02/e43e332ad8ce4f6c4342d151a471a7f2900ed1d76901da62eb3762663a71/rpds_py-0.27.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bbf94c58e8e0cd6b6f38d8de67acae41b3a515c26169366ab58bdca4a6883bb8", size = 382117, upload-time = "2025-08-27T12:15:09.275Z" },
+    { url = "https://files.pythonhosted.org/packages/d0/05/b0fdeb5b577197ad72812bbdfb72f9a08fa1e64539cc3940b1b781cd3596/rpds_py-0.27.1-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:c2a8fed130ce946d5c585eddc7c8eeef0051f58ac80a8ee43bd17835c144c2cc", size = 394520, upload-time = "2025-08-27T12:15:10.727Z" },
+    { url = "https://files.pythonhosted.org/packages/67/1f/4cfef98b2349a7585181e99294fa2a13f0af06902048a5d70f431a66d0b9/rpds_py-0.27.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:037a2361db72ee98d829bc2c5b7cc55598ae0a5e0ec1823a56ea99374cfd73c1", size = 522657, upload-time = "2025-08-27T12:15:12.613Z" },
+    { url = "https://files.pythonhosted.org/packages/44/55/ccf37ddc4c6dce7437b335088b5ca18da864b334890e2fe9aa6ddc3f79a9/rpds_py-0.27.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5281ed1cc1d49882f9997981c88df1a22e140ab41df19071222f7e5fc4e72125", size = 402967, upload-time = "2025-08-27T12:15:14.113Z" },
+    { url = "https://files.pythonhosted.org/packages/74/e5/5903f92e41e293b07707d5bf00ef39a0eb2af7190aff4beaf581a6591510/rpds_py-0.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2fd50659a069c15eef8aa3d64bbef0d69fd27bb4a50c9ab4f17f83a16cbf8905", size = 384372, upload-time = "2025-08-27T12:15:15.842Z" },
+    { url = "https://files.pythonhosted.org/packages/8f/e3/fbb409e18aeefc01e49f5922ac63d2d914328430e295c12183ce56ebf76b/rpds_py-0.27.1-cp39-cp39-manylinux_2_31_riscv64.whl", hash = "sha256:c4b676c4ae3921649a15d28ed10025548e9b561ded473aa413af749503c6737e", size = 401264, upload-time = "2025-08-27T12:15:17.388Z" },
+    { url = "https://files.pythonhosted.org/packages/55/79/529ad07794e05cb0f38e2f965fc5bb20853d523976719400acecc447ec9d/rpds_py-0.27.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:079bc583a26db831a985c5257797b2b5d3affb0386e7ff886256762f82113b5e", size = 418691, upload-time = "2025-08-27T12:15:19.144Z" },
+    { url = "https://files.pythonhosted.org/packages/33/39/6554a7fd6d9906fda2521c6d52f5d723dca123529fb719a5b5e074c15e01/rpds_py-0.27.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:4e44099bd522cba71a2c6b97f68e19f40e7d85399de899d66cdb67b32d7cb786", size = 558989, upload-time = "2025-08-27T12:15:21.087Z" },
+    { url = "https://files.pythonhosted.org/packages/19/b2/76fa15173b6f9f445e5ef15120871b945fb8dd9044b6b8c7abe87e938416/rpds_py-0.27.1-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:e202e6d4188e53c6661af813b46c37ca2c45e497fc558bacc1a7630ec2695aec", size = 589835, upload-time = "2025-08-27T12:15:22.696Z" },
+    { url = "https://files.pythonhosted.org/packages/ee/9e/5560a4b39bab780405bed8a88ee85b30178061d189558a86003548dea045/rpds_py-0.27.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:f41f814b8eaa48768d1bb551591f6ba45f87ac76899453e8ccd41dba1289b04b", size = 555227, upload-time = "2025-08-27T12:15:24.278Z" },
+    { url = "https://files.pythonhosted.org/packages/52/d7/cd9c36215111aa65724c132bf709c6f35175973e90b32115dedc4ced09cb/rpds_py-0.27.1-cp39-cp39-win32.whl", hash = "sha256:9e71f5a087ead99563c11fdaceee83ee982fd39cf67601f4fd66cb386336ee52", size = 217899, upload-time = "2025-08-27T12:15:25.926Z" },
+    { url = "https://files.pythonhosted.org/packages/5b/e0/d75ab7b4dd8ba777f6b365adbdfc7614bbfe7c5f05703031dfa4b61c3d6c/rpds_py-0.27.1-cp39-cp39-win_amd64.whl", hash = "sha256:71108900c9c3c8590697244b9519017a400d9ba26a36c48381b3f64743a44aab", size = 228725, upload-time = "2025-08-27T12:15:27.398Z" },
+    { url = "https://files.pythonhosted.org/packages/d5/63/b7cc415c345625d5e62f694ea356c58fb964861409008118f1245f8c3347/rpds_py-0.27.1-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:7ba22cb9693df986033b91ae1d7a979bc399237d45fccf875b76f62bb9e52ddf", size = 371360, upload-time = "2025-08-27T12:15:29.218Z" },
+    { url = "https://files.pythonhosted.org/packages/e5/8c/12e1b24b560cf378b8ffbdb9dc73abd529e1adcfcf82727dfd29c4a7b88d/rpds_py-0.27.1-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:5b640501be9288c77738b5492b3fd3abc4ba95c50c2e41273c8a1459f08298d3", size = 353933, upload-time = "2025-08-27T12:15:30.837Z" },
+    { url = "https://files.pythonhosted.org/packages/9b/85/1bb2210c1f7a1b99e91fea486b9f0f894aa5da3a5ec7097cbad7dec6d40f/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fb08b65b93e0c6dd70aac7f7890a9c0938d5ec71d5cb32d45cf844fb8ae47636", size = 382962, upload-time = "2025-08-27T12:15:32.348Z" },
+    { url = "https://files.pythonhosted.org/packages/cc/c9/a839b9f219cf80ed65f27a7f5ddbb2809c1b85c966020ae2dff490e0b18e/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:d7ff07d696a7a38152ebdb8212ca9e5baab56656749f3d6004b34ab726b550b8", size = 394412, upload-time = "2025-08-27T12:15:33.839Z" },
+    { url = "https://files.pythonhosted.org/packages/02/2d/b1d7f928b0b1f4fc2e0133e8051d199b01d7384875adc63b6ddadf3de7e5/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:fb7c72262deae25366e3b6c0c0ba46007967aea15d1eea746e44ddba8ec58dcc", size = 523972, upload-time = "2025-08-27T12:15:35.377Z" },
+    { url = "https://files.pythonhosted.org/packages/a9/af/2cbf56edd2d07716df1aec8a726b3159deb47cb5c27e1e42b71d705a7c2f/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7b002cab05d6339716b03a4a3a2ce26737f6231d7b523f339fa061d53368c9d8", size = 403273, upload-time = "2025-08-27T12:15:37.051Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/93/425e32200158d44ff01da5d9612c3b6711fe69f606f06e3895511f17473b/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:23f6b69d1c26c4704fec01311963a41d7de3ee0570a84ebde4d544e5a1859ffc", size = 385278, upload-time = "2025-08-27T12:15:38.571Z" },
+    { url = "https://files.pythonhosted.org/packages/eb/1a/1a04a915ecd0551bfa9e77b7672d1937b4b72a0fc204a17deef76001cfb2/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_31_riscv64.whl", hash = "sha256:530064db9146b247351f2a0250b8f00b289accea4596a033e94be2389977de71", size = 402084, upload-time = "2025-08-27T12:15:40.529Z" },
+    { url = "https://files.pythonhosted.org/packages/51/f7/66585c0fe5714368b62951d2513b684e5215beaceab2c6629549ddb15036/rpds_py-0.27.1-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:7b90b0496570bd6b0321724a330d8b545827c4df2034b6ddfc5f5275f55da2ad", size = 419041, upload-time = "2025-08-27T12:15:42.191Z" },
+    { url = "https://files.pythonhosted.org/packages/8e/7e/83a508f6b8e219bba2d4af077c35ba0e0cdd35a751a3be6a7cba5a55ad71/rpds_py-0.27.1-pp310-pypy310_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:879b0e14a2da6a1102a3fc8af580fc1ead37e6d6692a781bd8c83da37429b5ab", size = 560084, upload-time = "2025-08-27T12:15:43.839Z" },
+    { url = "https://files.pythonhosted.org/packages/66/66/bb945683b958a1b19eb0fe715594630d0f36396ebdef4d9b89c2fa09aa56/rpds_py-0.27.1-pp310-pypy310_pp73-musllinux_1_2_i686.whl", hash = "sha256:0d807710df3b5faa66c731afa162ea29717ab3be17bdc15f90f2d9f183da4059", size = 590115, upload-time = "2025-08-27T12:15:46.647Z" },
+    { url = "https://files.pythonhosted.org/packages/12/00/ccfaafaf7db7e7adace915e5c2f2c2410e16402561801e9c7f96683002d3/rpds_py-0.27.1-pp310-pypy310_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:3adc388fc3afb6540aec081fa59e6e0d3908722771aa1e37ffe22b220a436f0b", size = 556561, upload-time = "2025-08-27T12:15:48.219Z" },
+    { url = "https://files.pythonhosted.org/packages/e1/b7/92b6ed9aad103bfe1c45df98453dfae40969eef2cb6c6239c58d7e96f1b3/rpds_py-0.27.1-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:c796c0c1cc68cb08b0284db4229f5af76168172670c74908fdbd4b7d7f515819", size = 229125, upload-time = "2025-08-27T12:15:49.956Z" },
+    { url = "https://files.pythonhosted.org/packages/0c/ed/e1fba02de17f4f76318b834425257c8ea297e415e12c68b4361f63e8ae92/rpds_py-0.27.1-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:cdfe4bb2f9fe7458b7453ad3c33e726d6d1c7c0a72960bcc23800d77384e42df", size = 371402, upload-time = "2025-08-27T12:15:51.561Z" },
+    { url = "https://files.pythonhosted.org/packages/af/7c/e16b959b316048b55585a697e94add55a4ae0d984434d279ea83442e460d/rpds_py-0.27.1-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:8fabb8fd848a5f75a2324e4a84501ee3a5e3c78d8603f83475441866e60b94a3", size = 354084, upload-time = "2025-08-27T12:15:53.219Z" },
+    { url = "https://files.pythonhosted.org/packages/de/c1/ade645f55de76799fdd08682d51ae6724cb46f318573f18be49b1e040428/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:eda8719d598f2f7f3e0f885cba8646644b55a187762bec091fa14a2b819746a9", size = 383090, upload-time = "2025-08-27T12:15:55.158Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/27/89070ca9b856e52960da1472efcb6c20ba27cfe902f4f23ed095b9cfc61d/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:3c64d07e95606ec402a0a1c511fe003873fa6af630bda59bac77fac8b4318ebc", size = 394519, upload-time = "2025-08-27T12:15:57.238Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/28/be120586874ef906aa5aeeae95ae8df4184bc757e5b6bd1c729ccff45ed5/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:93a2ed40de81bcff59aabebb626562d48332f3d028ca2036f1d23cbb52750be4", size = 523817, upload-time = "2025-08-27T12:15:59.237Z" },
+    { url = "https://files.pythonhosted.org/packages/a8/ef/70cc197bc11cfcde02a86f36ac1eed15c56667c2ebddbdb76a47e90306da/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:387ce8c44ae94e0ec50532d9cb0edce17311024c9794eb196b90e1058aadeb66", size = 403240, upload-time = "2025-08-27T12:16:00.923Z" },
+    { url = "https://files.pythonhosted.org/packages/cf/35/46936cca449f7f518f2f4996e0e8344db4b57e2081e752441154089d2a5f/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:aaf94f812c95b5e60ebaf8bfb1898a7d7cb9c1af5744d4a67fa47796e0465d4e", size = 385194, upload-time = "2025-08-27T12:16:02.802Z" },
+    { url = "https://files.pythonhosted.org/packages/e1/62/29c0d3e5125c3270b51415af7cbff1ec587379c84f55a5761cc9efa8cd06/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_31_riscv64.whl", hash = "sha256:4848ca84d6ded9b58e474dfdbad4b8bfb450344c0551ddc8d958bf4b36aa837c", size = 402086, upload-time = "2025-08-27T12:16:04.806Z" },
+    { url = "https://files.pythonhosted.org/packages/8f/66/03e1087679227785474466fdd04157fb793b3b76e3fcf01cbf4c693c1949/rpds_py-0.27.1-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:2bde09cbcf2248b73c7c323be49b280180ff39fadcfe04e7b6f54a678d02a7cf", size = 419272, upload-time = "2025-08-27T12:16:06.471Z" },
+    { url = "https://files.pythonhosted.org/packages/6a/24/e3e72d265121e00b063aef3e3501e5b2473cf1b23511d56e529531acf01e/rpds_py-0.27.1-pp311-pypy311_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:94c44ee01fd21c9058f124d2d4f0c9dc7634bec93cd4b38eefc385dabe71acbf", size = 560003, upload-time = "2025-08-27T12:16:08.06Z" },
+    { url = "https://files.pythonhosted.org/packages/26/ca/f5a344c534214cc2d41118c0699fffbdc2c1bc7046f2a2b9609765ab9c92/rpds_py-0.27.1-pp311-pypy311_pp73-musllinux_1_2_i686.whl", hash = "sha256:df8b74962e35c9249425d90144e721eed198e6555a0e22a563d29fe4486b51f6", size = 590482, upload-time = "2025-08-27T12:16:10.137Z" },
+    { url = "https://files.pythonhosted.org/packages/ce/08/4349bdd5c64d9d193c360aa9db89adeee6f6682ab8825dca0a3f535f434f/rpds_py-0.27.1-pp311-pypy311_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:dc23e6820e3b40847e2f4a7726462ba0cf53089512abe9ee16318c366494c17a", size = 556523, upload-time = "2025-08-27T12:16:12.188Z" },
+    { url = "https://files.pythonhosted.org/packages/4e/ea/5463cd5048a7a2fcdae308b6e96432802132c141bfb9420260142632a0f1/rpds_py-0.27.1-pp39-pypy39_pp73-macosx_10_12_x86_64.whl", hash = "sha256:aa8933159edc50be265ed22b401125c9eebff3171f570258854dbce3ecd55475", size = 371778, upload-time = "2025-08-27T12:16:13.851Z" },
+    { url = "https://files.pythonhosted.org/packages/0d/c8/f38c099db07f5114029c1467649d308543906933eebbc226d4527a5f4693/rpds_py-0.27.1-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:a50431bf02583e21bf273c71b89d710e7a710ad5e39c725b14e685610555926f", size = 354394, upload-time = "2025-08-27T12:16:15.609Z" },
+    { url = "https://files.pythonhosted.org/packages/7d/79/b76f97704d9dd8ddbd76fed4c4048153a847c5d6003afe20a6b5c3339065/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:78af06ddc7fe5cc0e967085a9115accee665fb912c22a3f54bad70cc65b05fe6", size = 382348, upload-time = "2025-08-27T12:16:17.251Z" },
+    { url = "https://files.pythonhosted.org/packages/8a/3f/ef23d3c1be1b837b648a3016d5bbe7cfe711422ad110b4081c0a90ef5a53/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:70d0738ef8fee13c003b100c2fbd667ec4f133468109b3472d249231108283a3", size = 394159, upload-time = "2025-08-27T12:16:19.251Z" },
+    { url = "https://files.pythonhosted.org/packages/74/8a/9e62693af1a34fd28b1a190d463d12407bd7cf561748cb4745845d9548d3/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e2f6fd8a1cea5bbe599b6e78a6e5ee08db434fc8ffea51ff201c8765679698b3", size = 522775, upload-time = "2025-08-27T12:16:20.929Z" },
+    { url = "https://files.pythonhosted.org/packages/36/0d/8d5bb122bf7a60976b54c5c99a739a3819f49f02d69df3ea2ca2aff47d5c/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:8177002868d1426305bb5de1e138161c2ec9eb2d939be38291d7c431c4712df8", size = 402633, upload-time = "2025-08-27T12:16:22.548Z" },
+    { url = "https://files.pythonhosted.org/packages/0f/0e/237948c1f425e23e0cf5a566d702652a6e55c6f8fbd332a1792eb7043daf/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:008b839781d6c9bf3b6a8984d1d8e56f0ec46dc56df61fd669c49b58ae800400", size = 384867, upload-time = "2025-08-27T12:16:24.29Z" },
+    { url = "https://files.pythonhosted.org/packages/d6/0a/da0813efcd998d260cbe876d97f55b0f469ada8ba9cbc47490a132554540/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_31_riscv64.whl", hash = "sha256:a55b9132bb1ade6c734ddd2759c8dc132aa63687d259e725221f106b83a0e485", size = 401791, upload-time = "2025-08-27T12:16:25.954Z" },
+    { url = "https://files.pythonhosted.org/packages/51/78/c6c9e8a8aaca416a6f0d1b6b4a6ee35b88fe2c5401d02235d0a056eceed2/rpds_py-0.27.1-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:a46fdec0083a26415f11d5f236b79fa1291c32aaa4a17684d82f7017a1f818b1", size = 419525, upload-time = "2025-08-27T12:16:27.659Z" },
+    { url = "https://files.pythonhosted.org/packages/a3/69/5af37e1d71487cf6d56dd1420dc7e0c2732c1b6ff612aa7a88374061c0a8/rpds_py-0.27.1-pp39-pypy39_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:8a63b640a7845f2bdd232eb0d0a4a2dd939bcdd6c57e6bb134526487f3160ec5", size = 559255, upload-time = "2025-08-27T12:16:29.343Z" },
+    { url = "https://files.pythonhosted.org/packages/40/7f/8b7b136069ef7ac3960eda25d832639bdb163018a34c960ed042dd1707c8/rpds_py-0.27.1-pp39-pypy39_pp73-musllinux_1_2_i686.whl", hash = "sha256:7e32721e5d4922deaaf963469d795d5bde6093207c52fec719bd22e5d1bedbc4", size = 590384, upload-time = "2025-08-27T12:16:31.005Z" },
+    { url = "https://files.pythonhosted.org/packages/d8/06/c316d3f6ff03f43ccb0eba7de61376f8ec4ea850067dddfafe98274ae13c/rpds_py-0.27.1-pp39-pypy39_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:2c426b99a068601b5f4623573df7a7c3d72e87533a2dd2253353a03e7502566c", size = 555959, upload-time = "2025-08-27T12:16:32.73Z" },
+    { url = "https://files.pythonhosted.org/packages/60/94/384cf54c430b9dac742bbd2ec26c23feb78ded0d43d6d78563a281aec017/rpds_py-0.27.1-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:4fc9b7fe29478824361ead6e14e4f5aed570d477e06088826537e202d25fe859", size = 228784, upload-time = "2025-08-27T12:16:34.428Z" },
+]
+
+[[package]]
+name = "rpds-py"
+version = "0.29.0"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+]
+sdist = { url = "https://files.pythonhosted.org/packages/98/33/23b3b3419b6a3e0f559c7c0d2ca8fc1b9448382b25245033788785921332/rpds_py-0.29.0.tar.gz", hash = "sha256:fe55fe686908f50154d1dc599232016e50c243b438c3b7432f24e2895b0e5359", size = 69359, upload-time = "2025-11-16T14:50:39.532Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/9e/7a/c5b2ff381b74bc742768e8d870f26babac4ef256ba160bdbf8d57af56461/rpds_py-0.29.0-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:4ae4b88c6617e1b9e5038ab3fccd7bac0842fdda2b703117b2aa99bc85379113", size = 372385, upload-time = "2025-11-16T14:47:36.287Z" },
+    { url = "https://files.pythonhosted.org/packages/28/36/531f1eb4d5bed4a9c150f363a7ec4a98d2dc746151bba5473bc38ee85dec/rpds_py-0.29.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:7d9128ec9d8cecda6f044001fde4fb71ea7c24325336612ef8179091eb9596b9", size = 362869, upload-time = "2025-11-16T14:47:38.196Z" },
+    { url = "https://files.pythonhosted.org/packages/54/df/7e9c0493a2015d9c82807a2d5f023ea9774e27a4c15b33ef1cdb7456138d/rpds_py-0.29.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d37812c3da8e06f2bb35b3cf10e4a7b68e776a706c13058997238762b4e07f4f", size = 391582, upload-time = "2025-11-16T14:47:39.746Z" },
+    { url = "https://files.pythonhosted.org/packages/15/38/42a981c3592ef46fbd7e17adbf8730cc5ec87e6aa1770c658c44bbb52960/rpds_py-0.29.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:66786c3fb1d8de416a7fa8e1cb1ec6ba0a745b2b0eee42f9b7daa26f1a495545", size = 405685, upload-time = "2025-11-16T14:47:41.472Z" },
+    { url = "https://files.pythonhosted.org/packages/12/45/628b8c15856c3849c3f52ec6dac93c046ed5faeed4a435af03b70525fd29/rpds_py-0.29.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b58f5c77f1af888b5fd1876c9a0d9858f6f88a39c9dd7c073a88e57e577da66d", size = 527067, upload-time = "2025-11-16T14:47:43.036Z" },
+    { url = "https://files.pythonhosted.org/packages/dc/ba/6b56d09badeabd95098016d72a437d4a0fd82d4672ce92a7607df5d70a42/rpds_py-0.29.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:799156ef1f3529ed82c36eb012b5d7a4cf4b6ef556dd7cc192148991d07206ae", size = 412532, upload-time = "2025-11-16T14:47:44.484Z" },
+    { url = "https://files.pythonhosted.org/packages/f1/39/2f1f3db92888314b50b8f9641f679188bd24b3665a8cb9923b7201ae8011/rpds_py-0.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:453783477aa4f2d9104c4b59b08c871431647cb7af51b549bbf2d9eb9c827756", size = 392736, upload-time = "2025-11-16T14:47:46.053Z" },
+    { url = "https://files.pythonhosted.org/packages/60/43/3c3b1dcd827e50f2ae28786d846b8a351080d8a69a3b49bc10ae44cc39b1/rpds_py-0.29.0-cp310-cp310-manylinux_2_31_riscv64.whl", hash = "sha256:24a7231493e3c4a4b30138b50cca089a598e52c34cf60b2f35cebf62f274fdea", size = 406300, upload-time = "2025-11-16T14:47:47.268Z" },
+    { url = "https://files.pythonhosted.org/packages/da/02/bc96021b67f8525e6bcdd68935c4543ada61e1f3dcb067ed037d68b8c6d2/rpds_py-0.29.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:7033c1010b1f57bb44d8067e8c25aa6fa2e944dbf46ccc8c92b25043839c3fd2", size = 423641, upload-time = "2025-11-16T14:47:48.878Z" },
+    { url = "https://files.pythonhosted.org/packages/38/e9/c435ddb602ced19a80b8277a41371734f33ad3f91cc4ceb4d82596800a3c/rpds_py-0.29.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:0248b19405422573621172ab8e3a1f29141362d13d9f72bafa2e28ea0cdca5a2", size = 574153, upload-time = "2025-11-16T14:47:50.435Z" },
+    { url = "https://files.pythonhosted.org/packages/84/82/dc3c32e1f89ecba8a59600d4cd65fe0ad81b6c636ccdbf6cd177fd6a7bac/rpds_py-0.29.0-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:f9f436aee28d13b9ad2c764fc273e0457e37c2e61529a07b928346b219fcde3b", size = 600304, upload-time = "2025-11-16T14:47:51.599Z" },
+    { url = "https://files.pythonhosted.org/packages/35/98/785290e0b7142470735dc1b1f68fb33aae29e5296f062c88396eedf796c8/rpds_py-0.29.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:24a16cb7163933906c62c272de20ea3c228e4542c8c45c1d7dc2b9913e17369a", size = 562211, upload-time = "2025-11-16T14:47:53.094Z" },
+    { url = "https://files.pythonhosted.org/packages/30/58/4eeddcb0737c6875f3e30c65dc9d7e7a10dfd5779646a990fa602c6d56c5/rpds_py-0.29.0-cp310-cp310-win32.whl", hash = "sha256:1a409b0310a566bfd1be82119891fefbdce615ccc8aa558aff7835c27988cbef", size = 221803, upload-time = "2025-11-16T14:47:54.404Z" },
+    { url = "https://files.pythonhosted.org/packages/54/77/b35a8dbdcbeb32505500547cdafaa9f8863e85f8faac50ef34464ec5a256/rpds_py-0.29.0-cp310-cp310-win_amd64.whl", hash = "sha256:c5523b0009e7c3c1263471b69d8da1c7d41b3ecb4cb62ef72be206b92040a950", size = 235530, upload-time = "2025-11-16T14:47:56.061Z" },
+    { url = "https://files.pythonhosted.org/packages/36/ab/7fb95163a53ab122c74a7c42d2d2f012819af2cf3deb43fb0d5acf45cc1a/rpds_py-0.29.0-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:9b9c764a11fd637e0322a488560533112837f5334ffeb48b1be20f6d98a7b437", size = 372344, upload-time = "2025-11-16T14:47:57.279Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/45/f3c30084c03b0d0f918cb4c5ae2c20b0a148b51ba2b3f6456765b629bedd/rpds_py-0.29.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:3fd2164d73812026ce970d44c3ebd51e019d2a26a4425a5dcbdfa93a34abc383", size = 363041, upload-time = "2025-11-16T14:47:58.908Z" },
+    { url = "https://files.pythonhosted.org/packages/e3/e9/4d044a1662608c47a87cbb37b999d4d5af54c6d6ebdda93a4d8bbf8b2a10/rpds_py-0.29.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4a097b7f7f7274164566ae90a221fd725363c0e9d243e2e9ed43d195ccc5495c", size = 391775, upload-time = "2025-11-16T14:48:00.197Z" },
+    { url = "https://files.pythonhosted.org/packages/50/c9/7616d3ace4e6731aeb6e3cd85123e03aec58e439044e214b9c5c60fd8eb1/rpds_py-0.29.0-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:7cdc0490374e31cedefefaa1520d5fe38e82fde8748cbc926e7284574c714d6b", size = 405624, upload-time = "2025-11-16T14:48:01.496Z" },
+    { url = "https://files.pythonhosted.org/packages/c2/e2/6d7d6941ca0843609fd2d72c966a438d6f22617baf22d46c3d2156c31350/rpds_py-0.29.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:89ca2e673ddd5bde9b386da9a0aac0cab0e76f40c8f0aaf0d6311b6bbf2aa311", size = 527894, upload-time = "2025-11-16T14:48:03.167Z" },
+    { url = "https://files.pythonhosted.org/packages/8d/f7/aee14dc2db61bb2ae1e3068f134ca9da5f28c586120889a70ff504bb026f/rpds_py-0.29.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a5d9da3ff5af1ca1249b1adb8ef0573b94c76e6ae880ba1852f033bf429d4588", size = 412720, upload-time = "2025-11-16T14:48:04.413Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/e2/2293f236e887c0360c2723d90c00d48dee296406994d6271faf1712e94ec/rpds_py-0.29.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8238d1d310283e87376c12f658b61e1ee23a14c0e54c7c0ce953efdbdc72deed", size = 392945, upload-time = "2025-11-16T14:48:06.252Z" },
+    { url = "https://files.pythonhosted.org/packages/14/cd/ceea6147acd3bd1fd028d1975228f08ff19d62098078d5ec3eed49703797/rpds_py-0.29.0-cp311-cp311-manylinux_2_31_riscv64.whl", hash = "sha256:2d6fb2ad1c36f91c4646989811e84b1ea5e0c3cf9690b826b6e32b7965853a63", size = 406385, upload-time = "2025-11-16T14:48:07.575Z" },
+    { url = "https://files.pythonhosted.org/packages/52/36/fe4dead19e45eb77a0524acfdbf51e6cda597b26fc5b6dddbff55fbbb1a5/rpds_py-0.29.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:534dc9df211387547267ccdb42253aa30527482acb38dd9b21c5c115d66a96d2", size = 423943, upload-time = "2025-11-16T14:48:10.175Z" },
+    { url = "https://files.pythonhosted.org/packages/a1/7b/4551510803b582fa4abbc8645441a2d15aa0c962c3b21ebb380b7e74f6a1/rpds_py-0.29.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:d456e64724a075441e4ed648d7f154dc62e9aabff29bcdf723d0c00e9e1d352f", size = 574204, upload-time = "2025-11-16T14:48:11.499Z" },
+    { url = "https://files.pythonhosted.org/packages/64/ba/071ccdd7b171e727a6ae079f02c26f75790b41555f12ca8f1151336d2124/rpds_py-0.29.0-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:a738f2da2f565989401bd6fd0b15990a4d1523c6d7fe83f300b7e7d17212feca", size = 600587, upload-time = "2025-11-16T14:48:12.822Z" },
+    { url = "https://files.pythonhosted.org/packages/03/09/96983d48c8cf5a1e03c7d9cc1f4b48266adfb858ae48c7c2ce978dbba349/rpds_py-0.29.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:a110e14508fd26fd2e472bb541f37c209409876ba601cf57e739e87d8a53cf95", size = 562287, upload-time = "2025-11-16T14:48:14.108Z" },
+    { url = "https://files.pythonhosted.org/packages/40/f0/8c01aaedc0fa92156f0391f39ea93b5952bc0ec56b897763858f95da8168/rpds_py-0.29.0-cp311-cp311-win32.whl", hash = "sha256:923248a56dd8d158389a28934f6f69ebf89f218ef96a6b216a9be6861804d3f4", size = 221394, upload-time = "2025-11-16T14:48:15.374Z" },
+    { url = "https://files.pythonhosted.org/packages/7e/a5/a8b21c54c7d234efdc83dc034a4d7cd9668e3613b6316876a29b49dece71/rpds_py-0.29.0-cp311-cp311-win_amd64.whl", hash = "sha256:539eb77eb043afcc45314d1be09ea6d6cafb3addc73e0547c171c6d636957f60", size = 235713, upload-time = "2025-11-16T14:48:16.636Z" },
+    { url = "https://files.pythonhosted.org/packages/a7/1f/df3c56219523947b1be402fa12e6323fe6d61d883cf35d6cb5d5bb6db9d9/rpds_py-0.29.0-cp311-cp311-win_arm64.whl", hash = "sha256:bdb67151ea81fcf02d8f494703fb728d4d34d24556cbff5f417d74f6f5792e7c", size = 229157, upload-time = "2025-11-16T14:48:17.891Z" },
+    { url = "https://files.pythonhosted.org/packages/3c/50/bc0e6e736d94e420df79be4deb5c9476b63165c87bb8f19ef75d100d21b3/rpds_py-0.29.0-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:a0891cfd8db43e085c0ab93ab7e9b0c8fee84780d436d3b266b113e51e79f954", size = 376000, upload-time = "2025-11-16T14:48:19.141Z" },
+    { url = "https://files.pythonhosted.org/packages/3e/3a/46676277160f014ae95f24de53bed0e3b7ea66c235e7de0b9df7bd5d68ba/rpds_py-0.29.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:3897924d3f9a0361472d884051f9a2460358f9a45b1d85a39a158d2f8f1ad71c", size = 360575, upload-time = "2025-11-16T14:48:20.443Z" },
+    { url = "https://files.pythonhosted.org/packages/75/ba/411d414ed99ea1afdd185bbabeeaac00624bd1e4b22840b5e9967ade6337/rpds_py-0.29.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2a21deb8e0d1571508c6491ce5ea5e25669b1dd4adf1c9d64b6314842f708b5d", size = 392159, upload-time = "2025-11-16T14:48:22.12Z" },
+    { url = "https://files.pythonhosted.org/packages/8f/b1/e18aa3a331f705467a48d0296778dc1fea9d7f6cf675bd261f9a846c7e90/rpds_py-0.29.0-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:9efe71687d6427737a0a2de9ca1c0a216510e6cd08925c44162be23ed7bed2d5", size = 410602, upload-time = "2025-11-16T14:48:23.563Z" },
+    { url = "https://files.pythonhosted.org/packages/2f/6c/04f27f0c9f2299274c76612ac9d2c36c5048bb2c6c2e52c38c60bf3868d9/rpds_py-0.29.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:40f65470919dc189c833e86b2c4bd21bd355f98436a2cef9e0a9a92aebc8e57e", size = 515808, upload-time = "2025-11-16T14:48:24.949Z" },
+    { url = "https://files.pythonhosted.org/packages/83/56/a8412aa464fb151f8bc0d91fb0bb888adc9039bd41c1c6ba8d94990d8cf8/rpds_py-0.29.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:def48ff59f181130f1a2cb7c517d16328efac3ec03951cca40c1dc2049747e83", size = 416015, upload-time = "2025-11-16T14:48:26.782Z" },
+    { url = "https://files.pythonhosted.org/packages/04/4c/f9b8a05faca3d9e0a6397c90d13acb9307c9792b2bff621430c58b1d6e76/rpds_py-0.29.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ad7bd570be92695d89285a4b373006930715b78d96449f686af422debb4d3949", size = 395325, upload-time = "2025-11-16T14:48:28.055Z" },
+    { url = "https://files.pythonhosted.org/packages/34/60/869f3bfbf8ed7b54f1ad9a5543e0fdffdd40b5a8f587fe300ee7b4f19340/rpds_py-0.29.0-cp312-cp312-manylinux_2_31_riscv64.whl", hash = "sha256:5a572911cd053137bbff8e3a52d31c5d2dba51d3a67ad902629c70185f3f2181", size = 410160, upload-time = "2025-11-16T14:48:29.338Z" },
+    { url = "https://files.pythonhosted.org/packages/91/aa/e5b496334e3aba4fe4c8a80187b89f3c1294c5c36f2a926da74338fa5a73/rpds_py-0.29.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d583d4403bcbf10cffc3ab5cee23d7643fcc960dff85973fd3c2d6c86e8dbb0c", size = 425309, upload-time = "2025-11-16T14:48:30.691Z" },
+    { url = "https://files.pythonhosted.org/packages/85/68/4e24a34189751ceb6d66b28f18159922828dd84155876551f7ca5b25f14f/rpds_py-0.29.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:070befbb868f257d24c3bb350dbd6e2f645e83731f31264b19d7231dd5c396c7", size = 574644, upload-time = "2025-11-16T14:48:31.964Z" },
+    { url = "https://files.pythonhosted.org/packages/8c/cf/474a005ea4ea9c3b4f17b6108b6b13cebfc98ebaff11d6e1b193204b3a93/rpds_py-0.29.0-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:fc935f6b20b0c9f919a8ff024739174522abd331978f750a74bb68abd117bd19", size = 601605, upload-time = "2025-11-16T14:48:33.252Z" },
+    { url = "https://files.pythonhosted.org/packages/f4/b1/c56f6a9ab8c5f6bb5c65c4b5f8229167a3a525245b0773f2c0896686b64e/rpds_py-0.29.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:8c5a8ecaa44ce2d8d9d20a68a2483a74c07f05d72e94a4dff88906c8807e77b0", size = 564593, upload-time = "2025-11-16T14:48:34.643Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/13/0494cecce4848f68501e0a229432620b4b57022388b071eeff95f3e1e75b/rpds_py-0.29.0-cp312-cp312-win32.whl", hash = "sha256:ba5e1aeaf8dd6d8f6caba1f5539cddda87d511331714b7b5fc908b6cfc3636b7", size = 223853, upload-time = "2025-11-16T14:48:36.419Z" },
+    { url = "https://files.pythonhosted.org/packages/1f/6a/51e9aeb444a00cdc520b032a28b07e5f8dc7bc328b57760c53e7f96997b4/rpds_py-0.29.0-cp312-cp312-win_amd64.whl", hash = "sha256:b5f6134faf54b3cb83375db0f113506f8b7770785be1f95a631e7e2892101977", size = 239895, upload-time = "2025-11-16T14:48:37.956Z" },
+    { url = "https://files.pythonhosted.org/packages/d1/d4/8bce56cdad1ab873e3f27cb31c6a51d8f384d66b022b820525b879f8bed1/rpds_py-0.29.0-cp312-cp312-win_arm64.whl", hash = "sha256:b016eddf00dca7944721bf0cd85b6af7f6c4efaf83ee0b37c4133bd39757a8c7", size = 230321, upload-time = "2025-11-16T14:48:39.71Z" },
+    { url = "https://files.pythonhosted.org/packages/fd/d9/c5de60d9d371bbb186c3e9bf75f4fc5665e11117a25a06a6b2e0afb7380e/rpds_py-0.29.0-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:1585648d0760b88292eecab5181f5651111a69d90eff35d6b78aa32998886a61", size = 375710, upload-time = "2025-11-16T14:48:41.063Z" },
+    { url = "https://files.pythonhosted.org/packages/b3/b3/0860cdd012291dc21272895ce107f1e98e335509ba986dd83d72658b82b9/rpds_py-0.29.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:521807963971a23996ddaf764c682b3e46459b3c58ccd79fefbe16718db43154", size = 360582, upload-time = "2025-11-16T14:48:42.423Z" },
+    { url = "https://files.pythonhosted.org/packages/92/8a/a18c2f4a61b3407e56175f6aab6deacdf9d360191a3d6f38566e1eaf7266/rpds_py-0.29.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0a8896986efaa243ab713c69e6491a4138410f0fe36f2f4c71e18bd5501e8014", size = 391172, upload-time = "2025-11-16T14:48:43.75Z" },
+    { url = "https://files.pythonhosted.org/packages/fd/49/e93354258508c50abc15cdcd5fcf7ac4117f67bb6233ad7859f75e7372a0/rpds_py-0.29.0-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:1d24564a700ef41480a984c5ebed62b74e6ce5860429b98b1fede76049e953e6", size = 409586, upload-time = "2025-11-16T14:48:45.498Z" },
+    { url = "https://files.pythonhosted.org/packages/5a/8d/a27860dae1c19a6bdc901f90c81f0d581df1943355802961a57cdb5b6cd1/rpds_py-0.29.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e6596b93c010d386ae46c9fba9bfc9fc5965fa8228edeac51576299182c2e31c", size = 516339, upload-time = "2025-11-16T14:48:47.308Z" },
+    { url = "https://files.pythonhosted.org/packages/fc/ad/a75e603161e79b7110c647163d130872b271c6b28712c803c65d492100f7/rpds_py-0.29.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5cc58aac218826d054c7da7f95821eba94125d88be673ff44267bb89d12a5866", size = 416201, upload-time = "2025-11-16T14:48:48.615Z" },
+    { url = "https://files.pythonhosted.org/packages/b9/42/555b4ee17508beafac135c8b450816ace5a96194ce97fefc49d58e5652ea/rpds_py-0.29.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:de73e40ebc04dd5d9556f50180395322193a78ec247e637e741c1b954810f295", size = 395095, upload-time = "2025-11-16T14:48:50.027Z" },
+    { url = "https://files.pythonhosted.org/packages/cd/f0/c90b671b9031e800ec45112be42ea9f027f94f9ac25faaac8770596a16a1/rpds_py-0.29.0-cp313-cp313-manylinux_2_31_riscv64.whl", hash = "sha256:295ce5ac7f0cf69a651ea75c8f76d02a31f98e5698e82a50a5f4d4982fbbae3b", size = 410077, upload-time = "2025-11-16T14:48:51.515Z" },
+    { url = "https://files.pythonhosted.org/packages/3d/80/9af8b640b81fe21e6f718e9dec36c0b5f670332747243130a5490f292245/rpds_py-0.29.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:1ea59b23ea931d494459c8338056fe7d93458c0bf3ecc061cd03916505369d55", size = 424548, upload-time = "2025-11-16T14:48:53.237Z" },
+    { url = "https://files.pythonhosted.org/packages/e4/0b/b5647446e991736e6a495ef510e6710df91e880575a586e763baeb0aa770/rpds_py-0.29.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:f49d41559cebd608042fdcf54ba597a4a7555b49ad5c1c0c03e0af82692661cd", size = 573661, upload-time = "2025-11-16T14:48:54.769Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/b3/1b1c9576839ff583d1428efbf59f9ee70498d8ce6c0b328ac02f1e470879/rpds_py-0.29.0-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:05a2bd42768ea988294ca328206efbcc66e220d2d9b7836ee5712c07ad6340ea", size = 600937, upload-time = "2025-11-16T14:48:56.247Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/7b/b6cfca2f9fee4c4494ce54f7fb1b9f578867495a9aa9fc0d44f5f735c8e0/rpds_py-0.29.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:33ca7bdfedd83339ca55da3a5e1527ee5870d4b8369456b5777b197756f3ca22", size = 564496, upload-time = "2025-11-16T14:48:57.691Z" },
+    { url = "https://files.pythonhosted.org/packages/b9/fb/ba29ec7f0f06eb801bac5a23057a9ff7670623b5e8013bd59bec4aa09de8/rpds_py-0.29.0-cp313-cp313-win32.whl", hash = "sha256:20c51ae86a0bb9accc9ad4e6cdeec58d5ebb7f1b09dd4466331fc65e1766aae7", size = 223126, upload-time = "2025-11-16T14:48:59.058Z" },
+    { url = "https://files.pythonhosted.org/packages/3c/6b/0229d3bed4ddaa409e6d90b0ae967ed4380e4bdd0dad6e59b92c17d42457/rpds_py-0.29.0-cp313-cp313-win_amd64.whl", hash = "sha256:6410e66f02803600edb0b1889541f4b5cc298a5ccda0ad789cc50ef23b54813e", size = 239771, upload-time = "2025-11-16T14:49:00.872Z" },
+    { url = "https://files.pythonhosted.org/packages/e4/38/d2868f058b164f8efd89754d85d7b1c08b454f5c07ac2e6cc2e9bd4bd05b/rpds_py-0.29.0-cp313-cp313-win_arm64.whl", hash = "sha256:56838e1cd9174dc23c5691ee29f1d1be9eab357f27efef6bded1328b23e1ced2", size = 229994, upload-time = "2025-11-16T14:49:02.673Z" },
+    { url = "https://files.pythonhosted.org/packages/52/91/5de91c5ec7d41759beec9b251630824dbb8e32d20c3756da1a9a9d309709/rpds_py-0.29.0-cp313-cp313t-macosx_10_12_x86_64.whl", hash = "sha256:37d94eadf764d16b9a04307f2ab1d7af6dc28774bbe0535c9323101e14877b4c", size = 365886, upload-time = "2025-11-16T14:49:04.133Z" },
+    { url = "https://files.pythonhosted.org/packages/85/7c/415d8c1b016d5f47ecec5145d9d6d21002d39dce8761b30f6c88810b455a/rpds_py-0.29.0-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:d472cf73efe5726a067dce63eebe8215b14beabea7c12606fd9994267b3cfe2b", size = 355262, upload-time = "2025-11-16T14:49:05.543Z" },
+    { url = "https://files.pythonhosted.org/packages/3d/14/bf83e2daa4f980e4dc848aed9299792a8b84af95e12541d9e7562f84a6ef/rpds_py-0.29.0-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:72fdfd5ff8992e4636621826371e3ac5f3e3b8323e9d0e48378e9c13c3dac9d0", size = 384826, upload-time = "2025-11-16T14:49:07.301Z" },
+    { url = "https://files.pythonhosted.org/packages/33/b8/53330c50a810ae22b4fbba5e6cf961b68b9d72d9bd6780a7c0a79b070857/rpds_py-0.29.0-cp313-cp313t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:2549d833abdf8275c901313b9e8ff8fba57e50f6a495035a2a4e30621a2f7cc4", size = 394234, upload-time = "2025-11-16T14:49:08.782Z" },
+    { url = "https://files.pythonhosted.org/packages/cc/32/01e2e9645cef0e584f518cfde4567563e57db2257244632b603f61b40e50/rpds_py-0.29.0-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4448dad428f28a6a767c3e3b80cde3446a22a0efbddaa2360f4bb4dc836d0688", size = 520008, upload-time = "2025-11-16T14:49:10.253Z" },
+    { url = "https://files.pythonhosted.org/packages/98/c3/0d1b95a81affae2b10f950782e33a1fd2edd6ce2a479966cac98c9a66f57/rpds_py-0.29.0-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:115f48170fd4296a33938d8c11f697f5f26e0472e43d28f35624764173a60e4d", size = 409569, upload-time = "2025-11-16T14:49:12.478Z" },
+    { url = "https://files.pythonhosted.org/packages/fa/60/aa3b8678f3f009f675b99174fa2754302a7fbfe749162e8043d111de2d88/rpds_py-0.29.0-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8e5bb73ffc029820f4348e9b66b3027493ae00bca6629129cd433fd7a76308ee", size = 385188, upload-time = "2025-11-16T14:49:13.88Z" },
+    { url = "https://files.pythonhosted.org/packages/92/02/5546c1c8aa89c18d40c1fcffdcc957ba730dee53fb7c3ca3a46f114761d2/rpds_py-0.29.0-cp313-cp313t-manylinux_2_31_riscv64.whl", hash = "sha256:b1581fcde18fcdf42ea2403a16a6b646f8eb1e58d7f90a0ce693da441f76942e", size = 398587, upload-time = "2025-11-16T14:49:15.339Z" },
+    { url = "https://files.pythonhosted.org/packages/6c/e0/ad6eeaf47e236eba052fa34c4073078b9e092bd44da6bbb35aaae9580669/rpds_py-0.29.0-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:16e9da2bda9eb17ea318b4c335ec9ac1818e88922cbe03a5743ea0da9ecf74fb", size = 416641, upload-time = "2025-11-16T14:49:16.832Z" },
+    { url = "https://files.pythonhosted.org/packages/1a/93/0acedfd50ad9cdd3879c615a6dc8c5f1ce78d2fdf8b87727468bb5bb4077/rpds_py-0.29.0-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:28fd300326dd21198f311534bdb6d7e989dd09b3418b3a91d54a0f384c700967", size = 566683, upload-time = "2025-11-16T14:49:18.342Z" },
+    { url = "https://files.pythonhosted.org/packages/62/53/8c64e0f340a9e801459fc6456821abc15b3582cb5dc3932d48705a9d9ac7/rpds_py-0.29.0-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:2aba991e041d031c7939e1358f583ae405a7bf04804ca806b97a5c0e0af1ea5e", size = 592730, upload-time = "2025-11-16T14:49:19.767Z" },
+    { url = "https://files.pythonhosted.org/packages/85/ef/3109b6584f8c4b0d2490747c916df833c127ecfa82be04d9a40a376f2090/rpds_py-0.29.0-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:7f437026dbbc3f08c99cc41a5b2570c6e1a1ddbe48ab19a9b814254128d4ea7a", size = 557361, upload-time = "2025-11-16T14:49:21.574Z" },
+    { url = "https://files.pythonhosted.org/packages/ff/3b/61586475e82d57f01da2c16edb9115a618afe00ce86fe1b58936880b15af/rpds_py-0.29.0-cp313-cp313t-win32.whl", hash = "sha256:6e97846e9800a5d0fe7be4d008f0c93d0feeb2700da7b1f7528dabafb31dfadb", size = 211227, upload-time = "2025-11-16T14:49:23.03Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/3a/12dc43f13594a54ea0c9d7e9d43002116557330e3ad45bc56097ddf266e2/rpds_py-0.29.0-cp313-cp313t-win_amd64.whl", hash = "sha256:f49196aec7c4b406495f60e6f947ad71f317a765f956d74bbd83996b9edc0352", size = 225248, upload-time = "2025-11-16T14:49:24.841Z" },
+    { url = "https://files.pythonhosted.org/packages/89/b1/0b1474e7899371d9540d3bbb2a499a3427ae1fc39c998563fe9035a1073b/rpds_py-0.29.0-cp314-cp314-macosx_10_12_x86_64.whl", hash = "sha256:394d27e4453d3b4d82bb85665dc1fcf4b0badc30fc84282defed71643b50e1a1", size = 363731, upload-time = "2025-11-16T14:49:26.683Z" },
+    { url = "https://files.pythonhosted.org/packages/28/12/3b7cf2068d0a334ed1d7b385a9c3c8509f4c2bcba3d4648ea71369de0881/rpds_py-0.29.0-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:55d827b2ae95425d3be9bc9a5838b6c29d664924f98146557f7715e331d06df8", size = 354343, upload-time = "2025-11-16T14:49:28.24Z" },
+    { url = "https://files.pythonhosted.org/packages/eb/73/5afcf8924bc02a749416eda64e17ac9c9b28f825f4737385295a0e99b0c1/rpds_py-0.29.0-cp314-cp314-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fc31a07ed352e5462d3ee1b22e89285f4ce97d5266f6d1169da1142e78045626", size = 385406, upload-time = "2025-11-16T14:49:29.943Z" },
+    { url = "https://files.pythonhosted.org/packages/c8/37/5db736730662508535221737a21563591b6f43c77f2e388951c42f143242/rpds_py-0.29.0-cp314-cp314-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:c4695dd224212f6105db7ea62197144230b808d6b2bba52238906a2762f1d1e7", size = 396162, upload-time = "2025-11-16T14:49:31.833Z" },
+    { url = "https://files.pythonhosted.org/packages/70/0d/491c1017d14f62ce7bac07c32768d209a50ec567d76d9f383b4cfad19b80/rpds_py-0.29.0-cp314-cp314-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:fcae1770b401167f8b9e1e3f566562e6966ffa9ce63639916248a9e25fa8a244", size = 517719, upload-time = "2025-11-16T14:49:33.804Z" },
+    { url = "https://files.pythonhosted.org/packages/d7/25/b11132afcb17cd5d82db173f0c8dab270ffdfaba43e5ce7a591837ae9649/rpds_py-0.29.0-cp314-cp314-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:90f30d15f45048448b8da21c41703b31c61119c06c216a1bf8c245812a0f0c17", size = 409498, upload-time = "2025-11-16T14:49:35.222Z" },
+    { url = "https://files.pythonhosted.org/packages/0f/7d/e6543cedfb2e6403a1845710a5ab0e0ccf8fc288e0b5af9a70bfe2c12053/rpds_py-0.29.0-cp314-cp314-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:44a91e0ab77bdc0004b43261a4b8cd6d6b451e8d443754cfda830002b5745b32", size = 382743, upload-time = "2025-11-16T14:49:36.704Z" },
+    { url = "https://files.pythonhosted.org/packages/75/11/a4ebc9f654293ae9fefb83b2b6be7f3253e85ea42a5db2f77d50ad19aaeb/rpds_py-0.29.0-cp314-cp314-manylinux_2_31_riscv64.whl", hash = "sha256:4aa195e5804d32c682e453b34474f411ca108e4291c6a0f824ebdc30a91c973c", size = 400317, upload-time = "2025-11-16T14:49:39.132Z" },
+    { url = "https://files.pythonhosted.org/packages/52/18/97677a60a81c7f0e5f64e51fb3f8271c5c8fcabf3a2df18e97af53d7c2bf/rpds_py-0.29.0-cp314-cp314-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:7971bdb7bf4ee0f7e6f67fa4c7fbc6019d9850cc977d126904392d363f6f8318", size = 416979, upload-time = "2025-11-16T14:49:40.575Z" },
+    { url = "https://files.pythonhosted.org/packages/f0/69/28ab391a9968f6c746b2a2db181eaa4d16afaa859fedc9c2f682d19f7e18/rpds_py-0.29.0-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:8ae33ad9ce580c7a47452c3b3f7d8a9095ef6208e0a0c7e4e2384f9fc5bf8212", size = 567288, upload-time = "2025-11-16T14:49:42.24Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/d3/0c7afdcdb830eee94f5611b64e71354ffe6ac8df82d00c2faf2bfffd1d4e/rpds_py-0.29.0-cp314-cp314-musllinux_1_2_i686.whl", hash = "sha256:c661132ab2fb4eeede2ef69670fd60da5235209874d001a98f1542f31f2a8a94", size = 593157, upload-time = "2025-11-16T14:49:43.782Z" },
+    { url = "https://files.pythonhosted.org/packages/e2/ac/a0fcbc2feed4241cf26d32268c195eb88ddd4bd862adfc9d4b25edfba535/rpds_py-0.29.0-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:bb78b3a0d31ac1bde132c67015a809948db751cb4e92cdb3f0b242e430b6ed0d", size = 554741, upload-time = "2025-11-16T14:49:45.557Z" },
+    { url = "https://files.pythonhosted.org/packages/0f/f1/fcc24137c470df8588674a677f33719d5800ec053aaacd1de8a5d5d84d9e/rpds_py-0.29.0-cp314-cp314-win32.whl", hash = "sha256:f475f103488312e9bd4000bc890a95955a07b2d0b6e8884aef4be56132adbbf1", size = 215508, upload-time = "2025-11-16T14:49:47.562Z" },
+    { url = "https://files.pythonhosted.org/packages/7b/c7/1d169b2045512eac019918fc1021ea07c30e84a4343f9f344e3e0aa8c788/rpds_py-0.29.0-cp314-cp314-win_amd64.whl", hash = "sha256:b9cf2359a4fca87cfb6801fae83a76aedf66ee1254a7a151f1341632acf67f1b", size = 228125, upload-time = "2025-11-16T14:49:49.064Z" },
+    { url = "https://files.pythonhosted.org/packages/be/36/0cec88aaba70ec4a6e381c444b0d916738497d27f0c30406e3d9fcbd3bc2/rpds_py-0.29.0-cp314-cp314-win_arm64.whl", hash = "sha256:9ba8028597e824854f0f1733d8b964e914ae3003b22a10c2c664cb6927e0feb9", size = 221992, upload-time = "2025-11-16T14:49:50.777Z" },
+    { url = "https://files.pythonhosted.org/packages/b1/fa/a2e524631717c9c0eb5d90d30f648cfba6b731047821c994acacb618406c/rpds_py-0.29.0-cp314-cp314t-macosx_10_12_x86_64.whl", hash = "sha256:e71136fd0612556b35c575dc2726ae04a1669e6a6c378f2240312cf5d1a2ab10", size = 366425, upload-time = "2025-11-16T14:49:52.691Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/a4/6d43ebe0746ff694a30233f63f454aed1677bd50ab7a59ff6b2bb5ac61f2/rpds_py-0.29.0-cp314-cp314t-macosx_11_0_arm64.whl", hash = "sha256:76fe96632d53f3bf0ea31ede2f53bbe3540cc2736d4aec3b3801b0458499ef3a", size = 355282, upload-time = "2025-11-16T14:49:54.292Z" },
+    { url = "https://files.pythonhosted.org/packages/fa/a7/52fd8270e0320b09eaf295766ae81dd175f65394687906709b3e75c71d06/rpds_py-0.29.0-cp314-cp314t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9459a33f077130dbb2c7c3cea72ee9932271fb3126404ba2a2661e4fe9eb7b79", size = 384968, upload-time = "2025-11-16T14:49:55.857Z" },
+    { url = "https://files.pythonhosted.org/packages/f4/7d/e6bc526b7a14e1ef80579a52c1d4ad39260a058a51d66c6039035d14db9d/rpds_py-0.29.0-cp314-cp314t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:5c9546cfdd5d45e562cc0444b6dddc191e625c62e866bf567a2c69487c7ad28a", size = 394714, upload-time = "2025-11-16T14:49:57.343Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/3f/f0ade3954e7db95c791e7eaf978aa7e08a756d2046e8bdd04d08146ed188/rpds_py-0.29.0-cp314-cp314t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:12597d11d97b8f7e376c88929a6e17acb980e234547c92992f9f7c058f1a7310", size = 520136, upload-time = "2025-11-16T14:49:59.162Z" },
+    { url = "https://files.pythonhosted.org/packages/87/b3/07122ead1b97009715ab9d4082be6d9bd9546099b2b03fae37c3116f72be/rpds_py-0.29.0-cp314-cp314t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:28de03cf48b8a9e6ec10318f2197b83946ed91e2891f651a109611be4106ac4b", size = 409250, upload-time = "2025-11-16T14:50:00.698Z" },
+    { url = "https://files.pythonhosted.org/packages/c9/c6/dcbee61fd1dc892aedcb1b489ba661313101aa82ec84b1a015d4c63ebfda/rpds_py-0.29.0-cp314-cp314t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fd7951c964069039acc9d67a8ff1f0a7f34845ae180ca542b17dc1456b1f1808", size = 384940, upload-time = "2025-11-16T14:50:02.312Z" },
+    { url = "https://files.pythonhosted.org/packages/47/11/914ecb6f3574cf9bf8b38aced4063e0f787d6e1eb30b181a7efbc6c1da9a/rpds_py-0.29.0-cp314-cp314t-manylinux_2_31_riscv64.whl", hash = "sha256:c07d107b7316088f1ac0177a7661ca0c6670d443f6fe72e836069025e6266761", size = 399392, upload-time = "2025-11-16T14:50:03.829Z" },
+    { url = "https://files.pythonhosted.org/packages/f5/fd/2f4bd9433f58f816434bb934313584caa47dbc6f03ce5484df8ac8980561/rpds_py-0.29.0-cp314-cp314t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:1de2345af363d25696969befc0c1688a6cb5e8b1d32b515ef84fc245c6cddba3", size = 416796, upload-time = "2025-11-16T14:50:05.558Z" },
+    { url = "https://files.pythonhosted.org/packages/79/a5/449f0281af33efa29d5c71014399d74842342ae908d8cd38260320167692/rpds_py-0.29.0-cp314-cp314t-musllinux_1_2_aarch64.whl", hash = "sha256:00e56b12d2199ca96068057e1ae7f9998ab6e99cda82431afafd32f3ec98cca9", size = 566843, upload-time = "2025-11-16T14:50:07.243Z" },
+    { url = "https://files.pythonhosted.org/packages/ab/32/0a6a1ccee2e37fcb1b7ba9afde762b77182dbb57937352a729c6cd3cf2bb/rpds_py-0.29.0-cp314-cp314t-musllinux_1_2_i686.whl", hash = "sha256:3919a3bbecee589300ed25000b6944174e07cd20db70552159207b3f4bbb45b8", size = 593956, upload-time = "2025-11-16T14:50:09.029Z" },
+    { url = "https://files.pythonhosted.org/packages/4a/3d/eb820f95dce4306f07a495ede02fb61bef36ea201d9137d4fcd5ab94ec1e/rpds_py-0.29.0-cp314-cp314t-musllinux_1_2_x86_64.whl", hash = "sha256:e7fa2ccc312bbd91e43aa5e0869e46bc03278a3dddb8d58833150a18b0f0283a", size = 557288, upload-time = "2025-11-16T14:50:10.73Z" },
+    { url = "https://files.pythonhosted.org/packages/e9/f8/b8ff786f40470462a252918e0836e0db903c28e88e3eec66bc4a7856ee5d/rpds_py-0.29.0-cp314-cp314t-win32.whl", hash = "sha256:97c817863ffc397f1e6a6e9d2d89fe5408c0a9922dac0329672fb0f35c867ea5", size = 211382, upload-time = "2025-11-16T14:50:12.827Z" },
+    { url = "https://files.pythonhosted.org/packages/c9/7f/1a65ae870bc9d0576aebb0c501ea5dccf1ae2178fe2821042150ebd2e707/rpds_py-0.29.0-cp314-cp314t-win_amd64.whl", hash = "sha256:2023473f444752f0f82a58dfcbee040d0a1b3d1b3c2ec40e884bd25db6d117d2", size = 225919, upload-time = "2025-11-16T14:50:14.734Z" },
+    { url = "https://files.pythonhosted.org/packages/f2/ac/b97e80bf107159e5b9ba9c91df1ab95f69e5e41b435f27bdd737f0d583ac/rpds_py-0.29.0-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:acd82a9e39082dc5f4492d15a6b6c8599aa21db5c35aaf7d6889aea16502c07d", size = 373963, upload-time = "2025-11-16T14:50:16.205Z" },
+    { url = "https://files.pythonhosted.org/packages/40/5a/55e72962d5d29bd912f40c594e68880d3c7a52774b0f75542775f9250712/rpds_py-0.29.0-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:715b67eac317bf1c7657508170a3e011a1ea6ccb1c9d5f296e20ba14196be6b3", size = 364644, upload-time = "2025-11-16T14:50:18.22Z" },
+    { url = "https://files.pythonhosted.org/packages/99/2a/6b6524d0191b7fc1351c3c0840baac42250515afb48ae40c7ed15499a6a2/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f3b1b87a237cb2dba4db18bcfaaa44ba4cd5936b91121b62292ff21df577fc43", size = 393847, upload-time = "2025-11-16T14:50:20.012Z" },
+    { url = "https://files.pythonhosted.org/packages/1c/b8/c5692a7df577b3c0c7faed7ac01ee3c608b81750fc5d89f84529229b6873/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:1c3c3e8101bb06e337c88eb0c0ede3187131f19d97d43ea0e1c5407ea74c0cbf", size = 407281, upload-time = "2025-11-16T14:50:21.64Z" },
+    { url = "https://files.pythonhosted.org/packages/f0/57/0546c6f84031b7ea08b76646a8e33e45607cc6bd879ff1917dc077bb881e/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:2b8e54d6e61f3ecd3abe032065ce83ea63417a24f437e4a3d73d2f85ce7b7cfe", size = 529213, upload-time = "2025-11-16T14:50:23.219Z" },
+    { url = "https://files.pythonhosted.org/packages/fa/c1/01dd5f444233605555bc11fe5fed6a5c18f379f02013870c176c8e630a23/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3fbd4e9aebf110473a420dea85a238b254cf8a15acb04b22a5a6b5ce8925b760", size = 413808, upload-time = "2025-11-16T14:50:25.262Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/0a/60f98b06156ea2a7af849fb148e00fbcfdb540909a5174a5ed10c93745c7/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:80fdf53d36e6c72819993e35d1ebeeb8e8fc688d0c6c2b391b55e335b3afba5a", size = 394600, upload-time = "2025-11-16T14:50:26.956Z" },
+    { url = "https://files.pythonhosted.org/packages/37/f1/dc9312fc9bec040ece08396429f2bd9e0977924ba7a11c5ad7056428465e/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_31_riscv64.whl", hash = "sha256:ea7173df5d86f625f8dde6d5929629ad811ed8decda3b60ae603903839ac9ac0", size = 408634, upload-time = "2025-11-16T14:50:28.989Z" },
+    { url = "https://files.pythonhosted.org/packages/ed/41/65024c9fd40c89bb7d604cf73beda4cbdbcebe92d8765345dd65855b6449/rpds_py-0.29.0-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:76054d540061eda273274f3d13a21a4abdde90e13eaefdc205db37c05230efce", size = 426064, upload-time = "2025-11-16T14:50:30.674Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/e0/cf95478881fc88ca2fdbf56381d7df36567cccc39a05394beac72182cd62/rpds_py-0.29.0-pp311-pypy311_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:9f84c549746a5be3bc7415830747a3a0312573afc9f95785eb35228bb17742ec", size = 575871, upload-time = "2025-11-16T14:50:33.428Z" },
+    { url = "https://files.pythonhosted.org/packages/ea/c0/df88097e64339a0218b57bd5f9ca49898e4c394db756c67fccc64add850a/rpds_py-0.29.0-pp311-pypy311_pp73-musllinux_1_2_i686.whl", hash = "sha256:0ea962671af5cb9a260489e311fa22b2e97103e3f9f0caaea6f81390af96a9ed", size = 601702, upload-time = "2025-11-16T14:50:36.051Z" },
+    { url = "https://files.pythonhosted.org/packages/87/f4/09ffb3ebd0cbb9e2c7c9b84d252557ecf434cd71584ee1e32f66013824df/rpds_py-0.29.0-pp311-pypy311_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:f7728653900035fb7b8d06e1e5900545d8088efc9d5d4545782da7df03ec803f", size = 564054, upload-time = "2025-11-16T14:50:37.733Z" },
+]
+
+[[package]]
+name = "rsa"
+version = "4.9.1"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "pyasn1" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/da/8a/22b7beea3ee0d44b1916c0c1cb0ee3af23b700b6da9f04991899d0c555d4/rsa-4.9.1.tar.gz", hash = "sha256:e7bdbfdb5497da4c07dfd35530e1a902659db6ff241e39d9953cad06ebd0ae75", size = 29034, upload-time = "2025-04-16T09:51:18.218Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl", hash = "sha256:68635866661c6836b8d39430f97a996acbd61bfa49406748ea243539fe239762", size = 34696, upload-time = "2025-04-16T09:51:17.142Z" },
+]
+
 [[package]]
 name = "ruff"
 version = "0.14.5"
@@ -1670,6 +3171,44 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/e5/80/69756670caedcf3b9be597a6e12276a6cf6197076eb62aad0c608f8efce0/ruff-0.14.5-py3-none-win_arm64.whl", hash = "sha256:4b700459d4649e2594b31f20a9de33bc7c19976d4746d8d0798ad959621d64a4", size = 13433331, upload-time = "2025-11-13T19:58:48.434Z" },
 ]
 
+[[package]]
+name = "secretstorage"
+version = "3.3.3"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version < '3.10'",
+]
+dependencies = [
+    { name = "cryptography", version = "46.0.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.10'" },
+    { name = "jeepney", marker = "python_full_version < '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/53/a4/f48c9d79cb507ed1373477dbceaba7401fd8a23af63b837fa61f1dcd3691/SecretStorage-3.3.3.tar.gz", hash = "sha256:2403533ef369eca6d2ba81718576c5e0f564d5cca1b58f73a8b23e7d4eeebd77", size = 19739, upload-time = "2022-08-13T16:22:46.976Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/54/24/b4293291fa1dd830f353d2cb163295742fa87f179fcc8a20a306a81978b7/SecretStorage-3.3.3-py3-none-any.whl", hash = "sha256:f356e6628222568e3af06f2eba8df495efa13b3b63081dafd4f7d9a7b7bc9f99", size = 15221, upload-time = "2022-08-13T16:22:44.457Z" },
+]
+
+[[package]]
+name = "secretstorage"
+version = "3.4.1"
+source = { registry = "https://pypi.org/simple" }
+resolution-markers = [
+    "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'",
+    "python_full_version == '3.13.*' and platform_python_implementation != 'PyPy'",
+    "python_full_version >= '3.13' and platform_python_implementation == 'PyPy'",
+    "python_full_version == '3.12.*'",
+    "python_full_version == '3.11.*'",
+    "python_full_version == '3.10.*'",
+]
+dependencies = [
+    { name = "cryptography", version = "45.0.7", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.14' and platform_python_implementation != 'PyPy'" },
+    { name = "cryptography", version = "46.0.0", source = { registry = "https://pypi.org/simple" }, marker = "(python_full_version >= '3.10' and python_full_version < '3.14') or (python_full_version >= '3.10' and platform_python_implementation == 'PyPy')" },
+    { name = "jeepney", marker = "python_full_version >= '3.10'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/32/8a/ed6747b1cc723c81f526d4c12c1b1d43d07190e1e8258dbf934392fc850e/secretstorage-3.4.1.tar.gz", hash = "sha256:a799acf5be9fb93db609ebaa4ab6e8f1f3ed5ae640e0fa732bfea59e9c3b50e8", size = 19871, upload-time = "2025-11-11T11:30:23.798Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/b0/6d/24ebb101484f1911a6be6695b76ce43219caa110ebbe07d8c3a5f3106cca/secretstorage-3.4.1-py3-none-any.whl", hash = "sha256:c55d57b4da3de568d8c3af89dad244ab24c35ca1da8625fc1b550edf005ebc41", size = 15301, upload-time = "2025-11-11T11:30:22.618Z" },
+]
+
 [[package]]
 name = "six"
 version = "1.17.0"
@@ -1679,6 +3218,41 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl", hash = "sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274", size = 11050, upload-time = "2024-12-04T17:35:26.475Z" },
 ]
 
+[[package]]
+name = "sqlalchemy"
+version = "1.4.54"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "greenlet", marker = "platform_machine == 'AMD64' or platform_machine == 'WIN32' or platform_machine == 'aarch64' or platform_machine == 'amd64' or platform_machine == 'ppc64le' or platform_machine == 'win32' or platform_machine == 'x86_64'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/ce/af/20290b55d469e873cba9d41c0206ab5461ff49d759989b3fe65010f9d265/sqlalchemy-1.4.54.tar.gz", hash = "sha256:4470fbed088c35dc20b78a39aaf4ae54fe81790c783b3264872a0224f437c31a", size = 8470350, upload-time = "2024-09-05T15:54:10.398Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/ef/7f/f7c1e0b65790649bd573f201aa958263a389f336d6e000a569275ff9bd97/SQLAlchemy-1.4.54-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:af00236fe21c4d4f4c227b6ccc19b44c594160cc3ff28d104cdce85855369277", size = 1573472, upload-time = "2024-09-05T17:38:45.351Z" },
+    { url = "https://files.pythonhosted.org/packages/e1/da/ff7f0fe50844496db523613979651f076f44da8625b8ad89c503dcff0a52/SQLAlchemy-1.4.54-cp310-cp310-manylinux1_x86_64.manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_5_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1183599e25fa38a1a322294b949da02b4f0da13dbc2688ef9dbe746df573f8a6", size = 1639088, upload-time = "2024-09-05T17:46:37.726Z" },
+    { url = "https://files.pythonhosted.org/packages/04/45/3a35bb156aa2fd87b66a4992bb8d65593efd7e16ca2e0597e68c32c29037/SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1990d5a6a5dc358a0894c8ca02043fb9a5ad9538422001fb2826e91c50f1d539", size = 1627447, upload-time = "2024-09-05T17:45:32.379Z" },
+    { url = "https://files.pythonhosted.org/packages/fe/5b/ed36a50e7147d0d090cd8e35de3b18d2c69a3e85df3be5fe42a570d6c331/SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:14b3f4783275339170984cadda66e3ec011cce87b405968dc8d51cf0f9997b0d", size = 1639081, upload-time = "2024-09-05T17:46:39.895Z" },
+    { url = "https://files.pythonhosted.org/packages/4b/75/bfbdeb5dece7bc98acb414751a62ee43398b34b10133b1853f4282597757/SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6b24364150738ce488333b3fb48bfa14c189a66de41cd632796fbcacb26b4585", size = 1638975, upload-time = "2024-09-05T17:46:41.569Z" },
+    { url = "https://files.pythonhosted.org/packages/f7/62/358a9291d2fc3d51ad50557e126ad5f48200f199878437f7cb38817d607b/SQLAlchemy-1.4.54-cp310-cp310-win32.whl", hash = "sha256:a8a72259a1652f192c68377be7011eac3c463e9892ef2948828c7d58e4829988", size = 1591719, upload-time = "2024-09-05T17:52:26.646Z" },
+    { url = "https://files.pythonhosted.org/packages/10/ad/87cd5578efdcef43a08ce4a21448192abf46bf69a5678ac0039e44364914/SQLAlchemy-1.4.54-cp310-cp310-win_amd64.whl", hash = "sha256:b67589f7955924865344e6eacfdcf70675e64f36800a576aa5e961f0008cde2a", size = 1593512, upload-time = "2024-09-05T17:51:21.402Z" },
+    { url = "https://files.pythonhosted.org/packages/da/49/fb98983b5568e93696a25fd5bec1b789095b79a72d5f57c6effddaa81d0a/SQLAlchemy-1.4.54-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:b05e0626ec1c391432eabb47a8abd3bf199fb74bfde7cc44a26d2b1b352c2c6e", size = 1589301, upload-time = "2024-09-05T19:22:42.197Z" },
+    { url = "https://files.pythonhosted.org/packages/03/98/5a81430bbd646991346cb088a2bdc84d1bcd3dbe6b0cfc1aaa898370e5c7/SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:13e91d6892b5fcb94a36ba061fb7a1f03d0185ed9d8a77c84ba389e5bb05e936", size = 1629553, upload-time = "2024-09-05T17:49:18.846Z" },
+    { url = "https://files.pythonhosted.org/packages/f1/17/14e35db2b0d6deaa27691d014addbb0dd6f7e044f7ee465446a3c0c71404/SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fb59a11689ff3c58e7652260127f9e34f7f45478a2f3ef831ab6db7bcd72108f", size = 1627640, upload-time = "2024-09-05T17:48:01.558Z" },
+    { url = "https://files.pythonhosted.org/packages/98/62/335006a8f2c98f704f391e1a0cc01446d1b1b9c198f579f03599f55bd860/SQLAlchemy-1.4.54-cp311-cp311-win32.whl", hash = "sha256:1390ca2d301a2708fd4425c6d75528d22f26b8f5cbc9faba1ddca136671432bc", size = 1591723, upload-time = "2024-09-05T17:53:17.486Z" },
+    { url = "https://files.pythonhosted.org/packages/e2/a1/6b4b8c07082920f5445ec65c221fa33baab102aced5dcc2d87a15d3f8db4/SQLAlchemy-1.4.54-cp311-cp311-win_amd64.whl", hash = "sha256:2b37931eac4b837c45e2522066bda221ac6d80e78922fb77c75eb12e4dbcdee5", size = 1593511, upload-time = "2024-09-05T17:51:50.947Z" },
+    { url = "https://files.pythonhosted.org/packages/a5/1b/aa9b99be95d1615f058b5827447c18505b7b3f1dfcbd6ce1b331c2107152/SQLAlchemy-1.4.54-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:3f01c2629a7d6b30d8afe0326b8c649b74825a0e1ebdcb01e8ffd1c920deb07d", size = 1589983, upload-time = "2024-09-05T17:39:02.132Z" },
+    { url = "https://files.pythonhosted.org/packages/59/47/cb0fc64e5344f0a3d02216796c342525ab283f8f052d1c31a1d487d08aa0/SQLAlchemy-1.4.54-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9c24dd161c06992ed16c5e528a75878edbaeced5660c3db88c820f1f0d3fe1f4", size = 1630158, upload-time = "2024-09-05T17:50:13.255Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/8b/f45dd378f6c97e8ff9332ff3d03ecb0b8c491be5bb7a698783b5a2f358ec/SQLAlchemy-1.4.54-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b5e0d47d619c739bdc636bbe007da4519fc953393304a5943e0b5aec96c9877c", size = 1629232, upload-time = "2024-09-05T17:48:15.514Z" },
+    { url = "https://files.pythonhosted.org/packages/0d/3c/884fe389f5bec86a310b81e79abaa1e26e5d78dc10a84d544a6822833e47/SQLAlchemy-1.4.54-cp312-cp312-win32.whl", hash = "sha256:12bc0141b245918b80d9d17eca94663dbd3f5266ac77a0be60750f36102bbb0f", size = 1592027, upload-time = "2024-09-05T17:54:02.253Z" },
+    { url = "https://files.pythonhosted.org/packages/01/c3/c690d037be57efd3a69cde16a2ef1bd2a905dafe869434d33836de0983d0/SQLAlchemy-1.4.54-cp312-cp312-win_amd64.whl", hash = "sha256:f941aaf15f47f316123e1933f9ea91a6efda73a161a6ab6046d1cde37be62c88", size = 1593827, upload-time = "2024-09-05T17:52:07.454Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/2c/d29f176e46fb81cdacc30e1cd60bbd2f56e97ce533a603a86fb5755a2812/SQLAlchemy-1.4.54-cp39-cp39-macosx_12_0_x86_64.whl", hash = "sha256:0b76bbb1cbae618d10679be8966f6d66c94f301cfc15cb49e2f2382563fb6efb", size = 1573472, upload-time = "2024-09-05T17:51:09.23Z" },
+    { url = "https://files.pythonhosted.org/packages/66/7c/6c7bae8e5a6ecd4d3cc34a2a5929c0599b954cd00877a50772fa42304d78/SQLAlchemy-1.4.54-cp39-cp39-manylinux1_x86_64.manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_5_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cdb2886c0be2c6c54d0651d5a61c29ef347e8eec81fd83afebbf7b59b80b7393", size = 1638334, upload-time = "2024-09-05T17:50:23.159Z" },
+    { url = "https://files.pythonhosted.org/packages/9f/84/719fa1c53f044aede7d20c5a0859f8302eadbf1777b054ebc8c46b46bf19/SQLAlchemy-1.4.54-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:954816850777ac234a4e32b8c88ac1f7847088a6e90cfb8f0e127a1bf3feddff", size = 1626761, upload-time = "2024-09-05T17:55:54.312Z" },
+    { url = "https://files.pythonhosted.org/packages/c4/89/7d0ab875d2e6f931617d4a8fff63436b2d05205f15de06ef29f6627759a1/SQLAlchemy-1.4.54-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:1d83cd1cc03c22d922ec94d0d5f7b7c96b1332f5e122e81b1a61fb22da77879a", size = 1638328, upload-time = "2024-09-05T17:50:24.642Z" },
+    { url = "https://files.pythonhosted.org/packages/4f/39/0c9186e581f07c2d58ab713490ab242920700ef162453cf6f0719c1661fe/SQLAlchemy-1.4.54-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1576fba3616f79496e2f067262200dbf4aab1bb727cd7e4e006076686413c80c", size = 1638219, upload-time = "2024-09-05T17:50:26.291Z" },
+    { url = "https://files.pythonhosted.org/packages/3a/8b/4676c988e933dccc7f26a8222ad08ccf4cf1697bd2464cdde05f6bf07eb2/SQLAlchemy-1.4.54-cp39-cp39-win32.whl", hash = "sha256:3112de9e11ff1957148c6de1df2bc5cc1440ee36783412e5eedc6f53638a577d", size = 1591716, upload-time = "2024-09-05T17:55:35.398Z" },
+    { url = "https://files.pythonhosted.org/packages/68/24/70f788b22d0799e0a8b4e952d42629e48beca0e5fb30688b9a431b2c4058/SQLAlchemy-1.4.54-cp39-cp39-win_amd64.whl", hash = "sha256:6da60fb24577f989535b8fc8b2ddc4212204aaf02e53c4c7ac94ac364150ed08", size = 1593546, upload-time = "2024-09-05T17:54:59.621Z" },
+]
+
 [[package]]
 name = "sqlfluff"
 version = "3.5.0"
@@ -1706,6 +3280,24 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/47/d5/83c3eacdd6c3249fb5f8a0b5612ab10b661862e0df869951f45fd837448d/sqlfluff-3.5.0-py3-none-any.whl", hash = "sha256:6e5fb7a0c491676ded68912245fc0627e88f8b0e6290bd4b54a65ce735f69716", size = 921597, upload-time = "2025-10-18T19:33:05.839Z" },
 ]
 
+[[package]]
+name = "sqlparams"
+version = "6.2.0"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/76/ec/5d6a5ca217ecd7b08d404b7dc2025c752bdb393c9b34fcc6d48e1f70bb7e/sqlparams-6.2.0.tar.gz", hash = "sha256:3744a2ad16f71293db6505b21fd5229b4757489a9b09f3553656a1ae97ba7ca5", size = 34932, upload-time = "2025-01-25T16:21:59.646Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/97/e2/f1355629bb1eeb274babc947e2ba4e2e49250e934c86adcce3e54943bc8a/sqlparams-6.2.0-py3-none-any.whl", hash = "sha256:63b32ed9051bdc52e7e8b38bc4f78aed51796cdd9135e730f4c6a7db1048dedf", size = 17629, upload-time = "2025-01-25T16:21:58.272Z" },
+]
+
+[[package]]
+name = "sqlparse"
+version = "0.5.3"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/e5/40/edede8dd6977b0d3da179a342c198ed100dd2aba4be081861ee5911e4da4/sqlparse-0.5.3.tar.gz", hash = "sha256:09f67787f56a0b16ecdbde1bfc7f5d9c3371ca683cfeaa8e6ff60b4807ec9272", size = 84999, upload-time = "2024-12-10T12:05:30.728Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a9/5c/bfd6bd0bf979426d405cc6e71eceb8701b148b16c21d2dc3c261efc61c7b/sqlparse-0.5.3-py3-none-any.whl", hash = "sha256:cf2196ed3418f3ba5de6af7e82c694a9fbdbfecccdfc72e281548517081f16ca", size = 44415, upload-time = "2024-12-10T12:05:27.824Z" },
+]
+
 [[package]]
 name = "stack-data"
 version = "0.6.3"
@@ -1729,6 +3321,24 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/02/be/5d2d47b1fb58943194fb59dcf222f7c4e35122ec0ffe8c36e18b5d728f0b/tblib-3.2.2-py3-none-any.whl", hash = "sha256:26bdccf339bcce6a88b2b5432c988b266ebbe63a4e593f6b578b1d2e723d2b76", size = 12893, upload-time = "2025-11-12T12:21:14.407Z" },
 ]
 
+[[package]]
+name = "text-unidecode"
+version = "1.3"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/ab/e2/e9a00f0ccb71718418230718b3d900e71a5d16e701a3dae079a21e9cd8f8/text-unidecode-1.3.tar.gz", hash = "sha256:bad6603bb14d279193107714b288be206cac565dfa49aa5b105294dd5c4aab93", size = 76885, upload-time = "2019-08-30T21:36:45.405Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl", hash = "sha256:1311f10e8b895935241623731c2ba64f4c455287888b18189350b67134a822e8", size = 78154, upload-time = "2019-08-30T21:37:03.543Z" },
+]
+
+[[package]]
+name = "thrift"
+version = "0.16.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "six" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/e4/23/dd951c9883cb49a73b750bdfe91e39d78e8a3f1f7175608634f381a197d5/thrift-0.16.0.tar.gz", hash = "sha256:2b5b6488fcded21f9d312aa23c9ff6a0195d0f6ae26ddbd5ad9e3e25dfc14408", size = 59605, upload-time = "2022-03-31T14:54:06.866Z" }
+
 [[package]]
 name = "tomli"
 version = "2.3.0"
@@ -1827,6 +3437,18 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl", hash = "sha256:f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548", size = 44614, upload-time = "2025-08-25T13:49:24.86Z" },
 ]
 
+[[package]]
+name = "typing-inspection"
+version = "0.4.2"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "typing-extensions" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/55/e3/70399cb7dd41c10ac53367ae42139cf4b1ca5f36bb3dc6c9d33acdb43655/typing_inspection-0.4.2.tar.gz", hash = "sha256:ba561c48a67c5958007083d386c3295464928b01faa735ab8547c5692e87f464", size = 75949, upload-time = "2025-10-01T02:14:41.687Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl", hash = "sha256:4ed1cacbdc298c220f1bd249ed5287caa16f34d44ef4e9c3d0cbad5b521545e7", size = 14611, upload-time = "2025-10-01T02:14:40.154Z" },
+]
+
 [[package]]
 name = "tzdata"
 version = "2025.2"
@@ -1838,11 +3460,11 @@ wheels = [
 
 [[package]]
 name = "urllib3"
-version = "2.5.0"
+version = "1.26.20"
 source = { registry = "https://pypi.org/simple" }
-sdist = { url = "https://files.pythonhosted.org/packages/15/22/9ee70a2574a4f4599c47dd506532914ce044817c7752a79b6a51286319bc/urllib3-2.5.0.tar.gz", hash = "sha256:3fc47733c7e419d4bc3f6b3dc2b4f890bb743906a30d56ba4a5bfa4bbff92760", size = 393185, upload-time = "2025-06-18T14:07:41.644Z" }
+sdist = { url = "https://files.pythonhosted.org/packages/e4/e8/6ff5e6bc22095cfc59b6ea711b687e2b7ed4bdb373f7eeec370a97d7392f/urllib3-1.26.20.tar.gz", hash = "sha256:40c2dc0c681e47eb8f90e7e27bf6ff7df2e677421fd46756da1161c39ca70d32", size = 307380, upload-time = "2024-08-29T15:43:11.37Z" }
 wheels = [
-    { url = "https://files.pythonhosted.org/packages/a7/c2/fe1e52489ae3122415c51f387e221dd0773709bad6c6cdaa599e8a2c5185/urllib3-2.5.0-py3-none-any.whl", hash = "sha256:e6b01673c0fa6a13e374b50871808eb3bf7046c4b125b216f6bf1cc604cff0dc", size = 129795, upload-time = "2025-06-18T14:07:40.39Z" },
+    { url = "https://files.pythonhosted.org/packages/33/cf/8435d5a7159e2a9c83a95896ed596f68cf798005fe107cc655b5c5c14704/urllib3-1.26.20-py2.py3-none-any.whl", hash = "sha256:0ed14ccfbf1c30a9072c7ca157e4319b70d65f623e91e7b32fadb2853431016e", size = 144225, upload-time = "2024-08-29T15:43:08.921Z" },
 ]
 
 [[package]]
